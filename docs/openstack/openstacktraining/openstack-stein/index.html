<!DOCTYPE html>
<html lang="en">

<head>
  <script data-ad-client="ca-pub-1022327295984162" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="Openstack Stain Manual 설치    1. 시스템 및 네트워크 구성   여기서는 Nat 네트워크를 외부, host1 대역을 내부로 사용하여 Openstack을 구축해보도록 하겠습니다.    운영체제 및 네트워크 구성  Hypervisor : Vmware Workstation 15 OS : CentOS7      노드 구성     OS Hostname Network Interface Network Interface2 CPU RAM DISK     CentOS7 controller Nat ( 192.168.10.100 ) HOST1 ( 10.">



<meta name="robots" content="index,follow">
<link rel="canonical" href=/docs/openstack/openstacktraining/openstack-stein/><meta property="og:title" content="Openstack Stain Manual 설치" />
<meta property="og:description" content="Openstack Stain Manual 설치    1. 시스템 및 네트워크 구성   여기서는 Nat 네트워크를 외부, host1 대역을 내부로 사용하여 Openstack을 구축해보도록 하겠습니다.    운영체제 및 네트워크 구성  Hypervisor : Vmware Workstation 15 OS : CentOS7      노드 구성     OS Hostname Network Interface Network Interface2 CPU RAM DISK     CentOS7 controller Nat ( 192.168.10.100 ) HOST1 ( 10." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://mung0001.github.io/docs/openstack/openstacktraining/openstack-stein/" />


<title>뭉게뭉게</title>
<link rel="icon" href="/favicon.png" type="image/x-icon">
<link rel="stylesheet" href="/book.min.63eb88daa545365405ecdbb21033286a325c60a36cfa6d22d21e7c3bc9286941.css" integrity="sha256-Y&#43;uI2qVFNlQF7NuyEDMoajJcYKNs&#43;m0i0h58O8koaUE=">
<script defer src="/en.search.min.0372ef7fcd8ad3e4f68ed49a92eb75b797a22f387dc967b8c2c10e5bf3a5db2b.js" integrity="sha256-A3Lvf82K0&#43;T2jtSakut1t5eiLzh9yWe4wsEOW/Ol2ys="></script>
<!--

-->

   

</head>

<body>
  <div class="background">
  <input type="checkbox" class="hidden" id="menu-control" />
  <main class="container flex" style="max-width:100%;" >
    <aside style="padding: 1.5%; max-width: 90%;" class="book-menu">
      
  
<nav styles="background-color:red; position=none;">
구름이 
<h2 class="book-brand">
  <a href="/"><span>뭉게뭉게</span>
  </a>
</h2>


<div style="padding-top: 0.2cm; font-size: 0.9em; font-weight: bolder;">
  <div style ="padding-bottom: 0.3cm;">
    Name : Jengkeun Lee
  </div>
  <div style ="padding-bottom: 0.3cm;">
    Mail : mung0001@naver.com
  </div>
</div>

<div class="book-search">
  <input type="text" id="book-search-input" placeholder="Search" aria-label="Search" maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>












  

  
  




 
  
    




  
  <ul>
    
      
        

  <li class="book-section-flat" >
    

  
  <a href="/docs/aws/" class="">Amazon Web Services</a>
  


    




  
  <ul>
    
      
        

  <li>
    

  
  <a href="/docs/aws/amazonwebservice/" class="collapsed ">AWS docs</a>
  


    






  </li>


      
    
      
        

  <li>
    

  
  <a href="/docs/aws/awstraining/" class="collapsed ">AWS Training</a>
  


    






  </li>


      
    
      
        

  <li>
    

  
  <a href="/docs/aws/awssaa/" class="collapsed ">AWS SAA 시험정리</a>
  


    






  </li>


      
    
  </ul>
  



  </li>


      
    
      
        

  <li class="book-section-flat" >
    

  
  <span>Microsoft Azure</span>
  


    




  
  <ul>
    
      
        

  <li>
    

  
  <a href="/docs/azure/microsoftazure/" class="collapsed ">Azure docs</a>
  


    






  </li>


      
    
      
        

  <li>
    

  
  <a href="/docs/azure/azuretraining/" class="collapsed ">Azure Training</a>
  


    






  </li>


      
    
  </ul>
  



  </li>


      
    
      
        

  <li class="book-section-flat" >
    

  
  <span>Google Cloud Platform</span>
  


    




  
  <ul>
    
      
        

  <li>
    

  
  <a href="/docs/gcp/googlecloudplatform/" class="collapsed ">GCP docs</a>
  


    






  </li>


      
    
      
        

  <li>
    

  
  <a href="/docs/gcp/gcptraining/" class="collapsed ">GCP Training</a>
  


    






  </li>


      
    
  </ul>
  



  </li>


      
    
      
        

  <li class="book-section-flat" >
    

  
  <span>Naver Cloud Platform</span>
  


    




  
  <ul>
    
      
        

  <li>
    

  
  <a href="/docs/ncp/navercloudplatform/" class="collapsed ">NCP docs</a>
  


    






  </li>


      
    
      
        

  <li>
    

  
  <a href="/docs/ncp/ncptraining/" class="collapsed ">NCP Training</a>
  


    






  </li>


      
    
  </ul>
  



  </li>


      
    
      
        

  <li class="book-section-flat" >
    

  
  <span>OpenStack</span>
  


    




  
  <ul>
    
      
        

  <li>
    

  
  <a href="/docs/openstack/openstack/" class="collapsed ">OpenStack docs</a>
  


    




  
  <ul>
    
      
        <li >

  
  <a href="/docs/openstack/openstack/openstack/" class="">OpenStack 개요</a>
  

</li>
      
    
      
        <li >

  
  <a href="/docs/openstack/openstack/keystone/" class="">Keystone</a>
  

</li>
      
    
      
        <li >

  
  <a href="/docs/openstack/openstack/glance/" class="">Glance</a>
  

</li>
      
    
      
        <li >

  
  <a href="/docs/openstack/openstack/nova/" class="">Nova</a>
  

</li>
      
    
      
        <li >

  
  <a href="/docs/openstack/openstack/neutron/" class="">Neutron</a>
  

</li>
      
    
      
        <li >

  
  <a href="/docs/openstack/openstack/cinder/" class="">Cinder</a>
  

</li>
      
    
      
        <li >

  
  <a href="/docs/openstack/openstack/ceilometer/" class="">Ceilometer</a>
  

</li>
      
    
      
        <li >

  
  <a href="/docs/openstack/openstack/horizon/" class="">Horizon</a>
  

</li>
      
    
      
        <li >

  
  <a href="/docs/openstack/openstack/swift/" class="">Swift</a>
  

</li>
      
    
      
        <li >

  
  <a href="/docs/openstack/openstack/heat/" class="">Heat</a>
  

</li>
      
    
      
        <li >

  
  <a href="/docs/openstack/openstack/trove/" class="">Trove</a>
  

</li>
      
    
      
        <li >

  
  <a href="/docs/openstack/openstack/sahara/" class="">Sahara</a>
  

</li>
      
    
      
        <li >

  
  <a href="/docs/openstack/openstack/ironic/" class="">Ironic</a>
  

</li>
      
    
      
        <li >

  
  <a href="/docs/openstack/openstack/service/" class="">Service</a>
  

</li>
      
    
  </ul>
  



  </li>


      
    
      
        

  <li>
    

  
  <a href="/docs/openstack/openstacktraining/" class="collapsed ">OpenStack Training</a>
  


    




  
  <ul>
    
      
        <li >

  
  <a href="/docs/openstack/openstacktraining/openstack-ussuri-01/" class="">OpenStack Ussuri : Overview</a>
  

</li>
      
    
      
        <li >

  
  <a href="/docs/openstack/openstacktraining/openstack-ussuri-02/" class="">OpenStack Ussuri : 환경설정</a>
  

</li>
      
    
      
        <li >

  
  <a href="/docs/openstack/openstacktraining/openstack-ussuri-03/" class="">OpenStack Ussuri : Keystone</a>
  

</li>
      
    
      
        <li >

  
  <a href="/docs/openstack/openstacktraining/openstack-ussuri-04/" class="">OpenStack Ussuri : Glance</a>
  

</li>
      
    
      
        <li >

  
  <a href="/docs/openstack/openstacktraining/openstack-ussuri-05/" class="">OpenStack Ussuri : Nova</a>
  

</li>
      
    
      
        <li >

  
  <a href="/docs/openstack/openstacktraining/openstack-ussuri-06/" class="">OpenStack Ussuri : Neutron</a>
  

</li>
      
    
      
        <li >

  
  <a href="/docs/openstack/openstacktraining/openstack-ussuri-07/" class="">OpenStack Ussuri : Cinder</a>
  

</li>
      
    
      
        <li >

  
  <a href="/docs/openstack/openstacktraining/openstack-ussuri-08/" class="">OpenStack Ussuri : Horizon</a>
  

</li>
      
    
      
        <li >

  
  <a href="/docs/openstack/openstacktraining/openstack-ussuri-09/" class="">OpenStack Ussuri : Swift</a>
  

</li>
      
    
      
        <li >

  
  <a href="/docs/openstack/openstacktraining/openstack-ussuri-10/" class="">OpenStack Ussuri : Heat</a>
  

</li>
      
    
      
        <li >

  
  <a href="/docs/openstack/openstacktraining/openstack-stein/" class="active">Openstack Stain Manual 설치</a>
  

</li>
      
    
      
        <li >

  
  <a href="/docs/openstack/openstacktraining/openstack-ussuri-11/" class="">OpenStack Ussuri : Gnocch</a>
  

</li>
      
    
      
        <li >

  
  <a href="/docs/openstack/openstacktraining/openstack-ussuri-12/" class="">OpenStack Ussuri : Trove</a>
  

</li>
      
    
      
        <li >

  
  <a href="/docs/openstack/openstacktraining/openstack-ussuri-13/" class="">OpenStack Ussuri : Designate</a>
  

</li>
      
    
      
        <li >

  
  <a href="/docs/openstack/openstacktraining/openstack-ussuri-14/" class="">OpenStack Ussuri : Barbican</a>
  

</li>
      
    
      
        <li >

  
  <a href="/docs/openstack/openstacktraining/openstack-ussuri-15/" class="">OpenStack Ussuri : Rally</a>
  

</li>
      
    
      
        <li >

  
  <a href="/docs/openstack/openstacktraining/openstack-ussuri-16/" class="">OpenStack Ussuri : Manila</a>
  

</li>
      
    
      
        <li >

  
  <a href="/docs/openstack/openstacktraining/devstack/" class="">DevStack</a>
  

</li>
      
    
      
        <li >

  
  <a href="/docs/openstack/openstacktraining/packstack/" class="">Packstack</a>
  

</li>
      
    
  </ul>
  



  </li>


      
    
  </ul>
  



  </li>


      
    
      
        

  <li class="book-section-flat" >
    

  
  <span>Docker</span>
  


    




  
  <ul>
    
      
        

  <li>
    

  
  <a href="/docs/docker/docker/" class="collapsed ">Docker docs</a>
  


    






  </li>


      
    
      
        

  <li>
    

  
  <a href="/docs/docker/dockertraining/" class="collapsed ">Docker Training</a>
  


    






  </li>


      
    
  </ul>
  



  </li>


      
    
      
        

  <li class="book-section-flat" >
    

  
  <span>Infra engineer</span>
  


    




  
  <ul>
    
      
        

  <li>
    

  
  <a href="/docs/infra/infra/" class="collapsed ">Infra engineer</a>
  


    






  </li>


      
    
  </ul>
  



  </li>


      
    
      
        

  <li class="book-section-flat" >
    

  
  <span>Programming</span>
  


    




  
  <ul>
    
      
        

  <li>
    

  
  <a href="/docs/programing/python/" class="collapsed ">Python docs</a>
  


    






  </li>


      
    
      
        

  <li>
    

  
  <a href="/docs/programing/shell/" class="collapsed ">Shell Script</a>
  


    






  </li>


      
    
      
        

  <li>
    

  
  <a href="/docs/programing/golang/" class="collapsed ">Golang</a>
  


    






  </li>


      
    
      
        

  <li>
    

  
  <a href="/docs/programing/web/" class="collapsed ">Web</a>
  


    






  </li>


      
    
      
        

  <li>
    

  
  <a href="/docs/programing/git/" class="collapsed ">Git</a>
  


    






  </li>


      
    
  </ul>
  



  </li>


      
    
      
        

  <li class="book-section-flat" >
    

  
  <span>Network</span>
  


    




  
  <ul>
    
      
        

  <li>
    

  
  <a href="/docs/network/network/" class="collapsed ">Network 기본</a>
  


    






  </li>


      
    
      
        

  <li>
    

  
  <a href="/docs/network/sophos/" class="collapsed ">Sophos</a>
  


    






  </li>


      
    
      
        

  <li>
    

  
  <a href="/docs/network/mail/" class="collapsed ">Mail</a>
  


    






  </li>


      
    
      
        

  <li>
    

  
  <a href="/docs/network/snort/" class="collapsed ">Snort</a>
  


    






  </li>


      
    
      
        

  <li>
    

  
  <a href="/docs/network/nm/" class="collapsed ">Network Master</a>
  


    






  </li>


      
    
  </ul>
  



  </li>


      
    
      
        

  <li class="book-section-flat" >
    

  
  <span>System</span>
  


    




  
  <ul>
    
      
        

  <li>
    

  
  <a href="/docs/system/nas/" class="collapsed ">NAS</a>
  


    






  </li>


      
    
      
        

  <li>
    

  
  <a href="/docs/system/linux/" class="collapsed ">Linux</a>
  


    






  </li>


      
    
      
        

  <li>
    

  
  <a href="/docs/system/window/" class="collapsed ">Windows Servers</a>
  


    






  </li>


      
    
  </ul>
  



  </li>


      
    
      
        

  <li class="book-section-flat" >
    

  
  <span>Database</span>
  


    




  
  <ul>
    
      
        

  <li>
    

  
  <a href="/docs/database/sqld/" class="collapsed ">SQLP&amp; SQLD</a>
  


    






  </li>


      
    
  </ul>
  



  </li>


      
    
      
        

  <li class="book-section-flat" >
    

  
  <a href="/docs/project/" class="">Project</a>
  


    




  
  <ul>
    
  </ul>
  



  </li>


      
    
  </ul>
  



  














  
<ul>
  
  <li>
    <a href="/posts/" >
        Blog
      </a>
  </li>
  
</ul>






<br>
<div>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-1022327295984162"
     data-ad-slot="6213387116"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
</div>

</nav>




  <script>(function(){var menu=document.querySelector("aside.book-menu nav");addEventListener("beforeunload",function(event){localStorage.setItem("menu.scrollTop",menu.scrollTop);});menu.scrollTop=localStorage.getItem("menu.scrollTop");})();</script>


 
    </aside>

    <div style="padding-left: 2.5%;" class="book-page">
      <header class="book-header">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/svg/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <strong>Openstack Stain Manual 설치</strong>

  <label for="toc-control">
    <img src="/svg/toc.svg" class="book-icon" alt="Table of Contents" />
  </label>
</div>


  
    <input type="checkbox" class="hidden" id="toc-control" />
    <aside class="hidden clearfix">
      
  <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#1-시스템-및-네트워크-구성"><strong>1. 시스템 및 네트워크 구성</strong></a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li>
      <ul>
        <li><a href="#2-openstack-기본-패키지-구성"><strong>2. Openstack 기본 패키지 구성</strong></a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li>
      <ul>
        <li><a href="#3-keystone--인증-서비스--구성"><strong>3. Keystone ( 인증 서비스 ) 구성</strong></a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li>
      <ul>
        <li><a href="#4-glance--이미지-서비스--구성"><strong>4. Glance ( 이미지 서비스 ) 구성</strong></a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li>
      <ul>
        <li><a href="#5-nova--컴퓨트-서비스--구성"><strong>5. Nova ( 컴퓨트 서비스 ) 구성</strong></a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li>
      <ul>
        <li><a href="#6-neutron--네트워크-서비스--구성"><strong>6. Neutron ( 네트워크 서비스 ) 구성</strong></a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li>
      <ul>
        <li><a href="#7-horizon--대시보드-서비스--구성"><strong>7. Horizon ( 대시보드 서비스 ) 구성</strong></a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li>
      <ul>
        <li><a href="#8-cinder--오브젝트-스토리지-및-블록-스토리지-구성-"><strong>8. Cinder ( 오브젝트 스토리지 및 블록 스토리지 구성 )</strong></a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li>
      <ul>
        <li><a href="#8-2-lvm으로-블록-스토리지-백엔드-구성"><strong>8-2. LVM으로 블록 스토리지 백엔드 구성</strong></a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li>
      <ul>
        <li><a href="#8-3-lbaas-설치"><strong>8-3. LBaaS 설치</strong></a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li>
      <ul>
        <li><a href="#8-4-lfs-lvm-기반-다중-스토리지-노드-구성"><strong>8-4. LFS, LVM 기반 다중 스토리지 노드 구성</strong></a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li>
      <ul>
        <li><a href="#9-swift--오브젝트-스토리지-서비스--구성"><strong>9. Swift ( 오브젝트 스토리지 서비스 ) 구성</strong></a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li>
      <ul>
        <li><a href="#10-heat--orchestration--설치"><strong>10. Heat ( Orchestration ) 설치</strong></a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li>
      <ul>
        <li><a href="#11-openstack-대시보드-메인-로고-및-링크-변경"><strong>11. Openstack 대시보드 메인 로고 및 링크 변경</strong></a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li>
      <ul>
        <li><a href="#12-neutron-기반-service-functon-chaining--sfc--기능-구성"><strong>12. Neutron 기반 Service Functon Chaining ( SFC ) 기능 구성</strong></a></li>
      </ul>
    </li>
  </ul>
</nav>


    </aside>
  
 
      </header>

      
      
  <article class="markdown"><h1 id="openstack-stain-manual-설치"><strong>Openstack Stain Manual 설치</strong></h1>
<hr>
<p> </p>
<h1 id="heading"></h1>
<h3 id="1-시스템-및-네트워크-구성"><strong>1. 시스템 및 네트워크 구성</strong></h3>
<hr>
<ul>
<li><strong>여기서는 Nat 네트워크를 외부, host1 대역을 내부로 사용하여 Openstack을 구축해보도록 하겠습니다.</strong></li>
</ul>
<h1 id="heading-1"></h1>
<ul>
<li><strong>운영체제 및 네트워크 구성</strong>
<ul>
<li><strong>Hypervisor : Vmware Workstation 15</strong></li>
<li><strong>OS : CentOS7</strong></li>
</ul>
</li>
</ul>
<h1 id="heading-2"></h1>
<ul>
<li><strong>노드 구성</strong></li>
</ul>
<table>
<thead>
<tr>
<th>OS</th>
<th>Hostname</th>
<th>Network Interface</th>
<th>Network Interface2</th>
<th>CPU</th>
<th>RAM</th>
<th>DISK</th>
</tr>
</thead>
<tbody>
<tr>
<td>CentOS7</td>
<td>controller</td>
<td>Nat ( 192.168.10.100 )</td>
<td>HOST1 ( 10.10.10.10 )</td>
<td>2cpu 4thread</td>
<td>8 RAm</td>
<td>30G</td>
</tr>
<tr>
<td>CentOS7</td>
<td>natwork</td>
<td>Nat ( 192.168.10.101 )</td>
<td>HOST1 ( 10.10.10.20 )</td>
<td>1cpu 2thread</td>
<td>2 RAm</td>
<td>20G</td>
</tr>
<tr>
<td>CentOS7</td>
<td>compute</td>
<td>Nat ( 192.168.10.102 )</td>
<td>HOST1 ( 10.10.10.30 )</td>
<td>1cpu 4thread</td>
<td>4 RAm</td>
<td>100G</td>
</tr>
</tbody>
</table>
<h1 id="heading-3"></h1>
<ul>
<li><strong>기본적인 업데이트 및 설정을 모든 노드에 진행합니다.</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ yum -y update
# 업데이트

$ vi /etc/hosts
10.10.10.10 controller
10.10.10.20 network
10.10.10.30 compute
# known host 등록
</code></pre></div><h1 id="heading-4"></h1>
<ul>
<li><strong>설정이 완료되면 기본 구성을 모든 노드에 진행합니다.</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ yum -y install chrony
# 시간 동기화를 위한 chrony 설치

$ vi /etc/chrony.conf

#server 0.centos.pool.ntp.org iburst
#server 1.centos.pool.ntp.org iburst
#server 2.centos.pool.ntp.org iburst
#server 3.centos.pool.ntp.org iburst
server ntp1.jst.mfeed.ad.jp iburst
server ntp2.jst.mfeed.ad.jp iburst
server ntp3.jst.mfeed.ad.jp iburst

allow 10.10.10.0/24
# 시간동기화

$ firewall-cmd --add-service=ntp --permanent
$ firewall-cmd --reload
# ntp 방화벽 허용 및 리로딩

$ init 6
# 시스템 재시작

$ chronyc sources
# 확인
</code></pre></div><h1 id="heading-5"></h1>
<p> </p>
<h1 id="heading-6"></h1>
<h3 id="2-openstack-기본-패키지-구성"><strong>2. Openstack 기본 패키지 구성</strong></h3>
<hr>
<ul>
<li><strong>Openstack의 기본 패키지 구성은 먼저 contorller 노드만을 통해 진행됨을 유의해주시길 바랍니다.</strong></li>
<li><strong>controller 노드에는 다음의 패키지가 설치됩니다.</strong>
<ul>
<li><strong>MariaDB: OpenStack 서비스 및 VM 관련 설정들을 보관하기 위해 사용</strong></li>
<li><strong>RabbitMQ: OpenStack 서비스 간 상호 메시지를 주고 받기 위하나 메시지 큐로 사용</strong></li>
<li><strong>Memcached: 범용 분산 메모리 캐시 시스템으로, 자주 외부 데이터에 접근해야 하는 경우에 발생하는 오버헤드를 줄이기 위해 메모리르르 캐싱하고 읽어들이는 역할을 담당, OpenStack 서비스에서는 주로 인증 메커니즘에서 토큰 캐싱을 위해 사용됩니다.</strong></li>
</ul>
</li>
</ul>
<h1 id="heading-7"></h1>
<ul>
<li><strong>Openstack 패키지 설치 및 레포지토리 구성</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ yum -y install centos-release-openstack-stein
$ sed -i -e &#34;s/enabled=1/enabled=0/g&#34; /etc/yum.repos.d/CentOS-OpenStack-stein.repo
# stein 패캐지를 등록합니다.
</code></pre></div><h1 id="heading-8"></h1>
<ul>
<li><strong>MariaDB를 설치합니다.</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ yum --enablerepo=centos-openstack-stein -y install mariadb-server
$ vi /etc/my.cnf
[mysqld]
character-set-server=utf8
# charset을 utf-8으로 변경합니다

$ systemctl start mariadb
$ systemctl enable mariadb
# mariadb을 시작 및 자동시작을 등록합니다.

$ mysql_secure_installation
# 패스워드 설정을 진행합니다.

$ firewall-cmd --add-service=mysql --permanent
$ firewall-cmd --reload
</code></pre></div><h1 id="heading-9"></h1>
<ul>
<li><strong>RabbitMQ 및 Memcached를 설치합니다.</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ yum --enablerepo=centos-openstack-stein -y install rabbitmq-server
$ yum --enablerepo=centos-openstack-stein -y install memcached

$ vi /etc/my.cnf.d/mariadb-server.cnf
[mysqld]
...
character-set-server=utf8
max_connections=500
# Mariadb의 위에 내용을 추가합니다.

$ vi /etc/sysconfig/memcached
OPTIONS=&#34;-l 0.0.0.0,::&#34;
# mamcached를 모든 리스닝 상태로 전환시킵니다.

$ systemctl restart mariadb rabbitmq-server memcached
$ systemctl enable mariadb rabbitmq-server memcached
# Mariadb와 함께 RabbitMQ 및 Memcached를 시작 및 자동시작을 등록합니다.

$ rabbitmqctl add_user [ id ] [ pw ]
# rabbitmq 유저를 생성합니다. 여기서는 openstack/qwer1234를 사용하도록 하겠습니다.

$ rabbitmqctl set_permissions [ id ] &#34;.*&#34; &#34;.*&#34; &#34;.*&#34;
# 생성한 사용자에게 모든 권한을 부여합니다.

$ firewall-cmd --add-port=<span style="color:#75715e">{</span><span style="color:#ae81ff">11211</span><span style="color:#f92672">/</span><span style="color:#a6e22e">tcp</span><span style="color:#f92672">,</span><span style="color:#ae81ff">5672</span><span style="color:#f92672">/</span><span style="color:#a6e22e">tcp</span><span style="color:#75715e">}</span> --permanent
$ firewall-cmd --reload
</code></pre></div><h1 id="heading-10"></h1>
<p> </p>
<h1 id="heading-11"></h1>
<h3 id="3-keystone--인증-서비스--구성"><strong>3. Keystone ( 인증 서비스 ) 구성</strong></h3>
<hr>
<ul>
<li><strong>Keystone 또한 controller의 설치를 진행합니다.</strong></li>
<li><strong>keystone에 대한 설명은 <a href="https://mung0001.github.io/docs/study/openstack/keystone/">keystone</a>을 참조해주세요.</strong></li>
</ul>
<h1 id="heading-12"></h1>
<ul>
<li><strong>keyston DB 생성</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ mysql -u root -p
MariaDB [(none)]&gt; create database keystone;
MariaDB [(none)]&gt; grant all privileges on keystone.* to keystone@&#39;localhost&#39; identified by &#39;pw&#39;;
MariaDB [(none)]&gt; grant all privileges on keystone.* to keystone@&#39;%&#39; identified by &#39;pw&#39;;
MariaDB [(none)]&gt; flush privileges;
# keystone 구성을 위한 db를 생성합니다. ( 저는 편의를 위해 모든 pw로 qwer1234 설정하였습니다. )
</code></pre></div><h1 id="heading-13"></h1>
<ul>
<li><strong>keystone 패키지 설치 및 수정</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ yum --enablerepo=centos-openstack-stein,epel -y install openstack-keystone openstack-utils python-openstackclient httpd mod_wsgi
# keystone 및 관련 패키지를 설치합니다.

$ vi /etc/keystone/keystone.conf
[cache]
...
memcache_servers = controller:11211

[database]
...
connection = mysql+pymysql://keystone:qwer1234@controller/keystone

[token]
...
provider = fernet
# keystone 구성을 위해 설정파일 수정합니다.
# hosts에 등록한 IP 혹은 controller의 IP를 기입하셔도 무관합니다.

$ su -s /bin/bash keystone -c &#34;keystone-manage db_sync&#34;
# 설정 값을 토대로 db의 설정을 저정합니다.

$ keystone-manage fernet_setup --keystone-user keystone --keystone-group keystone
$ keystone-manage credential_setup --keystone-user keystone --keystone-group keystone
# 토큰 및 자격 증명 암호화를 위해 사용되는 키 저장소를 생성합니다.

$ export controller=10.10.10.10
$ keystone-manage bootstrap --bootstrap-password qwer1234 \
--bootstrap-admin-url http://$controller:5000/v3/ \
--bootstrap-internal-url http://$controller:5000/v3/ \
--bootstrap-public-url http://$controller:5000/v3/ \
--bootstrap-region-id RegionOne
# controlelr의 IP로 keystone을 부트스트랩합니다.

$ setsebool -P httpd_use_openstack on
$ setsebool -P httpd_can_network_connect on
$ setsebool -P httpd_can_network_connect_db on
$ firewall-cmd --add-port=5000/tcp --permanent
$ firewall-cmd --reload
# Selinux와 방화벽으르 설정합니다.

$ ln -s /usr/share/keystone/wsgi-keystone.conf /etc/httpd/conf.d/
$ systemctl start httpd
$ systemctl enable httpd
# keystone 설정 활성화 및 httpd 를 시작합니다.
</code></pre></div><h1 id="heading-14"></h1>
<ul>
<li><strong>정상 동작 확인을 위한 토큰 파일 생성</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ vi ~/admin
export OS_PROJECT_DOMAIN_NAME=default
export OS_USER_DOMAIN_NAME=default
export OS_PROJECT_NAME=admin
export OS_USERNAME=admin
export OS_PASSWORD=qwer1234
export OS_AUTH_URL=http://controller:5000/v3
export OS_IDENTITY_API_VERSION=3
export OS_IMAGE_API_VERSION=2

$ chmod 600 ~/admin
$ source ~/admin
</code></pre></div><h1 id="heading-15"></h1>
<ul>
<li><strong>project 생성</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ cd ~
$ . admin

$ openstack project create --domain default --description &#34;Service Project&#34; service
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | Service Project                  |
| domain_id   | default                          |
| enabled     | True                             |
| id          | 3f0b3ef5b8c94a0a9cca8e34ea2fdbd6 |
| is_domain   | False                            |
| name        | service                          |
| parent_id   | default                          |
| tags        | []                               |
+-------------+----------------------------------+
# project 생성

$ openstack project list
+----------------------------------+---------+
| ID                               | Name    |
+----------------------------------+---------+
| 3f0b3ef5b8c94a0a9cca8e34ea2fdbd6 | service |
| ec1a4336cfa64d04bbc8f908b26a6cda | admin   |
+----------------------------------+---------+
</code></pre></div><h1 id="heading-16"></h1>
<ul>
<li><strong>이것으로 keystone에 대한 설치가 끝났습니다.</strong></li>
<li><strong>혹시 오류가 발생할 경우 /var/log/keystone/ 혹은 /var/log/httpd/에서 error 로그, keystone 로그를 검색하여 오류를 찾아내시면 보다 쉽게 문제를 해결하실 수 있습니다.</strong></li>
</ul>
<h1 id="heading-17"></h1>
<p> </p>
<h1 id="heading-18"></h1>
<h3 id="4-glance--이미지-서비스--구성"><strong>4. Glance ( 이미지 서비스 ) 구성</strong></h3>
<hr>
<ul>
<li><strong>Glance 또한 controller에서만 설치를 진행합니다.</strong></li>
<li><strong>에 대한 설명은 <a href="https://mung0001.github.io/docs/study/openstack/glance/">Glance</a>을 참조해주세요.</strong></li>
</ul>
<h1 id="heading-19"></h1>
<ul>
<li><strong>glance 사용자 추가</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ source ~/admin
# 전에 생성했던 토큰 값을 적용합니다.

$ openstack user create --domain default --project service --password qwer1234 glance
# glance 게정을 추가합니다.

$ openstack role add --project service --user glance admin
# glance에 admin의 권한을 부여합니다.

$ openstack service create --name glance --description &#34;OpenStack Image service&#34; image
# glance 서비스 엔트리를 생성합니다.

$ export controller=10.10.10.10
$ openstack endpoint create --region RegionOne image public http://$controller:9292
$ openstack endpoint create --region RegionOne image internal http://$controller:9292
$ openstack endpoint create --region RegionOne image admin http://$controller:9292
# glance 서비스의 endpoint를 추가합니다 ( public, internal, admin )

$ openstack user list
+----------------------------------+--------+
| ID                               | Name   |
+----------------------------------+--------+
| bd36365f2459468a9c480cb48bab3ac0 | glance |
| e19db9d5ec2c4c30b7a85d18b8b0e589 | admin  |
+----------------------------------+--------+

$ openstack endpoint list
+----------------------------------+-----------+--------------+--------------+---------+-----------+-----------------------------+
| ID                               | Region    | Service Name | Service Type | Enabled | Interface | URL                         |
+----------------------------------+-----------+--------------+--------------+---------+-----------+-----------------------------+
| 00b38774cef048ee9950eda6938accc3 | RegionOne | keystone     | identity     | True    | public    | http://10.10.10.10:5000/v3/ |
| 4591b06391374fe888380fa23b8f5121 | RegionOne | glance       | image        | True    | admin     | http://10.10.10.10:9292                |
| 53dd31fecf2d44949c141149a13c673b | RegionOne | keystone     | identity     | True    | admin     | http://10.10.10.10:5000/v3/ |
| 555f3d900f7e416bb783120f7ce74fe8 | RegionOne | glance       | image        | True    | internal  | http://10.10.10.10:9292                |
| 5b3ac620bb7d4d9aabdf0f33229ee346 | RegionOne | glance       | image        | True    | public    | http://10.10.10.10:9292                |
| bdd7df7c8cba46f6ada2c12155a9f1d6 | RegionOne | keystone     | identity     | True    | internal  | http://10.10.10.10:5000/v3/ |
+----------------------------------+-----------+--------------+--------------+---------+-----------+-----------------------------+

</code></pre></div><ul>
<li><strong>Glance DB 생성</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ mysql -u root -p
MariaDB [(none)]&gt; create database glance;
MariaDB [(none)]&gt; grant all privileges on glance.* to glance@&#39;localhost&#39; identified by &#39;pw&#39;;
MariaDB [(none)]&gt; grant all privileges on glance.* to glance@&#39;%&#39; identified by &#39;pw&#39;;
MariaDB [(none)]&gt; flush privileges;
#  구성을 위한 db를 생성합니다. ( 저는 편의를 위해 모든 pw로 qwer1234 설정하였습니다. )
</code></pre></div><h1 id="heading-20"></h1>
<ul>
<li><strong>glance 패키지 설치 및 수정</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ yum --enablerepo=centos-openstack-stein,epel -y install openstack-glance
# glance 패키지를 설치합니다.

$ vi /etc/glance/glance-api.conf
[DEFAULT]
bind_host = 0.0.0.0

[glance_store]
stores = file,http
default_store = file
filesystem_store_datadir = /var/lib/glance/images/ # 이미지 경로 지정

[database]  # database 연동
connection = mysql+pymysql://glance:qwer1234@controller/glance

[keystone_authtoken]  # keystone 인증
www_authenticate_uri = http://controller:5000
auth_url = http://controller:5000
memcached_servers = controller:11211
auth_type = password
project_domain_name = default
user_domain_name = default
project_name = service
username = glance
password = qwer1234

[paste_deploy]
flavor = keystone
# glance.conf를 수정합니다.

$ su -s /bin/bash glance -c &#34;glance-manage db_sync&#34;
# glance db를 동기화 시킵니다.

$ systemctl start openstack-glance-api
$ systemctl enable openstack-glance-api
# glance를 시작 및 실행시 자동시작을 등록합니다.

$ setsebool -P glance_api_can_network on
$ firewall-cmd --add-port=9292/tcp --permanent
$ firewall-cmd --reload
# Selinux 및 firewall을 설정합니다.
</code></pre></div><h1 id="heading-21"></h1>
<ul>
<li><strong>확인을 위한 이미지 생성</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ wget http://download.cirros-cloud.net/0.5.1/cirros-0.5.1-x86_64-disk.img
# 확인을 위해 cirros 이미지를 다운 받습니다.

$ openstack image create &#34;Cirros&#34; --file cirros-0.5.1-x86_64-disk.img --disk-format qcow2
# image 등록

$ openstack image list
+--------------------------------------+--------+--------+
| ID                                   | Name   | Status |
+--------------------------------------+--------+--------+
| 38e15009-022b-49ce-bcdf-b220eb3c5b12 | Cirros | active |
+--------------------------------------+--------+--------+
# 확인
</code></pre></div><h1 id="heading-22"></h1>
<p> </p>
<h1 id="heading-23"></h1>
<h3 id="5-nova--컴퓨트-서비스--구성"><strong>5. Nova ( 컴퓨트 서비스 ) 구성</strong></h3>
<hr>
<ul>
<li><strong>Nova 서비스는 controller 노드와 compute노드에 구성됩니다.</strong></li>
<li><strong>설치는 contoller &gt; compute 순으로 진행하도록 하겠습니다.</strong></li>
<li><strong>Nova에 대한 설명은 <a href="https://mung0001.github.io/docs/study/openstack/nova/">Nova</a>을 참조해주세요.</strong></li>
</ul>
<h1 id="heading-24"></h1>
<ul>
<li><strong>Nova, Placement 추가 및 등록</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ source ~/admin
$ openstack user create --domain default --project service --password qwer1234 nova
$ openstack role add --project service --user nova admin
$ openstack user create --domain default --project service --password qwer1234 placement
$ openstack role add --project service --user placement admin
# nova 유저와 placement유저를 생성합니다.

$ openstack service create --name nova --description &#34;OpenStack Compute Service&#34; compute
# nova 서버 엔트리 저장

$ openstack service create --name placement --description &#34;OpenStack Compute Placement Service&#34; placement
# placement 서버 엔트리 저장

$ openstack user list
# 확인
+----------------------------------+-----------+
| ID                               | Name      |
+----------------------------------+-----------+
| 18bdf3e68a754aa182f93196a918ba65 | nova      |
| 18ff8b52493a408d9933596ed20cca9c | glance    |
| bfd0cf6d358e49bf88f183a463c689a2 | placement |
| e19db9d5ec2c4c30b7a85d18b8b0e589 | admin     |
+----------------------------------+-----------+


$ export controller=10.10.10.10
$ openstack endpoint create --region RegionOne compute public http://$controller:8774/v2.1/%\(tenant_id\)s
$ openstack endpoint create --region RegionOne compute internal http://$controller:8774/v2.1/%\(tenant_id\)s
$ openstack endpoint create --region RegionOne compute admin http://$controller:8774/v2.1/%\(tenant_id\)s
# nova 서비스의 endpoint를 추가합니다

$ openstack endpoint create --region RegionOne placement public http://$controller:8778
$ openstack endpoint create --region RegionOne placement internal http://$controller:8778
$ openstack endpoint create --region RegionOne placement admin http://$controller:8778
$ placement의 endpoint를 추가합니다.

$ openstack endpoint list
# 확인
-------+-----------+--------------------------------------------+
| ID                               | Region    | Service Name | Service Type | Enabled | Interface | URL                                        |
+----------------------------------+-----------+--------------+--------------+---------+-----------+--------------------------------------------+
| 00b38774cef048ee9950eda6938accc3 | RegionOne | keystone     | identity     | True    | public    | http://10.10.10.10:5000/v3/                |
| 04ca5fb6701348089777d68a68ca7cd2 | RegionOne | placement    | placement    | True    | public    | http://10.10.10.10:8778                    |
| 53ad55ce8897463b86ea616a8ba64d95 | RegionOne | glance       | image        | True    | public    | http://10.10.10.10:9292                    |
| 53dd31fecf2d44949c141149a13c673b | RegionOne | keystone     | identity     | True    | admin     | http://10.10.10.10:5000/v3/                |
| 595a2045543b42c2bb6f23e2dd30a3bb | RegionOne | glance       | image        | True    | internal  | http://10.10.10.10:9292                    |
| 6820b49138d54b63ac34cd52f1be08f6 | RegionOne | placement    | placement    | True    | internal  | http://10.10.10.10:8778                    |
| 6ad740445fca4a0fb684d913909fe129 | RegionOne | nova         | compute      | True    | admin     | http://10.10.10.10:8774/v2.1/%(tenant_id)s |
| 9863826e093943cf97a05dfc6e3c159a | RegionOne | nova         | compute      | True    | internal  | http://10.10.10.10:8774/v2.1/%(tenant_id)s |
| b9f9701a57ec40e487ce493a63903cae | RegionOne | placement    | placement    | True    | admin     | http://10.10.10.10:8778                    |
| bd787b85b3124f0ab15854998624cb19 | RegionOne | nova         | compute      | True    | public    | http://10.10.10.10:8774/v2.1/%(tenant_id)s |
| bdd7df7c8cba46f6ada2c12155a9f1d6 | RegionOne | keystone     | identity     | True    | internal  | http://10.10.10.10:5000/v3/                |
| d394eaf13ac840b3b2e69e074c2c1c20 | RegionOne | glance       | image        | True    | admin     | http://10.10.10.10:9292                    |
+----------------------------------+-----------+--------------+--------------+---------+-----------+--------------------------------------------+

</code></pre></div><h1 id="heading-25"></h1>
<ul>
<li><strong>Nova DB 생성</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ mysql -u root -p
MariaDB [(none)]&gt; create database nova;
MariaDB [(none)]&gt; grant all privileges on nova.* to nova@&#39;localhost&#39; identified by &#39;pw&#39;;
MariaDB [(none)]&gt; grant all privileges on nova.* to nova@&#39;%&#39; identified by &#39;pw&#39;;

MariaDB [(none)]&gt; create database nova_api;
MariaDB [(none)]&gt; grant all privileges on nova_api.* to nova@&#39;localhost&#39; identified by &#39;pw&#39;;
MariaDB [(none)]&gt; grant all privileges on nova_api.* to nova@&#39;%&#39; identified by &#39;pw&#39;;

MariaDB [(none)]&gt; create database nova_placement;
MariaDB [(none)]&gt; grant all privileges on nova_placement.* to nova@&#39;localhost&#39; identified by &#39;pw&#39;;
MariaDB [(none)]&gt; grant all privileges on nova_placement.* to nova@&#39;%&#39; identified by &#39;pw&#39;;

MariaDB [(none)]&gt; create database nova_cell0;
MariaDB [(none)]&gt; grant all privileges on nova_cell0.* to nova@&#39;localhost&#39; identified by &#39;pw&#39;;
MariaDB [(none)]&gt; grant all privileges on nova_cell0.* to nova@&#39;%&#39; identified by &#39;pw&#39;;
MariaDB [(none)]&gt; flush privileges;
#  nova 구성을 위한 db를 생성합니다. ( 저는 편의를 위해 모든 pw로 qwer1234 설정하였습니다. )
</code></pre></div><h1 id="heading-26"></h1>
<ul>
<li><strong>nova 서비스를 설치 및 수정합니다.</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ yum --enablerepo=centos-openstack-stein,epel -y install openstack-nova
# nova 패키지를 설치합니다.

$ vi /etc/nova/nova.conf
[DEFAULT]
my_ip = 10.10.10.10
state_path = /var/lib/nova
enabled_apis = osapi_compute,metadata
log_dir = /var/log/nova

[api]
auth_strategy = keystone

[glance]
api_servers = http://controller:9292

[oslo_concurrency]
lock_path = $state_path/tmp

[api_database]
connection = mysql+pymysql://nova:qwer1234@controller/nova_api

[database]
connection = mysql+pymysql://nova:qwer1234@controller/nova

[keystone_authtoken]
www_authenticate_uri = http://controller:5000
auth_url = http://controller:5000
memcached_servers = controller:11211
auth_type = password
project_domain_name = default
user_domain_name = default
project_name = service
username = nova
password = qwer1234

[placement]
auth_url = http://controller:5000
os_region_name = RegionOne
auth_type = password
project_domain_name = default
user_domain_name = default
project_name = service
username = placement
password = qwer1234

[placement_database]
connection = mysql+pymysql://nova:qwer1234@controller/nova_placement

[wsgi]
api_paste_config = /etc/nova/api-paste.ini
# nova의 설정 파일을 수정합니다.
</code></pre></div><h1 id="heading-27"></h1>
<ul>
<li><strong>Selinux 및 firewalld을 설정합니다.</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ yum --enablerepo=centos-openstack-stein -y install openstack-selinux
$ semanage port -a -t http_port_t -p tcp 8778
$ firewall-cmd --add-port=<span style="color:#75715e">{</span><span style="color:#ae81ff">6080</span><span style="color:#f92672">/</span><span style="color:#a6e22e">tcp</span><span style="color:#f92672">,</span><span style="color:#ae81ff">6081</span><span style="color:#f92672">/</span><span style="color:#a6e22e">tcp</span><span style="color:#f92672">,</span><span style="color:#ae81ff">6082</span><span style="color:#f92672">/</span><span style="color:#a6e22e">tcp</span><span style="color:#f92672">,</span><span style="color:#ae81ff">8774</span><span style="color:#f92672">/</span><span style="color:#a6e22e">tcp</span><span style="color:#f92672">,</span><span style="color:#ae81ff">8775</span><span style="color:#f92672">/</span><span style="color:#a6e22e">tcp</span><span style="color:#f92672">,</span><span style="color:#ae81ff">8778</span><span style="color:#f92672">/</span><span style="color:#a6e22e">tcp</span><span style="color:#75715e">}</span> --permanent
$ firewall-cmd --reload
</code></pre></div><h1 id="heading-28"></h1>
<ul>
<li><strong>nova 서비스를 DB에 저장합니다.</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ su -s /bin/bash nova -c &#34;nova-manage api_db sync&#34;
$ su -s /bin/bash nova -c &#34;nova-manage cell_v2 map_cell0&#34;
$ su -s /bin/bash nova -c &#34;nova-manage db sync&#34;
$ su -s /bin/bash nova -c &#34;nova-manage cell_v2 create_cell --name cell1&#34;
</code></pre></div><h1 id="heading-29"></h1>
<ul>
<li><strong>nova 서비스를 시작 및 자동시작을 설정합니다.</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ systemctl restart httpd
$ chown nova. /var/log/nova/nova-placement-api.log
$ for service in api consoleauth conductor scheduler novncproxy; do
systemctl start openstack-nova-$service
systemctl enable openstack-nova-$service
done
</code></pre></div><ul>
<li><strong>이상으로 controller 노드에서의 구성을 마치겠습니다.</strong></li>
<li><strong>하단부터의 패키지 설치는 compute노드에서 진행해주세요</strong></li>
</ul>
<h1 id="heading-30"></h1>
<p> </p>
<h1 id="heading-31"></h1>
<ul>
<li><strong>Stein 레포지터리를 활성화합니다.</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ yum -y install centos-release-openstack-stein
$ sed -i -e &#34;s/enabled=1/enabled=0/g&#34; /etc/yum.repos.d/CentOS-OpenStack-stein.repo
# stein 패캐지를 등록합니다.
</code></pre></div><h1 id="heading-32"></h1>
<ul>
<li><strong>KVM 하이퍼바이저를 구성합니다.</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ yum -y install qemu-kvm libvirt virt-install bridge-utils
# KVM 구성에 필요한 가상화 및 네트워크 도구들을 설치합니다.

$ lsmod | grep kvm
# 확인

$ systemctl start libvirtd
$ systenctk ebable libvirtd
</code></pre></div><h1 id="heading-33"></h1>
<ul>
<li><strong>compute 노드에 nova 서비스를 설치 및 수정합니다.</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ yum --enablerepo=centos-openstack-stein,epel -y install openstack-nova
# nova 패키지를 설치합니다.

$ vi /etc/nova/nova.conf
[DEFAULT]
my_ip = 10.10.10.30
state_path = /var/lib/nova
enabled_apis = osapi_compute,metadata
log_dir = /var/log/nova

transport_url = rabbit://openstack:qwer1234@controller

[api]
auth_strategy = keystone

[vnc]
enabled = True
server_listen = 0.0.0.0
server_proxyclient_address = 192.168.10.102
novncproxy_base_url = http://192.168.10.102/vnc_auto.html
# vnc 화면으르 활성화 합니다. 추후 오픈스택 대시보드 혹은 vnc 클라이언트 프로그램으로 접속할 때 사용합니다.

[glance]
api_servers = http://controller:9292

[oslo_concurrency]
lock_path = $state_path/tmp

[keystone_authtoken]
www_authenticate_uri = http://controller:5000
auth_url = http://controller:5000
memcached_servers = controller:11211
auth_type = password
project_domain_name = default
user_domain_name = default
project_name = service
username = nova
password = qwer1234

[placement]
auth_url = http://controller:5000
os_region_name = RegionOne
auth_type = password
project_domain_name = default
user_domain_name = default
project_name = service
username = placement
password = qwer1234

[wsgi]
api_paste_config = /etc/nova/api-paste.ini
# nova의 설정 파일을 수정합니다.
</code></pre></div><h1 id="heading-34"></h1>
<ul>
<li><strong>Selinux 및 firewall 설정</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ yum --enablerepo=centos-openstack-stein -y install openstack-selinux
$ firewall-cmd --add-port=5900-5999/tcp --permanent
$ firewall-cmd --reload
</code></pre></div><h1 id="heading-35"></h1>
<ul>
<li><strong>nova 서비스 시작</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ systemctl start openstack-nova-compute
$ systemctl enable openstack-nova-compute

&amp; controller# openstack compute service list
# 확인
+----+------------------+------------+----------+---------+-------+----------------------------+
| ID | Binary           | Host       | Zone     | Status  | State | Updated At                 |
+----+------------------+------------+----------+---------+-------+----------------------------+
|  4 | nova-consoleauth | controller | internal | enabled | up    | 2020-07-19T02:47:16.000000 |
|  5 | nova-conductor   | controller | internal | enabled | up    | 2020-07-19T02:47:12.000000 |
|  8 | nova-scheduler   | controller | internal | enabled | up    | 2020-07-19T02:47:12.000000 |
|  9 | nova-compute     | compute    | nova     | enabled | up    | 2020-07-19T02:47:08.000000 |
+----+------------------+------------+----------+---------+-------+----------------------------+
</code></pre></div><h1 id="heading-36"></h1>
<p> </p>
<h1 id="heading-37"></h1>
<h3 id="6-neutron--네트워크-서비스--구성"><strong>6. Neutron ( 네트워크 서비스 ) 구성</strong></h3>
<hr>
<ul>
<li><strong>Neutron 서비스르르 구성하는 과정에서는 모든 노드에 설치가 진행됩니다.</strong></li>
<li><strong>기본적으로 openvswithch를 중심으로 진행하며, 경우에 따라서는 linuxbridge로 서비스를 대체하는 것이 가능합니다.</strong></li>
<li><strong>설치 과정은 controller, compute, network 노드 순으로 진행하겠습니다.</strong></li>
<li><strong>Neutron에 대한 설명은 <a href="https://mung0001.github.io/docs/study/openstack/neutron/">Neutron</a>을 참조해주세요.</strong></li>
</ul>
<h1 id="heading-38"></h1>
<ul>
<li><strong>Neutron 사용자 추가</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ openstack user create --domain default --project service --password qwer1234 neutron
$ openstack role add --project service --user neutron admin
$ openstack service create --name neutron --description &#34;OpenStack Networking service&#34; network
# Netutron 사용자를 추가 및 서비스를 등록합니다.

$ export controller=10.10.10.10
$ openstack endpoint create --region RegionOne network public http://$controller:9696
$ openstack endpoint create --region RegionOne network internal http://$controller:9696
$ openstack endpoint create --region RegionOne network admin http://$controller:9696
# neutron의 endpoint를 생성합니다.
</code></pre></div><h1 id="heading-39"></h1>
<ul>
<li><strong>Neutron DB 생성</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ mysql -u root -p
MariaDB [(none)]&gt; create database neutron_ml2;
MariaDB [(none)]&gt; grant all privileges on neutron_ml2.* to neutron@&#39;localhost&#39; identified by &#39;pw&#39;;
MariaDB [(none)]&gt; grant all privileges on neutron_ml2.* to neutron@&#39;%&#39; identified by &#39;pw&#39;;
MariaDB [(none)]&gt; flush privileges;
#  neutron 구성을 위한 db를 생성합니다. ( 저는 편의를 위해 모든 pw로 qwer1234 설정하였습니다. )
</code></pre></div><h1 id="heading-40"></h1>
<ul>
<li><strong>Neutron 설치 및 설정</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ yum --enablerepo=centos-openstack-stein,epel -y install openstack-neutron openstack-neutron-ml2
# neutron 패키지 설치

$ vi /etc/neutron/neutron.conf
[DEFAULT]
core_plugin = ml2
service_plugins = router
auth_strategy = keystone
stae_path = /var/lib/neutron
dhcp_agent_notification = True
allow_overlapping_ips = True
notify_nova_on_port_status_changes = True
notify_nova_on_port_data_changes = True

transport_url = rabbit://openstack:qwer1234@controller

[keystone_authtoken]
www_authenticate_uri = http://controller:5000
auth_url = http://controller:5000
memcached_servers = controller:11211
auth_type = password
project_domain_name = default
user_domain_name = default
project_name = service
username = neutron
password = qwer1234

[database]
connection = mysql+pymysql://neutron:qwer1234@controller/neutron_ml2

[nova]
auth_url = http://controller:5000
auth_type = password
project_domain_name = default
user_domain_name = default
region_name = RegionOne
project_name = service
username = nova
password = qwer1234

[oslo_concurrency]
lock_path = $state_path/tmp

$ vi /etc/neutron/metadata_agent.ini
[DEFAULT]
nova_metadata_host = controller
metadata_proxy_shared_secret = metadata_secret
memcache_servers = controller:11211
# metadata_agent.ini 파일을 수정합니다.

$ vi /etc/neutron/plugins/ml2/ml2_conf.ini
[ml2]
type_drivers = flat,vlan,gre,vxlan
tenant_network_types =
mechanism_drivers = openvswitch
extension_drivers = port_security
# ml2_conf.ini 파일에 설정을 수정합니다.
</code></pre></div><h1 id="heading-41"></h1>
<ul>
<li><strong>이어 nova.conf 파일에 설정을 추가합니다.</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ vi /etc/nova/nova.conf
[DEFAULT]
...
use_neutron = True
linuxnet_interface_driver = nova.network.linux_net.LinuxOVSInterfaceDriver
firewall_driver = nova.virt.firewall.NoopFirewallDriver

[neutron]
auth_url = http://controller:5000
auth_type = password
project_domain_name = default
user_domain_name = default
region_name = RegionOne
project_name = service
username = neutron
password = qwer1234
service_metadata_proxy = True
metadata_proxy_shared_secret = metadata_secret
</code></pre></div><h1 id="heading-42"></h1>
<ul>
<li><strong>Selinux 및 방화벽 설정</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ yum --enablerepo=centos-openstack-stein -y install openstack-selinux
$ setsebool -P neutron_can_network on
$ setsebool -P daemons_enable_cluster_mode on
$ firewall-cmd --add-port=9696/tcp --permanent
$ firewall-cmd --reload
# Selinux 및 방화벽을 설정합니다.
</code></pre></div><h1 id="heading-43"></h1>
<ul>
<li><strong>Neutron DB를 생성 및 서비스를 시작합니다.</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ ln -s /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugin.ini
$ su -s /bin/bash neutron -c &#34;neutron-db-manage --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugin.ini upgrade head&#34;
# Neutron DB를 생성합니다.

$ systemctl start neutron-server neutron-metadata-agent
$ systemctl enable neutron-server neutron-metadata-agent
$ systemctl restart openstack-nova-api
</code></pre></div><h1 id="heading-44"></h1>
<p> </p>
<h1 id="heading-45"></h1>
<ul>
<li><strong>이제 다음으로는 network 노드에 구현해보도록 하겠습니다.</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ yum -y install centos-release-openstack-stein
$ sed -i -e &#34;s/enabled=1/enabled=0/g&#34; /etc/yum.repos.d/CentOS-OpenStack-stein.repo
# stein 패캐지를 등록합니다.

$ yum --enablerepo=centos-openstack-stein,epel -y install openstack-neutron openstack-neutron-ml2 openstack-neutron-openvswitch libibverbs
# neutron 패키지를 설치합니다.
</code></pre></div><h1 id="heading-46"></h1>
<ul>
<li><strong>neutron 설정합니다.</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ vi /etc/neutron/neutron.conf
[DEFAULT]
core_plugin = ml2
service_plugins = router
auth_strategy = keystone
stae_path = /var/lib/neutron
allow_overlapping_ips = True

transport_url = rabbit://openstack:qwer1234@controller

[keystone_authtoken]
www_authenticate_uri = http://controller:5000
auth_url = http://controller:5000
memcached_servers = controller:11211
auth_type = password
project_domain_name = default
user_domain_name = default
project_name = service
username = neutron
password = qwer1234

[oslo_concurrency]
lock_path = $state_path/tmp

$ vi /etc/neutron/l3_agent.ini
[DEFAULT]
...
interface_driver = openvswitch
# l3_agent.ini 파일을 수정합니다.

$ vi /etc/neutron/dhcp_agent.ini
[DEFAULT]
...
interface_driver = openvswitch
dhcp_driver = neutron.agent.linux.dhcp.Dnsmasq
enable_isolated_metadata = true
# dhcp_agent.ini 파일을 수정합니다.

$ vi /etc/neutron/metadata_agent.ini
[DEFAULT]
nova_metadata_host = controller
metadata_proxy_shared_secret = metadata_secret
# metadata_agent.ini 파일을 수정합니다.

$ vi /etc/neutron/plugins/ml2/ml2_conf.ini
[ml2]
type_drivers = flat,vlan,gre,vxlan
tenant_network_types =
mechanism_drivers = openvswitch
extension_drivers = port_security
# ml2_conf.ini 파일에 설정을 수정합니다.

$ vi /etc/neutron/plugins/ml2/openvswitch_agent.ini
[securitygroup]
firewall_driver = openvswitch
enable_security_group = true
enable_ipset = true
# openvswitch_agent.ini 파일의 하단에 추가합니다.
</code></pre></div><h1 id="heading-47"></h1>
<ul>
<li><strong>Selinux 및 방화벽 설정</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ yum --enablerepo=centos-openstack-stein -y install openstack-selinux
$ setsebool -P neutron_can_network on
$ setsebool -P haproxy_connect_any on
$ setsebool -P daemons_enable_cluster_mode on

$ vi my-ovsofctl.te
# create new
module my-ovsofctl 1.0;

require <span style="color:#75715e">{</span>
        <span style="color:#a6e22e">type</span> <span style="color:#a6e22e">neutron_t</span><span style="color:#f92672">;</span>
        <span style="color:#a6e22e">class</span> <span style="color:#a6e22e">capability</span> <span style="color:#a6e22e">sys_rawio</span><span style="color:#f92672">;</span>
<span style="color:#75715e">}</span>

#============= neutron_t ==============
allow neutron_t self:capability sys_rawio;

$ checkmodule -m -M -o my-ovsofctl.mod my-ovsofctl.te 
$ semodule_package --outfile my-ovsofctl.pp --module my-ovsofctl.mod 
$ semodule -i my-ovsofctl.pp 
# Selinux 및 방화벽을 추가설정합니다.
</code></pre></div><h1 id="heading-48"></h1>
<ul>
<li><strong>시스템을 재시작 합니다.</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ ln -s /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugin.ini
$ systemctl start openvswitch
$ systemctl enable openvswitch
$ ovs-vsctl add-br br-int
$ systemctl restart openstack-nova-compute
$ systemctl start neutron-openvswitch-agent
$ systemctl enable neutron-openvswitch-agent
</code></pre></div><h1 id="heading-49"></h1>
<ul>
<li><strong>이어서 compute 노드에서의 설정을 진행하겠습니다.</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ yum --enablerepo=centos-openstack-stein,epel -y install openstack-neutron openstack-neutron-ml2 openstack-neutron-openvswitch
# neutron 패키지를 설치합니다.
</code></pre></div><h1 id="heading-50"></h1>
<ul>
<li><strong>neutron 설정합니다.</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ vi /etc/neutron/neutron.conf
[DEFAULT]
core_plugin = ml2
service_plugins = router
auth_strategy = keystone
stae_path = /var/lib/neutron
allow_overlapping_ips = True

transport_url = rabbit://openstack:qwer1234@controller

[keystone_authtoken]
www_authenticate_uri = http://controller:5000
auth_url = http://controller:5000
memcached_servers = controller:11211
auth_type = password
project_domain_name = default
user_domain_name = default
project_name = service
username = neutron
password = qwer1234

[oslo_concurrency]
lock_path = $state_path/tmp

$ vi /etc/neutron/plugins/ml2/ml2_conf.ini
[ml2]
type_drivers = flat,vlan,gre,vxlan
tenant_network_types =
mechanism_drivers = openvswitch
extension_drivers = port_security
# ml2_conf.ini 파일에 설정을 수정합니다.

$ vi /etc/neutron/plugins/ml2/openvswitch_agent.ini
[securitygroup]
firewall_driver = openvswitch
enable_security_group = true
enable_ipset = true
# openvswitch_agent.ini 파일의 하단에 추가합니다.
</code></pre></div><h1 id="heading-51"></h1>
<ul>
<li><strong>이어서 Nova.conf 파일을 수정합니다.</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ vi /etc/nova/nova.conf
[DEFAULT]
...
use_neutron = True
linuxnet_interface_driver = nova.network.linux_net.LinuxOVSInterfaceDriver
firewall_driver = nova.virt.firewall.NoopFirewallDriver
vif_plugging_is_fatal = True
vif_plugging_timeout = 300

[neutron]
auth_url = http://controller:5000
auth_type = password
project_domain_name = default
user_domain_name = default
region_name = RegionOne
project_name = service
username = neutron
password = qwer1234
service_metadata_proxy = True
metadata_proxy_shared_secret = metadata_secret
</code></pre></div><h1 id="heading-52"></h1>
<ul>
<li><strong>Selinux 및 방화벽 설정</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ yum --enablerepo=centos-openstack-stein -y install openstack-selinux
$ setsebool -P neutron_can_network on
$ setsebool -P haproxy_connect_any on
$ setsebool -P daemons_enable_cluster_mode on
$ vi my-ovsofctl.te
# create new
module my-ovsofctl 1.0;

require <span style="color:#75715e">{</span>
        <span style="color:#a6e22e">type</span> <span style="color:#a6e22e">neutron_t</span><span style="color:#f92672">;</span>
        <span style="color:#a6e22e">class</span> <span style="color:#a6e22e">capability</span> <span style="color:#a6e22e">sys_rawio</span><span style="color:#f92672">;</span>
<span style="color:#75715e">}</span>

#============= neutron_t ==============
allow neutron_t self:capability sys_rawio;

$ checkmodule -m -M -o my-ovsofctl.mod my-ovsofctl.te 
$ semodule_package --outfile my-ovsofctl.pp --module my-ovsofctl.mod 
$ semodule -i my-ovsofctl.pp 
# Selinux 및 방화벽을 추가설정합니다.
</code></pre></div><h1 id="heading-53"></h1>
<ul>
<li><strong>시스템을 재시작 합니다.</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ ln -s /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugin.ini
$ systemctl start openvswitch
$ systemctl enable openvswitch
$ ovs-vsctl add-br br-int
$ for service in dhcp-agent l3-agent metadata-agent openvswitch-agent; do
systemctl start neutron-$service
systemctl enable neutron-$service
done
</code></pre></div><h1 id="heading-54"></h1>
<p> </p>
<h1 id="heading-55"></h1>
<ul>
<li><strong>이제 이어 compute 노드에서 neutron 서비스를 설치하도록 하겠습니다.</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ yum --enablerepo=centos-openstack-stein,epel -y install openstack-neutron openstack-neutron-ml2 openstack-neutron-openvswitch
# neutron 서비스를 설치합니다.

$ vi /etc/neutron/neutron.conf
[DEFAULT]
core_plugin = ml2
service_plugins = router
auth_strategy = keystone
stae_path = /var/lib/neutron
allow_overlapping_ips = True

transport_url = rabbit://openstack:qwer1234@controller

[keystone_authtoken]
www_authenticate_uri = http://controller:5000
auth_url = http://controller:5000
memcached_servers = controller:11211
auth_type = password
project_domain_name = default
user_domain_name = default
project_name = service
username = neutron
password = qwer1234

[oslo_concurrency]
lock_path = $state_path/tmp

$ vi /etc/neutron/plugins/ml2/ml2_conf.ini
[ml2]
type_drivers = flat,vlan,gre,vxlan
tenant_network_types =
mechanism_drivers = openvswitch
extension_drivers = port_security

$ vi /etc/neutron/plugins/ml2/openvswitch_agent.ini
[securitygroup]
firewall_driver = openvswitch
enable_security_group = true
enable_ipset = true
</code></pre></div><h1 id="heading-56"></h1>
<ul>
<li><strong>이어서 nova.conf 파일을 수정합니다.</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ vi /etc/nova/nova.conf
[DEFAULT]
...
use_neutron = True
linuxnet_interface_driver = nova.network.linux_net.LinuxOVSInterfaceDriver
firewall_driver = nova.virt.firewall.NoopFirewallDriver
vif_plugging_is_fatal = True
vif_plugging_timeout = 300

[neutron]
auth_url = http://controller:5000
auth_type = password
project_domain_name = default
user_domain_name = default
region_name = RegionOne
project_name = service
username = neutron
password = qwer1234
service_metadata_proxy = True
metadata_proxy_shared_secret = metadata_secret
</code></pre></div><h1 id="heading-57"></h1>
<ul>
<li><strong>Selinux 및 방화벽 설정</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ yum --enablerepo=centos-openstack-stein -y install openstack-selinux
$ setsebool -P neutron_can_network on
$ setsebool -P haproxy_connect_any on
$ setsebool -P daemons_enable_cluster_mode on
$ vi my-ovsofctl.te
# create new
module my-ovsofctl 1.0;

require <span style="color:#75715e">{</span>
        <span style="color:#a6e22e">type</span> <span style="color:#a6e22e">neutron_t</span><span style="color:#f92672">;</span>
        <span style="color:#a6e22e">class</span> <span style="color:#a6e22e">capability</span> <span style="color:#a6e22e">sys_rawio</span><span style="color:#f92672">;</span>
<span style="color:#75715e">}</span>

#============= neutron_t ==============
allow neutron_t self:capability sys_rawio;

$ checkmodule -m -M -o my-ovsofctl.mod my-ovsofctl.te 
$ semodule_package --outfile my-ovsofctl.pp --module my-ovsofctl.mod 
$ semodule -i my-ovsofctl.pp 
# Selinux 및 방화벽을 추가설정합니다.
</code></pre></div><h1 id="heading-58"></h1>
<ul>
<li><strong>서비스를 재시작 및 등록합니다.</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ ln -s /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugin.ini
$ systemctl start openvswitch
$ systemctl enable openvswitch
$ ovs-vsctl add-br br-int
$ systemctl restart openstack-nova-compute
$ systemctl start neutron-openvswitch-agent
$ systemctl enable neutron-openvswitch-agent
</code></pre></div><h1 id="heading-59"></h1>
<p> </p>
<h1 id="heading-60"></h1>
<ul>
<li><strong>이제 다음으로는 본격적으로 neutron 네트워크를 구현해보도록 하겠습니다.</strong></li>
<li><strong>먼저 controller 노드에서 ml2_conf 파일을 수정 및 추가합니다.</strong></li>
<li><strong>위에서 tenant 타입을 비워둔 이유는, 타입에 따라 사용하는 네트워크 구조가 달라지기 때문입니다.</strong></li>
<li><strong>여기서는 vxlan을 사용해 구성해보도록 하겠습니다.</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ vi /etc/neutron/plugins/ml2/ml2_conf.ini
[ml2]
tenant_network_types = vxlan

[ml2_type_flat]
flat_networks = physnet1

[ml2_type_vxlan]
vni_ranges = 1:1000
# ml2.conf 파일을 수정합니다

$ systemctl restart neutron-server
# neutron 서비스를 재시작 합니다.
</code></pre></div><h1 id="heading-61"></h1>
<ul>
<li><strong>이제 Network 노드에서의 설치를 진행해보도록 하겠습니다.</strong></li>
</ul>
<h1 id="heading-62"></h1>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ ovs-vsctl add-br br-eth1
$ ovs-vsctl add-port br-eth1 ens33
# 네트워크 브릿지를 생성하고, 네트워크 노드의 외부대역의 인터페이스 번호를 바인딩합니다.
</code></pre></div><h1 id="heading-63"></h1>
<ul>
<li><strong>neutron 서비스 사용을 위한 설정을 진행합니다.</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ vi /etc/neutron/plugins/ml2/ml2_conf.ini
[ml2]
type_drivers = flat,vlan,gre,vxlan
tenant_network_types = vxlan
mechanism_drivers = openvswitch
extension_drivers = port_security

[ml2_type_flat]
flat_networks = physnet1

[ml2_type_vxlan]
vni_ranges = 1:1000
# ml2_conf.ini 파일에 설정을 추가 설정합니다.

$ vi /etc/neutron/plugins/ml2/openvswitch_agent.ini
[agent]
tunnel_type = vxlan
prevent_arp_spoofing = True

[ovs]
local_ip = 10.10.10.20
bridge_mappings = physnet1:br-eth1
# openvswitch_agent.ini 파일의 하단에 추가합니다.

$ for service in dhcp-agent l3-agent metadata-agent openvswitch-agent; do systemctl restart neutron-$service
done
# neutron 서비스를 재시작합니다.

$ systemctl stop firewalld
$ systemctl disable firewalld
# 방화벽을 해제합니다.
</code></pre></div><h1 id="heading-64"></h1>
<ul>
<li><strong>바인딩 오류를 해결하기 위해 설정을 진행합니다.</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ vi /etc/sysconfig/network-scripts/ifcfg-ens33
TYPE=Ethernet
BOOTPROTO=static
DEFROUTE=yes
NAME=ens33
DEVICE=ens33
ONBOOT=yes

$ vi /var/tmp/create_interface.sh
#!/bin/bash

ip link set up br-eth1
ip addr add 192.168.10.101/24 dev br-eth1
route add default gw 192.168.10.2 dev br-eth1
echo &#34;nameserver 8.8.8.8&#34; &gt; /etc/resolv.conf

$ chmod 755 /var/tmp/create_interface.sh

$ vi /etc/systemd/system/set_interface.service
[Unit]
Description=Description for sample script goes here
After=network.target

[Service]
Type=simple
ExecStart=/var/tmp/create_interface.sh
TimeoutStartSec=0

[Install]
WantedBy=default.target

$ systemctl enable set_interface
$ init 6
</code></pre></div><h1 id="heading-65"></h1>
<ul>
<li><strong>이어 compute 노드에서의 설정을 진행합니다.</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ vi /etc/neutron/plugins/ml2/ml2_conf.ini
[ml2]
type_drivers = flat,vlan,gre,vxlan
tenant_network_types = vxlan
mechanism_drivers = openvswitch
extension_drivers = port_security

[ml2_type_flat]
flat_networks = physnet1

[ml2_type_vxlan]
vni_ranges = 1:1000
# ml2_conf.ini 파일에 설정을 추가 설정합니다.

$ vi /etc/neutron/plugins/ml2/openvswitch_agent.ini
[agent]
tunnel_type = vxlan
prevent_arp_spoofing = True

[ovs]
local_ip = 10.10.10.30
# openvswitch_agent.ini 파일의 하단에 추가합니다.

$ for service in dhcp-agent l3-agent metadata-agent openvswitch-agent; do systemctl restart neutron-$service
done
# neutron 서비스를 재시작합니다.

$ systemctl stop firewalld
$ systemctl disable firewalld
# 방화벽을 해제합니다.
</code></pre></div><h1 id="heading-66"></h1>
<ul>
<li><strong>확인</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ openstack network agent list
+--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+
| ID                                   | Agent Type         | Host       | Availability Zone | Alive | State | Binary                    |
+--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+
| 261bbd8f-ece9-4818-91c3-be75b928fa54 | Open vSwitch agent | network    | None              | :-)   | UP    | neutron-openvswitch-agent |
| 26376b7b-e4d0-413c-85b9-521994c41bf6 | Open vSwitch agent | compute    | None              | :-)   | UP    | neutron-openvswitch-agent |
| 8b520189-c500-47ec-b330-b84bc0a3b622 | Metadata agent     | controller | None              | :-)   | UP    | neutron-metadata-agent    |
| ba443e32-a931-465f-acff-05621dac0424 | Metadata agent     | network    | None              | :-)   | UP    | neutron-metadata-agent    |
| be878ec2-b8c9-4923-8d01-111d7c11c8f1 | L3 agent           | network    | nova              | :-)   | UP    | neutron-l3-agent          |
| cb74c09d-7ec5-4457-a384-8303235adc97 | DHCP agent         | network    | nova              | :-)   | UP    | neutron-dhcp-agent        |
+--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+

$ openstack router create router01
$ openstack network create int --provider-network-type vxlan
$ openstack subnet create int_sub --network int \
--subnet-range 1.1.1.0/24 --gateway 1.1.1.2 \
--dns-nameserver 8.8.8.8
# 라우터와 내부대역을 생성합니다.

$ openstack router add subnet router01 int_sub
# 라우터와 내부대벽을 연결시킵니다.

$ openstack network create \
--provider-physical-network physnet1 \
--provider-network-type flat --external ext
$ openstack subnet create subnet2 \
--network ext_net --subnet-range 192.168.10.0/24 \
--allocation-pool start=192.168.10.150,end=192.168.10.200 \
--gateway 192.168.10.2 --dns-nameserver 8.8.8.8
# 외부대역을 생성합니다. 외부대역의 IP는 바인딩한 br-eth1의 IP 대역과 동일해야합니다.

$ openstack router set router01 --external-gateway ext
# 생성한 라우터의 게이트웨이를 생성한 외부대역에 바운딩시킵니다.

$ openstack network list
+--------------------------------------+------+--------------------------------------+
| ID                                   | Name | Subnets                              |
+--------------------------------------+------+--------------------------------------+
| 2875f833-2d46-4740-bdd4-09c75c53e2b1 | int  | 698d35ae-8d7c-436f-be1b-fcf4319eb5fe |
| 4a25933d-ed21-4a5c-a87b-4e782e93c14c | ext  | 47b0ee11-b628-4260-9185-71d1dab401ea |
+--------------------------------------+------+--------------------------------------+


$ openstack subnet list
+--------------------------------------+---------+--------------------------------------+-----------------+
| ID                                   | Name    | Network                              | Subnet          |
+--------------------------------------+---------+--------------------------------------+-----------------+
| 47b0ee11-b628-4260-9185-71d1dab401ea | ext-sub | 4a25933d-ed21-4a5c-a87b-4e782e93c14c | 192.168.10.0/24 |
| 698d35ae-8d7c-436f-be1b-fcf4319eb5fe | int-sub | 2875f833-2d46-4740-bdd4-09c75c53e2b1 | 1.1.1.0/24      |
+--------------------------------------+---------+--------------------------------------+-----------------+


$ wget http://cloud-images.ubuntu.com/releases/18.04/release/ubuntu-18.04-server-cloudimg-amd64.img -P /var/kvm/images
$ openstack image create &#34;Ubuntu1804&#34; --file /var/kvm/images/ubuntu-18.04-server-cloudimg-amd64.img --disk-format qcow2 --container-format bare --public
# 이미지를 다운로드 및 등록합니다.

$ openstack flavor create --ram 1024 --disk 10 --vcpus 1 m1.small
# flavor를 생성합니다.

$ ssh-keygen -q -N &#34;&#34;
$ openstack keypair create --public-key ~/.ssh/id_rsa.pub mykey
# keypair를 생성합니다.

$ openstack floating ip create ext
# floating ip를 생성합니다.

$ openstack create server --image Ubuntu1804 --flavor m1.small --key mykey --network int Ubuntu
$ openstack server add floating ip Ubuntu 192.168.10.170
# 인스턴스를 생성하고 floating ip를 추가합니다.

$ openstack server list
+--------------------------------------+--------+--------+-------------------------------+------------+----------+
| ID                                   | Name   | Status | Networks                      | Image      | Flavor   |
+--------------------------------------+--------+--------+-------------------------------+------------+----------+
| 75fa0186-ab63-4aaa-a27c-3f2126e5d31d | Ubuntu | ACTIVE | int=1.1.1.248, 192.168.10.170 | Ubuntu1804 | m1.small |
+--------------------------------------+--------+--------+-------------------------------+------------+----------+

$ openstack security group create open
$ openstack security group rule create --protocol icmp --ingress open
$ openstack security group rule create --protocol tcp --dst-port 22:22 open
$ openstack security group rule create --protocol tcp --dst-port 80:80 open
$ openstack server add security group Ubuntu open
# 보안그룹을 생성하고 적용시킵니다.

$ ssh ubuntu@192.168.10.170
$ ping 8.8.8.8
$ sudo apt -y install apache2
$ sudo service apache2 start
# 본체 Host에서 접속해서 확인

</code></pre></div><ul>
<li><strong>이것으로 기본적인 openstack-stein 버전의 설치를 완료하였습니다.</strong></li>
</ul>
<h1 id="heading-67"></h1>
<p> </p>
<h1 id="heading-68"></h1>
<h3 id="7-horizon--대시보드-서비스--구성"><strong>7. Horizon ( 대시보드 서비스 ) 구성</strong></h3>
<hr>
<ul>
<li><strong>Horizon은 controller 노드에서 설치가 진행됩니다.</strong></li>
<li><strong>에 대한 설명은 <a href="https://mung0001.github.io/docs/study/openstack/horizon/">Horizone</a>을 참조해주세요.</strong></li>
</ul>
<h1 id="heading-69"></h1>
<ul>
<li><strong>Horizon 패키지 설치</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$  yum --enablerepo=centos-openstack-stein,epel -y install openstack-dashboard
# Horizon 패키지를 설치합니다.
</code></pre></div><h1 id="heading-70"></h1>
<ul>
<li><strong>대시보드를 설정합니다.</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ vi /etc/openstack-dashboard/local_settings
ALLOWED_HOSTS = [&#39;*&#39;] 
# 수정
OPENSTACK_API_VERSIONS = <span style="color:#75715e">{</span> 
    <span style="color:#e6db74">&#34;identity&#34;</span><span style="color:#f92672">:</span> <span style="color:#ae81ff">3</span><span style="color:#f92672">,</span>
    <span style="color:#e6db74">&#34;image&#34;</span><span style="color:#f92672">:</span> <span style="color:#ae81ff">3</span><span style="color:#f92672">,</span>
    <span style="color:#e6db74">&#34;volume&#34;</span><span style="color:#f92672">:</span> <span style="color:#ae81ff">3</span><span style="color:#f92672">,</span>
    <span style="color:#e6db74">&#34;compute&#34;</span><span style="color:#f92672">:</span> <span style="color:#ae81ff">2</span><span style="color:#f92672">,</span>
<span style="color:#75715e">}</span>
# 주석 제거 및 수정

OPENSTACK_KEYSTONE_MULTIDOMAIN_SUPPORT = True 
# 주석 해제 및 수정

OPENSTACK_KEYSTONE_DEFAULT_DOMAIN = &#39;Default&#39; 
# 주석 제거

CACHES = <span style="color:#75715e">{</span> 
    <span style="color:#e6db74">&#39;default&#39;</span><span style="color:#f92672">:</span> <span style="color:#75715e">{</span>
        <span style="color:#e6db74">&#39;BACKEND&#39;</span><span style="color:#f92672">:</span> <span style="color:#e6db74">&#39;django.core.cache.backends.memcached.MemcachedCache&#39;</span><span style="color:#f92672">,</span>
        <span style="color:#e6db74">&#39;LOCATION&#39;</span><span style="color:#f92672">:</span> <span style="color:#e6db74">&#39;127.0.0.1:11211&#39;</span><span style="color:#f92672">,</span>
    <span style="color:#75715e">}</span><span style="color:#f92672">,</span>
<span style="color:#75715e">}</span>
# 주석제거

OPENSTACK_HOST = &#34;controller&#34;
# IP 변경

OPENSTACK_KEYSTONE_DEFAULT_ROLE = &#34;member&#34;
# 수정

$ vi /etc/httpd/conf.d/openstack-dashboard.conf

WSGIDaemonProcess dashboard
WSGIProcessGroup dashboard
WSGISocketPrefix run/wsgi

WSGIApplicationGroup %<span style="color:#75715e">{</span><span style="color:#a6e22e">GLOBAL</span><span style="color:#75715e">}</span>
# 추가
</code></pre></div><h1 id="heading-71"></h1>
<ul>
<li><strong>Selinux 및 방화벽 설정</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ setsebool -P httpd_can_network_connect on
$ firewall-cmd --add-service=<span style="color:#75715e">{</span><span style="color:#a6e22e">http</span><span style="color:#f92672">,</span><span style="color:#a6e22e">https</span><span style="color:#75715e">}</span> --permanent
$ firewall-cmd --reload

$ systemctl restart httpd
</code></pre></div><h1 id="heading-72"></h1>
<ul>
<li>** DB 생성**</li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ mysql -u root -p
MariaDB [(none)]&gt; create database keystone;
MariaDB [(none)]&gt; grant all privileges on .* to @&#39;localhost&#39; identified by &#39;pw&#39;;
MariaDB [(none)]&gt; grant all privileges on .* to @&#39;%&#39; identified by &#39;pw&#39;;
MariaDB [(none)]&gt; flush privileges;
#  구성을 위한 db를 생성합니다. ( 저는 편의를 위해 모든 pw로 qwer1234 설정하였습니다. )
</code></pre></div><h1 id="heading-73"></h1>
<p> </p>
<h1 id="heading-74"></h1>
<h3 id="8-cinder--오브젝트-스토리지-및-블록-스토리지-구성-"><strong>8. Cinder ( 오브젝트 스토리지 및 블록 스토리지 구성 )</strong></h3>
<hr>
<ul>
<li><strong>Cinder는 기본적으로 독립적으로 storage 노드를 구성하거나 혹은 compute 노드에 추가하여 사용합니다.</strong></li>
<li><strong>여기서는 compute 노드에 포함하여 구성하도록 하겠습니다/</strong></li>
<li><strong>구성 순서는 controller &gt; compute 노드 순으로 진행하겠습니다.</strong></li>
<li><strong>Cinder에 대한 설명은 <a href="https://mung0001.github.io/docs/study/openstack/cinder/">Cinder</a>을 참조해주세요.</strong></li>
</ul>
<h1 id="heading-75"></h1>
<ul>
<li><strong>Cinder 서비스 등록</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ source ~/admin
$ openstack user create --domain default --project service --password qwer1234 cinder
$ openstack role add --project service --user cinder admin
$ openstack service create --name cinderv3 --description &#34;OpenStack Block service&#34; volumev3
# cinder 사용자를 추가 및 서비스를 등록합니다.

$ export controller=10.10.10.10
$ openstack endpoint create --region RegionOne volumev3 public http://$controller:8776/v3/%\(tenant_id\)s
$ openstack endpoint create --region RegionOne volumev3 internal http://$controller:8776/v3/%\(tenant_id\)s
$ openstack endpoint create --region RegionOne volumev3 admin http://$controller:8776/v3/%\(tenant_id\)s
# cinder의 endpoint를 생성합니다.
</code></pre></div><h1 id="heading-76"></h1>
<ul>
<li><strong>Cinder DB 생성</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ mysql -u root -p
MariaDB [(none)]&gt; create database cinder;
MariaDB [(none)]&gt; grant all privileges on cinder.* to cinder@&#39;localhost&#39; identified by &#39;pw&#39;;
MariaDB [(none)]&gt; grant all privileges on cinder.* to cinder@&#39;%&#39; identified by &#39;pw&#39;;
MariaDB [(none)]&gt; flush privileges;
# cinder 구성을 위한 db를 생성합니다. ( 저는 편의를 위해 모든 pw로 qwer1234 설정하였습니다. )
</code></pre></div><h1 id="heading-77"></h1>
<ul>
<li><strong>cinder 패키지 설치 및 수정</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$  yum --enablerepo=centos-openstack-stein,epel -y install openstack-cinder

$ vi /etc/cinder/cinder.conf
[DEFAULT]
my_ip = 10.10.10.10
log_dir = /var/log/cinder
state_path = /var/lib/cinder
auth_strategy = keystone

transport_url = rabbit://openstack:qwer1234@controller
enable_v3_api = True

[keystone_authtoken]
www_authenticate_uri = http://controller:5000
auth_url = http://controller:5000
memcached_servers = controller:11211
auth_type = password
project_domain_name = default
user_domain_name = default
project_name = service
username = cinder
password = qwer1234

[database]
connection = mysql+pymysql://cinder:qwer1234@controller/cinder

[oslo_concurrency]
lock_path = $state_path/tmp
# cinder.conf 파일을 수정합니다.

$ su -s /bin/bash cinder -c &#34;cinder-manage db sync&#34;
# cinder db를 동기화시킵니다.

$ systemctl start openstack-cinder-api openstack-cinder-scheduler
$ systemctl enable openstack-cinder-api openstack-cinder-scheduler
# cinder 시작 및 자동시작을 등록합니다.

$ echo &#34;export OS_VOLUME_API_VERSION=3&#34; &gt;&gt; ~/admin
$ source ~/admin
# 볼륨 버전을 API 3로 지정합니다.

$ firewall-cmd --add-port=8776/tcp --permanent
$ firewall-cmd --reload
</code></pre></div><h1 id="heading-78"></h1>
<p> </p>
<h1 id="heading-79"></h1>
<ul>
<li><strong>이어서 compute 노드에 설치를 진행하겠습니다.</strong></li>
<li><strong>cinder 패키지 설치 및 수정</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$  yum --enablerepo=centos-openstack-stein,epel -y install openstack-cinder python2-crypto targetcli

$ vi /etc/cinder/cinder.conf
[DEFAULT]
my_ip = 10.10.10.30
log_dir = /var/log/cinder
state_path = /var/lib/cinder
auth_strategy = keystone

transport_url = rabbit://openstack:qwer1234@controller

glance_api_servers = http://controller:9292
enable_v3_api = True

[keystone_authtoken]
www_authenticate_uri = http://controller:5000
auth_url = http://controller:5000
memcached_servers = controller:11211
auth_type = password
project_domain_name = default
user_domain_name = default
project_name = service
username = cinder
password = qwer1234

[database]
connection = mysql+pymysql://cinder:qwer1234@controller/cinder

[oslo_concurrency]
lock_path = $state_path/tmp
# cinder.conf 파일을 수정합니다.

$ systemctl start openstack-cinder-volume
$ systemctl enable openstack-cinder-volume
# cinder 서비스를 시작 및 자동시작을 등록합니다.

$ controller $openstack volume service list
# 확인
+------------------+------------+------+---------+-------+----------------------------+
| Binary           | Host       | Zone | Status  | State | Updated At                 |
+------------------+------------+------+---------+-------+----------------------------+
| cinder-scheduler | controller | nova | enabled | up    | 2020-07-20T04:02:31.000000 |
+------------------+------------+------+---------+-------+----------------------------+
</code></pre></div><h1 id="heading-80"></h1>
<p> </p>
<h1 id="heading-81"></h1>
<h3 id="8-2-lvm으로-블록-스토리지-백엔드-구성"><strong>8-2. LVM으로 블록 스토리지 백엔드 구성</strong></h3>
<h1 id="heading-82"></h1>
<ul>
<li><strong>compute 노드에 cinder 서비스를 설치한 것에 이어 LVM 백엔드를 설정해보도록 하겠습니다.</strong></li>
<li><strong><a href="">VG 생성 참조</a></strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ fdisk /dev/sd[ n ]
# 만약 디스크 파티션이 없으시면 새로 생성 후 등록합니다.
# 저는 간단하게 100G 하드를 추가한 후, cinder 이름으로 vg를 생성하였습니다.

$ vi /etc/cinder/cinder.conf
[DEFAULT]
...
enabled_backends = lvm

[lvm]
target_helper = lioadm
target_protocol = iscsi

target_ip_address = 10.10.10.30

volume_group = cinder
volume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver
volume_dir = $state_path/volumes
# cinder.conf의 상단에 내용을 추가설정합니다.

$ firewall-cmd --add-service=iscsi-target --permanent
$ firewall-cmd --reload
# 방화벽 설정을 추가합니다.

$ systemctl restart openstack-cinder-volume
# 서비스를 재시작합니다.
</code></pre></div><h1 id="heading-83"></h1>
<ul>
<li><strong>이어서 compute 노드의 nova.conf 파일을 수정합니다.</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ vi /etc/nova/nova.conf
[cinder]
os_region_name = RegionOne
# nova.conf의 하단에 상단의 내용을 추가합니다.

$ systemctl restart openstack-nova-compute
# nova 서비스를 재시작합니다.

$ controller $ openstack volume service list
# 생성을 확인합니다.
+------------------+-------------+------+---------+-------+----------------------------+
| Binary           | Host        | Zone | Status  | State | Updated At                 |
+------------------+-------------+------+---------+-------+----------------------------+
| cinder-scheduler | controller  | nova | enabled | up    | 2020-07-20T04:54:52.000000 |
| cinder-volume    | compute@lvm | nova | enabled | up    | 2020-07-20T04:54:52.000000 |
+------------------+-------------+------+---------+-------+----------------------------+

$ controller $ openstack volume cretae --size 1 test
# 확인용 1G volume을 생성합니다.
+---------------------+--------------------------------------+
| Field               | Value                                |
+---------------------+--------------------------------------+
| attachments         | []                                   |
| availability_zone   | nova                                 |
| bootable            | false                                |
| consistencygroup_id | None                                 |
| created_at          | 2020-07-20T05:00:21.000000           |
| description         | None                                 |
| encrypted           | False                                |
| id                  | f09ee80f-3ec8-4eaf-a4a5-af13cccbd5ae |
| migration_status    | None                                 |
| multiattach         | False                                |
| name                | test                                 |
| properties          |                                      |
| replication_status  | None                                 |
| size                | 1                                    |
| snapshot_id         | None                                 |
| source_volid        | None                                 |
| status              | creating                             |
| type                | None                                 |
| updated_at          | None                                 |
| user_id             | 296ce49d1dc94931b62a726fb64712e9     |
+---------------------+--------------------------------------+


$ openstack volume list
# 생성한 volume을 확인합니다.
+--------------------------------------+------+-----------+------+-------------+
| ID                                   | Name | Status    | Size | Attached to |
+--------------------------------------+------+-----------+------+-------------+
| f09ee80f-3ec8-4eaf-a4a5-af13cccbd5ae | test | available |    1 |             |
+--------------------------------------+------+-----------+------+-------------+

</code></pre></div><h1 id="heading-84"></h1>
<p> </p>
<h1 id="heading-85"></h1>
<h3 id="8-3-lbaas-설치"><strong>8-3. LBaaS 설치</strong></h3>
<ul>
<li><strong>로드밸런싱을 위해서는 LBaaS를 사용해야 합니다.</strong></li>
<li><strong>LBaaS에 대해서는 <a href="https://mung0001.github.io/docs/study/openstack/neutron/">LBaaS</a>를 참조해주세요.</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ yum --enablerepo=centos-openstack-stein,epel -y install openstack-neutron-lbaas net-tools
# LBaaS 서비스를 설치합니다.

$ vi /etc/neutron/neutron.conf
service_plugins = router,lbaasv2
# lbaasv2 서비스를 추가합니다.

$ vi /etc/neutron/neutron_lbaas.conf
[service_providers]
service_provider = LOADBALANCERV2:Haproxy:neutron_lbaas.drivers.haproxy.plugin_driver.HaproxyOnHostPluginDriver:default

$ vi /etc/neutron/lbaas_agent.ini
[DEFAULT]
interface_driver = openvswitch

$ su -s /bin/bash neutron -c &#34;neutron-db-manage --subproject neutron-lbaas --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugin.ini upgrade head&#34;

$ systemctl restart neutron-server
</code></pre></div><h1 id="heading-86"></h1>
<ul>
<li><strong>network 노드와 compute 노드는 동일하게 진행합니다.</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ yum --enablerepo=centos-openstack-stein,epel -y install openstack-neutron-lbaas haproxy net-tools

$ vi /etc/neutron/neutron.conf
service_plugins = router,lbaasv2

$ vi /etc/neutron/neutron_lbaas.conf
[service_providers]
service_provider = LOADBALANCERV2:Haproxy:neutron_lbaas.drivers.haproxy.plugin_driver.HaproxyOnHostPluginDriver:default

$ vi /etc/neutron/lbaas_agent.ini
[DEFAULT]
interface_driver = openvswitch

$ systemctl start neutron-lbaasv2-agent
$ systemctl enable neutron-lbaasv2-agent
</code></pre></div><h1 id="heading-87"></h1>
<p> </p>
<h1 id="heading-88"></h1>
<h3 id="8-4-lfs-lvm-기반-다중-스토리지-노드-구성"><strong>8-4. LFS, LVM 기반 다중 스토리지 노드 구성</strong></h3>
<h1 id="heading-89"></h1>
<p> </p>
<h1 id="heading-90"></h1>
<h3 id="9-swift--오브젝트-스토리지-서비스--구성"><strong>9. Swift ( 오브젝트 스토리지 서비스 ) 구성</strong></h3>
<hr>
<ul>
<li><strong>Swift란 오브젝트 스토리지 서비스로, 흔히 우리가 생각하는 네이버 클라우드와 거의 동일한 맥락이라 할 수 있습니다.</strong></li>
<li><strong>swift는 기본적으로 controller에 설치하나 여기서는 비교적 자원소모가 적은 network 노드에 proxy-sever를, compute 노드를 storage로 사용하여 설치하여 진행하겠습니다.</strong></li>
<li><strong>swift</strong>에 대한 설명은 <a href="https://mung0001.github.io/docs/study/openstack/swift/">swift</a>을 참조해주세요.**</li>
</ul>
<h1 id="heading-91"></h1>
<ul>
<li><strong>swift 서비스 생성</strong></li>
<li><strong>controlloer 노드에는 swift 관련 패키지를 설치하지는 않지만 서비스의 관리를 위해 유저, 엔드포인트, url을 생성합니다.</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ openstack user create --domain default --project service --password qwer1234 swift
$ openstack role add --project service --user swift admin
$ openstack service create --name swift --description &#34;OpenStack Object Storage&#34; object-store
# swfit 유저를 생성하고 관리자의 권한을 부여합니다.

$ export swift_proxy=10.10.10.20
$ openstack endpoint create --region RegionOne object-store public http://$swift_proxy:8080/v1/AUTH_%\(tenant_id\)s
$ openstack endpoint create --region RegionOne object-store internal http://$swift_proxy:8080/v1/AUTH_%\(tenant_id\)s
$ openstack endpoint create --region RegionOne object-store admin http://$swift_proxy:8080/v1/AUTH_%\(tenant_id\)s
# swift의 endpoint를 등록합니다. 여기서 proxy 서버는 네트워크 노드를 등록합니다.
</code></pre></div><h1 id="heading-92"></h1>
<p> </p>
<h1 id="heading-93"></h1>
<ul>
<li><strong>이어서 network 노드에서의 swift 설치 및 설정을 진행하겠습니다.</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ yum --enablerepo=centos-openstack-stein,epel -y install openstack-swift-proxy python-memcached openssh-clients
# swift 서비스에 필요한 패키지를 설치합니다.

$ vi /etc/swift/proxy-server.conf
[filter:cache]
use = egg:swift#memcache
#memcache_servers = 127.0.0.1:11211
memcache_servers = controller:11211

[filter:authtoken]
paste.filter_factory = keystonemiddleware.auth_token:filter_factory
#admin_tenant_name = %SERVICE_TENANT_NAME%
#admin_user = %SERVICE_USER%
#admin_password = %SERVICE_PASSWORD%
#admin_host = 127.0.0.1
#admin_port = 35357
#admin_protocol = http
#admin_ /tmp/keystone-signing-swift
# paste.filter_factory를 제외한 기존 정보는 주석처리

www_authenticate_uri = http://controller:5000
auth_url = http://controller:5000
memcached_servers = controller:11211
auth_type = password
project_domain_name = default
user_domain_name = default
project_name = service
username = swift
password = qwer1234
delay_auth_decision = true
# 위에 내용을 대신 주석 추가

# proxy-server.conf 파일을 수정합니다.
# memcache_servers의 IP는 controller 노드의 IP로 수정합니다.

$ vi /etc/swift/swift.conf
[swift-hash]
#swift_hash_path_suffix = %SWIFT_HASH_PATH_SUFFIX%
swift_hash_path_suffix = swift_shared_path
swift_hash_path_prefix = swift_shared_path
</code></pre></div><h1 id="heading-94"></h1>
<ul>
<li><strong>swift 서비스의 사용을 위해 account, container, object를 생성합니다.</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ swift-ring-builder /etc/swift/account.builder create 12 1 1
$ swift-ring-builder /etc/swift/container.builder create 12 1 1
$ swift-ring-builder /etc/swift/object.builder create 12 1 1
# account, container, object를 생성합니다.
# 12 = 한 클러스터 스토리지에서 생성 가능한 파티션의 수
# 1 = 오브젝트 복수 수 ( 스토리지의 개수 )
# 1 = 데이터 이동, 복제, 파티션 이동 등이 진행될 때 잠기는 최소 시간, 데이터 손실을 방지하기 위한 기능

$ swift-ring-builder /etc/swift/account.builder add r0z0-10.10.10.30:6202/device0 100
$ swift-ring-builder /etc/swift/container.builder add r0z0-10.10.10.30:6201/device0 100
$ swift-ring-builder /etc/swift/object.builder add r0z0-10.10.10.30:6200/device0 100
$ swift-ring-builder /etc/swift/account.builder rebalance
$ swift-ring-builder /etc/swift/container.builder rebalance
$ swift-ring-builder /etc/swift/object.builder rebalance
# compute 노드의 builder에 region과 zone을 추가 후 반영시킵니다.
# r = region, z = zone

$ chown swift. /etc/swift/*.gz
# swift 관련 파일의 소유권을 변경합니다.

$ systemctl start openstack-swift-proxy
$ systemctl enable openstack-swift-proxy
# 프록시 서비스를 시작합니다.

$ firewall-cmd --add-port=8080/tcp --permanent
$ firewall-cmd --reload
# 방화벽을 사용 중이라면 방화벽을 등록합니다.
</code></pre></div><h1 id="heading-95"></h1>
<p> </p>
<h1 id="heading-96"></h1>
<ul>
<li><strong>이제 이어 storage를 구성하기 위해 compute 노드에서의 설치를 진행해보도록 하겠습니다.</strong></li>
<li><strong>compute 노드는 이미 cinder 서비스가 동작하고 있어 기본적인 네트워크, 시간 설정, 레포지터리 지정 등은 구성이 마친 상태의 노드입니다.</strong></li>
<li><strong>만약 다른 노드에 구성하시거나 swift 서비스를 다중 노드로 구성하시는  경우 위와 같은 설정을 먼저 진행해주시길 바랍니다.</strong></li>
<li><strong>여기서는 swift 서비스를 위해 100G의 버츄얼 디스크( dev/sdc )를 추가하여 진행하였습니다.</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ yum --enablerepo=centos-openstack-stein,epel -y install openstack-swift-account openstack-swift-container openstack-swift-object xfsprogs rsync openssh-clients
# swift 서비스를 설치합니다.

$ scp root@network:/etc/swift/*.gz /etc/swift/
$ chown swift. /etc/swift/*.gz
# network 노드에서의 설정파일을 복사옵니다.

$ vi /etc/swift/swift.conf
[swift-hash]
#swift_hash_path_suffix = %SWIFT_HASH_PATH_SUFFIX%
swift_hash_path_suffix = swift_shared_path
swift_hash_path_prefix = swift_shared_path
$ swift.conf 파일을 설정합니다.

$ vi /etc/swift/account-server.conf
bind-ip = 0.0.0.0
bind_port = 6202

$ vi /etc/swift/container-server.conf
bind-ip = 0.0.0.0
bind_port = 6201

$ vi /etc/swift/object-server.conf
bind-ip = 0.0.0.0
bind_port = 6200

$ vi /etc/rsyncd.conf
pid file = /var/run/rsymcd.pid
log file = /var/log/rsymcd.log
uid = swift
gid = swift

address = compute

[account]
path            = /srv/node
read only       = false
write only      = no
list            = yes
incoming chmod  = 0644
outgoing chmod  = 0644
max connections = 25
lock file =     /var/lock/account.lock

[container]
path            = /srv/node
read only       = false
write only      = no
list            = yes
incoming chmod  = 0644
outgoing chmod  = 0644
max connections = 25
lock file =     /var/lock/container.lock

[object]
path            = /srv/node
read only       = false
write only      = no
list            = yes
incoming chmod  = 0644
outgoing chmod  = 0644
max connections = 25
lock file =     /var/lock/object.lock

[swift_server]
path            = /etc/swift
read only       = true
write only      = no
list            = yes
incoming chmod  = 0644
outgoing chmod  = 0644
max connections = 5
lock file =     /var/lock/swift_server.lock
# swift 서비스관련 파일을 수정합니다.
</code></pre></div><h1 id="heading-97"></h1>
<ul>
<li><strong>compute 노드에서 disk 설정을 진행합니다.</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ mkfs.xfs -i size=1024 -s size=4096 /dev/sdb1
meta-data=/dev/sdc1              isize=1024   agcount=4, agsize=6553536 blks
         =                       sectsz=4096  attr=2, projid32bit=1
         =                       crc=1        finobt=0, sparse=0
data     =                       bsize=4096   blocks=26214144, imaxpct=25
         =                       sunit=0      swidth=0 blks
naming   =version 2              bsize=4096   ascii-ci=0 ftype=1
log      =internal log           bsize=4096   blocks=12799, version=2
         =                       sectsz=4096  sunit=1 blks, lazy-count=1
realtime =none                   extsz=4096   blocks=0, rtextents=0
# 디스크의 xfs의 유형으로 포맷시킵니다.

$ mkdir -p /srv/node/device0
$ mount -o noatime,nodiratime,nobarrier /dev/sdc1 /srv/node/device0
$ chown -R swift. /srv/node
# device0 디렉토리를 생성하고 해당 디렉토리에 sdb1 볼륨을 마운트시킨 후, swift로 소유권을 변경시킵니다.

$ vi /etc/fstab
/dev/sdc1     /srv/node/device0     xfs     noatime,nodiratime,nobarrier 0 0
# 재부팅할 경우를 대비하여 생성한 볼륨을 fstab에 등록합니다.
</code></pre></div><h1 id="heading-98"></h1>
<p> </p>
<h1 id="heading-99"></h1>
<ul>
<li><strong>selinux 및 방화벽 관련 서비스를 설정합니다.</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ semanage fcontext -a -t swift_data_t /srv/node/device0
$ restorecon /srv/node/device0
$ firewall-cmd --add-port=<span style="color:#75715e">{</span><span style="color:#ae81ff">873</span><span style="color:#f92672">/</span><span style="color:#a6e22e">tcp</span><span style="color:#f92672">,</span><span style="color:#ae81ff">6200</span><span style="color:#f92672">/</span><span style="color:#a6e22e">tcp</span><span style="color:#f92672">,</span><span style="color:#ae81ff">6201</span><span style="color:#f92672">/</span><span style="color:#a6e22e">tcp</span><span style="color:#f92672">,</span><span style="color:#ae81ff">6202</span><span style="color:#f92672">/</span><span style="color:#a6e22e">tcp</span><span style="color:#75715e">}</span> --permanent 
$ firewall-cmd --reload 
</code></pre></div><h1 id="heading-100"></h1>
<ul>
<li><strong>swift 관련 서비스를 재시작합니다.</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ systemctl restart rsyncd openstack-swift-account-auditor openstack-swift-account-replicator openstack-swift-account openstack-swift-container-auditor openstack-swift-container-replicator openstack-swift-container-updater openstack-swift-container openstack-swift-object-auditor openstack-swift-object-replicator openstack-swift-object-updater openstack-swift-object
$ systemctl enable rsyncd openstack-swift-account-auditor openstack-swift-account-replicator openstack-swift-account openstack-swift-container-auditor openstack-swift-container-replicator openstack-swift-container-updater openstack-swift-container openstack-swift-object-auditor openstack-swift-object-replicator openstack-swift-object-updater openstack-swift-object
</code></pre></div><h1 id="heading-101"></h1>
<ul>
<li><strong>확인을 위해 controller 노드에 httpd를 재시작합니다.</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ systemctl restart httpd
# 대시보드 접속 후 프로젝트에서 오브젝트 스토리지가 메뉴에 있는 지를 확인합니다.

$ openstack container create test
+---------------------------------------+-----------+------------------------------------+
| account                               | container | x-trans-id                         |
+---------------------------------------+-----------+------------------------------------+
| AUTH_2ac06290d2d943d5a768fe3daa53b118 | test      | tx22f3dd125f134a189602c-005f24cef1 |
+---------------------------------------+-----------+------------------------------------+

$ echo Hello &gt; test.txt
$ swift upload test test.txt
$ swift list
test
$ swift list test
test.txt
</code></pre></div><h1 id="heading-102"></h1>
<p> </p>
<h1 id="heading-103"></h1>
<h3 id="10-heat--orchestration--설치"><strong>10. Heat ( Orchestration ) 설치</strong></h3>
<h1 id="heading-104"></h1>
<ul>
<li><strong>클라우딩 컴퓨팅이 꽃인 Orchestaration 기능을 수행하는 Heat 서비스를 설치해보도록 하겠습니다.</strong></li>
<li><strong>Heat 설치는 controller, network 노드 순으로 우리어집니다.</strong></li>
<li><strong>Heat*에 대한 설명은 <a href="https://mung0001.github.io/docs/study/openstack/heat/">Heat</a>을 참조해주세요.</strong></li>
</ul>
<h1 id="heading-105"></h1>
<ul>
<li><strong>Heat 서비스 생성</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ yum --enablerepo=centos-openstack-stein,epel -y install openstack-heat-common python-heatclient
# heat 서비스 관련 패키지를 다운로드 합니다.

$ openstack user create --domain default --project service --password qwer1234 heat
$ openstack role add --project service --user heat admin
$ openstack role create heat_stack_owner
$ openstack role create heat_stack_user
$ openstack role add --project admin --user admin heat_stack_owner
$ openstack service create --name heat --description &#34;Openstack Orchestration&#34; orchestration
$ openstack service create --name heat-cfn --description &#34;Openstack Orchestration&#34; cloudformation
# heat 유저를 생성하고 관리자의 권한을 부여합니다.

$ export heat_api=10.10.10.20
$ openstack endpoint create --region RegionOne orchestration public http://$heat_api:8004/v1/AUTH_%\(tenant_id\)s
$ openstack endpoint create --region RegionOne orchestration internal http://$heat_api:8004/v1/AUTH_%\(tenant_id\)s
$ openstack endpoint create --region RegionOne orchestration admin http://$heat_api:8004/v1/AUTH_%\(tenant_id\)s
$ openstack endpoint create --region RegionOne cloudformation public http://$heat_api:8000/v1
$ openstack endpoint create --region RegionOne cloudformation internal http://$heat_api:8000/v1
$ openstack endpoint create --region RegionOne cloudformation admin http://$heat_api:8000/v1
# heat 서비스의 endpoint를 등록합니다. 여기서 proxy 서버는 네트워크 노드를 등록합니다.

$ openstack domain create --description &#34;Stack projects and users&#34; heat
$ openstack user create --domain heat --password qwer1234 heat_domain_admin
$ openstack role add --domain heat --user heat_domain_admin admin
# heat domain을 생성하고 heat 유저에게 권한을 부여합니다.
</code></pre></div><h1 id="heading-106"></h1>
<ul>
<li><strong>heat의 DB를 생성합니다.</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ mysql -u root -p
MariaDB [(none)]&gt; create database heat;
MariaDB [(none)]&gt; grant all privileges on heat.* to heat@&#39;localhost&#39; identified by &#39;pw&#39;;
MariaDB [(none)]&gt; grant all privileges on heat.* to keystone@&#39;%&#39; identified by &#39;pw&#39;;
MariaDB [(none)]&gt; flush privileges;
# heat DB를 생성합니다. 여기서 pw는 qwer1234으로 모두 통일하였습니다.
</code></pre></div><h1 id="heading-107"></h1>
<ul>
<li><strong>이어서 network 노드에서 heat 서비스를 설치해보겠습니다.</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ yum --enablerepo=centos-openstack-stein,epel -y install openstack-heat-api openstack-heat-api-cfn openstack-heat-engine python-heatclient
# heat 서비스를 위한 패키지를 설치합니다.

$ vi /etc/heat/heat.conf
[DEFAULT]
deferred_auth_method = trusts
trusts_delegated_roles = heat_stack_owner

# Heat installed server
heat_metadata_server_url = http://network:8000
heat_waitcondition_server_url = http://network:8000/v1/waitcondition
heat_watch_server_url = http://network:8003
heat_stack_user_role = heat_stack_user

# Heat domain name
stack_user_domain_name = heat

# Heat domain admin name
stack_domain_admin = heat_domain_admin

# Heat domain admin&#39;s password
stack_domain_admin_password = qwer1234

# RabbitMQ connection info
transport_url = rabbit://openstack:qwer1234@controller

# MariaDB connection info
[database]
connection = mysql+pymysql://heat:qwer1234@controller/heat

# Keystone auth info
[clients_keystone]
auth_uri = http://controller:5000

# Keystone auth info
[ec2authtoken]
auth_uri = http://controller:5000

[heat_api]
bind_host = 0.0.0.0
bind_port = 8004

[heat_api_cfn]
bind_host = 0.0.0.0
bind_port = 8000

# Keystone auth info
[keystone_authtoken]
www_authenticate_uri = http://controller:5000
auth_url = http://controller:5000
memcached_servers = controller:11211
auth_type = password
project_domain_name = default
user_domain_name = default
project_name = service
username = heat
password = qwer1234

[trustee]
auth_plugin = password
auth_url = http://controller:5000
username = heat
password = qwer1234
user_domain_name = default
# heat.conf 파일을 수정합니다.

$ su -s /bin/bash heat -c &#34;heat-manage db_sync&#34;
$ systemctl start openstack-heat-api openstack-heat-api-cfn openstack-heat-engine
$ systemctl enable openstack-heat-api openstack-heat-api-cfn openstack-heat-engine
# DB의 데이터를 삽입하고, 서비스슬 등록합니다.
</code></pre></div><h1 id="heading-108"></h1>
<ul>
<li><strong>방화벽을 사용중이면 방화벽을 설정합니다.</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ firewall-cmd --add-port=<span style="color:#75715e">{</span><span style="color:#ae81ff">8000</span><span style="color:#f92672">/</span><span style="color:#a6e22e">tcp</span><span style="color:#f92672">,</span><span style="color:#ae81ff">8004</span><span style="color:#f92672">/</span><span style="color:#a6e22e">tcp</span><span style="color:#75715e">}</span> --permanent
$ firewall-cmd --reload
</code></pre></div><h1 id="heading-109"></h1>
<p> </p>
<h1 id="heading-110"></h1>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ yum --enablerepo=centos-openstack-stein,epel -y install openstack-designate-api openstack-designate-central openstack-designate-worker openstack-designate-producer openstack-designate-mdns python-designateclient bind bind-utils
#  서비스 관련 패키지를 설치합니다.

$ rndc-confgen -a -k designate -c /etc/designate.key -r /dev/urandom
$ chown named:designate /etc/designate.key
$ chmod 640 /etc/designate.key
# key를 생성합니다.

$ vi /etc/named.conf
# create new
options <span style="color:#75715e">{</span>
        <span style="color:#a6e22e">listen</span><span style="color:#f92672">-</span><span style="color:#a6e22e">on</span> <span style="color:#a6e22e">port</span> <span style="color:#ae81ff">53</span> <span style="color:#75715e">{</span> <span style="color:#a6e22e">any</span><span style="color:#f92672">;</span> <span style="color:#75715e">}</span><span style="color:#f92672">;</span>
        <span style="color:#a6e22e">listen</span><span style="color:#f92672">-</span><span style="color:#a6e22e">on</span><span style="color:#f92672">-</span><span style="color:#a6e22e">v6</span> <span style="color:#a6e22e">port</span> <span style="color:#ae81ff">53</span> <span style="color:#75715e">{</span> <span style="color:#a6e22e">none</span><span style="color:#f92672">;</span> <span style="color:#75715e">}</span><span style="color:#f92672">;</span>
        <span style="color:#a6e22e">directory</span>       <span style="color:#e6db74">&#34;/var/named&#34;</span><span style="color:#f92672">;</span>
        <span style="color:#a6e22e">dump</span><span style="color:#f92672">-</span><span style="color:#a6e22e">file</span>       <span style="color:#e6db74">&#34;/var/named/data/cache_dump.db&#34;</span><span style="color:#f92672">;</span>
        <span style="color:#a6e22e">statistics</span><span style="color:#f92672">-</span><span style="color:#a6e22e">file</span> <span style="color:#e6db74">&#34;/var/named/data/named_stats.txt&#34;</span><span style="color:#f92672">;</span>
        <span style="color:#a6e22e">memstatistics</span><span style="color:#f92672">-</span><span style="color:#a6e22e">file</span> <span style="color:#e6db74">&#34;/var/named/data/named_mem_stats.txt&#34;</span><span style="color:#f92672">;</span>
        <span style="color:#960050;background-color:#1e0010">#</span> <span style="color:#a6e22e">replace</span> <span style="color:#a6e22e">query</span> <span style="color:#a6e22e">range</span> <span style="color:#a6e22e">to</span> <span style="color:#a6e22e">your</span> <span style="color:#a6e22e">own</span> <span style="color:#a6e22e">environment</span>
        <span style="color:#a6e22e">allow</span><span style="color:#f92672">-</span><span style="color:#a6e22e">query</span>     <span style="color:#75715e">{</span> <span style="color:#a6e22e">localhost</span><span style="color:#f92672">;</span> <span style="color:#ae81ff">10.10</span><span style="color:#f92672">.</span><span style="color:#ae81ff">10.0</span><span style="color:#f92672">/</span><span style="color:#ae81ff">24</span><span style="color:#f92672">;</span> <span style="color:#75715e">}</span><span style="color:#f92672">;</span>
        <span style="color:#a6e22e">allow</span><span style="color:#f92672">-</span><span style="color:#a6e22e">new</span><span style="color:#f92672">-</span><span style="color:#a6e22e">zones</span> <span style="color:#a6e22e">yes</span><span style="color:#f92672">;</span>
        <span style="color:#a6e22e">request</span><span style="color:#f92672">-</span><span style="color:#a6e22e">ixfr</span> <span style="color:#a6e22e">no</span><span style="color:#f92672">;</span>
        <span style="color:#a6e22e">recursion</span> <span style="color:#a6e22e">no</span><span style="color:#f92672">;</span>
        <span style="color:#a6e22e">bindkeys</span><span style="color:#f92672">-</span><span style="color:#a6e22e">file</span> <span style="color:#e6db74">&#34;/etc/named.iscdlv.key&#34;</span><span style="color:#f92672">;</span>
        <span style="color:#a6e22e">managed</span><span style="color:#f92672">-</span><span style="color:#a6e22e">keys</span><span style="color:#f92672">-</span><span style="color:#a6e22e">directory</span> <span style="color:#e6db74">&#34;/var/named/dynamic&#34;</span><span style="color:#f92672">;</span>
        <span style="color:#a6e22e">pid</span><span style="color:#f92672">-</span><span style="color:#a6e22e">file</span> <span style="color:#e6db74">&#34;/run/named/named.pid&#34;</span><span style="color:#f92672">;</span>
        <span style="color:#a6e22e">session</span><span style="color:#f92672">-</span><span style="color:#a6e22e">keyfile</span> <span style="color:#e6db74">&#34;/run/named/session.key&#34;</span><span style="color:#f92672">;</span>
<span style="color:#75715e">}</span>;
include &#34;/etc/designate.key&#34;;
controls <span style="color:#75715e">{</span>
    <span style="color:#a6e22e">inet</span> <span style="color:#ae81ff">0.0</span><span style="color:#f92672">.</span><span style="color:#ae81ff">0.0</span> <span style="color:#a6e22e">port</span> <span style="color:#ae81ff">953</span>
    <span style="color:#a6e22e">allow</span> <span style="color:#75715e">{</span> <span style="color:#a6e22e">localhost</span><span style="color:#f92672">;</span> <span style="color:#75715e">}</span> <span style="color:#a6e22e">keys</span> <span style="color:#75715e">{</span> <span style="color:#e6db74">&#34;designate&#34;</span><span style="color:#f92672">;</span> <span style="color:#75715e">}</span><span style="color:#f92672">;</span>
<span style="color:#75715e">}</span>;
logging <span style="color:#75715e">{</span>
        <span style="color:#a6e22e">channel</span> <span style="color:#a6e22e">default_debug</span> <span style="color:#75715e">{</span>
                <span style="color:#a6e22e">file</span> <span style="color:#e6db74">&#34;data/named.run&#34;</span><span style="color:#f92672">;</span>
                <span style="color:#a6e22e">severity</span> <span style="color:#a6e22e">dynamic</span><span style="color:#f92672">;</span>
        <span style="color:#75715e">}</span><span style="color:#f92672">;</span>
<span style="color:#75715e">}</span>;
zone &#34;.&#34; IN <span style="color:#75715e">{</span>
        <span style="color:#a6e22e">type</span> <span style="color:#a6e22e">hint</span><span style="color:#f92672">;</span>
        <span style="color:#a6e22e">file</span> <span style="color:#e6db74">&#34;named.ca&#34;</span><span style="color:#f92672">;</span>
<span style="color:#75715e">}</span>;

$ chown -R named. /var/named
$ systemctl start named
$ systemctl enable naemd


$ vi /etc/designate/designate.conf
[DEFAULT]
log_dir = /var/log/designate
transport_url = rabbit://openstack:qwer1234@controller
root_helper = sudo designate-rootwrap /etc/designate/rootwrap.conf

[database]
connection = mysql+pymysql://heat:qwer1234@controller/heat

[service:api]
listen = 0.0.0.0:9001
auth_strategy = keystone
api_base_uri = http://controller:9001
enable_api_v2 = True
enabled_extensions_v2 = quotas, reports

[keystone_authtoken]
www_authenticate_uri = http://controller:5000
auth_url = http://controller:5000
memcached_servers = controller:11211
auth_type = password
project_domain_name = default
user_domain_name = default
project_name = service
username = heat
password = qwer1234


[service:worker]
enabled = True
notify = True

[storage:sqlalchemy]
connection = mysql+pymysql://heat:qwer1234@controller/heat

$ su -s /bin/sh -c &#34;designate-manage database sync&#34; designate
$ systemctl start designate-central designate-api
$ systemctl enable designate-central designate-api

$ vi /etc/designate/pools.yaml
# create new (replace hostname and IP address to your own environment)
- name: default
  description: Default Pool
  attributes: <span style="color:#75715e">{}</span>
  ns_records:
    - hostname: network.srv.world.
      priority: 1
  nameservers:
    - host: 10.10.10.20
      port: 53
  targets:
    - type: bind9
      description: BIND9 Server
      masters:
        - host: 10.10.10.20
          port: 5354
      options:
        host: 10.10.10.20
        port: 53
        rndc_host: 10.10.10.20
        rndc_port: 953
        rndc_key_file: /etc/designate.key

$ su -s /bin/sh -c &#34;designate-manage pool update&#34; designate
Updating Pools Configuration
$ systemctl start designate-worker designate-producer designate-mdns
$ systemctl enable designate-worker designate-producer designate-mdns
</code></pre></div><h1 id="heading-111"></h1>
<ul>
<li><strong>이어서 selinux와 방화벽을 설정합니다.</strong></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-tpl" data-lang="tpl">$ setsebool -P named_write_master_zones on
$ firewall-cmd --add-service=dns --permanent
$ firewall-cmd --add-port=<span style="color:#75715e">{</span><span style="color:#ae81ff">5354</span><span style="color:#f92672">/</span><span style="color:#a6e22e">tcp</span><span style="color:#f92672">,</span><span style="color:#ae81ff">9001</span><span style="color:#f92672">/</span><span style="color:#a6e22e">tcp</span><span style="color:#75715e">}</span> --permanent
$ firewall-cmd --reload

controller&gt; $openstack dns service list
# 확인
</code></pre></div><h1 id="heading-112"></h1>
<p> </p>
<h1 id="heading-113"></h1>
<p> </p>
<h1 id="heading-114"></h1>
<h3 id="11-openstack-대시보드-메인-로고-및-링크-변경"><strong>11. Openstack 대시보드 메인 로고 및 링크 변경</strong></h3>
<h1 id="heading-115"></h1>
<p> </p>
<h1 id="heading-116"></h1>
<h3 id="12-neutron-기반-service-functon-chaining--sfc--기능-구성"><strong>12. Neutron 기반 Service Functon Chaining ( SFC ) 기능 구성</strong></h3>
<h1 id="heading-117"></h1>
<p> 
#</p>
</article>
 
      
<div>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-1022327295984162"
     data-ad-slot="8742279271"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
</div>


      <footer class="book-footer">
        
  <div class="flex justify-between">





</div>

 
        
      </footer>

      
  
  <div class="book-comments">

</div>
  
 

      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

    
    <aside style="max-width: 14%;" class="book-toc">
      
  <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#1-시스템-및-네트워크-구성"><strong>1. 시스템 및 네트워크 구성</strong></a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li>
      <ul>
        <li><a href="#2-openstack-기본-패키지-구성"><strong>2. Openstack 기본 패키지 구성</strong></a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li>
      <ul>
        <li><a href="#3-keystone--인증-서비스--구성"><strong>3. Keystone ( 인증 서비스 ) 구성</strong></a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li>
      <ul>
        <li><a href="#4-glance--이미지-서비스--구성"><strong>4. Glance ( 이미지 서비스 ) 구성</strong></a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li>
      <ul>
        <li><a href="#5-nova--컴퓨트-서비스--구성"><strong>5. Nova ( 컴퓨트 서비스 ) 구성</strong></a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li>
      <ul>
        <li><a href="#6-neutron--네트워크-서비스--구성"><strong>6. Neutron ( 네트워크 서비스 ) 구성</strong></a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li>
      <ul>
        <li><a href="#7-horizon--대시보드-서비스--구성"><strong>7. Horizon ( 대시보드 서비스 ) 구성</strong></a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li>
      <ul>
        <li><a href="#8-cinder--오브젝트-스토리지-및-블록-스토리지-구성-"><strong>8. Cinder ( 오브젝트 스토리지 및 블록 스토리지 구성 )</strong></a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li>
      <ul>
        <li><a href="#8-2-lvm으로-블록-스토리지-백엔드-구성"><strong>8-2. LVM으로 블록 스토리지 백엔드 구성</strong></a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li>
      <ul>
        <li><a href="#8-3-lbaas-설치"><strong>8-3. LBaaS 설치</strong></a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li>
      <ul>
        <li><a href="#8-4-lfs-lvm-기반-다중-스토리지-노드-구성"><strong>8-4. LFS, LVM 기반 다중 스토리지 노드 구성</strong></a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li>
      <ul>
        <li><a href="#9-swift--오브젝트-스토리지-서비스--구성"><strong>9. Swift ( 오브젝트 스토리지 서비스 ) 구성</strong></a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li>
      <ul>
        <li><a href="#10-heat--orchestration--설치"><strong>10. Heat ( Orchestration ) 설치</strong></a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li>
      <ul>
        <li><a href="#11-openstack-대시보드-메인-로고-및-링크-변경"><strong>11. Openstack 대시보드 메인 로고 및 링크 변경</strong></a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li>
      <ul>
        <li><a href="#12-neutron-기반-service-functon-chaining--sfc--기능-구성"><strong>12. Neutron 기반 Service Functon Chaining ( SFC ) 기능 구성</strong></a></li>
      </ul>
    </li>
  </ul>
</nav>

 
    </aside>
    
  </main>

  
</body>
</div>
</html>















